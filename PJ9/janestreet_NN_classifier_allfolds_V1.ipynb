{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch classifier notebook\n",
    "\n",
    "V1 : only 1 split. First implementation  \n",
    "V2 : with all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "DATASET_INPUT_FILE = 'train.csv'\n",
    "\n",
    "FEATURES_LIST_TOTRAIN = ['feature_'+str(i) for i in range(130)]\n",
    "\n",
    "#pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deterministic Behavior\n",
    "seed = 42\n",
    "#os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "# Torch RNG\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "# Python RNG\n",
    "np.random.seed(seed)\n",
    "#random.seed(seed)\n",
    "# CuDA Determinism\n",
    "torch.backends.cudnn.deterministic = True\n",
    "#torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50000\n",
    "#BATCH_SIZE = 80000\n",
    "NUM_EPOCHS = 100\n",
    "MODEL_COMMENT = \"All folds, Less layers, dropout 0.3, shuffle=True, early stop on loss only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "\n",
    "# modified code for group gaps; source\n",
    "# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\n",
    "class PurgedGroupTimeSeriesSplit(_BaseKFold):\n",
    "    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n",
    "    Allows for a gap in groups to avoid potentially leaking info from\n",
    "    train into test if the model has windowed or lag features.\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals according to a\n",
    "    third-party provided group.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    The same group will not appear in two different folds (the number of\n",
    "    distinct groups has to be at least equal to the number of folds).\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of splits. Must be at least 2.\n",
    "    max_train_group_size : int, default=Inf\n",
    "        Maximum group size for a single training set.\n",
    "    group_gap : int, default=None\n",
    "        Gap between train and test\n",
    "    max_test_group_size : int, default=Inf\n",
    "        We discard this number of groups from the end of each train split\n",
    "    \"\"\"\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self,\n",
    "                 n_splits=5,\n",
    "                 *,\n",
    "                 max_train_group_size=np.inf,\n",
    "                 max_test_group_size=np.inf,\n",
    "                 group_gap=None,\n",
    "                 verbose=False\n",
    "                 ):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_group_size = max_train_group_size\n",
    "        self.group_gap = group_gap\n",
    "        self.max_test_group_size = max_test_group_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        group_gap = self.group_gap\n",
    "        max_test_group_size = self.max_test_group_size\n",
    "        max_train_group_size = self.max_train_group_size\n",
    "        n_folds = n_splits + 1\n",
    "        group_dict = {}\n",
    "        u, ind = np.unique(groups, return_index=True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_samples = _num_samples(X)\n",
    "        n_groups = _num_samples(unique_groups)\n",
    "        for idx in np.arange(n_samples):\n",
    "            if (groups[idx] in group_dict):\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "\n",
    "        group_test_size = min(n_groups // n_folds, max_test_group_size)\n",
    "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
    "                                  n_groups, group_test_size)\n",
    "        for group_test_start in group_test_starts:\n",
    "            train_array = []\n",
    "            test_array = []\n",
    "\n",
    "            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n",
    "            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n",
    "                train_array_tmp = group_dict[train_group_idx]\n",
    "                \n",
    "                train_array = np.sort(np.unique(\n",
    "                                      np.concatenate((train_array,\n",
    "                                                      train_array_tmp)),\n",
    "                                      axis=None), axis=None)\n",
    "\n",
    "            train_end = train_array.size\n",
    " \n",
    "            for test_group_idx in unique_groups[group_test_start:\n",
    "                                                group_test_start +\n",
    "                                                group_test_size]:\n",
    "                test_array_tmp = group_dict[test_group_idx]\n",
    "                test_array = np.sort(np.unique(\n",
    "                                              np.concatenate((test_array,\n",
    "                                                              test_array_tmp)),\n",
    "                                     axis=None), axis=None)\n",
    "\n",
    "            test_array  = test_array[group_gap:]\n",
    "            \n",
    "            \n",
    "            if self.verbose > 0:\n",
    "                    pass\n",
    "                    \n",
    "            yield [int(i) for i in train_array], [int(i) for i in test_array]\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "    \n",
    "# this is code slightly modified from the sklearn docs here:\n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py\n",
    "def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "    \n",
    "    cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "    jet = plt.cm.get_cmap('jet', 256)\n",
    "    seq = np.linspace(0, 1, 256)\n",
    "    _ = np.random.shuffle(seq)   # inplace\n",
    "    cmap_data = ListedColormap(jet(seq))\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                   c=indices, marker='_', lw=lw, cmap=cmap_cv,\n",
    "                   vmin=-.2, vmax=1.2)\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(range(len(X)), [ii + 1.5] * len(X),\n",
    "               c=y, marker='_', lw=lw, cmap=plt.cm.Set3)\n",
    "\n",
    "    ax.scatter(range(len(X)), [ii + 2.5] * len(X),\n",
    "               c=group, marker='_', lw=lw, cmap=cmap_data)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + ['target', 'day']\n",
    "    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Sample index', ylabel=\"CV iteration\",\n",
    "           ylim=[n_splits+2.2, -.2], xlim=[0, len(y)])\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function accounts for variable instance counts in each split by dividing utility_pi by number of instances (but this has been removed)\n",
    "# It also does some copy of dataframe to prevent memory overwrite\n",
    "def utility_function(df_test, df_test_predictions):\n",
    "    df_test_copy = df_test.copy(deep=True)\n",
    "    df_test_copy.loc[:, 'utility_pj'] = df_test_copy['weight'] * df_test_copy['resp'] * df_test_predictions\n",
    "    #df_test_utility_pi = df_test_copy.groupby('date')['utility_pj'].sum() / df_test_copy.groupby('date')['utility_pj'].count()\n",
    "    df_test_utility_pi = df_test_copy.groupby('date')['utility_pj'].sum()\n",
    "\n",
    "    nb_unique_dates = df_test_utility_pi.shape[0]\n",
    "    t = (df_test_utility_pi.sum() / np.sqrt(df_test_utility_pi.pow(2).sum())) * (np.sqrt(250 / np.abs(nb_unique_dates)))\n",
    "    u = min(max(t, 0), 6) * df_test_utility_pi.sum()\n",
    "    del df_test_copy\n",
    "    \n",
    "    return(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = PurgedGroupTimeSeriesSplit(\n",
    "    n_splits=5,\n",
    "    max_train_group_size=100,\n",
    "    group_gap=80,\n",
    "    max_test_group_size=60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "plot_cv_indices(cv, df.loc[:, FEATURES_LIST_TOTRAIN], (df['resp'] > 0), df['date'], \n",
    "                         ax, 5, lw=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.device"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 3090'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "    \n",
    "df = pd.read_csv(DATASET_INPUT_FILE)\n",
    "df['resp_positive'] = ((df['resp'])>0)*1  # Target to predict\n",
    "\n",
    "print('Data loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = PurgedGroupTimeSeriesSplit(\n",
    "    n_splits=5,\n",
    "    max_train_group_size=180,\n",
    "    group_gap=20,\n",
    "    max_test_group_size=60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_index, test_index = next(cv.split(df, (df['resp'] > 0)*1, df['date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(df.loc[train_index, 'resp'] > 0).astype(np.byte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mean = df.loc[:, FEATURES_LIST_TOTRAIN].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130,)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(f_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Sum of model parameters:')\n",
    "#[print(p.sum()) for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writer = SummaryWriter()\n",
    "\n",
    "#writer.add_text('test', 'test:'  + str(model).replace('\\n', '<BR>'))\n",
    "\n",
    "#writer.flush()\n",
    "#writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#str([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_list = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(cv.split(df, (df['resp'] > 0)*1, df['date'])):\n",
    "    folds_list.append((train_index, test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_list_train = [folds_list[i][0] for i in range(5)]\n",
    "folds_list_train_flat = [folds_list_train_item for sublist in folds_list_train for folds_list_train_item in sublist]\n",
    "folds_list_train_unique = list(set(folds_list_train_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1967466"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds_list_train_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4011251"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([len(folds_list_train_item) for folds_list_train_item in folds_list_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4011251"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds_list_train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_list_test = [folds_list[i][1] for i in range(5)]\n",
    "folds_list_test_flat = [folds_list_test_item for sublist in folds_list_test for folds_list_test_item in sublist]\n",
    "folds_list_test_unique = set(folds_list_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1429335"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([len(folds_list_test_item) for folds_list_test_item in folds_list_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1429335"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds_list_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5440586"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds_list_train_flat) + len(folds_list_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(323071, 130)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[folds_list_test[4], FEATURES_LIST_TOTRAIN].to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters :\n",
      "Epoch(0) - Training Loss: 0.6930\n",
      "Epoch(0) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(0) - Fold 0 - Validation Accuracy : 0.5164\n",
      "Epoch(0) - Fold 0 - Validation Utility score : 230.1245\n",
      "Epoch(0) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(0) - Fold 1 - Validation Accuracy : 0.5156\n",
      "Epoch(0) - Fold 1 - Validation Utility score : 293.6322\n",
      "Epoch(0) - Fold 2 - Validation Loss : 0.6923\n",
      "Epoch(0) - Fold 2 - Validation Accuracy : 0.5161\n",
      "Epoch(0) - Fold 2 - Validation Utility score : 552.3524\n",
      "Epoch(0) - Fold 3 - Validation Loss : 0.6926\n",
      "Epoch(0) - Fold 3 - Validation Accuracy : 0.5131\n",
      "Epoch(0) - Fold 3 - Validation Utility score : 204.3031\n",
      "Epoch(0) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(0) - Fold 4 - Validation Accuracy : 0.5185\n",
      "Epoch(0) - Fold 4 - Validation Utility score : 2044.7116\n",
      "Epoch(0) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(0) - GLOBAL - Validation Accuracy: 0.5159\n",
      "Epoch(0) - GLOBAL - Validation Utility score: 3325.1239\n",
      "Saving model corresponding to last_utility_score == 3325.123854034515\n",
      "\n",
      "\n",
      "Epoch(1) - Training Loss: 0.6917\n",
      "Epoch(1) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(1) - Fold 0 - Validation Accuracy : 0.5188\n",
      "Epoch(1) - Fold 0 - Validation Utility score : 215.1545\n",
      "Epoch(1) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(1) - Fold 1 - Validation Accuracy : 0.5184\n",
      "Epoch(1) - Fold 1 - Validation Utility score : 496.1441\n",
      "Epoch(1) - Fold 2 - Validation Loss : 0.6918\n",
      "Epoch(1) - Fold 2 - Validation Accuracy : 0.5195\n",
      "Epoch(1) - Fold 2 - Validation Utility score : 632.6441\n",
      "Epoch(1) - Fold 3 - Validation Loss : 0.6926\n",
      "Epoch(1) - Fold 3 - Validation Accuracy : 0.5133\n",
      "Epoch(1) - Fold 3 - Validation Utility score : 142.2181\n",
      "Epoch(1) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(1) - Fold 4 - Validation Accuracy : 0.5205\n",
      "Epoch(1) - Fold 4 - Validation Utility score : 2285.7046\n",
      "Epoch(1) - GLOBAL - Validation Loss: 0.6918\n",
      "Epoch(1) - GLOBAL - Validation Accuracy: 0.5181\n",
      "Epoch(1) - GLOBAL - Validation Utility score: 3771.8653\n",
      "Saving model corresponding to last_utility_score == 3771.8653406927756\n",
      "\n",
      "\n",
      "Epoch(2) - Training Loss: 0.6913\n",
      "Epoch(2) - Fold 0 - Validation Loss : 0.6912\n",
      "Epoch(2) - Fold 0 - Validation Accuracy : 0.5209\n",
      "Epoch(2) - Fold 0 - Validation Utility score : 234.3834\n",
      "Epoch(2) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(2) - Fold 1 - Validation Accuracy : 0.5206\n",
      "Epoch(2) - Fold 1 - Validation Utility score : 487.6759\n",
      "Epoch(2) - Fold 2 - Validation Loss : 0.6914\n",
      "Epoch(2) - Fold 2 - Validation Accuracy : 0.5230\n",
      "Epoch(2) - Fold 2 - Validation Utility score : 943.8484\n",
      "Epoch(2) - Fold 3 - Validation Loss : 0.6924\n",
      "Epoch(2) - Fold 3 - Validation Accuracy : 0.5145\n",
      "Epoch(2) - Fold 3 - Validation Utility score : 162.5253\n",
      "Epoch(2) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(2) - Fold 4 - Validation Accuracy : 0.5219\n",
      "Epoch(2) - Fold 4 - Validation Utility score : 2739.2014\n",
      "Epoch(2) - GLOBAL - Validation Loss: 0.6916\n",
      "Epoch(2) - GLOBAL - Validation Accuracy: 0.5202\n",
      "Epoch(2) - GLOBAL - Validation Utility score: 4567.6343\n",
      "Saving model corresponding to last_utility_score == 4567.634331082541\n",
      "\n",
      "\n",
      "Epoch(3) - Training Loss: 0.6910\n",
      "Epoch(3) - Fold 0 - Validation Loss : 0.6911\n",
      "Epoch(3) - Fold 0 - Validation Accuracy : 0.5219\n",
      "Epoch(3) - Fold 0 - Validation Utility score : 818.0775\n",
      "Epoch(3) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(3) - Fold 1 - Validation Accuracy : 0.5219\n",
      "Epoch(3) - Fold 1 - Validation Utility score : 721.6996\n",
      "Epoch(3) - Fold 2 - Validation Loss : 0.6914\n",
      "Epoch(3) - Fold 2 - Validation Accuracy : 0.5224\n",
      "Epoch(3) - Fold 2 - Validation Utility score : 1269.0284\n",
      "Epoch(3) - Fold 3 - Validation Loss : 0.6922\n",
      "Epoch(3) - Fold 3 - Validation Accuracy : 0.5147\n",
      "Epoch(3) - Fold 3 - Validation Utility score : 209.1603\n",
      "Epoch(3) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(3) - Fold 4 - Validation Accuracy : 0.5218\n",
      "Epoch(3) - Fold 4 - Validation Utility score : 2422.5437\n",
      "Epoch(3) - GLOBAL - Validation Loss: 0.6915\n",
      "Epoch(3) - GLOBAL - Validation Accuracy: 0.5205\n",
      "Epoch(3) - GLOBAL - Validation Utility score: 5440.5096\n",
      "Saving model corresponding to last_utility_score == 5440.509588285215\n",
      "\n",
      "\n",
      "Epoch(4) - Training Loss: 0.6907\n",
      "Epoch(4) - Fold 0 - Validation Loss : 0.6910\n",
      "Epoch(4) - Fold 0 - Validation Accuracy : 0.5236\n",
      "Epoch(4) - Fold 0 - Validation Utility score : 703.8234\n",
      "Epoch(4) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(4) - Fold 1 - Validation Accuracy : 0.5237\n",
      "Epoch(4) - Fold 1 - Validation Utility score : 820.4145\n",
      "Epoch(4) - Fold 2 - Validation Loss : 0.6912\n",
      "Epoch(4) - Fold 2 - Validation Accuracy : 0.5234\n",
      "Epoch(4) - Fold 2 - Validation Utility score : 1210.7269\n",
      "Epoch(4) - Fold 3 - Validation Loss : 0.6921\n",
      "Epoch(4) - Fold 3 - Validation Accuracy : 0.5157\n",
      "Epoch(4) - Fold 3 - Validation Utility score : 350.7913\n",
      "Epoch(4) - Fold 4 - Validation Loss : 0.6912\n",
      "Epoch(4) - Fold 4 - Validation Accuracy : 0.5234\n",
      "Epoch(4) - Fold 4 - Validation Utility score : 2637.6250\n",
      "Epoch(4) - GLOBAL - Validation Loss: 0.6913\n",
      "Epoch(4) - GLOBAL - Validation Accuracy: 0.5220\n",
      "Epoch(4) - GLOBAL - Validation Utility score: 5723.3811\n",
      "Saving model corresponding to last_utility_score == 5723.381064264493\n",
      "\n",
      "\n",
      "Epoch(5) - Training Loss: 0.6906\n",
      "Epoch(5) - Fold 0 - Validation Loss : 0.6906\n",
      "Epoch(5) - Fold 0 - Validation Accuracy : 0.5238\n",
      "Epoch(5) - Fold 0 - Validation Utility score : 851.6098\n",
      "Epoch(5) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(5) - Fold 1 - Validation Accuracy : 0.5244\n",
      "Epoch(5) - Fold 1 - Validation Utility score : 799.9265\n",
      "Epoch(5) - Fold 2 - Validation Loss : 0.6909\n",
      "Epoch(5) - Fold 2 - Validation Accuracy : 0.5246\n",
      "Epoch(5) - Fold 2 - Validation Utility score : 1395.2339\n",
      "Epoch(5) - Fold 3 - Validation Loss : 0.6920\n",
      "Epoch(5) - Fold 3 - Validation Accuracy : 0.5167\n",
      "Epoch(5) - Fold 3 - Validation Utility score : 262.9585\n",
      "Epoch(5) - Fold 4 - Validation Loss : 0.6911\n",
      "Epoch(5) - Fold 4 - Validation Accuracy : 0.5231\n",
      "Epoch(5) - Fold 4 - Validation Utility score : 2612.6343\n",
      "Epoch(5) - GLOBAL - Validation Loss: 0.6911\n",
      "Epoch(5) - GLOBAL - Validation Accuracy: 0.5225\n",
      "Epoch(5) - GLOBAL - Validation Utility score: 5922.3630\n",
      "Saving model corresponding to last_utility_score == 5922.362969177229\n",
      "\n",
      "\n",
      "Epoch(6) - Training Loss: 0.6903\n",
      "Epoch(6) - Fold 0 - Validation Loss : 0.6904\n",
      "Epoch(6) - Fold 0 - Validation Accuracy : 0.5259\n",
      "Epoch(6) - Fold 0 - Validation Utility score : 1032.9866\n",
      "Epoch(6) - Fold 1 - Validation Loss : 0.6909\n",
      "Epoch(6) - Fold 1 - Validation Accuracy : 0.5246\n",
      "Epoch(6) - Fold 1 - Validation Utility score : 677.2352\n",
      "Epoch(6) - Fold 2 - Validation Loss : 0.6908\n",
      "Epoch(6) - Fold 2 - Validation Accuracy : 0.5236\n",
      "Epoch(6) - Fold 2 - Validation Utility score : 1362.3111\n",
      "Epoch(6) - Fold 3 - Validation Loss : 0.6920\n",
      "Epoch(6) - Fold 3 - Validation Accuracy : 0.5163\n",
      "Epoch(6) - Fold 3 - Validation Utility score : 215.6724\n",
      "Epoch(6) - Fold 4 - Validation Loss : 0.6912\n",
      "Epoch(6) - Fold 4 - Validation Accuracy : 0.5216\n",
      "Epoch(6) - Fold 4 - Validation Utility score : 2269.7328\n",
      "Epoch(6) - GLOBAL - Validation Loss: 0.6911\n",
      "Epoch(6) - GLOBAL - Validation Accuracy: 0.5224\n",
      "Epoch(6) - GLOBAL - Validation Utility score: 5557.9382\n",
      "Saving model corresponding to last_utility_score == 5557.9381740910585\n",
      "\n",
      "\n",
      "Epoch(7) - Training Loss: 0.6901\n",
      "Epoch(7) - Fold 0 - Validation Loss : 0.6902\n",
      "Epoch(7) - Fold 0 - Validation Accuracy : 0.5268\n",
      "Epoch(7) - Fold 0 - Validation Utility score : 1250.1379\n",
      "Epoch(7) - Fold 1 - Validation Loss : 0.6907\n",
      "Epoch(7) - Fold 1 - Validation Accuracy : 0.5252\n",
      "Epoch(7) - Fold 1 - Validation Utility score : 914.4342\n",
      "Epoch(7) - Fold 2 - Validation Loss : 0.6906\n",
      "Epoch(7) - Fold 2 - Validation Accuracy : 0.5257\n",
      "Epoch(7) - Fold 2 - Validation Utility score : 1434.9087\n",
      "Epoch(7) - Fold 3 - Validation Loss : 0.6917\n",
      "Epoch(7) - Fold 3 - Validation Accuracy : 0.5183\n",
      "Epoch(7) - Fold 3 - Validation Utility score : 340.6895\n",
      "Epoch(7) - Fold 4 - Validation Loss : 0.6912\n",
      "Epoch(7) - Fold 4 - Validation Accuracy : 0.5217\n",
      "Epoch(7) - Fold 4 - Validation Utility score : 2398.8726\n",
      "Epoch(7) - GLOBAL - Validation Loss: 0.6909\n",
      "Epoch(7) - GLOBAL - Validation Accuracy: 0.5235\n",
      "Epoch(7) - GLOBAL - Validation Utility score: 6339.0429\n",
      "Saving model corresponding to last_utility_score == 6339.042934104148\n",
      "\n",
      "\n",
      "Epoch(8) - Training Loss: 0.6898\n",
      "Epoch(8) - Fold 0 - Validation Loss : 0.6900\n",
      "Epoch(8) - Fold 0 - Validation Accuracy : 0.5273\n",
      "Epoch(8) - Fold 0 - Validation Utility score : 1116.0631\n",
      "Epoch(8) - Fold 1 - Validation Loss : 0.6902\n",
      "Epoch(8) - Fold 1 - Validation Accuracy : 0.5262\n",
      "Epoch(8) - Fold 1 - Validation Utility score : 895.4033\n",
      "Epoch(8) - Fold 2 - Validation Loss : 0.6904\n",
      "Epoch(8) - Fold 2 - Validation Accuracy : 0.5260\n",
      "Epoch(8) - Fold 2 - Validation Utility score : 1615.1999\n",
      "Epoch(8) - Fold 3 - Validation Loss : 0.6918\n",
      "Epoch(8) - Fold 3 - Validation Accuracy : 0.5177\n",
      "Epoch(8) - Fold 3 - Validation Utility score : 278.0612\n",
      "Epoch(8) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(8) - Fold 4 - Validation Accuracy : 0.5222\n",
      "Epoch(8) - Fold 4 - Validation Utility score : 2434.6322\n",
      "Epoch(8) - GLOBAL - Validation Loss: 0.6907\n",
      "Epoch(8) - GLOBAL - Validation Accuracy: 0.5239\n",
      "Epoch(8) - GLOBAL - Validation Utility score: 6339.3597\n",
      "Saving model corresponding to last_utility_score == 6339.359688561437\n",
      "\n",
      "\n",
      "Epoch(9) - Training Loss: 0.6895\n",
      "Epoch(9) - Fold 0 - Validation Loss : 0.6897\n",
      "Epoch(9) - Fold 0 - Validation Accuracy : 0.5271\n",
      "Epoch(9) - Fold 0 - Validation Utility score : 1257.8609\n",
      "Epoch(9) - Fold 1 - Validation Loss : 0.6902\n",
      "Epoch(9) - Fold 1 - Validation Accuracy : 0.5261\n",
      "Epoch(9) - Fold 1 - Validation Utility score : 1046.3097\n",
      "Epoch(9) - Fold 2 - Validation Loss : 0.6903\n",
      "Epoch(9) - Fold 2 - Validation Accuracy : 0.5261\n",
      "Epoch(9) - Fold 2 - Validation Utility score : 1705.2839\n",
      "Epoch(9) - Fold 3 - Validation Loss : 0.6915\n",
      "Epoch(9) - Fold 3 - Validation Accuracy : 0.5183\n",
      "Epoch(9) - Fold 3 - Validation Utility score : 302.1390\n",
      "Epoch(9) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(9) - Fold 4 - Validation Accuracy : 0.5219\n",
      "Epoch(9) - Fold 4 - Validation Utility score : 2341.0286\n",
      "Epoch(9) - GLOBAL - Validation Loss: 0.6906\n",
      "Epoch(9) - GLOBAL - Validation Accuracy: 0.5239\n",
      "Epoch(9) - GLOBAL - Validation Utility score: 6652.6221\n",
      "Saving model corresponding to last_utility_score == 6652.622080453408\n",
      "\n",
      "\n",
      "Epoch(10) - Training Loss: 0.6893\n",
      "Epoch(10) - Fold 0 - Validation Loss : 0.6894\n",
      "Epoch(10) - Fold 0 - Validation Accuracy : 0.5281\n",
      "Epoch(10) - Fold 0 - Validation Utility score : 1273.3117\n",
      "Epoch(10) - Fold 1 - Validation Loss : 0.6896\n",
      "Epoch(10) - Fold 1 - Validation Accuracy : 0.5268\n",
      "Epoch(10) - Fold 1 - Validation Utility score : 1092.4739\n",
      "Epoch(10) - Fold 2 - Validation Loss : 0.6901\n",
      "Epoch(10) - Fold 2 - Validation Accuracy : 0.5271\n",
      "Epoch(10) - Fold 2 - Validation Utility score : 1638.6127\n",
      "Epoch(10) - Fold 3 - Validation Loss : 0.6916\n",
      "Epoch(10) - Fold 3 - Validation Accuracy : 0.5183\n",
      "Epoch(10) - Fold 3 - Validation Utility score : 402.8446\n",
      "Epoch(10) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(10) - Fold 4 - Validation Accuracy : 0.5214\n",
      "Epoch(10) - Fold 4 - Validation Utility score : 2363.4084\n",
      "Epoch(10) - GLOBAL - Validation Loss: 0.6904\n",
      "Epoch(10) - GLOBAL - Validation Accuracy: 0.5243\n",
      "Epoch(10) - GLOBAL - Validation Utility score: 6770.6512\n",
      "Saving model corresponding to last_utility_score == 6770.651246923297\n",
      "\n",
      "\n",
      "Epoch(11) - Training Loss: 0.6890\n",
      "Epoch(11) - Fold 0 - Validation Loss : 0.6890\n",
      "Epoch(11) - Fold 0 - Validation Accuracy : 0.5286\n",
      "Epoch(11) - Fold 0 - Validation Utility score : 1169.7159\n",
      "Epoch(11) - Fold 1 - Validation Loss : 0.6893\n",
      "Epoch(11) - Fold 1 - Validation Accuracy : 0.5285\n",
      "Epoch(11) - Fold 1 - Validation Utility score : 929.9352\n",
      "Epoch(11) - Fold 2 - Validation Loss : 0.6898\n",
      "Epoch(11) - Fold 2 - Validation Accuracy : 0.5291\n",
      "Epoch(11) - Fold 2 - Validation Utility score : 1565.8379\n",
      "Epoch(11) - Fold 3 - Validation Loss : 0.6914\n",
      "Epoch(11) - Fold 3 - Validation Accuracy : 0.5193\n",
      "Epoch(11) - Fold 3 - Validation Utility score : 546.1664\n",
      "Epoch(11) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(11) - Fold 4 - Validation Accuracy : 0.5220\n",
      "Epoch(11) - Fold 4 - Validation Utility score : 2313.6465\n",
      "Epoch(11) - GLOBAL - Validation Loss: 0.6902\n",
      "Epoch(11) - GLOBAL - Validation Accuracy: 0.5255\n",
      "Epoch(11) - GLOBAL - Validation Utility score: 6525.3019\n",
      "Saving model corresponding to last_utility_score == 6525.30192476535\n",
      "\n",
      "\n",
      "Epoch(12) - Training Loss: 0.6887\n",
      "Epoch(12) - Fold 0 - Validation Loss : 0.6889\n",
      "Epoch(12) - Fold 0 - Validation Accuracy : 0.5296\n",
      "Epoch(12) - Fold 0 - Validation Utility score : 1793.9820\n",
      "Epoch(12) - Fold 1 - Validation Loss : 0.6890\n",
      "Epoch(12) - Fold 1 - Validation Accuracy : 0.5288\n",
      "Epoch(12) - Fold 1 - Validation Utility score : 1042.3452\n",
      "Epoch(12) - Fold 2 - Validation Loss : 0.6898\n",
      "Epoch(12) - Fold 2 - Validation Accuracy : 0.5294\n",
      "Epoch(12) - Fold 2 - Validation Utility score : 1983.8406\n",
      "Epoch(12) - Fold 3 - Validation Loss : 0.6912\n",
      "Epoch(12) - Fold 3 - Validation Accuracy : 0.5207\n",
      "Epoch(12) - Fold 3 - Validation Utility score : 640.3276\n",
      "Epoch(12) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(12) - Fold 4 - Validation Accuracy : 0.5218\n",
      "Epoch(12) - Fold 4 - Validation Utility score : 2488.8318\n",
      "Epoch(12) - GLOBAL - Validation Loss: 0.6901\n",
      "Epoch(12) - GLOBAL - Validation Accuracy: 0.5261\n",
      "Epoch(12) - GLOBAL - Validation Utility score: 7949.3273\n",
      "Saving model corresponding to last_utility_score == 7949.327265097707\n",
      "\n",
      "\n",
      "Epoch(13) - Training Loss: 0.6885\n",
      "Epoch(13) - Fold 0 - Validation Loss : 0.6886\n",
      "Epoch(13) - Fold 0 - Validation Accuracy : 0.5296\n",
      "Epoch(13) - Fold 0 - Validation Utility score : 1608.4608\n",
      "Epoch(13) - Fold 1 - Validation Loss : 0.6885\n",
      "Epoch(13) - Fold 1 - Validation Accuracy : 0.5296\n",
      "Epoch(13) - Fold 1 - Validation Utility score : 1188.8177\n",
      "Epoch(13) - Fold 2 - Validation Loss : 0.6896\n",
      "Epoch(13) - Fold 2 - Validation Accuracy : 0.5291\n",
      "Epoch(13) - Fold 2 - Validation Utility score : 1854.9025\n",
      "Epoch(13) - Fold 3 - Validation Loss : 0.6912\n",
      "Epoch(13) - Fold 3 - Validation Accuracy : 0.5206\n",
      "Epoch(13) - Fold 3 - Validation Utility score : 710.8038\n",
      "Epoch(13) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(13) - Fold 4 - Validation Accuracy : 0.5209\n",
      "Epoch(13) - Fold 4 - Validation Utility score : 2553.1694\n",
      "Epoch(13) - GLOBAL - Validation Loss: 0.6899\n",
      "Epoch(13) - GLOBAL - Validation Accuracy: 0.5260\n",
      "Epoch(13) - GLOBAL - Validation Utility score: 7916.1543\n",
      "Saving model corresponding to last_utility_score == 7916.154262898267\n",
      "\n",
      "\n",
      "Epoch(14) - Training Loss: 0.6881\n",
      "Epoch(14) - Fold 0 - Validation Loss : 0.6884\n",
      "Epoch(14) - Fold 0 - Validation Accuracy : 0.5294\n",
      "Epoch(14) - Fold 0 - Validation Utility score : 1530.7074\n",
      "Epoch(14) - Fold 1 - Validation Loss : 0.6882\n",
      "Epoch(14) - Fold 1 - Validation Accuracy : 0.5302\n",
      "Epoch(14) - Fold 1 - Validation Utility score : 1452.4623\n",
      "Epoch(14) - Fold 2 - Validation Loss : 0.6895\n",
      "Epoch(14) - Fold 2 - Validation Accuracy : 0.5288\n",
      "Epoch(14) - Fold 2 - Validation Utility score : 1725.4045\n",
      "Epoch(14) - Fold 3 - Validation Loss : 0.6910\n",
      "Epoch(14) - Fold 3 - Validation Accuracy : 0.5202\n",
      "Epoch(14) - Fold 3 - Validation Utility score : 617.4778\n",
      "Epoch(14) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(14) - Fold 4 - Validation Accuracy : 0.5207\n",
      "Epoch(14) - Fold 4 - Validation Utility score : 2582.5582\n",
      "Epoch(14) - GLOBAL - Validation Loss: 0.6898\n",
      "Epoch(14) - GLOBAL - Validation Accuracy: 0.5259\n",
      "Epoch(14) - GLOBAL - Validation Utility score: 7908.6101\n",
      "Saving model corresponding to last_utility_score == 7908.610137109995\n",
      "\n",
      "\n",
      "Epoch(15) - Training Loss: 0.6879\n",
      "Epoch(15) - Fold 0 - Validation Loss : 0.6882\n",
      "Epoch(15) - Fold 0 - Validation Accuracy : 0.5295\n",
      "Epoch(15) - Fold 0 - Validation Utility score : 1257.0801\n",
      "Epoch(15) - Fold 1 - Validation Loss : 0.6876\n",
      "Epoch(15) - Fold 1 - Validation Accuracy : 0.5299\n",
      "Epoch(15) - Fold 1 - Validation Utility score : 1287.8324\n",
      "Epoch(15) - Fold 2 - Validation Loss : 0.6893\n",
      "Epoch(15) - Fold 2 - Validation Accuracy : 0.5309\n",
      "Epoch(15) - Fold 2 - Validation Utility score : 1979.2942\n",
      "Epoch(15) - Fold 3 - Validation Loss : 0.6910\n",
      "Epoch(15) - Fold 3 - Validation Accuracy : 0.5211\n",
      "Epoch(15) - Fold 3 - Validation Utility score : 713.3679\n",
      "Epoch(15) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(15) - Fold 4 - Validation Accuracy : 0.5212\n",
      "Epoch(15) - Fold 4 - Validation Utility score : 2579.8690\n",
      "Epoch(15) - GLOBAL - Validation Loss: 0.6896\n",
      "Epoch(15) - GLOBAL - Validation Accuracy: 0.5265\n",
      "Epoch(15) - GLOBAL - Validation Utility score: 7817.4437\n",
      "Saving model corresponding to last_utility_score == 7817.443652838124\n",
      "\n",
      "\n",
      "Epoch(16) - Training Loss: 0.6876\n",
      "Epoch(16) - Fold 0 - Validation Loss : 0.6878\n",
      "Epoch(16) - Fold 0 - Validation Accuracy : 0.5315\n",
      "Epoch(16) - Fold 0 - Validation Utility score : 1684.9984\n",
      "Epoch(16) - Fold 1 - Validation Loss : 0.6871\n",
      "Epoch(16) - Fold 1 - Validation Accuracy : 0.5328\n",
      "Epoch(16) - Fold 1 - Validation Utility score : 1227.8182\n",
      "Epoch(16) - Fold 2 - Validation Loss : 0.6888\n",
      "Epoch(16) - Fold 2 - Validation Accuracy : 0.5319\n",
      "Epoch(16) - Fold 2 - Validation Utility score : 1918.2465\n",
      "Epoch(16) - Fold 3 - Validation Loss : 0.6906\n",
      "Epoch(16) - Fold 3 - Validation Accuracy : 0.5207\n",
      "Epoch(16) - Fold 3 - Validation Utility score : 555.4329\n",
      "Epoch(16) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(16) - Fold 4 - Validation Accuracy : 0.5210\n",
      "Epoch(16) - Fold 4 - Validation Utility score : 2440.9272\n",
      "Epoch(16) - GLOBAL - Validation Loss: 0.6892\n",
      "Epoch(16) - GLOBAL - Validation Accuracy: 0.5276\n",
      "Epoch(16) - GLOBAL - Validation Utility score: 7827.4232\n",
      "Saving model corresponding to last_utility_score == 7827.423199951217\n",
      "\n",
      "\n",
      "Epoch(17) - Training Loss: 0.6873\n",
      "Epoch(17) - Fold 0 - Validation Loss : 0.6876\n",
      "Epoch(17) - Fold 0 - Validation Accuracy : 0.5318\n",
      "Epoch(17) - Fold 0 - Validation Utility score : 1525.4384\n",
      "Epoch(17) - Fold 1 - Validation Loss : 0.6868\n",
      "Epoch(17) - Fold 1 - Validation Accuracy : 0.5325\n",
      "Epoch(17) - Fold 1 - Validation Utility score : 1414.4346\n",
      "Epoch(17) - Fold 2 - Validation Loss : 0.6887\n",
      "Epoch(17) - Fold 2 - Validation Accuracy : 0.5323\n",
      "Epoch(17) - Fold 2 - Validation Utility score : 1788.2538\n",
      "Epoch(17) - Fold 3 - Validation Loss : 0.6911\n",
      "Epoch(17) - Fold 3 - Validation Accuracy : 0.5200\n",
      "Epoch(17) - Fold 3 - Validation Utility score : 477.7435\n",
      "Epoch(17) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(17) - Fold 4 - Validation Accuracy : 0.5203\n",
      "Epoch(17) - Fold 4 - Validation Utility score : 2341.2437\n",
      "Epoch(17) - GLOBAL - Validation Loss: 0.6892\n",
      "Epoch(17) - GLOBAL - Validation Accuracy: 0.5274\n",
      "Epoch(17) - GLOBAL - Validation Utility score: 7547.1139\n",
      "Intermediate early stopping : vepoch_loss = 0.6892, the_last_loss=0.6892\n",
      "\n",
      "\n",
      "Epoch(18) - Training Loss: 0.6870\n",
      "Epoch(18) - Fold 0 - Validation Loss : 0.6875\n",
      "Epoch(18) - Fold 0 - Validation Accuracy : 0.5316\n",
      "Epoch(18) - Fold 0 - Validation Utility score : 2127.3879\n",
      "Epoch(18) - Fold 1 - Validation Loss : 0.6865\n",
      "Epoch(18) - Fold 1 - Validation Accuracy : 0.5329\n",
      "Epoch(18) - Fold 1 - Validation Utility score : 1721.3019\n",
      "Epoch(18) - Fold 2 - Validation Loss : 0.6889\n",
      "Epoch(18) - Fold 2 - Validation Accuracy : 0.5314\n",
      "Epoch(18) - Fold 2 - Validation Utility score : 2057.5311\n",
      "Epoch(18) - Fold 3 - Validation Loss : 0.6908\n",
      "Epoch(18) - Fold 3 - Validation Accuracy : 0.5202\n",
      "Epoch(18) - Fold 3 - Validation Utility score : 673.6276\n",
      "Epoch(18) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(18) - Fold 4 - Validation Accuracy : 0.5198\n",
      "Epoch(18) - Fold 4 - Validation Utility score : 2377.6864\n",
      "Epoch(18) - GLOBAL - Validation Loss: 0.6892\n",
      "Epoch(18) - GLOBAL - Validation Accuracy: 0.5272\n",
      "Epoch(18) - GLOBAL - Validation Utility score: 8957.5349\n",
      "Saving model corresponding to last_utility_score == 8957.534880585366\n",
      "\n",
      "\n",
      "Epoch(19) - Training Loss: 0.6869\n",
      "Epoch(19) - Fold 0 - Validation Loss : 0.6872\n",
      "Epoch(19) - Fold 0 - Validation Accuracy : 0.5333\n",
      "Epoch(19) - Fold 0 - Validation Utility score : 1858.4379\n",
      "Epoch(19) - Fold 1 - Validation Loss : 0.6862\n",
      "Epoch(19) - Fold 1 - Validation Accuracy : 0.5341\n",
      "Epoch(19) - Fold 1 - Validation Utility score : 1752.3369\n",
      "Epoch(19) - Fold 2 - Validation Loss : 0.6885\n",
      "Epoch(19) - Fold 2 - Validation Accuracy : 0.5325\n",
      "Epoch(19) - Fold 2 - Validation Utility score : 1996.3948\n",
      "Epoch(19) - Fold 3 - Validation Loss : 0.6907\n",
      "Epoch(19) - Fold 3 - Validation Accuracy : 0.5207\n",
      "Epoch(19) - Fold 3 - Validation Utility score : 512.3898\n",
      "Epoch(19) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(19) - Fold 4 - Validation Accuracy : 0.5195\n",
      "Epoch(19) - Fold 4 - Validation Utility score : 2369.5951\n",
      "Epoch(19) - GLOBAL - Validation Loss: 0.6890\n",
      "Epoch(19) - GLOBAL - Validation Accuracy: 0.5280\n",
      "Epoch(19) - GLOBAL - Validation Utility score: 8489.1544\n",
      "Saving model corresponding to last_utility_score == 8489.154441572897\n",
      "\n",
      "\n",
      "Epoch(20) - Training Loss: 0.6866\n",
      "Epoch(20) - Fold 0 - Validation Loss : 0.6872\n",
      "Epoch(20) - Fold 0 - Validation Accuracy : 0.5331\n",
      "Epoch(20) - Fold 0 - Validation Utility score : 2181.7746\n",
      "Epoch(20) - Fold 1 - Validation Loss : 0.6859\n",
      "Epoch(20) - Fold 1 - Validation Accuracy : 0.5343\n",
      "Epoch(20) - Fold 1 - Validation Utility score : 1750.9929\n",
      "Epoch(20) - Fold 2 - Validation Loss : 0.6883\n",
      "Epoch(20) - Fold 2 - Validation Accuracy : 0.5332\n",
      "Epoch(20) - Fold 2 - Validation Utility score : 1930.4864\n",
      "Epoch(20) - Fold 3 - Validation Loss : 0.6905\n",
      "Epoch(20) - Fold 3 - Validation Accuracy : 0.5207\n",
      "Epoch(20) - Fold 3 - Validation Utility score : 550.8208\n",
      "Epoch(20) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(20) - Fold 4 - Validation Accuracy : 0.5200\n",
      "Epoch(20) - Fold 4 - Validation Utility score : 2372.7575\n",
      "Epoch(20) - GLOBAL - Validation Loss: 0.6888\n",
      "Epoch(20) - GLOBAL - Validation Accuracy: 0.5283\n",
      "Epoch(20) - GLOBAL - Validation Utility score: 8786.8322\n",
      "Saving model corresponding to last_utility_score == 8786.83224015967\n",
      "\n",
      "\n",
      "Epoch(21) - Training Loss: 0.6864\n",
      "Epoch(21) - Fold 0 - Validation Loss : 0.6872\n",
      "Epoch(21) - Fold 0 - Validation Accuracy : 0.5324\n",
      "Epoch(21) - Fold 0 - Validation Utility score : 1922.2894\n",
      "Epoch(21) - Fold 1 - Validation Loss : 0.6858\n",
      "Epoch(21) - Fold 1 - Validation Accuracy : 0.5343\n",
      "Epoch(21) - Fold 1 - Validation Utility score : 1705.4263\n",
      "Epoch(21) - Fold 2 - Validation Loss : 0.6883\n",
      "Epoch(21) - Fold 2 - Validation Accuracy : 0.5330\n",
      "Epoch(21) - Fold 2 - Validation Utility score : 1868.7902\n",
      "Epoch(21) - Fold 3 - Validation Loss : 0.6905\n",
      "Epoch(21) - Fold 3 - Validation Accuracy : 0.5212\n",
      "Epoch(21) - Fold 3 - Validation Utility score : 612.0387\n",
      "Epoch(21) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(21) - Fold 4 - Validation Accuracy : 0.5202\n",
      "Epoch(21) - Fold 4 - Validation Utility score : 2414.4104\n",
      "Epoch(21) - GLOBAL - Validation Loss: 0.6888\n",
      "Epoch(21) - GLOBAL - Validation Accuracy: 0.5282\n",
      "Epoch(21) - GLOBAL - Validation Utility score: 8522.9550\n",
      "Intermediate early stopping : vepoch_loss = 0.6888, the_last_loss=0.6888\n",
      "\n",
      "\n",
      "Epoch(22) - Training Loss: 0.6861\n",
      "Epoch(22) - Fold 0 - Validation Loss : 0.6870\n",
      "Epoch(22) - Fold 0 - Validation Accuracy : 0.5326\n",
      "Epoch(22) - Fold 0 - Validation Utility score : 1887.3575\n",
      "Epoch(22) - Fold 1 - Validation Loss : 0.6854\n",
      "Epoch(22) - Fold 1 - Validation Accuracy : 0.5346\n",
      "Epoch(22) - Fold 1 - Validation Utility score : 1567.4546\n",
      "Epoch(22) - Fold 2 - Validation Loss : 0.6882\n",
      "Epoch(22) - Fold 2 - Validation Accuracy : 0.5334\n",
      "Epoch(22) - Fold 2 - Validation Utility score : 1942.6094\n",
      "Epoch(22) - Fold 3 - Validation Loss : 0.6902\n",
      "Epoch(22) - Fold 3 - Validation Accuracy : 0.5210\n",
      "Epoch(22) - Fold 3 - Validation Utility score : 569.4043\n",
      "Epoch(22) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(22) - Fold 4 - Validation Accuracy : 0.5208\n",
      "Epoch(22) - Fold 4 - Validation Utility score : 2487.7500\n",
      "Epoch(22) - GLOBAL - Validation Loss: 0.6886\n",
      "Epoch(22) - GLOBAL - Validation Accuracy: 0.5285\n",
      "Epoch(22) - GLOBAL - Validation Utility score: 8454.5758\n",
      "Saving model corresponding to last_utility_score == 8454.575829848422\n",
      "\n",
      "\n",
      "Epoch(23) - Training Loss: 0.6859\n",
      "Epoch(23) - Fold 0 - Validation Loss : 0.6867\n",
      "Epoch(23) - Fold 0 - Validation Accuracy : 0.5329\n",
      "Epoch(23) - Fold 0 - Validation Utility score : 1976.3480\n",
      "Epoch(23) - Fold 1 - Validation Loss : 0.6852\n",
      "Epoch(23) - Fold 1 - Validation Accuracy : 0.5358\n",
      "Epoch(23) - Fold 1 - Validation Utility score : 1834.7089\n",
      "Epoch(23) - Fold 2 - Validation Loss : 0.6880\n",
      "Epoch(23) - Fold 2 - Validation Accuracy : 0.5331\n",
      "Epoch(23) - Fold 2 - Validation Utility score : 1657.3202\n",
      "Epoch(23) - Fold 3 - Validation Loss : 0.6903\n",
      "Epoch(23) - Fold 3 - Validation Accuracy : 0.5214\n",
      "Epoch(23) - Fold 3 - Validation Utility score : 523.8637\n",
      "Epoch(23) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(23) - Fold 4 - Validation Accuracy : 0.5213\n",
      "Epoch(23) - Fold 4 - Validation Utility score : 2524.3611\n",
      "Epoch(23) - GLOBAL - Validation Loss: 0.6885\n",
      "Epoch(23) - GLOBAL - Validation Accuracy: 0.5289\n",
      "Epoch(23) - GLOBAL - Validation Utility score: 8516.6020\n",
      "Saving model corresponding to last_utility_score == 8516.60199314455\n",
      "\n",
      "\n",
      "Epoch(24) - Training Loss: 0.6857\n",
      "Epoch(24) - Fold 0 - Validation Loss : 0.6867\n",
      "Epoch(24) - Fold 0 - Validation Accuracy : 0.5341\n",
      "Epoch(24) - Fold 0 - Validation Utility score : 2220.5379\n",
      "Epoch(24) - Fold 1 - Validation Loss : 0.6850\n",
      "Epoch(24) - Fold 1 - Validation Accuracy : 0.5359\n",
      "Epoch(24) - Fold 1 - Validation Utility score : 1846.3316\n",
      "Epoch(24) - Fold 2 - Validation Loss : 0.6879\n",
      "Epoch(24) - Fold 2 - Validation Accuracy : 0.5342\n",
      "Epoch(24) - Fold 2 - Validation Utility score : 2113.4522\n",
      "Epoch(24) - Fold 3 - Validation Loss : 0.6898\n",
      "Epoch(24) - Fold 3 - Validation Accuracy : 0.5215\n",
      "Epoch(24) - Fold 3 - Validation Utility score : 833.0612\n",
      "Epoch(24) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(24) - Fold 4 - Validation Accuracy : 0.5197\n",
      "Epoch(24) - Fold 4 - Validation Utility score : 2487.5361\n",
      "Epoch(24) - GLOBAL - Validation Loss: 0.6884\n",
      "Epoch(24) - GLOBAL - Validation Accuracy: 0.5291\n",
      "Epoch(24) - GLOBAL - Validation Utility score: 9500.9191\n",
      "Saving model corresponding to last_utility_score == 9500.919071005204\n",
      "\n",
      "\n",
      "Epoch(25) - Training Loss: 0.6855\n",
      "Epoch(25) - Fold 0 - Validation Loss : 0.6867\n",
      "Epoch(25) - Fold 0 - Validation Accuracy : 0.5338\n",
      "Epoch(25) - Fold 0 - Validation Utility score : 2409.8983\n",
      "Epoch(25) - Fold 1 - Validation Loss : 0.6848\n",
      "Epoch(25) - Fold 1 - Validation Accuracy : 0.5367\n",
      "Epoch(25) - Fold 1 - Validation Utility score : 1933.4351\n",
      "Epoch(25) - Fold 2 - Validation Loss : 0.6877\n",
      "Epoch(25) - Fold 2 - Validation Accuracy : 0.5346\n",
      "Epoch(25) - Fold 2 - Validation Utility score : 1991.6641\n",
      "Epoch(25) - Fold 3 - Validation Loss : 0.6898\n",
      "Epoch(25) - Fold 3 - Validation Accuracy : 0.5231\n",
      "Epoch(25) - Fold 3 - Validation Utility score : 775.1015\n",
      "Epoch(25) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(25) - Fold 4 - Validation Accuracy : 0.5187\n",
      "Epoch(25) - Fold 4 - Validation Utility score : 2307.0882\n",
      "Epoch(25) - GLOBAL - Validation Loss: 0.6883\n",
      "Epoch(25) - GLOBAL - Validation Accuracy: 0.5294\n",
      "Epoch(25) - GLOBAL - Validation Utility score: 9417.1873\n",
      "Saving model corresponding to last_utility_score == 9417.187283774994\n",
      "\n",
      "\n",
      "Epoch(26) - Training Loss: 0.6854\n",
      "Epoch(26) - Fold 0 - Validation Loss : 0.6860\n",
      "Epoch(26) - Fold 0 - Validation Accuracy : 0.5341\n",
      "Epoch(26) - Fold 0 - Validation Utility score : 1962.0429\n",
      "Epoch(26) - Fold 1 - Validation Loss : 0.6841\n",
      "Epoch(26) - Fold 1 - Validation Accuracy : 0.5365\n",
      "Epoch(26) - Fold 1 - Validation Utility score : 1544.3064\n",
      "Epoch(26) - Fold 2 - Validation Loss : 0.6873\n",
      "Epoch(26) - Fold 2 - Validation Accuracy : 0.5349\n",
      "Epoch(26) - Fold 2 - Validation Utility score : 2156.0190\n",
      "Epoch(26) - Fold 3 - Validation Loss : 0.6897\n",
      "Epoch(26) - Fold 3 - Validation Accuracy : 0.5211\n",
      "Epoch(26) - Fold 3 - Validation Utility score : 655.0242\n",
      "Epoch(26) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(26) - Fold 4 - Validation Accuracy : 0.5197\n",
      "Epoch(26) - Fold 4 - Validation Utility score : 2605.8973\n",
      "Epoch(26) - GLOBAL - Validation Loss: 0.6880\n",
      "Epoch(26) - GLOBAL - Validation Accuracy: 0.5293\n",
      "Epoch(26) - GLOBAL - Validation Utility score: 8923.2898\n",
      "Saving model corresponding to last_utility_score == 8923.28980501805\n",
      "\n",
      "\n",
      "Epoch(27) - Training Loss: 0.6851\n",
      "Epoch(27) - Fold 0 - Validation Loss : 0.6860\n",
      "Epoch(27) - Fold 0 - Validation Accuracy : 0.5344\n",
      "Epoch(27) - Fold 0 - Validation Utility score : 2246.8103\n",
      "Epoch(27) - Fold 1 - Validation Loss : 0.6841\n",
      "Epoch(27) - Fold 1 - Validation Accuracy : 0.5367\n",
      "Epoch(27) - Fold 1 - Validation Utility score : 1842.3046\n",
      "Epoch(27) - Fold 2 - Validation Loss : 0.6874\n",
      "Epoch(27) - Fold 2 - Validation Accuracy : 0.5349\n",
      "Epoch(27) - Fold 2 - Validation Utility score : 1865.6785\n",
      "Epoch(27) - Fold 3 - Validation Loss : 0.6898\n",
      "Epoch(27) - Fold 3 - Validation Accuracy : 0.5220\n",
      "Epoch(27) - Fold 3 - Validation Utility score : 719.7910\n",
      "Epoch(27) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(27) - Fold 4 - Validation Accuracy : 0.5209\n",
      "Epoch(27) - Fold 4 - Validation Utility score : 2460.0079\n",
      "Epoch(27) - GLOBAL - Validation Loss: 0.6880\n",
      "Epoch(27) - GLOBAL - Validation Accuracy: 0.5298\n",
      "Epoch(27) - GLOBAL - Validation Utility score: 9134.5923\n",
      "Intermediate early stopping : vepoch_loss = 0.6880, the_last_loss=0.6880\n",
      "\n",
      "\n",
      "Epoch(28) - Training Loss: 0.6849\n",
      "Epoch(28) - Fold 0 - Validation Loss : 0.6860\n",
      "Epoch(28) - Fold 0 - Validation Accuracy : 0.5341\n",
      "Epoch(28) - Fold 0 - Validation Utility score : 2671.8454\n",
      "Epoch(28) - Fold 1 - Validation Loss : 0.6836\n",
      "Epoch(28) - Fold 1 - Validation Accuracy : 0.5369\n",
      "Epoch(28) - Fold 1 - Validation Utility score : 2148.9196\n",
      "Epoch(28) - Fold 2 - Validation Loss : 0.6870\n",
      "Epoch(28) - Fold 2 - Validation Accuracy : 0.5345\n",
      "Epoch(28) - Fold 2 - Validation Utility score : 2135.8668\n",
      "Epoch(28) - Fold 3 - Validation Loss : 0.6893\n",
      "Epoch(28) - Fold 3 - Validation Accuracy : 0.5231\n",
      "Epoch(28) - Fold 3 - Validation Utility score : 1042.9693\n",
      "Epoch(28) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(28) - Fold 4 - Validation Accuracy : 0.5195\n",
      "Epoch(28) - Fold 4 - Validation Utility score : 2392.0245\n",
      "Epoch(28) - GLOBAL - Validation Loss: 0.6878\n",
      "Epoch(28) - GLOBAL - Validation Accuracy: 0.5296\n",
      "Epoch(28) - GLOBAL - Validation Utility score: 10391.6255\n",
      "Saving model corresponding to last_utility_score == 10391.625535225856\n",
      "\n",
      "\n",
      "Epoch(29) - Training Loss: 0.6848\n",
      "Epoch(29) - Fold 0 - Validation Loss : 0.6856\n",
      "Epoch(29) - Fold 0 - Validation Accuracy : 0.5353\n",
      "Epoch(29) - Fold 0 - Validation Utility score : 2818.1449\n",
      "Epoch(29) - Fold 1 - Validation Loss : 0.6834\n",
      "Epoch(29) - Fold 1 - Validation Accuracy : 0.5371\n",
      "Epoch(29) - Fold 1 - Validation Utility score : 2397.6205\n",
      "Epoch(29) - Fold 2 - Validation Loss : 0.6868\n",
      "Epoch(29) - Fold 2 - Validation Accuracy : 0.5370\n",
      "Epoch(29) - Fold 2 - Validation Utility score : 2457.9325\n",
      "Epoch(29) - Fold 3 - Validation Loss : 0.6893\n",
      "Epoch(29) - Fold 3 - Validation Accuracy : 0.5233\n",
      "Epoch(29) - Fold 3 - Validation Utility score : 856.1562\n",
      "Epoch(29) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(29) - Fold 4 - Validation Accuracy : 0.5204\n",
      "Epoch(29) - Fold 4 - Validation Utility score : 2407.3542\n",
      "Epoch(29) - GLOBAL - Validation Loss: 0.6876\n",
      "Epoch(29) - GLOBAL - Validation Accuracy: 0.5306\n",
      "Epoch(29) - GLOBAL - Validation Utility score: 10937.2083\n",
      "Saving model corresponding to last_utility_score == 10937.208346761054\n",
      "\n",
      "\n",
      "Epoch(30) - Training Loss: 0.6844\n",
      "Epoch(30) - Fold 0 - Validation Loss : 0.6857\n",
      "Epoch(30) - Fold 0 - Validation Accuracy : 0.5355\n",
      "Epoch(30) - Fold 0 - Validation Utility score : 2470.4876\n",
      "Epoch(30) - Fold 1 - Validation Loss : 0.6833\n",
      "Epoch(30) - Fold 1 - Validation Accuracy : 0.5374\n",
      "Epoch(30) - Fold 1 - Validation Utility score : 2123.5828\n",
      "Epoch(30) - Fold 2 - Validation Loss : 0.6868\n",
      "Epoch(30) - Fold 2 - Validation Accuracy : 0.5367\n",
      "Epoch(30) - Fold 2 - Validation Utility score : 2255.6297\n",
      "Epoch(30) - Fold 3 - Validation Loss : 0.6893\n",
      "Epoch(30) - Fold 3 - Validation Accuracy : 0.5230\n",
      "Epoch(30) - Fold 3 - Validation Utility score : 814.4206\n",
      "Epoch(30) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(30) - Fold 4 - Validation Accuracy : 0.5206\n",
      "Epoch(30) - Fold 4 - Validation Utility score : 2199.6013\n",
      "Epoch(30) - GLOBAL - Validation Loss: 0.6876\n",
      "Epoch(30) - GLOBAL - Validation Accuracy: 0.5306\n",
      "Epoch(30) - GLOBAL - Validation Utility score: 9863.7219\n",
      "Saving model corresponding to last_utility_score == 9863.721915589853\n",
      "\n",
      "\n",
      "Epoch(31) - Training Loss: 0.6843\n",
      "Epoch(31) - Fold 0 - Validation Loss : 0.6855\n",
      "Epoch(31) - Fold 0 - Validation Accuracy : 0.5358\n",
      "Epoch(31) - Fold 0 - Validation Utility score : 2837.6211\n",
      "Epoch(31) - Fold 1 - Validation Loss : 0.6833\n",
      "Epoch(31) - Fold 1 - Validation Accuracy : 0.5373\n",
      "Epoch(31) - Fold 1 - Validation Utility score : 1906.6543\n",
      "Epoch(31) - Fold 2 - Validation Loss : 0.6866\n",
      "Epoch(31) - Fold 2 - Validation Accuracy : 0.5367\n",
      "Epoch(31) - Fold 2 - Validation Utility score : 2257.3341\n",
      "Epoch(31) - Fold 3 - Validation Loss : 0.6890\n",
      "Epoch(31) - Fold 3 - Validation Accuracy : 0.5229\n",
      "Epoch(31) - Fold 3 - Validation Utility score : 790.3167\n",
      "Epoch(31) - Fold 4 - Validation Loss : 0.6930\n",
      "Epoch(31) - Fold 4 - Validation Accuracy : 0.5209\n",
      "Epoch(31) - Fold 4 - Validation Utility score : 2487.4738\n",
      "Epoch(31) - GLOBAL - Validation Loss: 0.6875\n",
      "Epoch(31) - GLOBAL - Validation Accuracy: 0.5307\n",
      "Epoch(31) - GLOBAL - Validation Utility score: 10279.4000\n",
      "Saving model corresponding to last_utility_score == 10279.399997517638\n",
      "\n",
      "\n",
      "Epoch(32) - Training Loss: 0.6842\n",
      "Epoch(32) - Fold 0 - Validation Loss : 0.6855\n",
      "Epoch(32) - Fold 0 - Validation Accuracy : 0.5354\n",
      "Epoch(32) - Fold 0 - Validation Utility score : 2628.6548\n",
      "Epoch(32) - Fold 1 - Validation Loss : 0.6833\n",
      "Epoch(32) - Fold 1 - Validation Accuracy : 0.5375\n",
      "Epoch(32) - Fold 1 - Validation Utility score : 2059.8253\n",
      "Epoch(32) - Fold 2 - Validation Loss : 0.6865\n",
      "Epoch(32) - Fold 2 - Validation Accuracy : 0.5374\n",
      "Epoch(32) - Fold 2 - Validation Utility score : 2533.8464\n",
      "Epoch(32) - Fold 3 - Validation Loss : 0.6890\n",
      "Epoch(32) - Fold 3 - Validation Accuracy : 0.5236\n",
      "Epoch(32) - Fold 3 - Validation Utility score : 842.2817\n",
      "Epoch(32) - Fold 4 - Validation Loss : 0.6930\n",
      "Epoch(32) - Fold 4 - Validation Accuracy : 0.5206\n",
      "Epoch(32) - Fold 4 - Validation Utility score : 2530.9224\n",
      "Epoch(32) - GLOBAL - Validation Loss: 0.6875\n",
      "Epoch(32) - GLOBAL - Validation Accuracy: 0.5309\n",
      "Epoch(32) - GLOBAL - Validation Utility score: 10595.5307\n",
      "Saving model corresponding to last_utility_score == 10595.530734038171\n",
      "\n",
      "\n",
      "Epoch(33) - Training Loss: 0.6840\n",
      "Epoch(33) - Fold 0 - Validation Loss : 0.6853\n",
      "Epoch(33) - Fold 0 - Validation Accuracy : 0.5365\n",
      "Epoch(33) - Fold 0 - Validation Utility score : 2794.5065\n",
      "Epoch(33) - Fold 1 - Validation Loss : 0.6827\n",
      "Epoch(33) - Fold 1 - Validation Accuracy : 0.5381\n",
      "Epoch(33) - Fold 1 - Validation Utility score : 2036.8089\n",
      "Epoch(33) - Fold 2 - Validation Loss : 0.6864\n",
      "Epoch(33) - Fold 2 - Validation Accuracy : 0.5373\n",
      "Epoch(33) - Fold 2 - Validation Utility score : 2410.8924\n",
      "Epoch(33) - Fold 3 - Validation Loss : 0.6890\n",
      "Epoch(33) - Fold 3 - Validation Accuracy : 0.5240\n",
      "Epoch(33) - Fold 3 - Validation Utility score : 709.5972\n",
      "Epoch(33) - Fold 4 - Validation Loss : 0.6931\n",
      "Epoch(33) - Fold 4 - Validation Accuracy : 0.5201\n",
      "Epoch(33) - Fold 4 - Validation Utility score : 2235.8914\n",
      "Epoch(33) - GLOBAL - Validation Loss: 0.6873\n",
      "Epoch(33) - GLOBAL - Validation Accuracy: 0.5312\n",
      "Epoch(33) - GLOBAL - Validation Utility score: 10187.6964\n",
      "Saving model corresponding to last_utility_score == 10187.69644146581\n",
      "\n",
      "\n",
      "Epoch(34) - Training Loss: 0.6838\n",
      "Epoch(34) - Fold 0 - Validation Loss : 0.6850\n",
      "Epoch(34) - Fold 0 - Validation Accuracy : 0.5368\n",
      "Epoch(34) - Fold 0 - Validation Utility score : 2980.3145\n",
      "Epoch(34) - Fold 1 - Validation Loss : 0.6827\n",
      "Epoch(34) - Fold 1 - Validation Accuracy : 0.5379\n",
      "Epoch(34) - Fold 1 - Validation Utility score : 2463.2121\n",
      "Epoch(34) - Fold 2 - Validation Loss : 0.6866\n",
      "Epoch(34) - Fold 2 - Validation Accuracy : 0.5370\n",
      "Epoch(34) - Fold 2 - Validation Utility score : 2507.3672\n",
      "Epoch(34) - Fold 3 - Validation Loss : 0.6887\n",
      "Epoch(34) - Fold 3 - Validation Accuracy : 0.5243\n",
      "Epoch(34) - Fold 3 - Validation Utility score : 1011.0668\n",
      "Epoch(34) - Fold 4 - Validation Loss : 0.6933\n",
      "Epoch(34) - Fold 4 - Validation Accuracy : 0.5197\n",
      "Epoch(34) - Fold 4 - Validation Utility score : 2235.6881\n",
      "Epoch(34) - GLOBAL - Validation Loss: 0.6873\n",
      "Epoch(34) - GLOBAL - Validation Accuracy: 0.5311\n",
      "Epoch(34) - GLOBAL - Validation Utility score: 11197.6487\n",
      "Saving model corresponding to last_utility_score == 11197.648680929586\n",
      "\n",
      "\n",
      "Epoch(35) - Training Loss: 0.6838\n",
      "Epoch(35) - Fold 0 - Validation Loss : 0.6849\n",
      "Epoch(35) - Fold 0 - Validation Accuracy : 0.5363\n",
      "Epoch(35) - Fold 0 - Validation Utility score : 2820.4066\n",
      "Epoch(35) - Fold 1 - Validation Loss : 0.6825\n",
      "Epoch(35) - Fold 1 - Validation Accuracy : 0.5381\n",
      "Epoch(35) - Fold 1 - Validation Utility score : 2170.9355\n",
      "Epoch(35) - Fold 2 - Validation Loss : 0.6860\n",
      "Epoch(35) - Fold 2 - Validation Accuracy : 0.5375\n",
      "Epoch(35) - Fold 2 - Validation Utility score : 2527.4062\n",
      "Epoch(35) - Fold 3 - Validation Loss : 0.6886\n",
      "Epoch(35) - Fold 3 - Validation Accuracy : 0.5246\n",
      "Epoch(35) - Fold 3 - Validation Utility score : 954.9429\n",
      "Epoch(35) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(35) - Fold 4 - Validation Accuracy : 0.5215\n",
      "Epoch(35) - Fold 4 - Validation Utility score : 2451.6564\n",
      "Epoch(35) - GLOBAL - Validation Loss: 0.6870\n",
      "Epoch(35) - GLOBAL - Validation Accuracy: 0.5316\n",
      "Epoch(35) - GLOBAL - Validation Utility score: 10925.3475\n",
      "Saving model corresponding to last_utility_score == 10925.347547453961\n",
      "\n",
      "\n",
      "Epoch(36) - Training Loss: 0.6836\n",
      "Epoch(36) - Fold 0 - Validation Loss : 0.6849\n",
      "Epoch(36) - Fold 0 - Validation Accuracy : 0.5365\n",
      "Epoch(36) - Fold 0 - Validation Utility score : 2988.0734\n",
      "Epoch(36) - Fold 1 - Validation Loss : 0.6822\n",
      "Epoch(36) - Fold 1 - Validation Accuracy : 0.5382\n",
      "Epoch(36) - Fold 1 - Validation Utility score : 1938.9680\n",
      "Epoch(36) - Fold 2 - Validation Loss : 0.6861\n",
      "Epoch(36) - Fold 2 - Validation Accuracy : 0.5385\n",
      "Epoch(36) - Fold 2 - Validation Utility score : 2506.1801\n",
      "Epoch(36) - Fold 3 - Validation Loss : 0.6885\n",
      "Epoch(36) - Fold 3 - Validation Accuracy : 0.5242\n",
      "Epoch(36) - Fold 3 - Validation Utility score : 896.3335\n",
      "Epoch(36) - Fold 4 - Validation Loss : 0.6934\n",
      "Epoch(36) - Fold 4 - Validation Accuracy : 0.5210\n",
      "Epoch(36) - Fold 4 - Validation Utility score : 2368.8926\n",
      "Epoch(36) - GLOBAL - Validation Loss: 0.6870\n",
      "Epoch(36) - GLOBAL - Validation Accuracy: 0.5317\n",
      "Epoch(36) - GLOBAL - Validation Utility score: 10698.4475\n",
      "Intermediate early stopping : vepoch_loss = 0.6870, the_last_loss=0.6870\n",
      "\n",
      "\n",
      "Epoch(37) - Training Loss: 0.6835\n",
      "Epoch(37) - Fold 0 - Validation Loss : 0.6847\n",
      "Epoch(37) - Fold 0 - Validation Accuracy : 0.5366\n",
      "Epoch(37) - Fold 0 - Validation Utility score : 2835.6572\n",
      "Epoch(37) - Fold 1 - Validation Loss : 0.6821\n",
      "Epoch(37) - Fold 1 - Validation Accuracy : 0.5394\n",
      "Epoch(37) - Fold 1 - Validation Utility score : 2302.6425\n",
      "Epoch(37) - Fold 2 - Validation Loss : 0.6859\n",
      "Epoch(37) - Fold 2 - Validation Accuracy : 0.5389\n",
      "Epoch(37) - Fold 2 - Validation Utility score : 2650.3370\n",
      "Epoch(37) - Fold 3 - Validation Loss : 0.6883\n",
      "Epoch(37) - Fold 3 - Validation Accuracy : 0.5251\n",
      "Epoch(37) - Fold 3 - Validation Utility score : 1194.3764\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"<ipython-input-136-a0ccf27822a3>\"\u001b[0m, line \u001b[1;32m109\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    for batch in test_loader[fold_indice]:\n",
      "  File \u001b[1;32m\"/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/torch/utils/data/dataloader.py\"\u001b[0m, line \u001b[1;32m435\u001b[0m, in \u001b[1;35m__next__\u001b[0m\n    data = self._next_data()\n",
      "  File \u001b[1;32m\"/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/torch/utils/data/dataloader.py\"\u001b[0m, line \u001b[1;32m475\u001b[0m, in \u001b[1;35m_next_data\u001b[0m\n    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \u001b[1;32m\"/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\"\u001b[0m, line \u001b[1;32m47\u001b[0m, in \u001b[1;35mfetch\u001b[0m\n    return self.collate_fn(data)\n",
      "  File \u001b[1;32m\"/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\"\u001b[0m, line \u001b[1;32m83\u001b[0m, in \u001b[1;35mdefault_collate\u001b[0m\n    return [default_collate(samples) for samples in transposed]\n",
      "  File \u001b[1;32m\"/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\"\u001b[0m, line \u001b[1;32m83\u001b[0m, in \u001b[1;35m<listcomp>\u001b[0m\n    return [default_collate(samples) for samples in transposed]\n",
      "\u001b[0;36m  File \u001b[0;32m\"/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\"\u001b[0;36m, line \u001b[0;32m55\u001b[0;36m, in \u001b[0;35mdefault_collate\u001b[0;36m\u001b[0m\n\u001b[0;31m    return torch.stack(batch, 0, out=out)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "patience=3\n",
    "\n",
    "utility_scores = [None] * 5\n",
    "accuracy_scores = [None] * 5\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    " \n",
    "ts_train = torch.tensor(df.loc[folds_list_train_unique, FEATURES_LIST_TOTRAIN].to_numpy(), device='cuda')\n",
    "ts_train_y = torch.tensor((df.loc[folds_list_train_unique, 'resp'] > 0).astype(np.byte).to_numpy(), device='cuda')\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(ts_train, ts_train_y)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True) # pin_memory : VOIR RESULTAT\n",
    "\n",
    "ts_test = [None] * 5\n",
    "ts_test_y = [None] * 5    \n",
    "test_dataset = [None] * 5\n",
    "test_loader = [None] * 5\n",
    "\n",
    "for fold_indice in range(5):\n",
    "    ts_test[fold_indice] = torch.tensor(df.loc[folds_list_test[fold_indice], FEATURES_LIST_TOTRAIN].to_numpy(), device='cuda')\n",
    "    ts_test_y[fold_indice] = torch.tensor((df.loc[folds_list_test[fold_indice], 'resp'] > 0).astype(np.byte).to_numpy(), device='cuda')\n",
    "\n",
    "    test_dataset[fold_indice] = torch.utils.data.TensorDataset(ts_test[fold_indice], ts_test_y[fold_indice])\n",
    "    test_loader[fold_indice] = torch.utils.data.DataLoader(test_dataset[fold_indice], batch_size=BATCH_SIZE)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    #nn.Dropout(0.2),\n",
    "    nn.Linear(len(FEATURES_LIST_TOTRAIN), 130),\n",
    "    #nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "\n",
    "    nn.Linear(130, 60),\n",
    "    #nn.BatchNorm1d(60),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "\n",
    "    nn.Linear(60, 30),\n",
    "    #nn.BatchNorm1d(50),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "\n",
    "    nn.Linear(30, 1),\n",
    "    nn.Sigmoid(),\n",
    ").double().to('cuda')\n",
    "\n",
    "print('Number of model parameters :')\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list\n",
    "\n",
    "loss_fn = nn.BCELoss().to('cuda')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) \n",
    "\n",
    "model.eval()\n",
    "#start_accuracy = accuracy_score(ts_test_y.cpu().numpy(), (model(ts_test).squeeze() > 0.5).cpu().numpy())\n",
    "#start_utility_score = utility_function(df.loc[test_index], (model(ts_test).squeeze() > 0.5).cpu().numpy())\n",
    "#print('Start Validation Accuracy: {:.4f}'.format(start_accuracy))\n",
    "#print('Start Validation Utility: {:.4f}'.format(start_utility_score))\n",
    "\n",
    "Val_Loss = 0\n",
    "N_Samples = 0\n",
    "\n",
    "the_last_loss = 100\n",
    "the_last_utility_score = 0\n",
    "the_last_accuracy = 0\n",
    "trigger_times=0\n",
    "early_stopping_met = False\n",
    "\n",
    "for epoch in range(NUM_EPOCHS): \n",
    "    running_loss = 0.0        \n",
    "    model.train()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        #inputs, labels = batch[0], batch[1]\n",
    "        inputs, labels = batch[0].to('cuda'), batch[1].to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels.unsqueeze(-1).double())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # update local train loss\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    # update global train loss\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print('Epoch({}) - Training Loss: {:.4f}'.format(epoch, epoch_loss))\n",
    "\n",
    "    writer.add_scalar(f\"Global train/loss\", epoch_loss, epoch)\n",
    "\n",
    "    # Validation \n",
    "    model.eval()\n",
    "\n",
    "    vrunning_loss = [None] * 5\n",
    "    num_samples = [None] * 5\n",
    "    vepoch_loss_folds = [None] * 5\n",
    "    vepoch_accuracy_folds = [None] * 5\n",
    "    vepoch_utility_score_folds = [None] * 5\n",
    "    \n",
    "    for fold_indice in range(5):    \n",
    "        vrunning_loss[fold_indice] = 0.0\n",
    "        num_samples[fold_indice] = 0\n",
    "\n",
    "        for batch in test_loader[fold_indice]:\n",
    "            inputs, labels = batch[0].to('cuda'), batch[1].to('cuda')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, labels.unsqueeze(-1).double())\n",
    "\n",
    "            vrunning_loss[fold_indice] += loss.item() * inputs.size(0)\n",
    "            num_samples[fold_indice] += labels.size(0)\n",
    "            \n",
    "            vepoch_loss_folds[fold_indice] = vrunning_loss[fold_indice] / num_samples[fold_indice]\n",
    "\n",
    "        print('Epoch({}) - Fold {} - Validation Loss : {:.4f}'.format(epoch, fold_indice, vepoch_loss_folds[fold_indice]))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            vepoch_accuracy_folds[fold_indice] = accuracy_score(ts_test_y[fold_indice].cpu().numpy(), (model(ts_test[fold_indice]).squeeze() > 0.5).cpu().numpy())\n",
    "            vepoch_utility_score_folds[fold_indice] = utility_function(df.loc[folds_list_test[fold_indice]], (model(ts_test[fold_indice]).squeeze() > 0.5).cpu().numpy())\n",
    "        print('Epoch({}) - Fold {} - Validation Accuracy : {:.4f}'.format(epoch, fold_indice, vepoch_accuracy_folds[fold_indice]))\n",
    "        print('Epoch({}) - Fold {} - Validation Utility score : {:.4f}'.format(epoch, fold_indice, vepoch_utility_score_folds[fold_indice]))\n",
    "        \n",
    "            \n",
    "    # update epoch loss\n",
    "    vepoch_loss = sum(vepoch_loss_folds) / len(vepoch_loss_folds)\n",
    "    vepoch_accuracy = sum(vepoch_accuracy_folds) / len(vepoch_accuracy_folds)\n",
    "    vepoch_utility_score = sum(vepoch_utility_score_folds) #/ len(vepoch_utility_score_folds)\n",
    "    print('Epoch({}) - GLOBAL - Validation Loss: {:.4f}'.format(epoch, vepoch_loss))\n",
    "    print('Epoch({}) - GLOBAL - Validation Accuracy: {:.4f}'.format(epoch, vepoch_accuracy))\n",
    "    print('Epoch({}) - GLOBAL - Validation Utility score: {:.4f}'.format(epoch, vepoch_utility_score))\n",
    "\n",
    "    #print(f'Sum of model parameters ({epoch}):')\n",
    "    #[print(p.sum()) for p in model.parameters()]\n",
    "\n",
    "    writer.add_scalar(\"Global valid/Loss\", vepoch_loss, epoch)\n",
    "    writer.add_scalar(\"Global valid/Accuracy\", vepoch_accuracy, epoch)\n",
    "    writer.add_scalar(\"Global valid/Utility\", vepoch_utility_score, epoch)\n",
    "\n",
    "    for fold_indice in range(5):\n",
    "        writer.add_scalar(\"Fold valid/Loss fold \"+str(fold_indice), vepoch_loss_folds[fold_indice], epoch)\n",
    "        writer.add_scalar(\"Fold valid/Accuracy fold \"+str(fold_indice), vepoch_accuracy_folds[fold_indice], epoch)\n",
    "        writer.add_scalar(\"Fold valid/Utility fold \"+str(fold_indice), vepoch_utility_score_folds[fold_indice], epoch)\n",
    "        \n",
    "    \n",
    "    writer.flush()\n",
    "\n",
    "    # Check if Early Stopping\n",
    "    #if vepoch_loss > the_last_loss:\n",
    "    #if (vepoch_utility_score < the_last_utility_score) and (vepoch_loss > the_last_loss) and (vepoch_accuracy < the_last_accuracy):\n",
    "    if (vepoch_loss > the_last_loss):\n",
    "        trigger_times += 1\n",
    "\n",
    "        print(f'Intermediate early stopping : vepoch_loss = {vepoch_loss:.4f}, the_last_loss={the_last_loss:.4f}')\n",
    "        #print(f'Intermediate early stopping : vepoch_accuracy = {vepoch_accuracy:.4f}, the_last_utility_score={the_last_accuracy:.4f}')\n",
    "        #print(f'Intermediate early stopping : vepoch_utility_score = {vepoch_utility_score:.4f}, the_last_utility_score={the_last_utility_score:.4f}')\n",
    "\n",
    "        if trigger_times >= patience:\n",
    "            print('Meet Early stopping!')\n",
    "            early_stopping_met = True\n",
    "            ##torch.save(model.state_dict(), f'model_{fold}.pt')\n",
    "            break\n",
    "    else:\n",
    "        trigger_times = 0\n",
    "        the_last_loss = vepoch_loss\n",
    "        the_last_utility_score = vepoch_utility_score\n",
    "        the_last_accuracy = vepoch_accuracy\n",
    "        \n",
    "        the_last_utility_score_folds = vepoch_utility_score_folds\n",
    "        the_last_accuracy_folds = vepoch_accuracy_folds\n",
    "        \n",
    "        the_best_epoch = epoch\n",
    "\n",
    "        # Save model for the best version so far\n",
    "        print(f'Saving model corresponding to last_utility_score == {the_last_utility_score}')\n",
    "        torch.save(model.state_dict(), f'model_NN_allfolds_V1.pt')\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "# Update global loss\n",
    "Val_Loss += vepoch_loss * num_samples\n",
    "\n",
    "# Update global # of samples \n",
    "N_Samples += num_samples\n",
    "\n",
    "if (early_stopping_met == False):\n",
    "    print(\"Didn't meet early stopping : saving final model\")\n",
    "    # Save model if don't meet early stopping\n",
    "    torch.save(model.state_dict(), f'model_NN_allfolds_V1.pt')\n",
    "\n",
    "#utility_scores.append(the_last_utility_score)\n",
    "#accuracy_scores.append(the_last_accuracy)\n",
    "writer.add_text(f\"Global valid/Utility\", f\"Best utility: {the_last_utility_score}\", the_best_epoch)\n",
    "        \n",
    "scores_results = {'utility_score': the_last_utility_score, 'utility_scores': the_last_utility_score_folds, 'utility_score_std': np.std(the_last_utility_score_folds), 'accuracy_scores': the_last_accuracy_folds}\n",
    "\n",
    "writer.add_text('Final utility score', str(scores_results))\n",
    "writer.add_text('Batch size', str(BATCH_SIZE))\n",
    "writer.add_text('Patience', str(patience))\n",
    "writer.add_text('Number of epochs', str(NUM_EPOCHS))\n",
    "writer.add_text('Number of parameters per layer', str([p.numel() for p in model.parameters()]))\n",
    "writer.add_text('Model architecture', str(model).replace('\\n', '<BR>'))\n",
    "writer.add_text('Comment', MODEL_COMMENT)\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print('Training summary:')\n",
    "print(scores_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.eval()\n",
    "#accuracy_score(ts_test_y.cpu().numpy(), (model(ts_test).squeeze() > 0.5).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.eval()\n",
    "#utility_function(df.loc[test_index], (model(ts_test).squeeze() > 0.5).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_load = nn.Sequential(\n",
    "        #nn.Dropout(0.2),\n",
    "        nn.Linear(len(FEATURES_LIST_TOTRAIN), 130),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "\n",
    "        nn.Linear(130, 60),\n",
    "        #nn.BatchNorm1d(60),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "\n",
    "        nn.Linear(60, 30),\n",
    "        #nn.BatchNorm1d(50),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "       \n",
    "        nn.Linear(30, 1),\n",
    "        nn.Sigmoid(),\n",
    "    ).double().to('cuda')\n",
    "    \n",
    "model_load.load_state_dict(torch.load(f'model_NN_allfolds_V1.pt',map_location=torch.device('cuda')))\n",
    "\n",
    "#model_load.eval()\n",
    "#print(accuracy_score(ts_test_y.cpu().numpy(), (model_load(ts_test).squeeze() > 0.5).cpu().numpy()))\n",
    "#\n",
    "#model_load.eval()\n",
    "#print(utility_function(df.loc[test_index], (model_load(ts_test).squeeze() > 0.5).cpu().numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
