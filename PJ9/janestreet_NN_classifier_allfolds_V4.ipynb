{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch classifier notebook\n",
    "\n",
    "V1 : only 1 split. First implementation  \n",
    "All folds V1 : with all folds  \n",
    "All folds V2 : add activation stats plot  \n",
    "All folds V3 : try 2 outputs regression and classification. Activation stats plot fixed.  \n",
    "All folds V4 : still 2 outputs regression and classification, but 2 variables on last layer, instead of 2 last layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as utils\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import io\n",
    "import PIL.Image\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "DATASET_INPUT_FILE = 'train.csv'\n",
    "\n",
    "FEATURES_LIST_TOTRAIN = ['feature_'+str(i) for i in range(130)]\n",
    "\n",
    "# For custom non-overlaped folds generation\n",
    "TRAIN_PERCENT = 0.70  \n",
    "TEST_PERCENT = 0.30\n",
    "\n",
    "#pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deterministic Behavior\n",
    "seed = 42\n",
    "#os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "# Torch RNG\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "# Python RNG\n",
    "np.random.seed(seed)\n",
    "#random.seed(seed)\n",
    "# CuDA Determinism\n",
    "torch.backends.cudnn.deterministic = True\n",
    "#torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BATCH_SIZE = 50000\n",
    "#BATCH_SIZE = 4096 # Gave once better results than 50000\n",
    "#BATCH_SIZE = 2048\n",
    "\n",
    "#BATCH_SIZE = 300000\n",
    "\n",
    "#BATCH_SIZE = 500000\n",
    "BATCH_SIZE = 100000\n",
    "\n",
    "#BATCH_SIZE = 8192\n",
    "#BATCH_SIZE = 40960\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "#MODEL_COMMENT = \"All folds, 3 layers 2000, 1000 and 1, batch size 4096, lr=1e-4, patience 5, standard scale, 0.7 dropout, activ stats, CLASSIF+REG without sigmoid on reg\"\n",
    "MODEL_COMMENT = \"All folds, 3 layers width 1300-1600, classif+reg, batch size 50000, lr=1e-3, patience 5, no standard scale, 0.3 dropout, activ stats, CLASSIF+REG 2 vars last layer, tanh, only reg used\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyStandardScale(tensor, mean, std):\n",
    "    return((tensor - mean) / std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "\n",
    "# modified code for group gaps; source\n",
    "# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\n",
    "class PurgedGroupTimeSeriesSplit(_BaseKFold):\n",
    "    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n",
    "    Allows for a gap in groups to avoid potentially leaking info from\n",
    "    train into test if the model has windowed or lag features.\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals according to a\n",
    "    third-party provided group.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    The same group will not appear in two different folds (the number of\n",
    "    distinct groups has to be at least equal to the number of folds).\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of splits. Must be at least 2.\n",
    "    max_train_group_size : int, default=Inf\n",
    "        Maximum group size for a single training set.\n",
    "    group_gap : int, default=None\n",
    "        Gap between train and test\n",
    "    max_test_group_size : int, default=Inf\n",
    "        We discard this number of groups from the end of each train split\n",
    "    \"\"\"\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self,\n",
    "                 n_splits=5,\n",
    "                 *,\n",
    "                 max_train_group_size=np.inf,\n",
    "                 max_test_group_size=np.inf,\n",
    "                 group_gap=None,\n",
    "                 verbose=False\n",
    "                 ):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_group_size = max_train_group_size\n",
    "        self.group_gap = group_gap\n",
    "        self.max_test_group_size = max_test_group_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        group_gap = self.group_gap\n",
    "        max_test_group_size = self.max_test_group_size\n",
    "        max_train_group_size = self.max_train_group_size\n",
    "        n_folds = n_splits + 1\n",
    "        group_dict = {}\n",
    "        u, ind = np.unique(groups, return_index=True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_samples = _num_samples(X)\n",
    "        n_groups = _num_samples(unique_groups)\n",
    "        for idx in np.arange(n_samples):\n",
    "            if (groups[idx] in group_dict):\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "\n",
    "        group_test_size = min(n_groups // n_folds, max_test_group_size)\n",
    "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
    "                                  n_groups, group_test_size)\n",
    "        for group_test_start in group_test_starts:\n",
    "            train_array = []\n",
    "            test_array = []\n",
    "\n",
    "            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n",
    "            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n",
    "                train_array_tmp = group_dict[train_group_idx]\n",
    "                \n",
    "                train_array = np.sort(np.unique(\n",
    "                                      np.concatenate((train_array,\n",
    "                                                      train_array_tmp)),\n",
    "                                      axis=None), axis=None)\n",
    "\n",
    "            train_end = train_array.size\n",
    " \n",
    "            for test_group_idx in unique_groups[group_test_start:\n",
    "                                                group_test_start +\n",
    "                                                group_test_size]:\n",
    "                test_array_tmp = group_dict[test_group_idx]\n",
    "                test_array = np.sort(np.unique(\n",
    "                                              np.concatenate((test_array,\n",
    "                                                              test_array_tmp)),\n",
    "                                     axis=None), axis=None)\n",
    "\n",
    "            test_array  = test_array[group_gap:]\n",
    "            \n",
    "            \n",
    "            if self.verbose > 0:\n",
    "                    pass\n",
    "                    \n",
    "            yield [int(i) for i in train_array], [int(i) for i in test_array]\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "    \n",
    "# this is code slightly modified from the sklearn docs here:\n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py\n",
    "def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "    \n",
    "    cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "    jet = plt.cm.get_cmap('jet', 256)\n",
    "    seq = np.linspace(0, 1, 256)\n",
    "    _ = np.random.shuffle(seq)   # inplace\n",
    "    cmap_data = ListedColormap(jet(seq))\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                   c=indices, marker='_', lw=lw, cmap=cmap_cv,\n",
    "                   vmin=-.2, vmax=1.2)\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(range(len(X)), [ii + 1.5] * len(X),\n",
    "               c=y, marker='_', lw=lw, cmap=plt.cm.Set3)\n",
    "\n",
    "    ax.scatter(range(len(X)), [ii + 2.5] * len(X),\n",
    "               c=group, marker='_', lw=lw, cmap=cmap_data)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + ['target', 'day']\n",
    "    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Sample index', ylabel=\"CV iteration\",\n",
    "           ylim=[n_splits+2.2, -.2], xlim=[0, len(y)])\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_cv_indices_custom(cv_custom, X, y, group, ax, n_splits, lw=10):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "    \n",
    "    cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "    jet = plt.cm.get_cmap('jet', 256)\n",
    "    seq = np.linspace(0, 1, 256)\n",
    "    _ = np.random.shuffle(seq)   # inplace\n",
    "    cmap_data = ListedColormap(jet(seq))\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv_custom):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                   c=indices, marker='_', lw=lw, cmap=cmap_cv,\n",
    "                   vmin=-.2, vmax=1.2)\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(range(len(X)), [ii + 1.5] * len(X),\n",
    "               c=y, marker='_', lw=lw, cmap=plt.cm.Set3)\n",
    "\n",
    "    ax.scatter(range(len(X)), [ii + 2.5] * len(X),\n",
    "               c=group, marker='_', lw=lw, cmap=cmap_data)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + ['target', 'day']\n",
    "    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Sample index', ylabel=\"CV iteration\",\n",
    "           ylim=[n_splits+2.2, -.2], xlim=[0, len(y)])\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function accounts for variable instance counts in each split by dividing utility_pi by number of instances (but this has been removed)\n",
    "# It also does some copy of dataframe to prevent memory overwrite\n",
    "def utility_function(df_test, df_test_predictions):\n",
    "    df_test_copy = df_test.copy(deep=True)\n",
    "    df_test_copy.loc[:, 'utility_pj'] = df_test_copy['weight'] * df_test_copy['resp'] * df_test_predictions\n",
    "    #df_test_utility_pi = df_test_copy.groupby('date')['utility_pj'].sum() / df_test_copy.groupby('date')['utility_pj'].count()\n",
    "    df_test_utility_pi = df_test_copy.groupby('date')['utility_pj'].sum()\n",
    "\n",
    "    nb_unique_dates = df_test_utility_pi.shape[0]\n",
    "    \n",
    "    if (np.sqrt(df_test_utility_pi.pow(2).sum()) == 0):\n",
    "        t = 0\n",
    "\n",
    "    else:\n",
    "        t = (df_test_utility_pi.sum() / np.sqrt(df_test_utility_pi.pow(2).sum())) * (np.sqrt(250 / np.abs(nb_unique_dates)))\n",
    "        \n",
    "    u = min(max(t, 0), 6) * df_test_utility_pi.sum()\n",
    "    del df_test_copy\n",
    "    \n",
    "    return(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "def take_closest(myList, myNumber):\n",
    "    \"\"\"\n",
    "    Assumes myList is sorted. Returns closest value to myNumber.\n",
    "\n",
    "    If two numbers are equally close, return the smallest number.\n",
    "    \"\"\"\n",
    "    pos = bisect_left(myList, myNumber)\n",
    "    if pos == 0:\n",
    "        return myList[0]\n",
    "    if pos == len(myList):\n",
    "        return myList[-1]\n",
    "    before = myList[pos - 1]\n",
    "    after = myList[pos]\n",
    "    if after - myNumber < myNumber - before:\n",
    "       return after\n",
    "    else:\n",
    "       return before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOutputActivationStats:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "        \n",
    "    def __call__(self, module, module_in, module_out):\n",
    "        #self.outputs.append(module_out)\n",
    "        self.outputs.append({'mean': module_out.mean().item(), 'std': module_out.std().item(),'near_zero': (module_out<=0.05).long().sum().item()/module_out.numel()})\n",
    "        \n",
    "    def clear(self):\n",
    "        self.outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(1, 1)\n",
    "#\n",
    "#plot_cv_indices(cv, df.loc[:, FEATURES_LIST_TOTRAIN], (df['resp'] > 0), df['date'], \n",
    "#                         ax, 5, lw=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.device"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 3090'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "    \n",
    "df = pd.read_csv(DATASET_INPUT_FILE)\n",
    "df['resp_positive'] = ((df['resp'])>0)*1  # Target to predict\n",
    "\n",
    "print('Data loaded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non overlap fold generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_indexes_list = df.groupby('date')['ts_id'].first().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train_split_size = int((df.shape[0] // 5) * TRAIN_PERCENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_test_split_size = int((df.shape[0] // 5) * TEST_PERCENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_start_indexes = [take_closest(date_indexes_list, (base_train_split_size + base_test_split_size)*fold_indice) for fold_indice in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split_start_indexes = [take_closest(date_indexes_list, (base_train_split_size + base_test_split_size)*fold_indice) for fold_indice in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 477711, 958233, 1435933, 1913985]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split_start_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2390490"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_FOLDS = 5\n",
    "last_index = df.shape[0] - 1\n",
    "\n",
    "cv_table = []\n",
    "\n",
    "for fold_indice in range(NB_FOLDS):\n",
    "    fold_train_start_index = train_split_start_indexes[fold_indice]\n",
    "    \n",
    "    if (fold_indice == NB_FOLDS - 1):    \n",
    "        nextfold_train_start_index = last_index\n",
    "        \n",
    "    else:\n",
    "        nextfold_train_start_index = train_split_start_indexes[fold_indice + 1]\n",
    "    \n",
    "    fold_test_start_index = take_closest(date_indexes_list, int(TRAIN_PERCENT * (nextfold_train_start_index - fold_train_start_index) + fold_train_start_index  ))\n",
    "    \n",
    "    cv_table.append(fold_train_start_index)\n",
    "    cv_table.append(fold_test_start_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_table.append(last_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_tuples = []\n",
    "\n",
    "for i in range(0, NB_FOLDS*2, 2):\n",
    "    cv_tuples.append([df.loc[cv_table[i]:cv_table[i+1]-1, :].index.to_list(), df.loc[cv_table[i+1]:cv_table[i+2]-1, :].index.to_list()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_tuples_generator = iter(cv_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "#plot_cv_indices_custom(cv_tuples_generator, df.loc[:, FEATURES_LIST_TOTRAIN], (df['resp'] > 0), df['date'], \n",
    "#                         ax, 5, lw=20); \n",
    "\n",
    "#cv_tuples_generator = iter(cv_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of training set :\n",
    "#train_sets_table =  [cv_tuples[i][0] for i in range(5)]\n",
    "#sum([len(train_set_table) for train_set_table in train_sets_table])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our old time series split (with overlap : required 1 neural network trained per split)\n",
    "# But in this script it's not needed because we're training 1 unique network, with a different fold strategy (non overlaped)\n",
    "#cv = PurgedGroupTimeSeriesSplit(\n",
    "#    n_splits=5,\n",
    "#    max_train_group_size=180,\n",
    "#    group_gap=20,\n",
    "#    max_test_group_size=60\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_index, test_index = next(cv.split(df, (df['resp'] > 0)*1, df['date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(df.loc[train_index, 'resp'] > 0).astype(np.byte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mean = df.loc[:, FEATURES_LIST_TOTRAIN].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(f_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Sum of model parameters:')\n",
    "#[print(p.sum()) for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writer = SummaryWriter()\n",
    "\n",
    "#writer.add_text('test', 'test:'  + str(model).replace('\\n', '<BR>'))\n",
    "\n",
    "#writer.flush()\n",
    "#writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#str([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_list = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(cv_tuples_generator):\n",
    "    folds_list.append((train_index, test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_list_train = [folds_list[i][0] for i in range(5)]\n",
    "folds_list_train_flat = [folds_list_train_item for sublist in folds_list_train for folds_list_train_item in sublist]\n",
    "folds_list_train_unique = list(set(folds_list_train_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1677155"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds_list_train_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1677155"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([len(folds_list_train_item) for folds_list_train_item in folds_list_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1677155"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds_list_train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_list_test = [folds_list[i][1] for i in range(5)]\n",
    "folds_list_test_flat = [folds_list_test_item for sublist in folds_list_test for folds_list_test_item in sublist]\n",
    "folds_list_test_unique = set(folds_list_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "713335"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([len(folds_list_test_item) for folds_list_test_item in folds_list_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "713335"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds_list_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2390490"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds_list_train_flat) + len(folds_list_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141980, 130)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[folds_list_test[4], FEATURES_LIST_TOTRAIN].to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2390491, 139)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n"
     ]
    }
   ],
   "source": [
    "print('Training started')\n",
    "patience=5\n",
    "\n",
    "utility_scores = [None] * 5\n",
    "accuracy_scores = [None] * 5\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "ts_train = torch.tensor(df.loc[folds_list_train_unique, FEATURES_LIST_TOTRAIN].to_numpy(), device='cuda')\n",
    "ts_train_y = torch.tensor((df.loc[folds_list_train_unique, 'resp'] > 0).astype(np.byte).to_numpy(), device='cuda')\n",
    "ts_train_y_reg = torch.tensor(df.loc[folds_list_train_unique, 'resp'].to_numpy(), device='cuda')\n",
    "\n",
    "# Normalize data\n",
    "ts_train_mean = torch.mean(ts_train, axis=0)\n",
    "ts_train_std = torch.std(ts_train, axis=0)\n",
    "#ts_train = pyStandardScale(ts_train, ts_train_mean, ts_train_std)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(ts_train, ts_train_y, ts_train_y_reg)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True) # pin_memory : VOIR RESULTAT\n",
    "\n",
    "ts_test = [None] * 5\n",
    "ts_test_y = [None] * 5    \n",
    "ts_test_y_reg = [None] * 5   \n",
    "test_dataset = [None] * 5\n",
    "test_loader = [None] * 5\n",
    "\n",
    "for fold_indice in range(5):\n",
    "    ts_test[fold_indice] = torch.tensor(df.loc[folds_list_test[fold_indice], FEATURES_LIST_TOTRAIN].to_numpy(), device='cuda')\n",
    "    ts_test_y[fold_indice] = torch.tensor((df.loc[folds_list_test[fold_indice], 'resp'] > 0).astype(np.byte).to_numpy(), device='cuda')\n",
    "    ts_test_y_reg[fold_indice] = torch.tensor(df.loc[folds_list_test[fold_indice], 'resp'].to_numpy(), device='cuda')\n",
    "\n",
    "    # Normalize\n",
    "    #ts_test[fold_indice] = pyStandardScale(ts_test[fold_indice], ts_train_mean, ts_train_std)\n",
    "    \n",
    "    test_dataset[fold_indice] = torch.utils.data.TensorDataset(ts_test[fold_indice], ts_test_y[fold_indice], ts_test_y_reg[fold_indice])\n",
    "    test_loader[fold_indice] = torch.utils.data.DataLoader(test_dataset[fold_indice], batch_size=BATCH_SIZE)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "'''\n",
    "model = nn.Sequential(\n",
    "        #nn.Dropout(0.2),\n",
    "        nn.Linear(len(FEATURES_LIST_TOTRAIN), 200),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.7),\n",
    "\n",
    "        nn.Linear(200, 100),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.7),\n",
    "    \n",
    "        nn.Linear(100, 1),\n",
    "        nn.Sigmoid(),\n",
    "    ).double().to('cuda')\n",
    "'''\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    #def __init__(self, n_feature, n_hidden): \n",
    "    def __init__(self): \n",
    "        super(MLP, self).__init__() \n",
    "\n",
    "        #nn.Dropout(0.2),\n",
    "        self.layer1 = nn.Linear(len(FEATURES_LIST_TOTRAIN), 1300)\n",
    "        #self.batchnorm1 = nn.BatchNorm1d(130)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "\n",
    "        self.layer2 = nn.Linear(1300, 600)\n",
    "        #self.batchnorm2 = nn.BatchNorm1d(130)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.layer3 = nn.Linear(600, 1)\n",
    "        \n",
    "        #self.layer11_classif = nn.Linear(30, 1)\n",
    "        #self.act11_classif = nn.Sigmoid()  \n",
    "\n",
    "        #self.layer11_reg = nn.Linear(30, 1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.act1(self.layer1(x)))\n",
    "        x = self.dropout2(self.act2(self.layer2(x)))\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        #x_out_classif = nn.Sigmoid()(x[:, 0]).unsqueeze(-1)\n",
    "        #x_out_reg = x[:, 1].unsqueeze(-1)\n",
    "\n",
    "        #x_out_classif = nn.Sigmoid()(x[:, 0])\n",
    "        #x_out_reg = x[:, 1]\n",
    "        x_out_reg = x\n",
    "\n",
    "        #return x_out_classif, x_out_reg\n",
    "        return x_out_reg\n",
    "\n",
    "model = MLP().double().to('cuda')\n",
    "print('Model created')\n",
    "\n",
    "#print('Number of model parameters :')\n",
    "#numel_list = [p.numel() for p in model.parameters()]\n",
    "#sum(numel_list), numel_list\n",
    "\n",
    "loss_fn = nn.BCELoss().to('cuda')\n",
    "loss_fn_reg = nn.MSELoss().to('cuda')\n",
    "\n",
    "#def MSE_SignedLoss(output, target):\n",
    "    #return((nn.LeakyReLU()(-(output*target)) / torch.abs(output*target)) * loss_fn_reg(output, target))\n",
    "\n",
    "def MSE_SignedLoss(output, target):\n",
    "    return(\n",
    "        torch.sqrt(\n",
    "            torch.mean(\n",
    "                (nn.LeakyReLU()(-(output*target)) / torch.abs(output*target)) * torch.pow(output - target, 2)\n",
    "        )\n",
    "    )\n",
    "    )\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) \n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-2) \n",
    "\n",
    "model.eval()\n",
    "#start_accuracy = accuracy_score(ts_test_y.cpu().numpy(), (model(ts_test).squeeze() > 0.5).cpu().numpy())\n",
    "#start_utility_score = utility_function(df.loc[test_index], (model(ts_test).squeeze() > 0.5).cpu().numpy())\n",
    "#print('Start Validation Accuracy: {:.4f}'.format(start_accuracy))\n",
    "#print('Start Validation Utility: {:.4f}'.format(start_utility_score))\n",
    "\n",
    "### Call back to save activation stats (mean, std dev and near 0 values after activation functions)\n",
    "\n",
    "Val_Loss = 0\n",
    "N_Samples = 0\n",
    "\n",
    "the_last_loss = 100\n",
    "the_last_utility_score = 0\n",
    "the_last_accuracy = 0\n",
    "trigger_times=0\n",
    "early_stopping_met = False\n",
    "\n",
    "for epoch in range(NUM_EPOCHS): \n",
    "    running_loss = 0.0        \n",
    "    \n",
    "    # Setting hook for activation layers stats\n",
    "    hook_handles = []\n",
    "    save_output_activation_stats = []\n",
    "\n",
    "    for layer in model.modules():\n",
    "        if ('activation' in str(type(layer))):\n",
    "            save_output_activation_stats_1layer = SaveOutputActivationStats()\n",
    "            handle = layer.register_forward_hook(save_output_activation_stats_1layer)\n",
    "            save_output_activation_stats.append(save_output_activation_stats_1layer)\n",
    "            hook_handles.append(handle)\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        #inputs, labels = batch[0], batch[1]\n",
    "        inputs, labels, labels_reg = batch[0].to('cuda'), batch[1].to('cuda'), batch[2].to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "            #outputs_classif, outputs_reg = model(inputs)\n",
    "            outputs_reg = model(inputs)\n",
    "            #loss_classif = loss_fn(outputs_classif.unsqueeze(-1), labels.unsqueeze(-1).double())\n",
    "            loss_classif = 0\n",
    "            #loss_reg = MSE_SignedLoss(outputs_reg, labels_reg.unsqueeze(-1).double()) * torch.tensor(864.625) # Coefficient to balance reg loss which is much smaller\n",
    "            loss_reg = MSE_SignedLoss(outputs_reg, labels_reg.unsqueeze(-1).double()) # Coefficient to balance reg loss which is much smaller\n",
    "            #loss_reg = loss_fn_reg(outputs_reg.unsqueeze(-1), labels_reg.unsqueeze(-1).double()) # Coefficient to balance reg loss which is much smaller\n",
    "            \n",
    "            #loss = loss_classif + loss_reg\n",
    "            loss = loss_reg\n",
    "            #loss = loss_classif\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # update local train loss\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    # update global train loss\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print('Epoch({}) - Training Loss: {:.4f}'.format(epoch, epoch_loss))\n",
    "\n",
    "    writer.add_scalar(f\"Global train/loss\", epoch_loss, epoch)\n",
    "\n",
    "    # Write activation stats graphs\n",
    "    for layer_number,save_output_activation_stats_layer in enumerate(save_output_activation_stats):\n",
    "        df_stats_layer = pd.DataFrame(save_output_activation_stats_layer.outputs)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(25, 4))\n",
    "\n",
    "        ax[0].set_title(f'Layer {layer_number} : Mean activation value', fontsize=16)\n",
    "        ax[0].set_xlabel('Batch instances')\n",
    "        ax[0].set_ylabel('Mean')\n",
    "        ax[0].plot(range(df_stats_layer.shape[0]), df_stats_layer['mean'])\n",
    "\n",
    "        ax[1].set_title(f'Layer {layer_number} : Std deviation activation value', fontsize=16)\n",
    "        ax[1].set_xlabel('Batch instances')\n",
    "        ax[1].set_ylabel('Standard deviation')\n",
    "        ax[1].plot(range(df_stats_layer.shape[0]), df_stats_layer['std'])\n",
    "\n",
    "        ax[2].set_title(f'Layer {layer_number} : Percentage of activation values near zero', fontsize=16)\n",
    "        ax[2].set_xlabel('Batch instances')\n",
    "        ax[2].set_ylabel('Percentage')\n",
    "        ax[2].plot(range(df_stats_layer.shape[0]), df_stats_layer['near_zero']);\n",
    "        \n",
    "        plot_buf = io.BytesIO()\n",
    "        plt.savefig(plot_buf, format='jpeg')\n",
    "        plt.close()\n",
    "        \n",
    "        plot_buf.seek(0)\n",
    "        image = PIL.Image.open(plot_buf)\n",
    "        image = transforms.ToTensor()(image)\n",
    "        writer.add_image(\"Train activation stats/Activation stats layer \" + str(layer_number), image, epoch)\n",
    "    \n",
    "    # Validation \n",
    "    model.eval()\n",
    "\n",
    "    vrunning_loss = [None] * 5\n",
    "    vrunning_loss_classif = [None] * 5\n",
    "    vrunning_loss_reg = [None] * 5\n",
    "    num_samples = [None] * 5\n",
    "    vepoch_loss_folds = [None] * 5\n",
    "    vepoch_loss_classif_folds = [None] * 5\n",
    "    vepoch_loss_reg_folds = [None] * 5\n",
    "    vepoch_accuracy_folds = [None] * 5\n",
    "    vepoch_utility_score_folds = [None] * 5\n",
    "    \n",
    "    for fold_indice in range(5):    \n",
    "        vrunning_loss[fold_indice] = 0.0\n",
    "        vrunning_loss_classif[fold_indice] = 0.0\n",
    "        vrunning_loss_reg[fold_indice] = 0.0\n",
    "        num_samples[fold_indice] = 0\n",
    "\n",
    "        for batch in test_loader[fold_indice]:\n",
    "            inputs, labels, labels_reg = batch[0].to('cuda'), batch[1].to('cuda'), batch[2].to('cuda')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                #outputs_classif, outputs_reg = model(inputs)\n",
    "                outputs_reg = model(inputs)\n",
    "                #loss_classif = loss_fn(outputs_classif.unsqueeze(-1), labels.unsqueeze(-1).double())\n",
    "\n",
    "                #loss_reg = loss_fn_reg(outputs_reg, torch.sigmoid(labels_reg.unsqueeze(-1).double()))\n",
    "                #loss_reg = loss_fn_reg(outputs_reg.unsqueeze(-1), labels_reg.unsqueeze(-1).double()) # Coefficient to balance reg loss which is much smaller\n",
    "                #loss_reg = MSE_SignedLoss(outputs_reg, labels_reg.unsqueeze(-1).double()) * torch.tensor(864.625) # Coefficient to balance reg loss which is much smaller\n",
    "                loss_reg = MSE_SignedLoss(outputs_reg, labels_reg.unsqueeze(-1).double()) # Coefficient to balance reg loss which is much smaller\n",
    "                \n",
    "                #loss = loss_classif + loss_reg \n",
    "                #loss = loss_classif \n",
    "                loss = loss_reg \n",
    "                \n",
    "            vrunning_loss[fold_indice] += loss.item() * inputs.size(0)\n",
    "            num_samples[fold_indice] += labels.size(0)\n",
    "            \n",
    "            #vrunning_loss_classif[fold_indice] += loss_classif.item() * inputs.size(0)\n",
    "            vrunning_loss_reg[fold_indice] += loss_reg.item() * inputs.size(0)\n",
    "            \n",
    "            vepoch_loss_folds[fold_indice] = vrunning_loss[fold_indice] / num_samples[fold_indice]\n",
    "            #vepoch_loss_classif_folds[fold_indice] = vrunning_loss_classif[fold_indice] / num_samples[fold_indice]\n",
    "            vepoch_loss_reg_folds[fold_indice] = vrunning_loss_reg[fold_indice] / num_samples[fold_indice]\n",
    "\n",
    "        print('Epoch({}) - Fold {} - Validation Loss : {:.4f}'.format(epoch, fold_indice, vepoch_loss_folds[fold_indice]))\n",
    "        #print('Epoch({}) - Fold {} -> Validation Loss Classif : {:.4f}'.format(epoch, fold_indice, vepoch_loss_classif_folds[fold_indice]))\n",
    "        print('Epoch({}) - Fold {} -> Validation Loss Reg : {:.4f}'.format(epoch, fold_indice, vepoch_loss_reg_folds[fold_indice]))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            vepoch_accuracy_folds[fold_indice] = accuracy_score(ts_test_y[fold_indice].cpu().numpy(), (model(ts_test[fold_indice]) > 0).squeeze().cpu().numpy())  # model...[0] is the classification output of model\n",
    "            vepoch_utility_score_folds[fold_indice] = utility_function(df.loc[folds_list_test[fold_indice]], (model(ts_test[fold_indice]) > 0).squeeze().cpu().numpy())\n",
    "        print('Epoch({}) - Fold {} - Validation Accuracy : {:.4f}'.format(epoch, fold_indice, vepoch_accuracy_folds[fold_indice]))\n",
    "        print('Epoch({}) - Fold {} - Validation Utility score : {:.4f}'.format(epoch, fold_indice, vepoch_utility_score_folds[fold_indice]))\n",
    "        \n",
    "            \n",
    "    # update epoch loss\n",
    "    vepoch_loss = sum(vepoch_loss_folds) / len(vepoch_loss_folds)\n",
    "    vepoch_accuracy = sum(vepoch_accuracy_folds) / len(vepoch_accuracy_folds)\n",
    "    vepoch_utility_score = sum(vepoch_utility_score_folds) #/ len(vepoch_utility_score_folds)\n",
    "    print('Epoch({}) - GLOBAL - Validation Loss: {:.4f}'.format(epoch, vepoch_loss))\n",
    "    print('Epoch({}) - GLOBAL - Validation Accuracy: {:.4f}'.format(epoch, vepoch_accuracy))\n",
    "    print('Epoch({}) - GLOBAL - Validation Utility score: {:.4f}'.format(epoch, vepoch_utility_score))\n",
    "\n",
    "    #print(f'Sum of model parameters ({epoch}):')\n",
    "    #[print(p.sum()) for p in model.parameters()]\n",
    "\n",
    "    writer.add_scalar(\"Global valid/Loss\", vepoch_loss, epoch)\n",
    "    writer.add_scalar(\"Global valid/Accuracy\", vepoch_accuracy, epoch)\n",
    "    writer.add_scalar(\"Global valid/Utility\", vepoch_utility_score, epoch)\n",
    "\n",
    "    for fold_indice in range(5):\n",
    "        writer.add_scalar(\"Fold valid Loss/Loss fold \"+str(fold_indice), vepoch_loss_folds[fold_indice], epoch)\n",
    "        writer.add_scalar(\"Fold valid Accuracy/Accuracy fold \"+str(fold_indice), vepoch_accuracy_folds[fold_indice], epoch)\n",
    "        writer.add_scalar(\"Fold valid Utility/Utility fold \"+str(fold_indice), vepoch_utility_score_folds[fold_indice], epoch)\n",
    "        \n",
    "    \n",
    "    writer.flush()\n",
    "\n",
    "    #if (epoch == 7):\n",
    "        #print('EPOCH 7 ATTAINED')\n",
    "        #break\n",
    "    \n",
    "    # Check if Early Stopping\n",
    "    #if vepoch_loss > the_last_loss:\n",
    "    #if (vepoch_utility_score < the_last_utility_score) and (vepoch_loss > the_last_loss) and (vepoch_accuracy < the_last_accuracy):\n",
    "    if (vepoch_loss > the_last_loss):\n",
    "        trigger_times += 1\n",
    "\n",
    "        print(f'Intermediate early stopping : vepoch_loss = {vepoch_loss:.4f}, the_last_loss={the_last_loss:.4f}')\n",
    "        #print(f'Intermediate early stopping : vepoch_accuracy = {vepoch_accuracy:.4f}, the_last_utility_score={the_last_accuracy:.4f}')\n",
    "        #print(f'Intermediate early stopping : vepoch_utility_score = {vepoch_utility_score:.4f}, the_last_utility_score={the_last_utility_score:.4f}')\n",
    "\n",
    "        if trigger_times >= patience:\n",
    "            print('Meet Early stopping!')\n",
    "            early_stopping_met = True\n",
    "            ##torch.save(model.state_dict(), f'model_{fold}.pt')\n",
    "            break\n",
    "    else:\n",
    "        trigger_times = 0\n",
    "        the_last_loss = vepoch_loss\n",
    "        the_last_utility_score = vepoch_utility_score\n",
    "        the_last_accuracy = vepoch_accuracy\n",
    "        \n",
    "        the_last_utility_score_folds = vepoch_utility_score_folds\n",
    "        the_last_accuracy_folds = vepoch_accuracy_folds\n",
    "        \n",
    "        the_best_epoch = epoch\n",
    "\n",
    "        # Save model for the best version so far\n",
    "        print(f'Saving model corresponding to last_utility_score == {the_last_utility_score}')\n",
    "        torch.save(model.state_dict(), f'model_NN_allfolds_V1.pt')\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "if (early_stopping_met == False):\n",
    "    print(\"Didn't meet early stopping : saving final model\")\n",
    "    # Save model if don't meet early stopping\n",
    "    torch.save(model.state_dict(), f'model_NN_allfolds_V1.pt')\n",
    "\n",
    "#utility_scores.append(the_last_utility_score)\n",
    "#accuracy_scores.append(the_last_accuracy)\n",
    "writer.add_text(f\"Global valid/Utility\", f\"Best utility: {the_last_utility_score}\", the_best_epoch)\n",
    "        \n",
    "scores_results = {'utility_score': the_last_utility_score, 'utility_scores': the_last_utility_score_folds, 'utility_score_std': np.std(the_last_utility_score_folds), 'accuracy_scores': the_last_accuracy_folds}\n",
    "\n",
    "writer.add_text('Final utility score', str(scores_results))\n",
    "writer.add_text('Batch size', str(BATCH_SIZE))\n",
    "writer.add_text('Patience', str(patience))\n",
    "writer.add_text('Number of epochs', str(NUM_EPOCHS))\n",
    "writer.add_text('Number of parameters per layer', str([p.numel() for p in model.parameters()]))\n",
    "writer.add_text('Model architecture', str(model).replace('\\n', '<BR>'))\n",
    "writer.add_text('Comment', MODEL_COMMENT)\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print('Training summary:')\n",
    "print(scores_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility_function(df_test, df_test_predictions):\n",
    "    df_test_copy = df_test.copy(deep=True)\n",
    "    df_test_copy.loc[:, 'utility_pj'] = df_test_copy['weight'] * df_test_copy['resp'] * df_test_predictions\n",
    "    #df_test_utility_pi = df_test_copy.groupby('date')['utility_pj'].sum() / df_test_copy.groupby('date')['utility_pj'].count()\n",
    "    df_test_utility_pi = df_test_copy.groupby('date')['utility_pj'].sum()\n",
    "\n",
    "    nb_unique_dates = df_test_utility_pi.shape[0]\n",
    "    \n",
    "    if (np.sqrt(df_test_utility_pi.pow(2).sum()) == 0):\n",
    "        t = 0\n",
    "\n",
    "    else:\n",
    "        t = (df_test_utility_pi.sum() / np.sqrt(df_test_utility_pi.pow(2).sum())) * (np.sqrt(250 / np.abs(nb_unique_dates)))\n",
    "        \n",
    "    u = min(max(t, 0), 6) * df_test_utility_pi.sum()\n",
    "    del df_test_copy\n",
    "    \n",
    "    return(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.loc[folds_list_test[fold_indice]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_predictions = (model(ts_test[fold_indice]) > 0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_copy = df_test.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_predictions.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336609   -0.005333\n",
       "336610    0.024160\n",
       "336611    0.011158\n",
       "336612   -0.012638\n",
       "336613    0.008440\n",
       "            ...   \n",
       "477706   -0.003889\n",
       "477707   -0.001269\n",
       "477708    0.008150\n",
       "477709    0.004887\n",
       "477710   -0.003817\n",
       "Name: resp, Length: 141102, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_copy['resp'] * df_test_predictions.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "relu(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"<ipython-input-82-eed93e59b991>\"\u001b[0m, line \u001b[1;32m3\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    (nn.ReLU()(-(df_test_predictions*df_test.to_numpy())) / torch.abs(df_test_predictions*df_test.to_numpy())) * torch.pow(df_test_predictions - df_test.to_numpy(), 2)))\n",
      "  File \u001b[1;32m\"/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[1;32m727\u001b[0m, in \u001b[1;35m_call_impl\u001b[0m\n    result = self.forward(*input, **kwargs)\n",
      "  File \u001b[1;32m\"/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/torch/nn/modules/activation.py\"\u001b[0m, line \u001b[1;32m102\u001b[0m, in \u001b[1;35mforward\u001b[0m\n    return F.relu(input, inplace=self.inplace)\n",
      "\u001b[0;36m  File \u001b[0;32m\"/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/torch/nn/functional.py\"\u001b[0;36m, line \u001b[0;32m1136\u001b[0;36m, in \u001b[0;35mrelu\u001b[0;36m\u001b[0m\n\u001b[0;31m    result = torch.relu(input)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m\u001b[0;31m:\u001b[0m relu(): argument 'input' (position 1) must be Tensor, not numpy.ndarray\n"
     ]
    }
   ],
   "source": [
    "        torch.sqrt(\n",
    "            torch.mean(\n",
    "                (nn.ReLU()(-(df_test_predictions*df_test.to_numpy())) / torch.abs(df_test_predictions*df_test.to_numpy())) * torch.pow(df_test_predictions - df_test.to_numpy(), 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141102, 139)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[folds_list_test[fold_indice]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([141102, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(ts_test[fold_indice]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.5434, 0.5418,  ..., 0.5532, 0.5421], device='cuda:0',\n",
       "       dtype=torch.float64, grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0031, -0.0032,  ..., -0.0032, -0.0031], device='cuda:0',\n",
       "       dtype=torch.float64, grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "(model(ts_test[fold_indice])[1].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model(ts_test[fold_indice])[1].squeeze() > 0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "<ipython-input-6-b97e47e75da2>:10: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  t = (df_test_utility_pi.sum() / np.sqrt(df_test_utility_pi.pow(2).sum())) * (np.sqrt(250 / np.abs(nb_unique_dates)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('always')\n",
    "\n",
    "utility_function(df.loc[folds_list_test[fold_indice]], (model(ts_test[fold_indice])[1].squeeze() > 0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  ..., False, False], device='cuda:0')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(ts_test[fold_indice])[1].squeeze() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_SignedLoss(output, target):\n",
    "    return(\n",
    "        torch.sqrt(\n",
    "            torch.mean(\n",
    "                (nn.ReLU()(-(output*target)) / torch.abs(output*target)) * torch.pow(output - target, 2)\n",
    "        )\n",
    "    )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = outputs_reg\n",
    "target = labels_reg.unsqueeze(-1).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0254, device='cuda:0', dtype=torch.float64, grad_fn=<SqrtBackward>)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(torch.mean((nn.ReLU()(-(output*target)) / torch.abs(output*target)) * torch.pow(output - target, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0094],\n",
       "        [-0.0127],\n",
       "        ...,\n",
       "        [-0.0086],\n",
       "        [-0.0037]], device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0091],\n",
       "        [-0.0070],\n",
       "        ...,\n",
       "        [-0.0111],\n",
       "        [ 0.0046]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0965, device='cuda:0', dtype=torch.float64, grad_fn=<SqrtBackward>)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_SignedLoss(outputs_reg, labels_reg.unsqueeze(-1).double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0962, device='cuda:0', dtype=torch.float64, grad_fn=<SqrtBackward>)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(torch.mean((nn.LeakyReLU()(-(outputs_reg*labels_reg.unsqueeze(-1).double())) \n",
    " / torch.abs(outputs_reg*labels_reg.unsqueeze(-1).double(),)) * torch.pow(outputs_reg - labels_reg.unsqueeze(-1).double(), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 1])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 1])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_reg.unsqueeze(-1).double().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0928],\n",
       "        [-0.1096],\n",
       "        ...,\n",
       "        [-0.1292],\n",
       "        [-0.1241]], device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0065],\n",
       "        [-0.0016],\n",
       "        ...,\n",
       "        [ 0.0042],\n",
       "        [ 0.0003]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_reg.unsqueeze(-1).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.0025e-04],\n",
       "        [-1.7041e-04],\n",
       "        ...,\n",
       "        [ 5.4833e-04],\n",
       "        [ 3.7653e-05]], device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(outputs_reg * labels_reg.unsqueeze(-1).double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.0025e-06],\n",
       "        [-1.7041e-06],\n",
       "        ...,\n",
       "        [ 5.4833e-04],\n",
       "        [ 3.7653e-05]], device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<LeakyReluBackward0>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.LeakyReLU()(-(outputs_reg * labels_reg.unsqueeze(-1).double()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30.6613, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(MSE_SignedLoss(outputs_reg, labels_reg.unsqueeze(-1).double()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.8765, device='cuda:0', dtype=torch.float64, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn_reg(outputs_reg, labels_reg.unsqueeze(-1).double()) * torch.tensor(864.625) # Coefficient to balance reg loss which is much smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.5451, 0.5409,  ..., 0.5415, 0.5436], device='cuda:0',\n",
       "        dtype=torch.float64, grad_fn=<SigmoidBackward>),\n",
       " tensor([-0.1072, -0.0855,  ..., -0.1060, -0.0965], device='cuda:0',\n",
       "        dtype=torch.float64, grad_fn=<SelectBackward>))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_classif, outputs_reg = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 1])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_classif.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6955, device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<BinaryCrossEntropyBackward>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(outputs_classif.unsqueeze(-1), labels.unsqueeze(-1).double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    #def __init__(self, n_feature, n_hidden): \n",
    "    def __init__(self): \n",
    "        super(MLP, self).__init__() \n",
    "\n",
    "        #nn.Dropout(0.2),\n",
    "        self.layer1 = nn.Linear(len(FEATURES_LIST_TOTRAIN), 130)\n",
    "        #self.batchnorm1 = nn.BatchNorm1d(130)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "\n",
    "        self.layer2 = nn.Linear(130, 130)\n",
    "        #self.batchnorm1 = nn.BatchNorm1d(130)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.layer3 = nn.Linear(130, 130)\n",
    "        #self.batchnorm1 = nn.BatchNorm1d(130)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "\n",
    "        self.layer4 = nn.Linear(130, 130)\n",
    "        #self.batchnorm1 = nn.BatchNorm1d(130)\n",
    "        self.act4 = nn.ReLU()\n",
    "        self.dropout4 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.layer5 = nn.Linear(130, 130)\n",
    "        #self.batchnorm1 = nn.BatchNorm1d(130)\n",
    "        self.act5 = nn.ReLU()\n",
    "        self.dropout5 = nn.Dropout(0.3)\n",
    "\n",
    "        self.layer6 = nn.Linear(130, 130)\n",
    "        #self.batchnorm1 = nn.BatchNorm1d(130)\n",
    "        self.act6 = nn.ReLU()\n",
    "        self.dropout6 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.layer7 = nn.Linear(130, 130)\n",
    "        #self.batchnorm1 = nn.BatchNorm1d(130)\n",
    "        self.act7 = nn.ReLU()\n",
    "        self.dropout7 = nn.Dropout(0.3)\n",
    "\n",
    "        self.layer8 = nn.Linear(130, 130)\n",
    "        #self.batchnorm1 = nn.BatchNorm1d(130)\n",
    "        self.act8 = nn.ReLU()\n",
    "        self.dropout8 = nn.Dropout(0.3)\n",
    "\n",
    "        self.layer9 = nn.Linear(130, 60)\n",
    "        #self.batchnorm1 = nn.BatchNorm1d(130)\n",
    "        self.act9 = nn.ReLU()\n",
    "        self.dropout9 = nn.Dropout(0.3)\n",
    "\n",
    "        self.layer10 = nn.Linear(60, 30)\n",
    "        #self.batchnorm1 = nn.BatchNorm1d(130)\n",
    "        self.act10 = nn.ReLU()\n",
    "        self.dropout10 = nn.Dropout(0.3)\n",
    "\n",
    "        self.layer11 = nn.Linear(30, 2)\n",
    "        \n",
    "        #self.layer11_classif = nn.Linear(30, 1)\n",
    "        #self.act11_classif = nn.Sigmoid()  \n",
    "\n",
    "        #self.layer11_reg = nn.Linear(30, 1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.act1(self.layer1(x)))\n",
    "        x = self.dropout2(self.act2(self.layer2(x)))\n",
    "        x = self.dropout3(self.act3(self.layer3(x)))\n",
    "        x = self.dropout4(self.act4(self.layer4(x)))\n",
    "        x = self.dropout5(self.act5(self.layer5(x)))\n",
    "        x = self.dropout6(self.act6(self.layer6(x)))\n",
    "        x = self.dropout7(self.act7(self.layer7(x)))\n",
    "        x = self.dropout8(self.act8(self.layer8(x)))\n",
    "        x = self.dropout9(self.act9(self.layer9(x)))\n",
    "        x = self.dropout10(self.act10(self.layer10(x)))\n",
    "        \n",
    "        x = self.layer11(x)\n",
    "\n",
    "        x_out_classif = nn.Sigmoid()(x[:, 0])\n",
    "        x_out_reg = x[:, 1]\n",
    "\n",
    "        return x_out_classif, x_out_reg\n",
    "        #return x\n",
    "\n",
    "model = MLP().double().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.5026, 0.5040,  ..., 0.5032, 0.5014], device='cuda:0',\n",
       "        dtype=torch.float64, grad_fn=<SigmoidBackward>),\n",
       " tensor([0.0799, 0.0667,  ..., 0.0797, 0.0894], device='cuda:0',\n",
       "        dtype=torch.float64, grad_fn=<SelectBackward>))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8808)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Sigmoid()(torch.tensor(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Sigmoid()(model(inputs)[:, 1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cnt batch train:410\n",
      "Epoch(7) - Training Loss: 0.0008\n"
     ]
    }
   ],
   "source": [
    "#### Test : only 1 epoch loop\n",
    "epoch = 7\n",
    "\n",
    "running_loss = 0.0        \n",
    "model.train()\n",
    "\n",
    "for layer in model.modules():\n",
    "    if ('activation' in str(type(layer))):\n",
    "        save_output_activation_stats_1layer = SaveOutputActivationStats()\n",
    "        handle = layer.register_forward_hook(save_output_activation_stats_1layer)\n",
    "        save_output_activation_stats.append(save_output_activation_stats_1layer)\n",
    "        hook_handles.append(handle)\n",
    "        \n",
    "for batch in train_loader:\n",
    "    #inputs, labels = batch[0], batch[1]\n",
    "    inputs, labels, labels_reg = batch[0].to('cuda'), batch[1].to('cuda'), batch[2].to('cuda')\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.set_grad_enabled(True):\n",
    "        outputs_classif, outputs_reg = model(inputs)\n",
    "        loss_classif = loss_fn(outputs_classif, labels.unsqueeze(-1).double())\n",
    "        loss_reg = loss_fn_reg(outputs_reg, labels_reg.unsqueeze(-1).double())\n",
    "        loss = loss_classif + loss_reg\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# update local train loss\n",
    "running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "# update global train loss\n",
    "epoch_loss = running_loss / len(train_loader.dataset)\n",
    "print('Epoch({}) - Training Loss: {:.4f}'.format(epoch, epoch_loss))\n",
    "\n",
    "writer.add_scalar(f\"Global train/loss\", epoch_loss, epoch)\n",
    "\n",
    "# Write activation stats graphs\n",
    "for layer_number,save_output_activation_stats_layer in enumerate(save_output_activation_stats):            \n",
    "    df_stats_layer = pd.DataFrame(save_output_activation_stats_layer.outputs)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(25, 4))\n",
    "\n",
    "    ax[0].set_title(f'Layer {layer_number} : Mean activation value', fontsize=16)\n",
    "    ax[0].set_xlabel('Batch instances')\n",
    "    ax[0].set_ylabel('Mean')\n",
    "    ax[0].plot(range(df_stats_layer.shape[0]), df_stats_layer['mean'])\n",
    "\n",
    "    ax[1].set_title(f'Layer {layer_number} : Std deviation activation value', fontsize=16)\n",
    "    ax[1].set_xlabel('Batch instances')\n",
    "    ax[1].set_ylabel('Standard deviation')\n",
    "    ax[1].plot(range(df_stats_layer.shape[0]), df_stats_layer['std'])\n",
    "\n",
    "    ax[2].set_title(f'Layer {layer_number} : Percentage of activation values near zero', fontsize=16)\n",
    "    ax[2].set_xlabel('Batch instances')\n",
    "    ax[2].set_ylabel('Percentage')\n",
    "    ax[2].plot(range(df_stats_layer.shape[0]), df_stats_layer['near_zero']);\n",
    "\n",
    "    plot_buf = io.BytesIO()\n",
    "    plt.savefig(plot_buf, format='jpeg')\n",
    "    plt.close()\n",
    "\n",
    "    plot_buf.seek(0)\n",
    "    image = PIL.Image.open(plot_buf)\n",
    "    image = transforms.ToTensor()(image)\n",
    "    writer.add_image(\"Train activation stats/Activation stats layer \" + str(layer_number), image, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>near_zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.508536</td>\n",
       "      <td>0.036475</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.506510</td>\n",
       "      <td>0.038325</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.507212</td>\n",
       "      <td>0.037117</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.507142</td>\n",
       "      <td>0.035025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.505896</td>\n",
       "      <td>0.038326</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0.503037</td>\n",
       "      <td>0.036197</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.504640</td>\n",
       "      <td>0.038607</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.504351</td>\n",
       "      <td>0.037685</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.504257</td>\n",
       "      <td>0.037360</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.506839</td>\n",
       "      <td>0.038380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean       std  near_zero\n",
       "0    0.508536  0.036475        0.0\n",
       "1    0.506510  0.038325        0.0\n",
       "2    0.507212  0.037117        0.0\n",
       "3    0.507142  0.035025        0.0\n",
       "4    0.505896  0.038326        0.0\n",
       "..        ...       ...        ...\n",
       "405  0.503037  0.036197        0.0\n",
       "406  0.504640  0.038607        0.0\n",
       "407  0.504351  0.037685        0.0\n",
       "408  0.504257  0.037360        0.0\n",
       "409  0.506839  0.038380        0.0\n",
       "\n",
       "[410 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(ts_test[fold_indice])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(ts_test_y[fold_indice].cpu().numpy(), (model(ts_test[fold_indice])[0].squeeze() > 0.5).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(plot_buf, format='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " transforms.ToTensor()(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.make_grid( transforms.ToTensor()(image)).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, param_object in enumerate(model[0].parameters()):\n",
    "    print(f'Object {i}')\n",
    "    print(param_object.shape)\n",
    "    print(param_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(model[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, param_object in enumerate(model[0].parameters()):\n",
    "    print(f'Object {i}')\n",
    "    print(param_object.shape)\n",
    "    print(param_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.eval()\n",
    "#accuracy_score(ts_test_y.cpu().numpy(), (model(ts_test).squeeze() > 0.5).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.eval()\n",
    "#utility_function(df.loc[test_index], (model(ts_test).squeeze() > 0.5).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model_load = nn.Sequential(\n",
    "        #nn.Dropout(0.2),\n",
    "        nn.Linear(len(FEATURES_LIST_TOTRAIN), 130),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "\n",
    "        nn.Linear(130, 130),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),    \n",
    "\n",
    "        nn.Linear(130, 130),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),    \n",
    "\n",
    "        nn.Linear(130, 130),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),    \n",
    "\n",
    "        nn.Linear(130, 130),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),    \n",
    "\n",
    "        nn.Linear(130, 130),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),    \n",
    "    \n",
    "        nn.Linear(130, 130),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),    \n",
    "    \n",
    "        nn.Linear(130, 130),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),    \n",
    "\n",
    "        nn.Linear(130, 60),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),    \n",
    "    \n",
    "        nn.Linear(60, 30),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),    \n",
    "       \n",
    "        nn.Linear(30, 1),\n",
    "        nn.Sigmoid(),\n",
    "    ).double().to('cuda')\n",
    "    \n",
    "model_load.load_state_dict(torch.load(f'model_NN_allfolds_V1.pt',map_location=torch.device('cuda')))\n",
    "'''\n",
    "\n",
    "#model_load.eval()\n",
    "#print(accuracy_score(ts_test_y.cpu().numpy(), (model_load(ts_test).squeeze() > 0.5).cpu().numpy()))\n",
    "#\n",
    "#model_load.eval()\n",
    "#print(utility_function(df.loc[test_index], (model_load(ts_test).squeeze() > 0.5).cpu().numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, fill NA with :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then, normalize with :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "        \n",
    "    def __call__(self, module, module_in, module_out):\n",
    "        self.outputs.append(module_out)\n",
    "        print(type(module_out))\n",
    "        \n",
    "    def clear(self):\n",
    "        self.outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 =  nn.Sequential(\n",
    "        nn.Linear(4, 2),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        nn.Linear(2, 2),\n",
    "        nn.ReLU(),\n",
    "\n",
    "\n",
    "    \n",
    "        nn.Linear(2, 1),\n",
    "        nn.Sigmoid(),\n",
    "\n",
    ")\n",
    "\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, param_object in enumerate(model2.parameters()):\n",
    "    print(f'Object {i}')\n",
    "    print(param_object.shape)\n",
    "    print(param_object.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'activation' in str(type(model2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(model2[1], torch.nn.ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_output = SaveOutput()\n",
    "\n",
    "hook_handles = []\n",
    "\n",
    "for layer in model2.modules():\n",
    "    if ('activation' in str(type(layer))):\n",
    "        handle = layer.register_forward_hook(save_output)\n",
    "        hook_handles.append(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with torch.no_grad():\n",
    "print(model2(torch.tensor([1, 1, 1, 2], dtype=torch.float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_output.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation.append([0.11, 01.11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour récupérer les gradients : https://discuss.pytorch.org/t/how-to-print-the-computed-gradient-values-for-a-network/34179\n",
    "print(model2[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created\n",
      "Cnt batch train:410\n",
      "Epoch(3) - Training Loss: 0.0008\n"
     ]
    }
   ],
   "source": [
    "MODEL_COMMENT = \"Test, to delete\"\n",
    "\n",
    "patience=5\n",
    "\n",
    "utility_scores = [None] * 5\n",
    "accuracy_scores = [None] * 5\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "ts_train = torch.tensor(df.loc[folds_list_train_unique, FEATURES_LIST_TOTRAIN].to_numpy(), device='cuda')\n",
    "ts_train_y = torch.tensor((df.loc[folds_list_train_unique, 'resp'] > 0).astype(np.byte).to_numpy(), device='cuda')\n",
    "ts_train_y_reg = torch.tensor(df.loc[folds_list_train_unique, 'resp'].to_numpy(), device='cuda')\n",
    "\n",
    "# Normalize data\n",
    "ts_train_mean = torch.mean(ts_train, axis=0)\n",
    "ts_train_std = torch.std(ts_train, axis=0)\n",
    "ts_train = pyStandardScale(ts_train, ts_train_mean, ts_train_std)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(ts_train, ts_train_y, ts_train_y_reg)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True) # pin_memory : VOIR RESULTAT\n",
    "\n",
    "ts_test = [None] * 5\n",
    "ts_test_y = [None] * 5    \n",
    "ts_test_y_reg = [None] * 5   \n",
    "test_dataset = [None] * 5\n",
    "test_loader = [None] * 5\n",
    "\n",
    "for fold_indice in range(5):\n",
    "    ts_test[fold_indice] = torch.tensor(df.loc[folds_list_test[fold_indice], FEATURES_LIST_TOTRAIN].to_numpy(), device='cuda')\n",
    "    ts_test_y[fold_indice] = torch.tensor((df.loc[folds_list_test[fold_indice], 'resp'] > 0).astype(np.byte).to_numpy(), device='cuda')\n",
    "    ts_test_y_reg[fold_indice] = torch.tensor(df.loc[folds_list_test[fold_indice], 'resp'].to_numpy(), device='cuda')\n",
    "\n",
    "    # Normalize\n",
    "    ts_test[fold_indice] = pyStandardScale(ts_test[fold_indice], ts_train_mean, ts_train_std)\n",
    "    \n",
    "    test_dataset[fold_indice] = torch.utils.data.TensorDataset(ts_test[fold_indice], ts_test_y[fold_indice], ts_test_y_reg[fold_indice])\n",
    "    test_loader[fold_indice] = torch.utils.data.DataLoader(test_dataset[fold_indice], batch_size=BATCH_SIZE)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "'''\n",
    "model = nn.Sequential(\n",
    "        #nn.Dropout(0.2),\n",
    "        nn.Linear(len(FEATURES_LIST_TOTRAIN), 200),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.7),\n",
    "\n",
    "        nn.Linear(200, 100),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.7),\n",
    "    \n",
    "        nn.Linear(100, 1),\n",
    "        nn.Sigmoid(),\n",
    "    ).double().to('cuda')\n",
    "'''\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    #def __init__(self, n_feature, n_hidden): \n",
    "    def __init__(self): \n",
    "        super(MLP, self).__init__() \n",
    "        self.layer1 = nn.Linear(len(FEATURES_LIST_TOTRAIN), 2000)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(0.7)\n",
    "\n",
    "        self.layer2 = nn.Linear(2000, 1000)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.drop2 = nn.Dropout(0.7)\n",
    "\n",
    "        self.layer3_classif = nn.Linear(1000, 1)\n",
    "        self.act3_classif = nn.Sigmoid()  \n",
    "\n",
    "        self.layer3_reg = nn.Linear(1000, 1)\n",
    "        #self.act3_reg = nn.Sigmoid()  \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop1(self.act1(self.layer1(x)))\n",
    "        x = self.drop2(self.act2(self.layer2(x)))\n",
    "\n",
    "        x_out_classif = self.act3_classif(self.layer3_classif(x))\n",
    "        #x_out_reg = self.act3_reg(self.layer3_reg(x))\n",
    "        x_out_reg = self.layer3_reg(x)\n",
    "\n",
    "        return x_out_classif, x_out_reg\n",
    "\n",
    "model = MLP().double().to('cuda')\n",
    "print('Model created')\n",
    "\n",
    "#print('Number of model parameters :')\n",
    "#numel_list = [p.numel() for p in model.parameters()]\n",
    "#sum(numel_list), numel_list\n",
    "\n",
    "loss_fn = nn.BCELoss().to('cuda')\n",
    "loss_fn_reg = nn.MSELoss().to('cuda')\n",
    "\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-2) \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) \n",
    "\n",
    "model.eval()\n",
    "#start_accuracy = accuracy_score(ts_test_y.cpu().numpy(), (model(ts_test).squeeze() > 0.5).cpu().numpy())\n",
    "#start_utility_score = utility_function(df.loc[test_index], (model(ts_test).squeeze() > 0.5).cpu().numpy())\n",
    "#print('Start Validation Accuracy: {:.4f}'.format(start_accuracy))\n",
    "#print('Start Validation Utility: {:.4f}'.format(start_utility_score))\n",
    "\n",
    "### Call back to save activation stats (mean, std dev and near 0 values after activation functions)\n",
    "\n",
    "hook_handles = []\n",
    "save_output_activation_stats = []\n",
    "\n",
    "Val_Loss = 0\n",
    "N_Samples = 0\n",
    "\n",
    "the_last_loss = 100\n",
    "the_last_utility_score = 0\n",
    "the_last_accuracy = 0\n",
    "trigger_times=0\n",
    "early_stopping_met = False\n",
    "\n",
    "\n",
    "#### Test : only 1 epoch loop\n",
    "epoch = 3\n",
    "\n",
    "running_loss = 0.0        \n",
    "model.train()\n",
    "\n",
    "for layer in model.modules():\n",
    "    if ('activation' in str(type(layer))):\n",
    "        save_output_activation_stats_1layer = SaveOutputActivationStats()\n",
    "        handle = layer.register_forward_hook(save_output_activation_stats_1layer)\n",
    "        save_output_activation_stats.append(save_output_activation_stats_1layer)\n",
    "        hook_handles.append(handle)\n",
    "\n",
    "for batch in train_loader:\n",
    "    #inputs, labels = batch[0], batch[1]\n",
    "    inputs, labels, labels_reg = batch[0].to('cuda'), batch[1].to('cuda'), batch[2].to('cuda')\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.set_grad_enabled(True):\n",
    "        outputs_classif, outputs_reg = model(inputs)\n",
    "        loss_classif = loss_fn(outputs_classif, labels.unsqueeze(-1).double())\n",
    "        loss_reg = loss_fn_reg(outputs_reg, labels_reg.unsqueeze(-1).double())\n",
    "        loss = loss_classif + loss_reg\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# update local train loss\n",
    "running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "# update global train loss\n",
    "epoch_loss = running_loss / len(train_loader.dataset)\n",
    "print('Epoch({}) - Training Loss: {:.4f}'.format(epoch, epoch_loss))\n",
    "\n",
    "writer.add_scalar(f\"Global train/loss\", epoch_loss, epoch)\n",
    "\n",
    "# Write activation stats graphs\n",
    "for layer_number,save_output_activation_stats_layer in enumerate(save_output_activation_stats):            \n",
    "    df_stats_layer = pd.DataFrame(save_output_activation_stats_layer.outputs)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(25, 4))\n",
    "\n",
    "    ax[0].set_title(f'Layer {layer_number} : Mean activation value', fontsize=16)\n",
    "    ax[0].set_xlabel('Batch instances')\n",
    "    ax[0].set_ylabel('Mean')\n",
    "    ax[0].plot(range(df_stats_layer.shape[0]), df_stats_layer['mean'])\n",
    "\n",
    "    ax[1].set_title(f'Layer {layer_number} : Std deviation activation value', fontsize=16)\n",
    "    ax[1].set_xlabel('Batch instances')\n",
    "    ax[1].set_ylabel('Standard deviation')\n",
    "    ax[1].plot(range(df_stats_layer.shape[0]), df_stats_layer['std'])\n",
    "\n",
    "    ax[2].set_title(f'Layer {layer_number} : Percentage of activation values near zero', fontsize=16)\n",
    "    ax[2].set_xlabel('Batch instances')\n",
    "    ax[2].set_ylabel('Percentage')\n",
    "    ax[2].plot(range(df_stats_layer.shape[0]), df_stats_layer['near_zero']);\n",
    "\n",
    "    plot_buf = io.BytesIO()\n",
    "    plt.savefig(plot_buf, format='jpeg')\n",
    "    plt.close()\n",
    "\n",
    "    plot_buf.seek(0)\n",
    "    image = PIL.Image.open(plot_buf)\n",
    "    image = transforms.ToTensor()(image)\n",
    "    writer.add_image(\"Train activation stats/Activation stats layer \" + str(layer_number), image, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>near_zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.513979</td>\n",
       "      <td>0.067728</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.511781</td>\n",
       "      <td>0.067834</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.506987</td>\n",
       "      <td>0.065692</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.509252</td>\n",
       "      <td>0.066704</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.508509</td>\n",
       "      <td>0.065194</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0.504025</td>\n",
       "      <td>0.026814</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.503545</td>\n",
       "      <td>0.026565</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.503636</td>\n",
       "      <td>0.025799</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.503646</td>\n",
       "      <td>0.026199</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.502172</td>\n",
       "      <td>0.024381</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean       std  near_zero\n",
       "0    0.513979  0.067728   0.000244\n",
       "1    0.511781  0.067834   0.000000\n",
       "2    0.506987  0.065692   0.000244\n",
       "3    0.509252  0.066704   0.000244\n",
       "4    0.508509  0.065194   0.000000\n",
       "..        ...       ...        ...\n",
       "405  0.504025  0.026814   0.000000\n",
       "406  0.503545  0.026565   0.000000\n",
       "407  0.503636  0.025799   0.000000\n",
       "408  0.503646  0.026199   0.000000\n",
       "409  0.502172  0.024381   0.000000\n",
       "\n",
       "[410 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1677155, 130])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cnt batch train:410\n",
      "Epoch(1) - Training Loss: 0.0008\n"
     ]
    }
   ],
   "source": [
    "#### Test : only 1 epoch loop\n",
    "epoch = 1\n",
    "\n",
    "running_loss = 0.0        \n",
    "model.train()\n",
    "\n",
    "for batch in train_loader:\n",
    "    #inputs, labels = batch[0], batch[1]\n",
    "    inputs, labels, labels_reg = batch[0].to('cuda'), batch[1].to('cuda'), batch[2].to('cuda')\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.set_grad_enabled(True):\n",
    "        outputs_classif, outputs_reg = model(inputs)\n",
    "        loss_classif = loss_fn(outputs_classif, labels.unsqueeze(-1).double())\n",
    "        loss_reg = loss_fn_reg(outputs_reg, labels_reg.unsqueeze(-1).double())\n",
    "        loss = loss_classif + loss_reg\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# update local train loss\n",
    "running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "# update global train loss\n",
    "epoch_loss = running_loss / len(train_loader.dataset)\n",
    "print('Epoch({}) - Training Loss: {:.4f}'.format(epoch, epoch_loss))\n",
    "\n",
    "writer.add_scalar(f\"Global train/loss\", epoch_loss, epoch)\n",
    "\n",
    "# Write activation stats graphs\n",
    "for layer_number,save_output_activation_stats_layer in enumerate(save_output_activation_stats):            \n",
    "    df_stats_layer = pd.DataFrame(save_output_activation_stats_layer.outputs)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(25, 4))\n",
    "\n",
    "    ax[0].set_title(f'Layer {layer_number} : Mean activation value', fontsize=16)\n",
    "    ax[0].set_xlabel('Batch instances')\n",
    "    ax[0].set_ylabel('Mean')\n",
    "    ax[0].plot(range(df_stats_layer.shape[0]), df_stats_layer['mean'])\n",
    "\n",
    "    ax[1].set_title(f'Layer {layer_number} : Std deviation activation value', fontsize=16)\n",
    "    ax[1].set_xlabel('Batch instances')\n",
    "    ax[1].set_ylabel('Standard deviation')\n",
    "    ax[1].plot(range(df_stats_layer.shape[0]), df_stats_layer['std'])\n",
    "\n",
    "    ax[2].set_title(f'Layer {layer_number} : Percentage of activation values near zero', fontsize=16)\n",
    "    ax[2].set_xlabel('Batch instances')\n",
    "    ax[2].set_ylabel('Percentage')\n",
    "    ax[2].plot(range(df_stats_layer.shape[0]), df_stats_layer['near_zero']);\n",
    "\n",
    "    plot_buf = io.BytesIO()\n",
    "    plt.savefig(plot_buf, format='jpeg')\n",
    "    plt.close()\n",
    "\n",
    "    plot_buf.seek(0)\n",
    "    image = PIL.Image.open(plot_buf)\n",
    "    image = transforms.ToTensor()(image)\n",
    "    writer.add_image(\"Train activation stats/Activation stats layer \" + str(layer_number), image, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>near_zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.513979</td>\n",
       "      <td>0.067728</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.511781</td>\n",
       "      <td>0.067834</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.506987</td>\n",
       "      <td>0.065692</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.509252</td>\n",
       "      <td>0.066704</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.508509</td>\n",
       "      <td>0.065194</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>0.504753</td>\n",
       "      <td>0.029052</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>0.505019</td>\n",
       "      <td>0.029217</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>0.504592</td>\n",
       "      <td>0.027172</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>0.504845</td>\n",
       "      <td>0.028485</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>0.505591</td>\n",
       "      <td>0.030055</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>820 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean       std  near_zero\n",
       "0    0.513979  0.067728   0.000244\n",
       "1    0.511781  0.067834   0.000000\n",
       "2    0.506987  0.065692   0.000244\n",
       "3    0.509252  0.066704   0.000244\n",
       "4    0.508509  0.065194   0.000000\n",
       "..        ...       ...        ...\n",
       "815  0.504753  0.029052   0.000000\n",
       "816  0.505019  0.029217   0.000000\n",
       "817  0.504592  0.027172   0.000000\n",
       "818  0.504845  0.028485   0.000000\n",
       "819  0.505591  0.030055   0.000000\n",
       "\n",
       "[820 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'mean': 0.5139788188306076,\n",
       "  'std': 0.06772770436168842,\n",
       "  'near_zero': 0.000244140625},\n",
       " {'mean': 0.5117813291592994, 'std': 0.06783359779301797, 'near_zero': 0.0},\n",
       " {'mean': 0.5069873233636126,\n",
       "  'std': 0.0656919374456853,\n",
       "  'near_zero': 0.000244140625},\n",
       " {'mean': 0.5092523903751377,\n",
       "  'std': 0.06670353116725221,\n",
       "  'near_zero': 0.000244140625},\n",
       " {'mean': 0.5085091656010448, 'std': 0.06519431091937036, 'near_zero': 0.0},\n",
       " {'mean': 0.5069798166132606, 'std': 0.06432620189112524, 'near_zero': 0.0},\n",
       " {'mean': 0.506369424821951, 'std': 0.06421988944568151, 'near_zero': 0.0},\n",
       " {'mean': 0.5037326678791945, 'std': 0.06348710612234558, 'near_zero': 0.0},\n",
       " {'mean': 0.5017513898907107, 'std': 0.0629272249696168, 'near_zero': 0.0},\n",
       " {'mean': 0.5026921244565044, 'std': 0.06098092688752796, 'near_zero': 0.0},\n",
       " {'mean': 0.5056950233824262, 'std': 0.061516884756710945, 'near_zero': 0.0},\n",
       " {'mean': 0.5064665989162688,\n",
       "  'std': 0.060570861926287134,\n",
       "  'near_zero': 0.000244140625},\n",
       " {'mean': 0.5069464507479611, 'std': 0.06146000655656442, 'near_zero': 0.0},\n",
       " {'mean': 0.5088651354136049, 'std': 0.0575577360799419, 'near_zero': 0.0},\n",
       " {'mean': 0.5096420871140102, 'std': 0.05751602439336471, 'near_zero': 0.0},\n",
       " {'mean': 0.508393320538799, 'std': 0.05560651349030468, 'near_zero': 0.0},\n",
       " {'mean': 0.5082764926495074, 'std': 0.05592778225354338, 'near_zero': 0.0},\n",
       " {'mean': 0.5070524954395539, 'std': 0.05660931582822739, 'near_zero': 0.0},\n",
       " {'mean': 0.5088539102058941, 'std': 0.055157741386316024, 'near_zero': 0.0},\n",
       " {'mean': 0.5102897298452931,\n",
       "  'std': 0.05491291896553469,\n",
       "  'near_zero': 0.000244140625},\n",
       " {'mean': 0.5093952873253944, 'std': 0.05567873894347306, 'near_zero': 0.0},\n",
       " {'mean': 0.5076310531890323, 'std': 0.05550816748435253, 'near_zero': 0.0},\n",
       " {'mean': 0.5061663979714133, 'std': 0.05345083925670973, 'near_zero': 0.0},\n",
       " {'mean': 0.5058940115762713, 'std': 0.05288498579722424, 'near_zero': 0.0},\n",
       " {'mean': 0.5067140371261402, 'std': 0.05176866444928391, 'near_zero': 0.0},\n",
       " {'mean': 0.5067236632534635, 'std': 0.05307269023412323, 'near_zero': 0.0},\n",
       " {'mean': 0.507069909966377, 'std': 0.05108240331967045, 'near_zero': 0.0},\n",
       " {'mean': 0.5058470947528809, 'std': 0.05128477736058557, 'near_zero': 0.0},\n",
       " {'mean': 0.5046357153675549, 'std': 0.051198830747598914, 'near_zero': 0.0},\n",
       " {'mean': 0.5041395001456683, 'std': 0.048953270824164466, 'near_zero': 0.0},\n",
       " {'mean': 0.5044685552782068, 'std': 0.04817936804025778, 'near_zero': 0.0},\n",
       " {'mean': 0.5043643077813305, 'std': 0.04998263703726312, 'near_zero': 0.0},\n",
       " {'mean': 0.5045123959522044,\n",
       "  'std': 0.049576066302514675,\n",
       "  'near_zero': 0.000244140625},\n",
       " {'mean': 0.5036496106136035, 'std': 0.04829595661201975, 'near_zero': 0.0},\n",
       " {'mean': 0.5023045851386861, 'std': 0.046414797013532676, 'near_zero': 0.0},\n",
       " {'mean': 0.503701950442318, 'std': 0.04875825344744324, 'near_zero': 0.0},\n",
       " {'mean': 0.5000290697308519,\n",
       "  'std': 0.04711662388687499,\n",
       "  'near_zero': 0.00048828125},\n",
       " {'mean': 0.5012560570910873, 'std': 0.04708659871708146, 'near_zero': 0.0},\n",
       " {'mean': 0.5001394024051284, 'std': 0.04436590102854573, 'near_zero': 0.0},\n",
       " {'mean': 0.5014376913034634,\n",
       "  'std': 0.046239798978804814,\n",
       "  'near_zero': 0.000244140625},\n",
       " {'mean': 0.5012412224543942, 'std': 0.04538791276648564, 'near_zero': 0.0},\n",
       " {'mean': 0.5016736088968847, 'std': 0.04481119430970366, 'near_zero': 0.0},\n",
       " {'mean': 0.5020925584778021, 'std': 0.043564591907277475, 'near_zero': 0.0},\n",
       " {'mean': 0.503690977383581, 'std': 0.04407777127869352, 'near_zero': 0.0},\n",
       " {'mean': 0.5053919331458314, 'std': 0.04367208277954208, 'near_zero': 0.0},\n",
       " {'mean': 0.5052026595444644, 'std': 0.04464144074807844, 'near_zero': 0.0},\n",
       " {'mean': 0.5070548408371346, 'std': 0.042745371418122055, 'near_zero': 0.0},\n",
       " {'mean': 0.5065055525443043, 'std': 0.04255821883702709, 'near_zero': 0.0},\n",
       " {'mean': 0.5063752725627693,\n",
       "  'std': 0.040833039707964654,\n",
       "  'near_zero': 0.000244140625},\n",
       " {'mean': 0.506751055287594, 'std': 0.04161528388376347, 'near_zero': 0.0},\n",
       " {'mean': 0.5060038164521138, 'std': 0.04132900234059713, 'near_zero': 0.0},\n",
       " {'mean': 0.5069083126945865, 'std': 0.040894501261396404, 'near_zero': 0.0},\n",
       " {'mean': 0.506812349912634, 'std': 0.04139687940683339, 'near_zero': 0.0},\n",
       " {'mean': 0.5050863530903472,\n",
       "  'std': 0.03861562026650734,\n",
       "  'near_zero': 0.000244140625},\n",
       " {'mean': 0.5062585773754003, 'std': 0.04076951947027799, 'near_zero': 0.0},\n",
       " {'mean': 0.5043602064132024, 'std': 0.04009423652790571, 'near_zero': 0.0},\n",
       " {'mean': 0.5022088903179773, 'std': 0.038634246750577105, 'near_zero': 0.0},\n",
       " {'mean': 0.5037005576549196, 'std': 0.04069303545967968, 'near_zero': 0.0},\n",
       " {'mean': 0.5019976765876848, 'std': 0.03992071394017188, 'near_zero': 0.0},\n",
       " {'mean': 0.501720936983642, 'std': 0.039362722981416194, 'near_zero': 0.0},\n",
       " {'mean': 0.5019197396812873, 'std': 0.0379343773374756, 'near_zero': 0.0},\n",
       " {'mean': 0.5014135945475465, 'std': 0.0401836899569729, 'near_zero': 0.0},\n",
       " {'mean': 0.5010652645410982, 'std': 0.03889321152922991, 'near_zero': 0.0},\n",
       " {'mean': 0.5028330805699034, 'std': 0.038488289199055524, 'near_zero': 0.0},\n",
       " {'mean': 0.5023916856753375, 'std': 0.0401463938294962, 'near_zero': 0.0},\n",
       " {'mean': 0.5026452123973568, 'std': 0.03938269773664348, 'near_zero': 0.0},\n",
       " {'mean': 0.5039309957018941, 'std': 0.038436399257319155, 'near_zero': 0.0},\n",
       " {'mean': 0.5046817291935024, 'std': 0.03845475804142869, 'near_zero': 0.0},\n",
       " {'mean': 0.5041317391359368, 'std': 0.03810028830683913, 'near_zero': 0.0},\n",
       " {'mean': 0.5043519725454862, 'std': 0.03792072268048389, 'near_zero': 0.0},\n",
       " {'mean': 0.5062583862798662, 'std': 0.03782927120309333, 'near_zero': 0.0},\n",
       " {'mean': 0.5065016756364362, 'std': 0.03726533842604197, 'near_zero': 0.0},\n",
       " {'mean': 0.5059810169213477, 'std': 0.03732901862147978, 'near_zero': 0.0},\n",
       " {'mean': 0.5071702598524228, 'std': 0.03735509528442038, 'near_zero': 0.0},\n",
       " {'mean': 0.5071360859664915, 'std': 0.03591841418911748, 'near_zero': 0.0},\n",
       " {'mean': 0.5066880779421465, 'std': 0.03688558818798576, 'near_zero': 0.0},\n",
       " {'mean': 0.5075192380840583, 'std': 0.03683913684352518, 'near_zero': 0.0},\n",
       " {'mean': 0.5062466339088822, 'std': 0.036092662855782415, 'near_zero': 0.0},\n",
       " {'mean': 0.5083338956993791, 'std': 0.03558970815802209, 'near_zero': 0.0},\n",
       " {'mean': 0.5075060528525934, 'std': 0.0365471012518858, 'near_zero': 0.0},\n",
       " {'mean': 0.5061224290899418, 'std': 0.0361664353858525, 'near_zero': 0.0},\n",
       " {'mean': 0.5070059759465022, 'std': 0.035750687199845574, 'near_zero': 0.0},\n",
       " {'mean': 0.5062963764201908, 'std': 0.035846606426971406, 'near_zero': 0.0},\n",
       " {'mean': 0.5062570210118342, 'std': 0.034628940134736275, 'near_zero': 0.0},\n",
       " {'mean': 0.5055601451920577, 'std': 0.035634998467538925, 'near_zero': 0.0},\n",
       " {'mean': 0.506127151521018, 'std': 0.03538749263042206, 'near_zero': 0.0},\n",
       " {'mean': 0.50583411245037, 'std': 0.03446791838347243, 'near_zero': 0.0},\n",
       " {'mean': 0.5072394380724753, 'std': 0.036083436552717674, 'near_zero': 0.0},\n",
       " {'mean': 0.507653552020247, 'std': 0.0343595657008015, 'near_zero': 0.0},\n",
       " {'mean': 0.5064109084242487, 'std': 0.034806720200708983, 'near_zero': 0.0},\n",
       " {'mean': 0.5047321505571363, 'std': 0.03297678207932382, 'near_zero': 0.0},\n",
       " {'mean': 0.5053598360476539, 'std': 0.03372882916827382, 'near_zero': 0.0},\n",
       " {'mean': 0.5057182031322309, 'std': 0.035005094713052985, 'near_zero': 0.0},\n",
       " {'mean': 0.5042056961100878, 'std': 0.0329026918476257, 'near_zero': 0.0},\n",
       " {'mean': 0.5039854232442601, 'std': 0.03471155193402993, 'near_zero': 0.0},\n",
       " {'mean': 0.5035148533965725, 'std': 0.03315381230895238, 'near_zero': 0.0},\n",
       " {'mean': 0.5029140500475855, 'std': 0.03274920428869135, 'near_zero': 0.0},\n",
       " {'mean': 0.5025252592811507, 'std': 0.03190417277105684, 'near_zero': 0.0},\n",
       " {'mean': 0.5017430629182289, 'std': 0.032152497023423064, 'near_zero': 0.0},\n",
       " {'mean': 0.5021521205093465, 'std': 0.03442223399239854, 'near_zero': 0.0},\n",
       " {'mean': 0.5028198212467165, 'std': 0.03144450877694055, 'near_zero': 0.0},\n",
       " {'mean': 0.5027151714267372, 'std': 0.03340286431126824, 'near_zero': 0.0},\n",
       " {'mean': 0.5033309852564524, 'std': 0.03285146744576899, 'near_zero': 0.0},\n",
       " {'mean': 0.5031099788654085, 'std': 0.032188775977229106, 'near_zero': 0.0},\n",
       " {'mean': 0.5033083199462304, 'std': 0.0318717681989322, 'near_zero': 0.0},\n",
       " {'mean': 0.5034644252579783, 'std': 0.032909393454298004, 'near_zero': 0.0},\n",
       " {'mean': 0.5037945887092623, 'std': 0.03112958783310703, 'near_zero': 0.0},\n",
       " {'mean': 0.5043585622940354, 'std': 0.03131975082833539, 'near_zero': 0.0},\n",
       " {'mean': 0.5054378032700566, 'std': 0.030453941071263736, 'near_zero': 0.0},\n",
       " {'mean': 0.5053153476042204, 'std': 0.030710909875548954, 'near_zero': 0.0},\n",
       " {'mean': 0.5063643418555493, 'std': 0.032034500841304235, 'near_zero': 0.0},\n",
       " {'mean': 0.5061115359172003, 'std': 0.03220221140368929, 'near_zero': 0.0},\n",
       " {'mean': 0.507069121255127, 'std': 0.03153520316406333, 'near_zero': 0.0},\n",
       " {'mean': 0.5071708512418529, 'std': 0.03261792359909369, 'near_zero': 0.0},\n",
       " {'mean': 0.507218699247588, 'std': 0.03137398117969353, 'near_zero': 0.0},\n",
       " {'mean': 0.507177233962198, 'std': 0.03333996474991255, 'near_zero': 0.0},\n",
       " {'mean': 0.5080507062557691, 'std': 0.031207813582085128, 'near_zero': 0.0},\n",
       " {'mean': 0.5071918138488589, 'std': 0.030287018525655247, 'near_zero': 0.0},\n",
       " {'mean': 0.5070564699477547, 'std': 0.030037082363105854, 'near_zero': 0.0},\n",
       " {'mean': 0.5077036244498581, 'std': 0.03010024685440846, 'near_zero': 0.0},\n",
       " {'mean': 0.5067133992280441, 'std': 0.030518879198783353, 'near_zero': 0.0},\n",
       " {'mean': 0.5074780756237083, 'std': 0.030230332404559142, 'near_zero': 0.0},\n",
       " {'mean': 0.5065467695178695, 'std': 0.030085969578447898, 'near_zero': 0.0},\n",
       " {'mean': 0.5055847942377256, 'std': 0.030753658872155528, 'near_zero': 0.0},\n",
       " {'mean': 0.5055997287921761, 'std': 0.030561137290236295, 'near_zero': 0.0},\n",
       " {'mean': 0.5055717430998461, 'std': 0.029969060214806, 'near_zero': 0.0},\n",
       " {'mean': 0.5051266886910522, 'std': 0.030062494005764318, 'near_zero': 0.0},\n",
       " {'mean': 0.5046181003855168, 'std': 0.030184917319179046, 'near_zero': 0.0},\n",
       " {'mean': 0.505040714945344, 'std': 0.03161542812187376, 'near_zero': 0.0},\n",
       " {'mean': 0.5040486196830151, 'std': 0.029880538222561807, 'near_zero': 0.0},\n",
       " {'mean': 0.5046357278318754, 'std': 0.02852326992191661, 'near_zero': 0.0},\n",
       " {'mean': 0.5036178752019567, 'std': 0.028560988262398605, 'near_zero': 0.0},\n",
       " {'mean': 0.5043836712355068, 'std': 0.030698635504707972, 'near_zero': 0.0},\n",
       " {'mean': 0.503788003450405, 'std': 0.030006374504669923, 'near_zero': 0.0},\n",
       " {'mean': 0.5047372504179275, 'std': 0.029472609412605495, 'near_zero': 0.0},\n",
       " {'mean': 0.5039100405141195, 'std': 0.029880447139262963, 'near_zero': 0.0},\n",
       " {'mean': 0.5034697812511504, 'std': 0.027632447383762256, 'near_zero': 0.0},\n",
       " {'mean': 0.5044291294689314, 'std': 0.028103882404367894, 'near_zero': 0.0},\n",
       " {'mean': 0.5038180546691341, 'std': 0.02854501480919171, 'near_zero': 0.0},\n",
       " {'mean': 0.5035593802642899, 'std': 0.02892646101307673, 'near_zero': 0.0},\n",
       " {'mean': 0.5036139450336011, 'std': 0.027451157923762806, 'near_zero': 0.0},\n",
       " {'mean': 0.5031556691736986, 'std': 0.02857000187891902, 'near_zero': 0.0},\n",
       " {'mean': 0.5021536203396758, 'std': 0.02872105936497856, 'near_zero': 0.0},\n",
       " {'mean': 0.5027401981954673, 'std': 0.028981648109391637, 'near_zero': 0.0},\n",
       " {'mean': 0.5025776254801937, 'std': 0.028842473546840296, 'near_zero': 0.0},\n",
       " {'mean': 0.5014110814903534, 'std': 0.02594956546579431, 'near_zero': 0.0},\n",
       " {'mean': 0.5023162507199994,\n",
       "  'std': 0.02897682460192533,\n",
       "  'near_zero': 0.000244140625},\n",
       " {'mean': 0.501904290121663, 'std': 0.02775292157426381, 'near_zero': 0.0},\n",
       " {'mean': 0.501551288522504, 'std': 0.027788712670167703, 'near_zero': 0.0},\n",
       " {'mean': 0.5016214506603709, 'std': 0.027436887195070963, 'near_zero': 0.0},\n",
       " {'mean': 0.5009164252279155, 'std': 0.027686645993606596, 'near_zero': 0.0},\n",
       " {'mean': 0.5016918727595816, 'std': 0.027483764160634885, 'near_zero': 0.0},\n",
       " {'mean': 0.5007207209037653, 'std': 0.02928739359609145, 'near_zero': 0.0},\n",
       " {'mean': 0.5012543729409689, 'std': 0.02721384444142842, 'near_zero': 0.0},\n",
       " {'mean': 0.5005822192704256, 'std': 0.027076521029507028, 'near_zero': 0.0},\n",
       " {'mean': 0.5016073802445984, 'std': 0.027978172705054205, 'near_zero': 0.0},\n",
       " {'mean': 0.5012263049391631, 'std': 0.026802833402019263, 'near_zero': 0.0},\n",
       " {'mean': 0.5020789188089433, 'std': 0.027500667265650883, 'near_zero': 0.0},\n",
       " {'mean': 0.5018837107540803, 'std': 0.027655212905620362, 'near_zero': 0.0},\n",
       " {'mean': 0.5011725067701528, 'std': 0.026541160861458163, 'near_zero': 0.0},\n",
       " {'mean': 0.5003465074970757, 'std': 0.027102358121210878, 'near_zero': 0.0},\n",
       " {'mean': 0.5011250029474509, 'std': 0.02773581980327541, 'near_zero': 0.0},\n",
       " {'mean': 0.5015663626466811, 'std': 0.028091934837646493, 'near_zero': 0.0},\n",
       " {'mean': 0.5007327473243988, 'std': 0.02620745570056133, 'near_zero': 0.0},\n",
       " {'mean': 0.5011369106981427, 'std': 0.028156246273256184, 'near_zero': 0.0},\n",
       " {'mean': 0.5021703128654564, 'std': 0.027012155683196756, 'near_zero': 0.0},\n",
       " {'mean': 0.5006537877492031, 'std': 0.02637510153516554, 'near_zero': 0.0},\n",
       " {'mean': 0.5022698487728965, 'std': 0.026317837887615558, 'near_zero': 0.0},\n",
       " {'mean': 0.5020428600060609, 'std': 0.02781328460766445, 'near_zero': 0.0},\n",
       " {'mean': 0.501993547015976, 'std': 0.025907038665430905, 'near_zero': 0.0},\n",
       " {'mean': 0.5027028224075787, 'std': 0.025669330448467, 'near_zero': 0.0},\n",
       " {'mean': 0.5026270090807409, 'std': 0.02735952815009555, 'near_zero': 0.0},\n",
       " {'mean': 0.5040470718978793, 'std': 0.025827244306874123, 'near_zero': 0.0},\n",
       " {'mean': 0.5033187423853881, 'std': 0.026280970388552777, 'near_zero': 0.0},\n",
       " {'mean': 0.5039381993415609, 'std': 0.026168470779269152, 'near_zero': 0.0},\n",
       " {'mean': 0.5043142505969216, 'std': 0.026022014578226258, 'near_zero': 0.0},\n",
       " {'mean': 0.5042857973824879, 'std': 0.02577748792336866, 'near_zero': 0.0},\n",
       " {'mean': 0.5048971789983173, 'std': 0.026007349154361932, 'near_zero': 0.0},\n",
       " {'mean': 0.5049658006007255, 'std': 0.026045653370664997, 'near_zero': 0.0},\n",
       " {'mean': 0.5050272495174022, 'std': 0.02741999962852514, 'near_zero': 0.0},\n",
       " {'mean': 0.5055107527315075, 'std': 0.026865716204113245, 'near_zero': 0.0},\n",
       " {'mean': 0.5061710778148425, 'std': 0.028571579066350383, 'near_zero': 0.0},\n",
       " {'mean': 0.506196056560417, 'std': 0.028456637471591367, 'near_zero': 0.0},\n",
       " {'mean': 0.5059745027611586, 'std': 0.026275723655954274, 'near_zero': 0.0},\n",
       " {'mean': 0.5064000125160746, 'std': 0.024988612097605594, 'near_zero': 0.0},\n",
       " {'mean': 0.5051982052776292, 'std': 0.02529835250340486, 'near_zero': 0.0},\n",
       " {'mean': 0.5060144623786835, 'std': 0.0259179777383435, 'near_zero': 0.0},\n",
       " {'mean': 0.5060440017767838, 'std': 0.0263469278657997, 'near_zero': 0.0},\n",
       " {'mean': 0.5058256758077445, 'std': 0.02567848024022857, 'near_zero': 0.0},\n",
       " {'mean': 0.5049525007917528, 'std': 0.02513447574045006, 'near_zero': 0.0},\n",
       " {'mean': 0.5053176282075855, 'std': 0.025652502550002315, 'near_zero': 0.0},\n",
       " {'mean': 0.5056643028643935, 'std': 0.025688221861434917, 'near_zero': 0.0},\n",
       " {'mean': 0.5060250509176913, 'std': 0.02601265993265923, 'near_zero': 0.0},\n",
       " {'mean': 0.5053384087908563, 'std': 0.024565468715042792, 'near_zero': 0.0},\n",
       " {'mean': 0.5051346786712301, 'std': 0.025671042901443595, 'near_zero': 0.0},\n",
       " {'mean': 0.5043491364560142, 'std': 0.02577383051283012, 'near_zero': 0.0},\n",
       " {'mean': 0.5039114917112065, 'std': 0.023912202275537003, 'near_zero': 0.0},\n",
       " {'mean': 0.5048027916914991, 'std': 0.02625339026627947, 'near_zero': 0.0},\n",
       " {'mean': 0.5039184216821162, 'std': 0.025704324819006075, 'near_zero': 0.0},\n",
       " {'mean': 0.5036871875133341, 'std': 0.025067373548278645, 'near_zero': 0.0},\n",
       " {'mean': 0.5037587167741271, 'std': 0.025370305695714652, 'near_zero': 0.0},\n",
       " {'mean': 0.5041874269340709, 'std': 0.024705142347025873, 'near_zero': 0.0},\n",
       " {'mean': 0.5031182194769599, 'std': 0.02429232867576137, 'near_zero': 0.0},\n",
       " {'mean': 0.5039259858961107, 'std': 0.024645987967916387, 'near_zero': 0.0},\n",
       " {'mean': 0.5029775342482312, 'std': 0.025396006153525236, 'near_zero': 0.0},\n",
       " {'mean': 0.5040208942839333, 'std': 0.02477853117713401, 'near_zero': 0.0},\n",
       " {'mean': 0.5035149957486136, 'std': 0.024771392144279276, 'near_zero': 0.0},\n",
       " {'mean': 0.5032319979337125, 'std': 0.0247506436389221, 'near_zero': 0.0},\n",
       " {'mean': 0.5039581048865895, 'std': 0.024117459296134847, 'near_zero': 0.0},\n",
       " {'mean': 0.5039342031823675, 'std': 0.023550886775754284, 'near_zero': 0.0},\n",
       " {'mean': 0.5034875384447706, 'std': 0.023745017793989145, 'near_zero': 0.0},\n",
       " {'mean': 0.5040846402764293, 'std': 0.02497527091969898, 'near_zero': 0.0},\n",
       " {'mean': 0.5037471068545194, 'std': 0.024156927275973978, 'near_zero': 0.0},\n",
       " {'mean': 0.5036728252114264, 'std': 0.024344428398750804, 'near_zero': 0.0},\n",
       " {'mean': 0.5041464215621494, 'std': 0.025846826727317685, 'near_zero': 0.0},\n",
       " {'mean': 0.5038323304339005, 'std': 0.024140535521234678, 'near_zero': 0.0},\n",
       " {'mean': 0.5038311485926616, 'std': 0.024255902624661187, 'near_zero': 0.0},\n",
       " {'mean': 0.5032737881727058, 'std': 0.02479566766301464, 'near_zero': 0.0},\n",
       " {'mean': 0.5040714700439313, 'std': 0.024359159297948577, 'near_zero': 0.0},\n",
       " {'mean': 0.5042589556027604, 'std': 0.0246553718017083, 'near_zero': 0.0},\n",
       " {'mean': 0.503083177747705, 'std': 0.025003884991153663, 'near_zero': 0.0},\n",
       " {'mean': 0.5041357315695116, 'std': 0.02433246036721407, 'near_zero': 0.0},\n",
       " {'mean': 0.5044114441899468, 'std': 0.02595433708112526, 'near_zero': 0.0},\n",
       " {'mean': 0.5034775568733757, 'std': 0.02348714744416165, 'near_zero': 0.0},\n",
       " {'mean': 0.5046008783994981, 'std': 0.024170905716714708, 'near_zero': 0.0},\n",
       " {'mean': 0.5044313998249292, 'std': 0.025747614123270327, 'near_zero': 0.0},\n",
       " {'mean': 0.5045516764313626, 'std': 0.02538374104168654, 'near_zero': 0.0},\n",
       " {'mean': 0.5047899082456175, 'std': 0.0246300127723715, 'near_zero': 0.0},\n",
       " {'mean': 0.5047308740081669, 'std': 0.024524570727307363, 'near_zero': 0.0},\n",
       " {'mean': 0.5043887550566117, 'std': 0.024745142770609664, 'near_zero': 0.0},\n",
       " {'mean': 0.504295019698864, 'std': 0.024211660445874306, 'near_zero': 0.0},\n",
       " {'mean': 0.5049770345344484, 'std': 0.025905106145404373, 'near_zero': 0.0},\n",
       " {'mean': 0.505663750872326, 'std': 0.025224032640290165, 'near_zero': 0.0},\n",
       " {'mean': 0.5051841051717509, 'std': 0.024233352485688576, 'near_zero': 0.0},\n",
       " {'mean': 0.5052375739983612, 'std': 0.02681078237065358, 'near_zero': 0.0},\n",
       " {'mean': 0.5051921076566928, 'std': 0.02376408183232754, 'near_zero': 0.0},\n",
       " {'mean': 0.5053341642446287, 'std': 0.024363076490154133, 'near_zero': 0.0},\n",
       " {'mean': 0.506588837802858, 'std': 0.025501574591982268, 'near_zero': 0.0},\n",
       " {'mean': 0.506288649375807, 'std': 0.02498623229733537, 'near_zero': 0.0},\n",
       " {'mean': 0.5063266846529126,\n",
       "  'std': 0.02722778375095116,\n",
       "  'near_zero': 0.000244140625},\n",
       " {'mean': 0.5068371885973865, 'std': 0.02445783202815603, 'near_zero': 0.0},\n",
       " {'mean': 0.5070481782774754, 'std': 0.024686040943310162, 'near_zero': 0.0},\n",
       " {'mean': 0.5069311187845859, 'std': 0.024697642756383125, 'near_zero': 0.0},\n",
       " {'mean': 0.507278154566507, 'std': 0.024949303595113975, 'near_zero': 0.0},\n",
       " {'mean': 0.5074092143050712, 'std': 0.024593606790514474, 'near_zero': 0.0},\n",
       " {'mean': 0.5069261805694871, 'std': 0.02581814521271875, 'near_zero': 0.0},\n",
       " {'mean': 0.5065052897886635, 'std': 0.024829964293323115, 'near_zero': 0.0},\n",
       " {'mean': 0.506918441498178, 'std': 0.025513496803302952, 'near_zero': 0.0},\n",
       " {'mean': 0.5066656434190498, 'std': 0.024581549393605753, 'near_zero': 0.0},\n",
       " {'mean': 0.5064453040759128, 'std': 0.025554311168752293, 'near_zero': 0.0},\n",
       " {'mean': 0.5061163448752706, 'std': 0.02551071973341264, 'near_zero': 0.0},\n",
       " {'mean': 0.5066260451360967, 'std': 0.024878712660697393, 'near_zero': 0.0},\n",
       " {'mean': 0.5059717219400418, 'std': 0.024837523175563342, 'near_zero': 0.0},\n",
       " {'mean': 0.5065689817578088, 'std': 0.025977004754366845, 'near_zero': 0.0},\n",
       " {'mean': 0.5063419606166328, 'std': 0.02587925404702362, 'near_zero': 0.0},\n",
       " {'mean': 0.5057712423498836, 'std': 0.023928135375910355, 'near_zero': 0.0},\n",
       " {'mean': 0.5069214036820152, 'std': 0.025449613946111196, 'near_zero': 0.0},\n",
       " {'mean': 0.5057645689608825, 'std': 0.025127617161585066, 'near_zero': 0.0},\n",
       " {'mean': 0.5071570646609042, 'std': 0.02577142436895292, 'near_zero': 0.0},\n",
       " {'mean': 0.5066892168209902, 'std': 0.02527015247644283, 'near_zero': 0.0},\n",
       " {'mean': 0.5071581836914676, 'std': 0.025475024045904848, 'near_zero': 0.0},\n",
       " {'mean': 0.50833324295107, 'std': 0.02626618120564081, 'near_zero': 0.0},\n",
       " {'mean': 0.5075465986356196, 'std': 0.02509684422777855, 'near_zero': 0.0},\n",
       " {'mean': 0.5084024888141983, 'std': 0.025597467981405313, 'near_zero': 0.0},\n",
       " {'mean': 0.5079066050809798, 'std': 0.024441811278783986, 'near_zero': 0.0},\n",
       " {'mean': 0.5087051414660193, 'std': 0.026521797709824366, 'near_zero': 0.0},\n",
       " {'mean': 0.5084345749168493, 'std': 0.02645894048737416, 'near_zero': 0.0},\n",
       " {'mean': 0.508579839198473, 'std': 0.024585200803913302, 'near_zero': 0.0},\n",
       " {'mean': 0.5076571223683218, 'std': 0.025231257075816176, 'near_zero': 0.0},\n",
       " {'mean': 0.5076219891310974, 'std': 0.025323032703255116, 'near_zero': 0.0},\n",
       " {'mean': 0.5078466674429598, 'std': 0.025219229472010305, 'near_zero': 0.0},\n",
       " {'mean': 0.5076833823587974, 'std': 0.025155318901855968, 'near_zero': 0.0},\n",
       " {'mean': 0.5076697976930766, 'std': 0.024758115640694876, 'near_zero': 0.0},\n",
       " {'mean': 0.5078939349389533, 'std': 0.025999521779472456, 'near_zero': 0.0},\n",
       " {'mean': 0.5074071441333884, 'std': 0.026343723014604626, 'near_zero': 0.0},\n",
       " {'mean': 0.507021608329431,\n",
       "  'std': 0.02761724940469309,\n",
       "  'near_zero': 0.000244140625},\n",
       " {'mean': 0.5068284741377751, 'std': 0.02546014168915168, 'near_zero': 0.0},\n",
       " {'mean': 0.5064996422696563, 'std': 0.026571032996411042, 'near_zero': 0.0},\n",
       " {'mean': 0.5068446404480436, 'std': 0.025927680620327496, 'near_zero': 0.0},\n",
       " {'mean': 0.5066595158344069, 'std': 0.02598411139630089, 'near_zero': 0.0},\n",
       " {'mean': 0.5064035137597744, 'std': 0.02702472708560428, 'near_zero': 0.0},\n",
       " {'mean': 0.5066347690022923, 'std': 0.025550777612429142, 'near_zero': 0.0},\n",
       " {'mean': 0.5061350110315969, 'std': 0.026682084905053548, 'near_zero': 0.0},\n",
       " {'mean': 0.505837101715862, 'std': 0.02624779581772137, 'near_zero': 0.0},\n",
       " {'mean': 0.5054761761676675, 'std': 0.025347873990423122, 'near_zero': 0.0},\n",
       " {'mean': 0.5058979306612386, 'std': 0.02594994544028689, 'near_zero': 0.0},\n",
       " {'mean': 0.5053263602417412, 'std': 0.024496854280624925, 'near_zero': 0.0},\n",
       " {'mean': 0.5053512655511778, 'std': 0.026381908403713482, 'near_zero': 0.0},\n",
       " {'mean': 0.5061873740130823, 'std': 0.025988331303758317, 'near_zero': 0.0},\n",
       " {'mean': 0.5056789265427742, 'std': 0.026505725682938117, 'near_zero': 0.0},\n",
       " {'mean': 0.5046540999055555, 'std': 0.02629891255834596, 'near_zero': 0.0},\n",
       " {'mean': 0.5052954845877715, 'std': 0.026771832239305782, 'near_zero': 0.0},\n",
       " {'mean': 0.505458527338082, 'std': 0.025675203768863317, 'near_zero': 0.0},\n",
       " {'mean': 0.5055571090389767, 'std': 0.02613350215680931, 'near_zero': 0.0},\n",
       " {'mean': 0.5051023678854832, 'std': 0.026504927427729707, 'near_zero': 0.0},\n",
       " {'mean': 0.5046364496094087, 'std': 0.025921956773466252, 'near_zero': 0.0},\n",
       " {'mean': 0.5056669201119479, 'std': 0.025680659135432576, 'near_zero': 0.0},\n",
       " {'mean': 0.5044427669498206, 'std': 0.02542428793696362, 'near_zero': 0.0},\n",
       " {'mean': 0.504411875926803, 'std': 0.02584378178528317, 'near_zero': 0.0},\n",
       " {'mean': 0.5038616573677408, 'std': 0.026207728522195863, 'near_zero': 0.0},\n",
       " {'mean': 0.5037310941874029, 'std': 0.026204423777224033, 'near_zero': 0.0},\n",
       " {'mean': 0.5043286341716127, 'std': 0.026024426101303923, 'near_zero': 0.0},\n",
       " {'mean': 0.503608522904931, 'std': 0.026435599050107048, 'near_zero': 0.0},\n",
       " {'mean': 0.5043759363411535, 'std': 0.025756196875487622, 'near_zero': 0.0},\n",
       " {'mean': 0.504640367892063, 'std': 0.025821158597061612, 'near_zero': 0.0},\n",
       " {'mean': 0.504163582142816, 'std': 0.0257353246747239, 'near_zero': 0.0},\n",
       " {'mean': 0.5037881199719134, 'std': 0.02616232544138677, 'near_zero': 0.0},\n",
       " {'mean': 0.5038412515289538, 'std': 0.02668352437884855, 'near_zero': 0.0},\n",
       " {'mean': 0.5034817919715922, 'std': 0.025219663121395147, 'near_zero': 0.0},\n",
       " {'mean': 0.5042460014553625, 'std': 0.02643529115164287, 'near_zero': 0.0},\n",
       " {'mean': 0.5046290864051984, 'std': 0.027031279936720953, 'near_zero': 0.0},\n",
       " {'mean': 0.5038333914046939, 'std': 0.026367326270274702, 'near_zero': 0.0},\n",
       " {'mean': 0.5047683571710466, 'std': 0.0266376106071888, 'near_zero': 0.0},\n",
       " {'mean': 0.5045742967118326, 'std': 0.02548240289416106, 'near_zero': 0.0},\n",
       " {'mean': 0.5045244170765234, 'std': 0.02624316947049679, 'near_zero': 0.0},\n",
       " {'mean': 0.5032853149062337, 'std': 0.02549903087344999, 'near_zero': 0.0},\n",
       " {'mean': 0.5033083824434132, 'std': 0.025969803334681178, 'near_zero': 0.0},\n",
       " {'mean': 0.5045826599100572, 'std': 0.025378459578213046, 'near_zero': 0.0},\n",
       " {'mean': 0.5054996363370987, 'std': 0.026170044325405952, 'near_zero': 0.0},\n",
       " {'mean': 0.5041823169674627, 'std': 0.025359978061247648, 'near_zero': 0.0},\n",
       " {'mean': 0.5037219110777293, 'std': 0.026483106386891594, 'near_zero': 0.0},\n",
       " {'mean': 0.5046482088076897, 'std': 0.026423194931448984, 'near_zero': 0.0},\n",
       " {'mean': 0.5034339292597664, 'std': 0.026024083764473033, 'near_zero': 0.0},\n",
       " {'mean': 0.5041553314623326, 'std': 0.025186917811750233, 'near_zero': 0.0},\n",
       " {'mean': 0.5033150736937982, 'std': 0.026291160550674254, 'near_zero': 0.0},\n",
       " {'mean': 0.5034140955012317, 'std': 0.02525171457093183, 'near_zero': 0.0},\n",
       " {'mean': 0.5033491347842916, 'std': 0.02618755857227717, 'near_zero': 0.0},\n",
       " {'mean': 0.5034252782114919, 'std': 0.02666606053454454, 'near_zero': 0.0},\n",
       " {'mean': 0.5034331686482887, 'std': 0.02589146949258584, 'near_zero': 0.0},\n",
       " {'mean': 0.5022389452637813, 'std': 0.026445999240130556, 'near_zero': 0.0},\n",
       " {'mean': 0.5016759884047177, 'std': 0.025428207328242695, 'near_zero': 0.0},\n",
       " {'mean': 0.5020852100366763, 'std': 0.02508321083091986, 'near_zero': 0.0},\n",
       " {'mean': 0.5011926501831334, 'std': 0.025465009457299508, 'near_zero': 0.0},\n",
       " {'mean': 0.5014442617665165, 'std': 0.026141701717370208, 'near_zero': 0.0},\n",
       " {'mean': 0.5012107894362084, 'std': 0.026787950304448777, 'near_zero': 0.0},\n",
       " {'mean': 0.5017070907975199, 'std': 0.026354308707934898, 'near_zero': 0.0},\n",
       " {'mean': 0.5015255001786532, 'std': 0.0244554289798782, 'near_zero': 0.0},\n",
       " {'mean': 0.5015843764687027, 'std': 0.025073350762411403, 'near_zero': 0.0},\n",
       " {'mean': 0.501647619468907, 'std': 0.02560794918371516, 'near_zero': 0.0},\n",
       " {'mean': 0.5014696090451314, 'std': 0.024902032921524497, 'near_zero': 0.0},\n",
       " {'mean': 0.5026388323696636, 'std': 0.027922124091655457, 'near_zero': 0.0},\n",
       " {'mean': 0.501991654399852, 'std': 0.025451995537326848, 'near_zero': 0.0},\n",
       " {'mean': 0.5023708461882077, 'std': 0.02506612152905485, 'near_zero': 0.0},\n",
       " {'mean': 0.5023134091405259, 'std': 0.025864978440985578, 'near_zero': 0.0},\n",
       " {'mean': 0.5020595452135759, 'std': 0.025913334591951845, 'near_zero': 0.0},\n",
       " {'mean': 0.5029104989309459, 'std': 0.02698785261459624, 'near_zero': 0.0},\n",
       " {'mean': 0.5035721767598507, 'std': 0.023962249953788466, 'near_zero': 0.0},\n",
       " {'mean': 0.5033197248868242, 'std': 0.02564936874551623, 'near_zero': 0.0},\n",
       " {'mean': 0.5041788969517491, 'std': 0.02647356126380961, 'near_zero': 0.0},\n",
       " {'mean': 0.505004966161948, 'std': 0.025676406874977686, 'near_zero': 0.0},\n",
       " {'mean': 0.5045952678419456, 'std': 0.025584052276902587, 'near_zero': 0.0},\n",
       " {'mean': 0.5054100746965238, 'std': 0.025730864882704145, 'near_zero': 0.0},\n",
       " {'mean': 0.5060888058194406, 'std': 0.026213580567358577, 'near_zero': 0.0},\n",
       " {'mean': 0.5061146285809472, 'std': 0.026694501783038536, 'near_zero': 0.0},\n",
       " {'mean': 0.5059938653284054, 'std': 0.02533176503087636, 'near_zero': 0.0},\n",
       " {'mean': 0.5060355023438705, 'std': 0.027647030129314118, 'near_zero': 0.0},\n",
       " {'mean': 0.5060881259782617, 'std': 0.025707004353854496, 'near_zero': 0.0},\n",
       " {'mean': 0.5057354538513865, 'std': 0.026412449452536558, 'near_zero': 0.0},\n",
       " {'mean': 0.5054351021411876, 'std': 0.026273015850301114, 'near_zero': 0.0},\n",
       " {'mean': 0.5063452371315007, 'std': 0.0270034748960249, 'near_zero': 0.0},\n",
       " {'mean': 0.5063870564979738, 'std': 0.02659589616714601, 'near_zero': 0.0},\n",
       " {'mean': 0.5060161130424357, 'std': 0.027305631802180017, 'near_zero': 0.0},\n",
       " {'mean': 0.506782652747151, 'std': 0.027670027360350753, 'near_zero': 0.0},\n",
       " {'mean': 0.5072317178510324, 'std': 0.0274123557868874, 'near_zero': 0.0},\n",
       " {'mean': 0.507216134692885, 'std': 0.028273234840781435, 'near_zero': 0.0},\n",
       " {'mean': 0.5067712708623855, 'std': 0.02533039853661665, 'near_zero': 0.0},\n",
       " {'mean': 0.5074802950761068, 'std': 0.02794663845784793, 'near_zero': 0.0},\n",
       " {'mean': 0.5078048631160577, 'std': 0.026564732429925565, 'near_zero': 0.0},\n",
       " {'mean': 0.5073761206220035, 'std': 0.02784273339318995, 'near_zero': 0.0},\n",
       " {'mean': 0.5080536305482252, 'std': 0.026708390303093944, 'near_zero': 0.0},\n",
       " {'mean': 0.5074333818931149, 'std': 0.026272368766013243, 'near_zero': 0.0},\n",
       " {'mean': 0.5075665057604171, 'std': 0.02717235610783877, 'near_zero': 0.0},\n",
       " {'mean': 0.5072815127195243, 'std': 0.026376717532116005, 'near_zero': 0.0},\n",
       " {'mean': 0.5069750828017678, 'std': 0.026174855855797773, 'near_zero': 0.0},\n",
       " {'mean': 0.5066376652984764, 'std': 0.02673079343105567, 'near_zero': 0.0},\n",
       " {'mean': 0.5069255456346502, 'std': 0.02564359431966309, 'near_zero': 0.0},\n",
       " {'mean': 0.5071358451141343, 'std': 0.02792615534973109, 'near_zero': 0.0},\n",
       " {'mean': 0.5074112498361992, 'std': 0.02611914381579434, 'near_zero': 0.0},\n",
       " {'mean': 0.506549895249764, 'std': 0.02648790434764613, 'near_zero': 0.0},\n",
       " {'mean': 0.5064287879327573, 'std': 0.026591237532321874, 'near_zero': 0.0},\n",
       " {'mean': 0.506031967837816, 'std': 0.02510900271347956, 'near_zero': 0.0},\n",
       " {'mean': 0.5060415994389994, 'std': 0.02705831360931948, 'near_zero': 0.0},\n",
       " {'mean': 0.5066773338940911, 'std': 0.02516983224637886, 'near_zero': 0.0},\n",
       " {'mean': 0.5070269734097105, 'std': 0.026788682968716854, 'near_zero': 0.0},\n",
       " {'mean': 0.5063753726376437, 'std': 0.026320087803512984, 'near_zero': 0.0},\n",
       " {'mean': 0.5060264430841789,\n",
       "  'std': 0.026541312864261025,\n",
       "  'near_zero': 0.000244140625},\n",
       " {'mean': 0.5061030777345045, 'std': 0.026781545936656367, 'near_zero': 0.0},\n",
       " {'mean': 0.5069114123920013, 'std': 0.02637530212118078, 'near_zero': 0.0},\n",
       " {'mean': 0.5070764918175682, 'std': 0.02622178470930239, 'near_zero': 0.0},\n",
       " {'mean': 0.5063291657150932, 'std': 0.026749866792013785, 'near_zero': 0.0},\n",
       " {'mean': 0.5065900663838758, 'std': 0.026255670390166692, 'near_zero': 0.0},\n",
       " {'mean': 0.5060330511229989, 'std': 0.024938209477029606, 'near_zero': 0.0},\n",
       " {'mean': 0.505959108756857, 'std': 0.02549450812530991, 'near_zero': 0.0},\n",
       " {'mean': 0.5055210232827199, 'std': 0.02583561823795253, 'near_zero': 0.0},\n",
       " {'mean': 0.5062113928223957, 'std': 0.02641863594289476, 'near_zero': 0.0},\n",
       " {'mean': 0.5057414420371392, 'std': 0.024749491967037303, 'near_zero': 0.0},\n",
       " {'mean': 0.505782073612165, 'std': 0.025784023475899902, 'near_zero': 0.0},\n",
       " {'mean': 0.5049299807310197, 'std': 0.0259831822515844, 'near_zero': 0.0},\n",
       " {'mean': 0.5050882790690625, 'std': 0.02476665421607564, 'near_zero': 0.0},\n",
       " {'mean': 0.5051777319584181, 'std': 0.02518616748274523, 'near_zero': 0.0},\n",
       " {'mean': 0.503858948091688, 'std': 0.025097893918828922, 'near_zero': 0.0},\n",
       " {'mean': 0.5041217290677786, 'std': 0.026324206506008987, 'near_zero': 0.0},\n",
       " {'mean': 0.5039785671198367, 'std': 0.025885663511593427, 'near_zero': 0.0},\n",
       " {'mean': 0.50371138937037, 'std': 0.026109164152346397, 'near_zero': 0.0},\n",
       " {'mean': 0.5029888440401886, 'std': 0.025400213245417833, 'near_zero': 0.0},\n",
       " {'mean': 0.5040245265254555, 'std': 0.02681437815548798, 'near_zero': 0.0},\n",
       " {'mean': 0.5035447819067677, 'std': 0.026565288574128685, 'near_zero': 0.0},\n",
       " {'mean': 0.5036357321491651, 'std': 0.02579930815651309, 'near_zero': 0.0},\n",
       " {'mean': 0.5036463184677771, 'std': 0.026199044391089263, 'near_zero': 0.0},\n",
       " {'mean': 0.5021721000506489, 'std': 0.02438051740951192, 'near_zero': 0.0},\n",
       " {'mean': 0.502718882523294, 'std': 0.025418333960147553, 'near_zero': 0.0},\n",
       " {'mean': 0.5033480251638714, 'std': 0.026558977903327896, 'near_zero': 0.0},\n",
       " {'mean': 0.5024598742109555, 'std': 0.024914207421999734, 'near_zero': 0.0},\n",
       " {'mean': 0.5026057728972116, 'std': 0.02548665158961605, 'near_zero': 0.0},\n",
       " {'mean': 0.5034921185460659, 'std': 0.02504741746656052, 'near_zero': 0.0},\n",
       " {'mean': 0.5027778802452694, 'std': 0.02533394120501825, 'near_zero': 0.0},\n",
       " {'mean': 0.5033237536914823, 'std': 0.026334881413653134, 'near_zero': 0.0},\n",
       " {'mean': 0.5042910973560095, 'std': 0.025243831536823247, 'near_zero': 0.0},\n",
       " {'mean': 0.5037525991580549, 'std': 0.026924405898231273, 'near_zero': 0.0},\n",
       " {'mean': 0.5041426316452304, 'std': 0.025934883029175883, 'near_zero': 0.0},\n",
       " {'mean': 0.5045499386008031, 'std': 0.02573354881812441, 'near_zero': 0.0},\n",
       " {'mean': 0.5039137146487886, 'std': 0.026502210661826325, 'near_zero': 0.0},\n",
       " {'mean': 0.5052299809447737, 'std': 0.027040944174412145, 'near_zero': 0.0},\n",
       " {'mean': 0.5047852190330735, 'std': 0.025283632163344283, 'near_zero': 0.0},\n",
       " {'mean': 0.5064142506467949, 'std': 0.026387487612751833, 'near_zero': 0.0},\n",
       " {'mean': 0.5055851927668954, 'std': 0.02641820972830469, 'near_zero': 0.0},\n",
       " {'mean': 0.5073475450223266, 'std': 0.027096925903201886, 'near_zero': 0.0},\n",
       " {'mean': 0.5061919645726258, 'std': 0.02684600954454341, 'near_zero': 0.0},\n",
       " {'mean': 0.5070329297837701, 'std': 0.027179726026529388, 'near_zero': 0.0},\n",
       " {'mean': 0.5071264844934966, 'std': 0.026525980812896373, 'near_zero': 0.0},\n",
       " {'mean': 0.5080662114905043, 'std': 0.026931963260902234, 'near_zero': 0.0},\n",
       " {'mean': 0.5075399772131297, 'std': 0.02610168660737365, 'near_zero': 0.0},\n",
       " {'mean': 0.5081370281205011, 'std': 0.02645208534504182, 'near_zero': 0.0},\n",
       " {'mean': 0.5078274312783094, 'std': 0.026450132756119422, 'near_zero': 0.0},\n",
       " {'mean': 0.508017739646845, 'std': 0.025160470348626486, 'near_zero': 0.0},\n",
       " {'mean': 0.5085221971360744, 'std': 0.026562113661772326, 'near_zero': 0.0},\n",
       " {'mean': 0.5086462527756116, 'std': 0.027772847039651445, 'near_zero': 0.0},\n",
       " {'mean': 0.5088477919385804, 'std': 0.02623039455221711, 'near_zero': 0.0},\n",
       " {'mean': 0.509265078028879, 'std': 0.026944381261551166, 'near_zero': 0.0},\n",
       " {'mean': 0.5081409873947456, 'std': 0.026589199955578003, 'near_zero': 0.0},\n",
       " {'mean': 0.5095682065210565, 'std': 0.028064841592883635, 'near_zero': 0.0},\n",
       " {'mean': 0.508762566496684, 'std': 0.02666044959169865, 'near_zero': 0.0},\n",
       " {'mean': 0.5090127088714047, 'std': 0.027603600790860525, 'near_zero': 0.0},\n",
       " {'mean': 0.5096991599185192, 'std': 0.02745693894441267, 'near_zero': 0.0},\n",
       " {'mean': 0.5095330181345311, 'std': 0.027316492326750826, 'near_zero': 0.0},\n",
       " {'mean': 0.5087853207452286, 'std': 0.027138732077160544, 'near_zero': 0.0},\n",
       " {'mean': 0.5089261410455637, 'std': 0.02703506364458902, 'near_zero': 0.0},\n",
       " {'mean': 0.5087561729431577, 'std': 0.026210140521360562, 'near_zero': 0.0},\n",
       " {'mean': 0.5093249985385451, 'std': 0.02655718383312618, 'near_zero': 0.0},\n",
       " {'mean': 0.5087080856964801, 'std': 0.027041320136419664, 'near_zero': 0.0},\n",
       " {'mean': 0.5090960179915545, 'std': 0.027407478133184532, 'near_zero': 0.0},\n",
       " {'mean': 0.5089949261841527, 'std': 0.027284730294473255, 'near_zero': 0.0},\n",
       " {'mean': 0.5088878753616781, 'std': 0.026778805310318364, 'near_zero': 0.0},\n",
       " {'mean': 0.5082909901639341, 'std': 0.026643336213010294, 'near_zero': 0.0},\n",
       " {'mean': 0.5085473984589546, 'std': 0.026603233539829522, 'near_zero': 0.0},\n",
       " {'mean': 0.5089178146169056, 'std': 0.027627635381436075, 'near_zero': 0.0},\n",
       " {'mean': 0.5075527773874988, 'std': 0.026753239035786653, 'near_zero': 0.0},\n",
       " {'mean': 0.5078307873350689, 'std': 0.02639086238635236, 'near_zero': 0.0},\n",
       " {'mean': 0.5077415590381061, 'std': 0.02630724507809431, 'near_zero': 0.0},\n",
       " {'mean': 0.5068644049763162, 'std': 0.027227760689049727, 'near_zero': 0.0},\n",
       " {'mean': 0.5073517921248452, 'std': 0.027300080901664938, 'near_zero': 0.0},\n",
       " {'mean': 0.5075102509602565, 'std': 0.02632493092010326, 'near_zero': 0.0},\n",
       " {'mean': 0.5072644730607989, 'std': 0.02683830322033521, 'near_zero': 0.0},\n",
       " {'mean': 0.506862721505611, 'std': 0.025982706218282463, 'near_zero': 0.0},\n",
       " {'mean': 0.5068488187547873, 'std': 0.026217331486774947, 'near_zero': 0.0},\n",
       " {'mean': 0.5067805545502697, 'std': 0.026734088010526083, 'near_zero': 0.0},\n",
       " {'mean': 0.5069494030439277, 'std': 0.028418545859855333, 'near_zero': 0.0},\n",
       " {'mean': 0.5067390207241611, 'std': 0.02689734066996136, 'near_zero': 0.0},\n",
       " {'mean': 0.5066838466891037, 'std': 0.026892371399768376, 'near_zero': 0.0},\n",
       " {'mean': 0.5065200859841337, 'std': 0.02589775932401054, 'near_zero': 0.0},\n",
       " {'mean': 0.506306572365349, 'std': 0.02658969731997294, 'near_zero': 0.0},\n",
       " {'mean': 0.5059485011418979, 'std': 0.026432388703923646, 'near_zero': 0.0},\n",
       " {'mean': 0.506575006511919, 'std': 0.028136347086906332, 'near_zero': 0.0},\n",
       " {'mean': 0.506281207547301, 'std': 0.027351112285972045, 'near_zero': 0.0},\n",
       " {'mean': 0.5055048475382431, 'std': 0.026171451157099557, 'near_zero': 0.0},\n",
       " {'mean': 0.5060581873692584, 'std': 0.028029665804208893, 'near_zero': 0.0},\n",
       " {'mean': 0.5051473713242433, 'std': 0.027269241961440205, 'near_zero': 0.0},\n",
       " {'mean': 0.505014983232707, 'std': 0.026669584798834047, 'near_zero': 0.0},\n",
       " {'mean': 0.504677820894913, 'std': 0.027778282048773188, 'near_zero': 0.0},\n",
       " {'mean': 0.5042693112313448, 'std': 0.02714836127707073, 'near_zero': 0.0},\n",
       " {'mean': 0.5043240359896966, 'std': 0.026762125307196908, 'near_zero': 0.0},\n",
       " {'mean': 0.5037458011818298, 'std': 0.027600728578840945, 'near_zero': 0.0},\n",
       " {'mean': 0.5037254052528995, 'std': 0.02805921785506162, 'near_zero': 0.0},\n",
       " {'mean': 0.5037012650563404, 'std': 0.028021054563177765, 'near_zero': 0.0},\n",
       " {'mean': 0.5035345121563617, 'std': 0.027526602049196654, 'near_zero': 0.0},\n",
       " {'mean': 0.5028366767854386, 'std': 0.027388630010475035, 'near_zero': 0.0},\n",
       " {'mean': 0.502459576163204, 'std': 0.02817595615581099, 'near_zero': 0.0},\n",
       " {'mean': 0.5029260057454374, 'std': 0.028872431952910522, 'near_zero': 0.0},\n",
       " {'mean': 0.5026353812043913, 'std': 0.02789969369142287, 'near_zero': 0.0},\n",
       " {'mean': 0.5024289832693895, 'std': 0.026649065717786836, 'near_zero': 0.0},\n",
       " {'mean': 0.5028931359250087, 'std': 0.02801708527434388, 'near_zero': 0.0},\n",
       " {'mean': 0.5026131137414745, 'std': 0.0289291590905431, 'near_zero': 0.0},\n",
       " {'mean': 0.5031769079975055, 'std': 0.027626481858477936, 'near_zero': 0.0},\n",
       " {'mean': 0.5033835313658763, 'std': 0.028431334604469193, 'near_zero': 0.0},\n",
       " {'mean': 0.503350409292666, 'std': 0.027930016367857458, 'near_zero': 0.0},\n",
       " {'mean': 0.5034905669240102, 'std': 0.028265360778323395, 'near_zero': 0.0},\n",
       " {'mean': 0.5027074570248762, 'std': 0.027914329423695226, 'near_zero': 0.0},\n",
       " {'mean': 0.5031875538209898, 'std': 0.02828979500758557, 'near_zero': 0.0},\n",
       " {'mean': 0.503383218901014, 'std': 0.02902084292542382, 'near_zero': 0.0},\n",
       " {'mean': 0.5036099177810405, 'std': 0.027605670642077522, 'near_zero': 0.0},\n",
       " {'mean': 0.5034149129460779, 'std': 0.02919861160380594, 'near_zero': 0.0},\n",
       " {'mean': 0.5039344410937672, 'std': 0.02742896738464564, 'near_zero': 0.0},\n",
       " {'mean': 0.5035207255340874, 'std': 0.028263264274597275, 'near_zero': 0.0},\n",
       " {'mean': 0.503995155262549, 'std': 0.027709881208727378, 'near_zero': 0.0},\n",
       " {'mean': 0.5059571536283844, 'std': 0.029974656078507113, 'near_zero': 0.0},\n",
       " {'mean': 0.5045654468350913, 'std': 0.028044261531065307, 'near_zero': 0.0},\n",
       " {'mean': 0.5041494835625044, 'std': 0.027780720361001057, 'near_zero': 0.0},\n",
       " {'mean': 0.5050923076096498, 'std': 0.028090090722353064, 'near_zero': 0.0},\n",
       " {'mean': 0.5054867327389835, 'std': 0.02866077192641553, 'near_zero': 0.0},\n",
       " {'mean': 0.505705155827826, 'std': 0.02821023801178693, 'near_zero': 0.0},\n",
       " {'mean': 0.5045177589992027, 'std': 0.027680332630751852, 'near_zero': 0.0},\n",
       " {'mean': 0.5051753256165378, 'std': 0.02702804579006116, 'near_zero': 0.0},\n",
       " {'mean': 0.5049268706058491, 'std': 0.03000474568242299, 'near_zero': 0.0},\n",
       " {'mean': 0.5050601949603688, 'std': 0.02749710167623531, 'near_zero': 0.0},\n",
       " {'mean': 0.5059021366172947, 'std': 0.03004786116522309, 'near_zero': 0.0},\n",
       " {'mean': 0.50635935294445, 'std': 0.029266727334582788, 'near_zero': 0.0},\n",
       " {'mean': 0.5048514444970799, 'std': 0.028468157005673872, 'near_zero': 0.0},\n",
       " {'mean': 0.5052433354549104, 'std': 0.02760733525409085, 'near_zero': 0.0},\n",
       " {'mean': 0.5068920125937544, 'std': 0.028618810743273094, 'near_zero': 0.0},\n",
       " {'mean': 0.5056811629357159, 'std': 0.02832973950134047, 'near_zero': 0.0},\n",
       " {'mean': 0.5060988312989673, 'std': 0.028897214706406667, 'near_zero': 0.0},\n",
       " {'mean': 0.5066742396754027, 'std': 0.028624231609399333, 'near_zero': 0.0},\n",
       " {'mean': 0.5072090616982379, 'std': 0.030221717394220388, 'near_zero': 0.0},\n",
       " {'mean': 0.5058318375881194, 'std': 0.026881142100810287, 'near_zero': 0.0},\n",
       " {'mean': 0.5063646916426727, 'std': 0.028855968042262075, 'near_zero': 0.0},\n",
       " {'mean': 0.5061266470279733, 'std': 0.027195521909063443, 'near_zero': 0.0},\n",
       " {'mean': 0.5066955178747766, 'std': 0.028152287862620962, 'near_zero': 0.0},\n",
       " {'mean': 0.5066760178433483, 'std': 0.027886075541215586, 'near_zero': 0.0},\n",
       " {'mean': 0.5066120285778656, 'std': 0.027668214010404386, 'near_zero': 0.0},\n",
       " {'mean': 0.506914515276986, 'std': 0.02753928889256309, 'near_zero': 0.0},\n",
       " {'mean': 0.5065739486020427, 'std': 0.02642681602785987, 'near_zero': 0.0},\n",
       " {'mean': 0.506826218848857, 'std': 0.02688891178634118, 'near_zero': 0.0},\n",
       " {'mean': 0.5058616825702285, 'std': 0.0267956153043285, 'near_zero': 0.0},\n",
       " {'mean': 0.5067862772854638, 'std': 0.028069725503516652, 'near_zero': 0.0},\n",
       " {'mean': 0.5061208825596923, 'std': 0.026453110443086427, 'near_zero': 0.0},\n",
       " {'mean': 0.5068344134047137, 'std': 0.027598757972396873, 'near_zero': 0.0},\n",
       " {'mean': 0.5055356966265265, 'std': 0.026327005128418846, 'near_zero': 0.0},\n",
       " {'mean': 0.5058741172930449, 'std': 0.026057471512839478, 'near_zero': 0.0},\n",
       " {'mean': 0.5051078042265387, 'std': 0.025800528884038037, 'near_zero': 0.0},\n",
       " {'mean': 0.5051308116474714, 'std': 0.02550135956478014, 'near_zero': 0.0},\n",
       " {'mean': 0.505423142615083, 'std': 0.026450279952539218, 'near_zero': 0.0},\n",
       " {'mean': 0.5052121454677615, 'std': 0.026091050739424852, 'near_zero': 0.0},\n",
       " {'mean': 0.5052826561838244, 'std': 0.02641813491262185, 'near_zero': 0.0},\n",
       " {'mean': 0.5051751288636972, 'std': 0.027159272819535975, 'near_zero': 0.0},\n",
       " {'mean': 0.5058617295192557, 'std': 0.027299299377578475, 'near_zero': 0.0},\n",
       " {'mean': 0.5051770833490714, 'std': 0.02727020997999559, 'near_zero': 0.0},\n",
       " {'mean': 0.5051455332613394, 'std': 0.026478552383394912, 'near_zero': 0.0},\n",
       " {'mean': 0.5054338756375878, 'std': 0.026527294248662216, 'near_zero': 0.0},\n",
       " {'mean': 0.5051319480654459, 'std': 0.02719879829062873, 'near_zero': 0.0},\n",
       " {'mean': 0.5051399892022141, 'std': 0.027165480133139436, 'near_zero': 0.0},\n",
       " {'mean': 0.5050118058278532, 'std': 0.026244287697870745, 'near_zero': 0.0},\n",
       " {'mean': 0.5053172854660113, 'std': 0.027355741524381607, 'near_zero': 0.0},\n",
       " {'mean': 0.505185247261555, 'std': 0.02717741279981527, 'near_zero': 0.0},\n",
       " {'mean': 0.5048975242480869, 'std': 0.027067294582162497, 'near_zero': 0.0},\n",
       " {'mean': 0.505230222867394, 'std': 0.028245203281682396, 'near_zero': 0.0},\n",
       " {'mean': 0.5051886537693295, 'std': 0.027492243566631804, 'near_zero': 0.0},\n",
       " {'mean': 0.5056710184668611, 'std': 0.028158661617443917, 'near_zero': 0.0},\n",
       " {'mean': 0.5055836475901383, 'std': 0.027128431295315003, 'near_zero': 0.0},\n",
       " {'mean': 0.5044327106536404, 'std': 0.02719798522370099, 'near_zero': 0.0},\n",
       " {'mean': 0.5049518122879406, 'std': 0.027627897811093746, 'near_zero': 0.0},\n",
       " {'mean': 0.5054357827613225, 'std': 0.027493520241378848, 'near_zero': 0.0},\n",
       " {'mean': 0.5051125037206567, 'std': 0.027585587461834996, 'near_zero': 0.0},\n",
       " {'mean': 0.5044153928951007, 'std': 0.027814610867353085, 'near_zero': 0.0},\n",
       " {'mean': 0.5043254196390374, 'std': 0.02823167528327836, 'near_zero': 0.0},\n",
       " {'mean': 0.5046530040334707, 'std': 0.027269951329169474, 'near_zero': 0.0},\n",
       " {'mean': 0.504037745024311, 'std': 0.02906062180549502, 'near_zero': 0.0},\n",
       " {'mean': 0.5045828121089236, 'std': 0.027840738194362617, 'near_zero': 0.0},\n",
       " {'mean': 0.5051489430488078, 'std': 0.028740860196963893, 'near_zero': 0.0},\n",
       " {'mean': 0.5046342614514756, 'std': 0.028272789989959916, 'near_zero': 0.0},\n",
       " {'mean': 0.505092646296921, 'std': 0.028132022304743903, 'near_zero': 0.0},\n",
       " {'mean': 0.5055685694118793, 'std': 0.02775976904774006, 'near_zero': 0.0},\n",
       " {'mean': 0.5052865818269658, 'std': 0.02853527328326039, 'near_zero': 0.0},\n",
       " {'mean': 0.5059393708650054, 'std': 0.02906754199377155, 'near_zero': 0.0},\n",
       " {'mean': 0.5053411952606517, 'std': 0.027158412270727725, 'near_zero': 0.0},\n",
       " {'mean': 0.5060271011453212, 'std': 0.02815534630493904, 'near_zero': 0.0},\n",
       " {'mean': 0.5065046052908692, 'std': 0.029608490506641306, 'near_zero': 0.0},\n",
       " {'mean': 0.5059260607475953, 'std': 0.02947442575490422, 'near_zero': 0.0},\n",
       " {'mean': 0.5062812997674359, 'std': 0.028069446349491534, 'near_zero': 0.0},\n",
       " {'mean': 0.5058474911212948, 'std': 0.028513887935207743, 'near_zero': 0.0},\n",
       " {'mean': 0.504810233552889, 'std': 0.028500429771693866, 'near_zero': 0.0},\n",
       " {'mean': 0.5043173457527921, 'std': 0.028190265653006245, 'near_zero': 0.0},\n",
       " {'mean': 0.5046137102629352, 'std': 0.026928009866730895, 'near_zero': 0.0},\n",
       " {'mean': 0.5043092104827392, 'std': 0.027454256433188058, 'near_zero': 0.0},\n",
       " {'mean': 0.5037546841959007, 'std': 0.02757087234536761, 'near_zero': 0.0},\n",
       " {'mean': 0.5041096232508486, 'std': 0.026969339058356013, 'near_zero': 0.0},\n",
       " {'mean': 0.5032553269284661, 'std': 0.027431593801172726, 'near_zero': 0.0},\n",
       " {'mean': 0.5036479593980341, 'std': 0.02809969294732939, 'near_zero': 0.0},\n",
       " {'mean': 0.5032372114921311, 'std': 0.027064546676470173, 'near_zero': 0.0},\n",
       " {'mean': 0.5031177567373402, 'std': 0.026757508357221228, 'near_zero': 0.0},\n",
       " {'mean': 0.5026942616642532, 'std': 0.027950015233096977, 'near_zero': 0.0},\n",
       " {'mean': 0.5030152182012095, 'std': 0.027427203793671567, 'near_zero': 0.0},\n",
       " {'mean': 0.5038924275762362, 'std': 0.028450827275361357, 'near_zero': 0.0},\n",
       " {'mean': 0.5037369609482533, 'std': 0.026584299756102596, 'near_zero': 0.0},\n",
       " {'mean': 0.5043062096442767, 'std': 0.026431303367151864, 'near_zero': 0.0},\n",
       " {'mean': 0.5054319152725246, 'std': 0.027850648346972005, 'near_zero': 0.0},\n",
       " {'mean': 0.5048950104102806, 'std': 0.027258595867929246, 'near_zero': 0.0},\n",
       " {'mean': 0.5042723706558705, 'std': 0.02687066333127881, 'near_zero': 0.0},\n",
       " {'mean': 0.5053455509262421, 'std': 0.028065877360132236, 'near_zero': 0.0},\n",
       " {'mean': 0.5049068420983541, 'std': 0.026342270752263128, 'near_zero': 0.0},\n",
       " {'mean': 0.5050430355119104, 'std': 0.026154135038239608, 'near_zero': 0.0},\n",
       " {'mean': 0.5058436863085465, 'std': 0.026462086995746762, 'near_zero': 0.0},\n",
       " {'mean': 0.505102047573878, 'std': 0.02783265530787285, 'near_zero': 0.0},\n",
       " {'mean': 0.5058641720421868, 'std': 0.027712581688520945, 'near_zero': 0.0},\n",
       " {'mean': 0.5057234987740745, 'std': 0.026940700353687844, 'near_zero': 0.0},\n",
       " {'mean': 0.5064508915774375, 'std': 0.02665256448328577, 'near_zero': 0.0},\n",
       " {'mean': 0.5062859716483683, 'std': 0.027681026142143517, 'near_zero': 0.0},\n",
       " {'mean': 0.5060670336730155, 'std': 0.027390190769603275, 'near_zero': 0.0},\n",
       " {'mean': 0.5059318321054505, 'std': 0.02766028075440372, 'near_zero': 0.0},\n",
       " {'mean': 0.5060449077291409, 'std': 0.027450190152416093, 'near_zero': 0.0},\n",
       " {'mean': 0.5064905391638961, 'std': 0.02853725782040462, 'near_zero': 0.0},\n",
       " {'mean': 0.5059195648182129, 'std': 0.027234294362024618, 'near_zero': 0.0},\n",
       " {'mean': 0.5067270738153418, 'std': 0.027742540730566468, 'near_zero': 0.0},\n",
       " {'mean': 0.5059631818337271, 'std': 0.027829910428290968, 'near_zero': 0.0},\n",
       " {'mean': 0.506072674632381, 'std': 0.027781169853321533, 'near_zero': 0.0},\n",
       " {'mean': 0.5062573822252543, 'std': 0.027999779146485635, 'near_zero': 0.0},\n",
       " {'mean': 0.5064230478832927, 'std': 0.029001479357338492, 'near_zero': 0.0},\n",
       " {'mean': 0.505831328460632, 'std': 0.02789488952989726, 'near_zero': 0.0},\n",
       " {'mean': 0.5061905533649238, 'std': 0.028245710219786772, 'near_zero': 0.0},\n",
       " {'mean': 0.5053156599812954, 'std': 0.027497143967012288, 'near_zero': 0.0},\n",
       " {'mean': 0.5048948487061445, 'std': 0.028895524881822364, 'near_zero': 0.0},\n",
       " {'mean': 0.5041796367573854, 'std': 0.02679781174116563, 'near_zero': 0.0},\n",
       " {'mean': 0.5044745668860326, 'std': 0.02767955762252108, 'near_zero': 0.0},\n",
       " {'mean': 0.5041879044445023, 'std': 0.028263702797387772, 'near_zero': 0.0},\n",
       " {'mean': 0.5046909744957531, 'std': 0.026667132334381404, 'near_zero': 0.0},\n",
       " {'mean': 0.5041195870969797, 'std': 0.02815175820223027, 'near_zero': 0.0},\n",
       " {'mean': 0.5042178765533247, 'std': 0.027423290291375312, 'near_zero': 0.0},\n",
       " {'mean': 0.5043840109392441, 'std': 0.028178507319016697, 'near_zero': 0.0},\n",
       " {'mean': 0.5036532730281674, 'std': 0.028520319991743485, 'near_zero': 0.0},\n",
       " {'mean': 0.5042650676362506, 'std': 0.028561779879682496, 'near_zero': 0.0},\n",
       " {'mean': 0.5039797139800334, 'std': 0.02800539864772153, 'near_zero': 0.0},\n",
       " {'mean': 0.5044259814799001, 'std': 0.027797274735331487, 'near_zero': 0.0},\n",
       " {'mean': 0.503879455496146, 'std': 0.02814781246256149, 'near_zero': 0.0},\n",
       " {'mean': 0.503953149866218, 'std': 0.02730866574227602, 'near_zero': 0.0},\n",
       " {'mean': 0.5031664381109635, 'std': 0.02776296234213471, 'near_zero': 0.0},\n",
       " {'mean': 0.5047777078378854, 'std': 0.02710077828474804, 'near_zero': 0.0},\n",
       " {'mean': 0.5048241273875516, 'std': 0.029489477585046813, 'near_zero': 0.0},\n",
       " {'mean': 0.5045637925820234, 'std': 0.02805448458700532, 'near_zero': 0.0},\n",
       " {'mean': 0.5044762467668363, 'std': 0.028020385968319638, 'near_zero': 0.0},\n",
       " {'mean': 0.504742135887405, 'std': 0.027863863894065338, 'near_zero': 0.0},\n",
       " {'mean': 0.5041489954192819, 'std': 0.027620580188440776, 'near_zero': 0.0},\n",
       " {'mean': 0.5049981673661474, 'std': 0.02886866009035691, 'near_zero': 0.0},\n",
       " {'mean': 0.5053292010510517, 'std': 0.02832798143793299, 'near_zero': 0.0},\n",
       " {'mean': 0.5044053267640747, 'std': 0.027687694322332358, 'near_zero': 0.0},\n",
       " {'mean': 0.505361506039838, 'std': 0.028100734266014487, 'near_zero': 0.0},\n",
       " {'mean': 0.5054860737685412, 'std': 0.028000628415314657, 'near_zero': 0.0},\n",
       " {'mean': 0.5054889929920007, 'std': 0.02837463754334356, 'near_zero': 0.0},\n",
       " {'mean': 0.504503912986634, 'std': 0.02768878460265817, 'near_zero': 0.0},\n",
       " {'mean': 0.5052975490214111, 'std': 0.028714802871826962, 'near_zero': 0.0},\n",
       " {'mean': 0.50562036586419, 'std': 0.028378432521904612, 'near_zero': 0.0},\n",
       " {'mean': 0.5052842342160517, 'std': 0.028769404084938565, 'near_zero': 0.0},\n",
       " {'mean': 0.5054087224511192, 'std': 0.0288528709617774, 'near_zero': 0.0},\n",
       " {'mean': 0.5066063768411899, 'std': 0.0282405786114889, 'near_zero': 0.0},\n",
       " {'mean': 0.5066736014104646, 'std': 0.029680594862763574, 'near_zero': 0.0},\n",
       " {'mean': 0.5061117247857241, 'std': 0.02975148787694021, 'near_zero': 0.0},\n",
       " {'mean': 0.5057611166378728, 'std': 0.029200378701617343, 'near_zero': 0.0},\n",
       " {'mean': 0.5069003840470515, 'std': 0.03003919035544886, 'near_zero': 0.0},\n",
       " {'mean': 0.5051730145320301, 'std': 0.029203380844694544, 'near_zero': 0.0},\n",
       " {'mean': 0.5064067291561187, 'std': 0.029072427474648315, 'near_zero': 0.0},\n",
       " {'mean': 0.5062873810647199, 'std': 0.029305555573466948, 'near_zero': 0.0},\n",
       " {'mean': 0.5063990419935984, 'std': 0.029755152354053047, 'near_zero': 0.0},\n",
       " {'mean': 0.5045940296280554, 'std': 0.028270328552225988, 'near_zero': 0.0},\n",
       " {'mean': 0.5053509772266465, 'std': 0.02869269159062323, 'near_zero': 0.0},\n",
       " {'mean': 0.5056236477632063, 'std': 0.02920965754763916, 'near_zero': 0.0},\n",
       " {'mean': 0.504416334235227, 'std': 0.029250568511715744, 'near_zero': 0.0},\n",
       " {'mean': 0.5044801191938995, 'std': 0.028859086031741272, 'near_zero': 0.0},\n",
       " {'mean': 0.5040714933608438, 'std': 0.028666957231443697, 'near_zero': 0.0},\n",
       " {'mean': 0.5042091667042399, 'std': 0.028070303944402967, 'near_zero': 0.0},\n",
       " {'mean': 0.5043694543743984, 'std': 0.028959153644466665, 'near_zero': 0.0},\n",
       " {'mean': 0.5038577649908162, 'std': 0.028664522810613966, 'near_zero': 0.0},\n",
       " {'mean': 0.5033770201776796, 'std': 0.029242507233514417, 'near_zero': 0.0},\n",
       " {'mean': 0.5031942150368962, 'std': 0.029110757506580383, 'near_zero': 0.0},\n",
       " {'mean': 0.5033570023398183, 'std': 0.02951100853879476, 'near_zero': 0.0},\n",
       " {'mean': 0.5029527663584124, 'std': 0.02874678125491839, 'near_zero': 0.0},\n",
       " {'mean': 0.5031148989768763, 'std': 0.02970892196368551, 'near_zero': 0.0},\n",
       " {'mean': 0.5024372184512366, 'std': 0.02854353760505078, 'near_zero': 0.0},\n",
       " {'mean': 0.5036306127693709, 'std': 0.030394812932487702, 'near_zero': 0.0},\n",
       " {'mean': 0.502792578802076, 'std': 0.02814193636736122, 'near_zero': 0.0},\n",
       " {'mean': 0.5033924149537357, 'std': 0.030234012684471432, 'near_zero': 0.0},\n",
       " {'mean': 0.5032713344420405, 'std': 0.029353100684224726, 'near_zero': 0.0},\n",
       " {'mean': 0.5040049439103615, 'std': 0.03057586132381903, 'near_zero': 0.0},\n",
       " {'mean': 0.5036294579017311, 'std': 0.030499433381303804, 'near_zero': 0.0},\n",
       " {'mean': 0.5035366329503673, 'std': 0.030031632779676035, 'near_zero': 0.0},\n",
       " {'mean': 0.5041784444198543, 'std': 0.028423407620209503, 'near_zero': 0.0},\n",
       " {'mean': 0.5040731328670867, 'std': 0.02974820345359129, 'near_zero': 0.0},\n",
       " {'mean': 0.5048314855550289, 'std': 0.031000061102785702, 'near_zero': 0.0},\n",
       " {'mean': 0.503988442423579,\n",
       "  'std': 0.02997837447207776,\n",
       "  'near_zero': 0.000244140625},\n",
       " {'mean': 0.5036713607031791, 'std': 0.030639318176234876, 'near_zero': 0.0},\n",
       " {'mean': 0.5043942449796701, 'std': 0.030212142449203894, 'near_zero': 0.0},\n",
       " {'mean': 0.5044097167111072, 'std': 0.03083054716179552, 'near_zero': 0.0},\n",
       " {'mean': 0.5049811211345834, 'std': 0.031149899996598784, 'near_zero': 0.0},\n",
       " {'mean': 0.5057526885113721, 'std': 0.03164668739818089, 'near_zero': 0.0},\n",
       " {'mean': 0.5061139221357361, 'std': 0.030091055357190803, 'near_zero': 0.0},\n",
       " {'mean': 0.506588067154923, 'std': 0.03143862631707555, 'near_zero': 0.0},\n",
       " {'mean': 0.5059560525985888, 'std': 0.029595622337823077, 'near_zero': 0.0},\n",
       " {'mean': 0.50622122413134, 'std': 0.031036498087720153, 'near_zero': 0.0},\n",
       " {'mean': 0.5071602744708553, 'std': 0.030842992790144193, 'near_zero': 0.0},\n",
       " {'mean': 0.5062780215160023, 'std': 0.029106586294985956, 'near_zero': 0.0},\n",
       " {'mean': 0.5071790148703681, 'std': 0.0288111653632318, 'near_zero': 0.0},\n",
       " {'mean': 0.5071568807244919, 'std': 0.030158244471802438, 'near_zero': 0.0},\n",
       " {'mean': 0.506479149414508, 'std': 0.029116215955868937, 'near_zero': 0.0},\n",
       " {'mean': 0.5069621345556026, 'std': 0.03131149451509487, 'near_zero': 0.0},\n",
       " {'mean': 0.5067542313594109, 'std': 0.030858060482292, 'near_zero': 0.0},\n",
       " {'mean': 0.5074034717367423, 'std': 0.0302468328364106, 'near_zero': 0.0},\n",
       " {'mean': 0.5063643446563046, 'std': 0.028928790293843373, 'near_zero': 0.0},\n",
       " {'mean': 0.5060699243480664, 'std': 0.030196732934931348, 'near_zero': 0.0},\n",
       " {'mean': 0.5059463017927524, 'std': 0.03026314454331245, 'near_zero': 0.0},\n",
       " {'mean': 0.5055694003662063, 'std': 0.029711209549322114, 'near_zero': 0.0},\n",
       " {'mean': 0.5056052912984277, 'std': 0.031636800919355806, 'near_zero': 0.0},\n",
       " {'mean': 0.5054876550453613, 'std': 0.030002652668331027, 'near_zero': 0.0},\n",
       " {'mean': 0.5049852661019023, 'std': 0.030552184137225803, 'near_zero': 0.0},\n",
       " {'mean': 0.5048009996700689, 'std': 0.028371960854015887, 'near_zero': 0.0},\n",
       " {'mean': 0.5054820660595122, 'std': 0.029514701766743066, 'near_zero': 0.0},\n",
       " {'mean': 0.5060833118882293, 'std': 0.030334220063850267, 'near_zero': 0.0},\n",
       " {'mean': 0.5051966225859444, 'std': 0.030334430057836773, 'near_zero': 0.0},\n",
       " {'mean': 0.504099959593624, 'std': 0.030602573254684365, 'near_zero': 0.0},\n",
       " {'mean': 0.5045592858599418, 'std': 0.02946838071936202, 'near_zero': 0.0},\n",
       " {'mean': 0.5038969166719669, 'std': 0.03030314530669562, 'near_zero': 0.0},\n",
       " {'mean': 0.5046738034505855, 'std': 0.03012979963197259, 'near_zero': 0.0},\n",
       " {'mean': 0.5044841837859109, 'std': 0.029430505069365512, 'near_zero': 0.0},\n",
       " {'mean': 0.5054407257429183,\n",
       "  'std': 0.03079130881982062,\n",
       "  'near_zero': 0.000244140625},\n",
       " {'mean': 0.5049782621416476, 'std': 0.030169725930489267, 'near_zero': 0.0},\n",
       " {'mean': 0.5059999843925638, 'std': 0.03097640148216087, 'near_zero': 0.0},\n",
       " {'mean': 0.505437517058502, 'std': 0.029660102190522217, 'near_zero': 0.0},\n",
       " {'mean': 0.5050485394193045, 'std': 0.02824411241777938, 'near_zero': 0.0},\n",
       " {'mean': 0.5045830762381941, 'std': 0.028403555329029665, 'near_zero': 0.0},\n",
       " {'mean': 0.5047768171270419, 'std': 0.028627190731336214, 'near_zero': 0.0},\n",
       " {'mean': 0.50524822596133, 'std': 0.02732032670207335, 'near_zero': 0.0},\n",
       " {'mean': 0.505426396472914, 'std': 0.029278697135054318, 'near_zero': 0.0},\n",
       " {'mean': 0.5059491437685812, 'std': 0.03046149163418519, 'near_zero': 0.0},\n",
       " {'mean': 0.5054734487210328, 'std': 0.028584020352470624, 'near_zero': 0.0},\n",
       " {'mean': 0.5058084392238009, 'std': 0.028849402526273063, 'near_zero': 0.0},\n",
       " {'mean': 0.5061503390551436, 'std': 0.0292417808285814, 'near_zero': 0.0},\n",
       " {'mean': 0.5060524613223056, 'std': 0.028981049650258703, 'near_zero': 0.0},\n",
       " {'mean': 0.5060681100217825, 'std': 0.028826155436441042, 'near_zero': 0.0},\n",
       " {'mean': 0.5055820861316094, 'std': 0.027728321087045385, 'near_zero': 0.0},\n",
       " {'mean': 0.506278748544781, 'std': 0.028337647490584268, 'near_zero': 0.0},\n",
       " {'mean': 0.5056915766041937, 'std': 0.029716416241818613, 'near_zero': 0.0},\n",
       " {'mean': 0.5061455695511694, 'std': 0.028620108682069257, 'near_zero': 0.0},\n",
       " {'mean': 0.5056618004776468, 'std': 0.029253491219161692, 'near_zero': 0.0},\n",
       " {'mean': 0.5066810381668034, 'std': 0.028046180349003004, 'near_zero': 0.0},\n",
       " {'mean': 0.5057734062917224, 'std': 0.028600683498283878, 'near_zero': 0.0},\n",
       " {'mean': 0.5069919202579686, 'std': 0.029150169956124027, 'near_zero': 0.0},\n",
       " {'mean': 0.50686406855632, 'std': 0.029142862319280493, 'near_zero': 0.0},\n",
       " {'mean': 0.5058940068997063, 'std': 0.029354628093956434, 'near_zero': 0.0},\n",
       " {'mean': 0.5060051924736719, 'std': 0.028106416553155204, 'near_zero': 0.0},\n",
       " {'mean': 0.5065471779568176, 'std': 0.028888330121005987, 'near_zero': 0.0},\n",
       " {'mean': 0.5057940295040237, 'std': 0.028823128494805887, 'near_zero': 0.0},\n",
       " {'mean': 0.5056443738827305, 'std': 0.029016792270220342, 'near_zero': 0.0},\n",
       " {'mean': 0.5049752119281973, 'std': 0.027314458291828075, 'near_zero': 0.0},\n",
       " {'mean': 0.5047540302236978, 'std': 0.02792558336348598, 'near_zero': 0.0},\n",
       " {'mean': 0.5052598620038786, 'std': 0.028600089208051092, 'near_zero': 0.0},\n",
       " {'mean': 0.5045844192698038, 'std': 0.028565888421620073, 'near_zero': 0.0},\n",
       " {'mean': 0.5044509767543277, 'std': 0.02770425258892767, 'near_zero': 0.0},\n",
       " {'mean': 0.504262172445426, 'std': 0.028757557373937398, 'near_zero': 0.0},\n",
       " {'mean': 0.5039810163903338, 'std': 0.02856247839460141, 'near_zero': 0.0},\n",
       " {'mean': 0.5040119841388058, 'std': 0.02818929585449355, 'near_zero': 0.0},\n",
       " {'mean': 0.504492464508458, 'std': 0.029865770612060624, 'near_zero': 0.0},\n",
       " {'mean': 0.503823286299093, 'std': 0.029678038988075892, 'near_zero': 0.0},\n",
       " {'mean': 0.5029259786376763, 'std': 0.02773746792282794, 'near_zero': 0.0},\n",
       " {'mean': 0.5035746765194096, 'std': 0.028587418681915625, 'near_zero': 0.0},\n",
       " {'mean': 0.5039402720174857, 'std': 0.0293954669727467, 'near_zero': 0.0},\n",
       " {'mean': 0.5040731562589285, 'std': 0.028797348499502176, 'near_zero': 0.0},\n",
       " {'mean': 0.503425278332224, 'std': 0.028175335211010795, 'near_zero': 0.0},\n",
       " {'mean': 0.5042014018514527, 'std': 0.029742587050872512, 'near_zero': 0.0},\n",
       " {'mean': 0.5026491150370178, 'std': 0.029235320275537206, 'near_zero': 0.0},\n",
       " {'mean': 0.502812964648509, 'std': 0.028518990719801393, 'near_zero': 0.0},\n",
       " {'mean': 0.5039186450037618, 'std': 0.02835536353201827, 'near_zero': 0.0},\n",
       " {'mean': 0.5036348223062642, 'std': 0.028822391885307976, 'near_zero': 0.0},\n",
       " {'mean': 0.5036582084632024, 'std': 0.029748672063461917, 'near_zero': 0.0},\n",
       " {'mean': 0.5036397589665967, 'std': 0.029346349670354713, 'near_zero': 0.0},\n",
       " {'mean': 0.5036043611869849, 'std': 0.02892831751075333, 'near_zero': 0.0},\n",
       " {'mean': 0.503817270474817, 'std': 0.030512235194217315, 'near_zero': 0.0},\n",
       " {'mean': 0.5039594731340944, 'std': 0.02852615638281086, 'near_zero': 0.0},\n",
       " {'mean': 0.5053585219465391, 'std': 0.029829406653510256, 'near_zero': 0.0},\n",
       " {'mean': 0.5048989079739816, 'std': 0.03042906852997403, 'near_zero': 0.0},\n",
       " {'mean': 0.5048989312956362, 'std': 0.030140206977837716, 'near_zero': 0.0},\n",
       " {'mean': 0.5040568639554722, 'std': 0.028239863648038682, 'near_zero': 0.0},\n",
       " {'mean': 0.5051071766937206, 'std': 0.028899544065341464, 'near_zero': 0.0},\n",
       " {'mean': 0.5046558976791067, 'std': 0.03017474843494499, 'near_zero': 0.0},\n",
       " {'mean': 0.5044977505454438, 'std': 0.029588046595350765, 'near_zero': 0.0},\n",
       " {'mean': 0.5038203173419751, 'std': 0.03044185447428104, 'near_zero': 0.0},\n",
       " {'mean': 0.5044766459345129, 'std': 0.030774792411806796, 'near_zero': 0.0},\n",
       " {'mean': 0.5043820206653451, 'std': 0.029333143673701993, 'near_zero': 0.0},\n",
       " {'mean': 0.5031842531529112,\n",
       "  'std': 0.03170283534848454,\n",
       "  'near_zero': 0.000244140625},\n",
       " {'mean': 0.5036731614352522, 'std': 0.029436088485672807, 'near_zero': 0.0},\n",
       " {'mean': 0.505100134080412, 'std': 0.02945773465452133, 'near_zero': 0.0},\n",
       " {'mean': 0.5034981067928708, 'std': 0.029149061884202906, 'near_zero': 0.0},\n",
       " {'mean': 0.503175246242368, 'std': 0.029320447734101005, 'near_zero': 0.0},\n",
       " {'mean': 0.5022274467836453, 'std': 0.030678958879505315, 'near_zero': 0.0},\n",
       " {'mean': 0.503298119967562, 'std': 0.029044159159828185, 'near_zero': 0.0},\n",
       " {'mean': 0.5029450752928559, 'std': 0.028218343066228613, 'near_zero': 0.0},\n",
       " {'mean': 0.5024685584532591, 'std': 0.029588540527064715, 'near_zero': 0.0},\n",
       " {'mean': 0.5032607967821665, 'std': 0.02955320749936491, 'near_zero': 0.0},\n",
       " {'mean': 0.5023752177842091, 'std': 0.02748657671217706, 'near_zero': 0.0},\n",
       " {'mean': 0.502673468649363, 'std': 0.028409247392096056, 'near_zero': 0.0},\n",
       " {'mean': 0.5026383439712252, 'std': 0.02839494897156063, 'near_zero': 0.0},\n",
       " {'mean': 0.5025288140015985, 'std': 0.028071625887978933, 'near_zero': 0.0},\n",
       " {'mean': 0.5027282603839853, 'std': 0.029326029890697162, 'near_zero': 0.0},\n",
       " {'mean': 0.502047720875324, 'std': 0.030513346728353253, 'near_zero': 0.0},\n",
       " {'mean': 0.5027462385012857, 'std': 0.028833835107167714, 'near_zero': 0.0},\n",
       " {'mean': 0.503030224769164, 'std': 0.02858727492593482, 'near_zero': 0.0},\n",
       " {'mean': 0.5029406305186057, 'std': 0.02828666976816, 'near_zero': 0.0},\n",
       " {'mean': 0.5034792308214531, 'std': 0.02894579809908957, 'near_zero': 0.0},\n",
       " {'mean': 0.5033922709833754, 'std': 0.028306674856607657, 'near_zero': 0.0},\n",
       " {'mean': 0.5036089425188963, 'std': 0.02938183965519141, 'near_zero': 0.0},\n",
       " {'mean': 0.5036116156920842, 'std': 0.029258062165133537, 'near_zero': 0.0},\n",
       " {'mean': 0.5035213267775689, 'std': 0.028536123252994657, 'near_zero': 0.0},\n",
       " {'mean': 0.504399462907285, 'std': 0.028321858243576435, 'near_zero': 0.0},\n",
       " {'mean': 0.5042067233804921, 'std': 0.028442881197059396, 'near_zero': 0.0},\n",
       " {'mean': 0.5041484126639874, 'std': 0.028736664239780357, 'near_zero': 0.0},\n",
       " {'mean': 0.5038586946055166, 'std': 0.029093891954359217, 'near_zero': 0.0},\n",
       " {'mean': 0.5047562431572145, 'std': 0.029667657455637802, 'near_zero': 0.0},\n",
       " {'mean': 0.5053921097542097, 'std': 0.027967766173166226, 'near_zero': 0.0},\n",
       " {'mean': 0.5057534089028475, 'std': 0.02950108992991543, 'near_zero': 0.0},\n",
       " {'mean': 0.5047062837710377, 'std': 0.02794456110190622, 'near_zero': 0.0},\n",
       " {'mean': 0.5047528121358489, 'std': 0.029052165871353886, 'near_zero': 0.0},\n",
       " {'mean': 0.505019071863557, 'std': 0.02921663806382645, 'near_zero': 0.0},\n",
       " {'mean': 0.5045919533523814, 'std': 0.027172272412456445, 'near_zero': 0.0},\n",
       " {'mean': 0.5048447897865291, 'std': 0.02848455492531267, 'near_zero': 0.0},\n",
       " {'mean': 0.5055908362055475, 'std': 0.030054685074853052, 'near_zero': 0.0}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_output_activation_stats_layer.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f92c43f36a0>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(25, 4))\n",
    "\n",
    "ax[0].set_title(f'Layer {layer_number} : Mean activation value', fontsize=16)\n",
    "ax[0].set_xlabel('Batch instances')\n",
    "ax[0].set_ylabel('Mean')\n",
    "ax[0].plot(range(df_stats_layer.shape[0]), df_stats_layer['mean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "410"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats_layer.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 3\n",
    "\n",
    "running_loss = 0.0        \n",
    "model.train()\n",
    "\n",
    "for batch in train_loader:\n",
    "    #inputs, labels = batch[0], batch[1]\n",
    "    inputs, labels = batch[0].to('cuda'), batch[1].to('cuda')\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.set_grad_enabled(True):\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels.unsqueeze(-1).double())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# update local train loss\n",
    "    running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "# update global train loss\n",
    "epoch_loss = running_loss / len(train_loader.dataset)\n",
    "print('Epoch({}) - Training Loss: {:.4f}'.format(epoch, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(save_output_activation_stats.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_output_activation_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(save_output_activation_stats[0].outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for layer_number,save_output_activation_stats_layer in enumerate(save_output_activation_stats):\n",
    "    df_stats_layer = pd.DataFrame(save_output_activation_stats_layer.outputs)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(25, 4))\n",
    "\n",
    "    ax[0].set_title(f'Layer {layer_number} : Mean activation value', fontsize=16)\n",
    "    ax[0].set_xlabel('Batch instances')\n",
    "    ax[0].set_ylabel('Mean')\n",
    "    ax[0].plot(range(df_stats_layer.shape[0]), df_stats_layer['mean'])\n",
    "\n",
    "    ax[1].set_title(f'Layer {layer_number} : Std deviation activation value', fontsize=16)\n",
    "    ax[1].set_xlabel('Batch instances')\n",
    "    ax[1].set_ylabel('Standard deviation')\n",
    "    ax[1].plot(range(df_stats_layer.shape[0]), df_stats_layer['std'])\n",
    "\n",
    "    ax[2].set_title(f'Layer {layer_number} : Percentage of activation values near zero', fontsize=16)\n",
    "    ax[2].set_xlabel('Batch instances')\n",
    "    ax[2].set_ylabel('Percentage')\n",
    "    ax[2].plot(range(df_stats_layer.shape[0]), df_stats_layer['near_zero']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
