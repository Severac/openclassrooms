{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch classifier notebook\n",
    "\n",
    "V1 : only 1 split. First implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "DATASET_INPUT_FILE = 'train.csv'\n",
    "\n",
    "FEATURES_LIST_TOTRAIN = ['feature_'+str(i) for i in range(130)]\n",
    "\n",
    "#pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deterministic Behavior\n",
    "seed = 42\n",
    "#os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "# Torch RNG\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "# Python RNG\n",
    "np.random.seed(seed)\n",
    "#random.seed(seed)\n",
    "# CuDA Determinism\n",
    "torch.backends.cudnn.deterministic = True\n",
    "#torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16000\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "\n",
    "# modified code for group gaps; source\n",
    "# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\n",
    "class PurgedGroupTimeSeriesSplit(_BaseKFold):\n",
    "    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n",
    "    Allows for a gap in groups to avoid potentially leaking info from\n",
    "    train into test if the model has windowed or lag features.\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals according to a\n",
    "    third-party provided group.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    The same group will not appear in two different folds (the number of\n",
    "    distinct groups has to be at least equal to the number of folds).\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of splits. Must be at least 2.\n",
    "    max_train_group_size : int, default=Inf\n",
    "        Maximum group size for a single training set.\n",
    "    group_gap : int, default=None\n",
    "        Gap between train and test\n",
    "    max_test_group_size : int, default=Inf\n",
    "        We discard this number of groups from the end of each train split\n",
    "    \"\"\"\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self,\n",
    "                 n_splits=5,\n",
    "                 *,\n",
    "                 max_train_group_size=np.inf,\n",
    "                 max_test_group_size=np.inf,\n",
    "                 group_gap=None,\n",
    "                 verbose=False\n",
    "                 ):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_group_size = max_train_group_size\n",
    "        self.group_gap = group_gap\n",
    "        self.max_test_group_size = max_test_group_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        group_gap = self.group_gap\n",
    "        max_test_group_size = self.max_test_group_size\n",
    "        max_train_group_size = self.max_train_group_size\n",
    "        n_folds = n_splits + 1\n",
    "        group_dict = {}\n",
    "        u, ind = np.unique(groups, return_index=True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_samples = _num_samples(X)\n",
    "        n_groups = _num_samples(unique_groups)\n",
    "        for idx in np.arange(n_samples):\n",
    "            if (groups[idx] in group_dict):\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "\n",
    "        group_test_size = min(n_groups // n_folds, max_test_group_size)\n",
    "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
    "                                  n_groups, group_test_size)\n",
    "        for group_test_start in group_test_starts:\n",
    "            train_array = []\n",
    "            test_array = []\n",
    "\n",
    "            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n",
    "            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n",
    "                train_array_tmp = group_dict[train_group_idx]\n",
    "                \n",
    "                train_array = np.sort(np.unique(\n",
    "                                      np.concatenate((train_array,\n",
    "                                                      train_array_tmp)),\n",
    "                                      axis=None), axis=None)\n",
    "\n",
    "            train_end = train_array.size\n",
    " \n",
    "            for test_group_idx in unique_groups[group_test_start:\n",
    "                                                group_test_start +\n",
    "                                                group_test_size]:\n",
    "                test_array_tmp = group_dict[test_group_idx]\n",
    "                test_array = np.sort(np.unique(\n",
    "                                              np.concatenate((test_array,\n",
    "                                                              test_array_tmp)),\n",
    "                                     axis=None), axis=None)\n",
    "\n",
    "            test_array  = test_array[group_gap:]\n",
    "            \n",
    "            \n",
    "            if self.verbose > 0:\n",
    "                    pass\n",
    "                    \n",
    "            yield [int(i) for i in train_array], [int(i) for i in test_array]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function accounts for variable instance counts in each split by dividing utility_pi by number of instances (but this has been removed)\n",
    "# It also does some copy of dataframe to prevent memory overwrite\n",
    "def utility_function(df_test, df_test_predictions):\n",
    "    df_test_copy = df_test.copy(deep=True)\n",
    "    df_test_copy.loc[:, 'utility_pj'] = df_test_copy['weight'] * df_test_copy['resp'] * df_test_predictions\n",
    "    #df_test_utility_pi = df_test_copy.groupby('date')['utility_pj'].sum() / df_test_copy.groupby('date')['utility_pj'].count()\n",
    "    df_test_utility_pi = df_test_copy.groupby('date')['utility_pj'].sum()\n",
    "\n",
    "    nb_unique_dates = df_test_utility_pi.shape[0]\n",
    "    t = (df_test_utility_pi.sum() / np.sqrt(df_test_utility_pi.pow(2).sum())) * (np.sqrt(250 / np.abs(nb_unique_dates)))\n",
    "    u = min(max(t, 0), 6) * df_test_utility_pi.sum()\n",
    "    del df_test_copy\n",
    "    \n",
    "    return(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.device"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 3090'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "    \n",
    "df = pd.read_csv(DATASET_INPUT_FILE)\n",
    "df['resp_positive'] = ((df['resp'])>0)*1  # Target to predict\n",
    "\n",
    "print('Data loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = PurgedGroupTimeSeriesSplit(\n",
    "    n_splits=5,\n",
    "    #n_splits=5,\n",
    "    #max_train_group_size=150,\n",
    "    max_train_group_size=180,\n",
    "    group_gap=20,\n",
    "    max_test_group_size=60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index, test_index = next(cv.split(df, (df['resp'] > 0)*1, df['date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         0\n",
       "2         1\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "877448    1\n",
       "877449    1\n",
       "877450    0\n",
       "877451    1\n",
       "877452    1\n",
       "Name: resp, Length: 877453, dtype: int8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.loc[train_index, 'resp'] > 0).astype(np.byte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mean = df.loc[:, FEATURES_LIST_TOTRAIN].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130,)"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(f_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_train = torch.tensor(df.loc[train_index, FEATURES_LIST_TOTRAIN].to_numpy(), device='cuda')\n",
    "ts_test = torch.tensor(df.loc[test_index, FEATURES_LIST_TOTRAIN].to_numpy(), device='cuda')\n",
    "ts_train_y = torch.tensor((df.loc[train_index, 'resp'] > 0).astype(np.byte).to_numpy(), device='cuda')\n",
    "ts_test_y = torch.tensor((df.loc[test_index, 'resp'] > 0).astype(np.byte).to_numpy(), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(ts_train, ts_train_y)\n",
    "test_dataset = torch.utils.data.TensorDataset(ts_test, ts_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(len(FEATURES_LIST_TOTRAIN), 130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 50),\n",
    "    nn.BatchNorm1d(50),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(50, 1),\n",
    "    nn.Sigmoid(),\n",
    ").double().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of model parameters:\n",
      "tensor(-2.9913, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-0.2815, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(2.6361, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-0.1894, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(130., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(8.0037, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-0.0797, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(130., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(6.2058, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-0.2718, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(130., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(4.1956, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(0.2314, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(130., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(1.3469, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-0.3594, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(50., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-0.1091, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(0.1388, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Sum of model parameters:')\n",
    "[print(p.sum()) for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.2, inplace=False)\n",
       "  (1): Linear(in_features=130, out_features=130, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.2, inplace=False)\n",
       "  (4): Linear(in_features=130, out_features=130, bias=True)\n",
       "  (5): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ReLU()\n",
       "  (7): Dropout(p=0.2, inplace=False)\n",
       "  (8): Linear(in_features=130, out_features=130, bias=True)\n",
       "  (9): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU()\n",
       "  (11): Dropout(p=0.2, inplace=False)\n",
       "  (12): Linear(in_features=130, out_features=130, bias=True)\n",
       "  (13): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): ReLU()\n",
       "  (15): Dropout(p=0.2, inplace=False)\n",
       "  (16): Linear(in_features=130, out_features=130, bias=True)\n",
       "  (17): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (18): ReLU()\n",
       "  (19): Dropout(p=0.2, inplace=False)\n",
       "  (20): Linear(in_features=130, out_features=50, bias=True)\n",
       "  (21): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (22): ReLU()\n",
       "  (23): Dropout(p=0.2, inplace=False)\n",
       "  (24): Linear(in_features=50, out_features=1, bias=True)\n",
       "  (25): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Sequential(\n",
       "  (0): Dropout(p=0.2, inplace=False)\n",
       "  (1): Linear(in_features=130, out_features=130, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.2, inplace=False)\n",
       "  (4): Linear(in_features=130, out_features=130, bias=True)\n",
       "  (5): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ReLU()\n",
       "  (7): Dropout(p=0.2, inplace=False)\n",
       "  (8): Linear(in_features=130, out_features=130, bias=True)\n",
       "  (9): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU()\n",
       "  (11): Dropout(p=0.2, inplace=False)\n",
       "  (12): Linear(in_features=130, out_features=130, bias=True)\n",
       "  (13): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): ReLU()\n",
       "  (15): Dropout(p=0.2, inplace=False)\n",
       "  (16): Linear(in_features=130, out_features=130, bias=True)\n",
       "  (17): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (18): ReLU()\n",
       "  (19): Dropout(p=0.2, inplace=False)\n",
       "  (20): Linear(in_features=130, out_features=50, bias=True)\n",
       "  (21): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (22): ReLU()\n",
       "  (23): Dropout(p=0.2, inplace=False)\n",
       "  (24): Linear(in_features=50, out_features=1, bias=True)\n",
       "  (25): Sigmoid()\n",
       ")>"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(92891,\n",
       " [16900,\n",
       "  130,\n",
       "  16900,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  16900,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  16900,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  16900,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  6500,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  1])"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of parameters :')\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "loss_fn = nn.BCELoss().to('cuda')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Validation Accuracy: 0.5035\n",
      "Start Validation Utility: -0.0000\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "start_accuracy = accuracy_score(ts_test_y.cpu().numpy(), (model(ts_test).squeeze() > 0.5).cpu().numpy())\n",
    "start_utility_score = utility_function(df.loc[test_index], (model(ts_test).squeeze() > 0.5).cpu().numpy())\n",
    "print('Start Validation Accuracy: {:.4f}'.format(start_accuracy))\n",
    "print('Start Validation Utility: {:.4f}'.format(start_utility_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(0) - Training Loss: 0.6968\n",
      "Epoch(0) - Validation Loss: 0.6927\n",
      "Epoch(0) - Validation Accuracy: 0.5078\n",
      "Epoch(0) - Validation Utility score: 10.5705\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 10.570534910607789\n",
      "Epoch(1) - Training Loss: 0.6933\n",
      "Epoch(1) - Validation Loss: 0.6925\n",
      "Epoch(1) - Validation Accuracy: 0.5126\n",
      "Epoch(1) - Validation Utility score: 27.6006\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 27.60060644939898\n",
      "Epoch(2) - Training Loss: 0.6926\n",
      "Epoch(2) - Validation Loss: 0.6924\n",
      "Epoch(2) - Validation Accuracy: 0.5142\n",
      "Epoch(2) - Validation Utility score: 146.4168\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 146.41680847934452\n",
      "Epoch(3) - Training Loss: 0.6921\n",
      "Epoch(3) - Validation Loss: 0.6922\n",
      "Epoch(3) - Validation Accuracy: 0.5150\n",
      "Epoch(3) - Validation Utility score: 91.4523\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 91.45228570415054\n",
      "Epoch(4) - Training Loss: 0.6916\n",
      "Epoch(4) - Validation Loss: 0.6922\n",
      "Epoch(4) - Validation Accuracy: 0.5152\n",
      "Epoch(4) - Validation Utility score: 61.3448\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 61.34477678263224\n",
      "Epoch(5) - Training Loss: 0.6913\n",
      "Epoch(5) - Validation Loss: 0.6921\n",
      "Epoch(5) - Validation Accuracy: 0.5154\n",
      "Epoch(5) - Validation Utility score: 74.6312\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 74.63122190145955\n",
      "Epoch(6) - Training Loss: 0.6911\n",
      "Epoch(6) - Validation Loss: 0.6920\n",
      "Epoch(6) - Validation Accuracy: 0.5157\n",
      "Epoch(6) - Validation Utility score: 68.8450\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 68.84501647985445\n",
      "Epoch(7) - Training Loss: 0.6908\n",
      "Epoch(7) - Validation Loss: 0.6920\n",
      "Epoch(7) - Validation Accuracy: 0.5161\n",
      "Epoch(7) - Validation Utility score: 95.5371\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 95.53714020986926\n",
      "Epoch(8) - Training Loss: 0.6906\n",
      "Epoch(8) - Validation Loss: 0.6920\n",
      "Epoch(8) - Validation Accuracy: 0.5160\n",
      "Epoch(8) - Validation Utility score: 90.1666\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 90.16660870699178\n",
      "Epoch(9) - Training Loss: 0.6905\n",
      "Epoch(9) - Validation Loss: 0.6919\n",
      "Epoch(9) - Validation Accuracy: 0.5171\n",
      "Epoch(9) - Validation Utility score: 105.4535\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 105.45349251790094\n",
      "Epoch(10) - Training Loss: 0.6902\n",
      "Epoch(10) - Validation Loss: 0.6919\n",
      "Epoch(10) - Validation Accuracy: 0.5174\n",
      "Epoch(10) - Validation Utility score: 94.3340\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 94.3340098000454\n",
      "Epoch(11) - Training Loss: 0.6901\n",
      "Epoch(11) - Validation Loss: 0.6919\n",
      "Epoch(11) - Validation Accuracy: 0.5179\n",
      "Epoch(11) - Validation Utility score: 189.2104\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 189.21037234371988\n",
      "Epoch(12) - Training Loss: 0.6899\n",
      "Epoch(12) - Validation Loss: 0.6919\n",
      "Epoch(12) - Validation Accuracy: 0.5173\n",
      "Epoch(12) - Validation Utility score: 106.1803\n",
      "\n",
      "\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "Intermediate early stopping : vepoch_accuracy = 0.5173, the_last_utility_score=0.5179\n",
      "Intermediate early stopping : vepoch_utility_score = 106.1803, the_last_utility_score=189.2104\n",
      "Epoch(13) - Training Loss: 0.6899\n",
      "Epoch(13) - Validation Loss: 0.6919\n"
     ]
    }
   ],
   "source": [
    "the_last_loss = 100\n",
    "the_last_utility_score = 1\n",
    "the_last_accuracy = 1\n",
    "trigger_times=0\n",
    "running_loss = 0\n",
    "patience=3\n",
    "\n",
    "Val_Loss = 0\n",
    "N_Samples = 0\n",
    "early_stopping_met = False\n",
    "\n",
    "for epoch in range(NUM_EPOCHS): \n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch[0], batch[1]\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels.unsqueeze(-1).double())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # update local train loss\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    # update global train loss\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print('Epoch({}) - Training Loss: {:.4f}'.format(epoch, epoch_loss))\n",
    "\n",
    "    # Validation \n",
    "    model.eval()\n",
    "    vrunning_loss = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    for batch in test_loader:\n",
    "        inputs, labels = batch[0], batch[1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels.unsqueeze(-1).double())\n",
    "\n",
    "        vrunning_loss += loss.item() * inputs.size(0)\n",
    "        num_samples += labels.size(0)\n",
    "\n",
    "    # update epoch loss\n",
    "    vepoch_loss = vrunning_loss/num_samples\n",
    "    print('Epoch({}) - Validation Loss: {:.4f}'.format(epoch, vepoch_loss))\n",
    "\n",
    "    #print(f'Sum of model parameters ({epoch}):')\n",
    "    #[print(p.sum()) for p in model.parameters()]\n",
    "\n",
    "    model.eval()\n",
    "    vepoch_accuracy = accuracy_score(ts_test_y.cpu().numpy(), (model(ts_test).squeeze() > 0.5).cpu().numpy())\n",
    "    print('Epoch({}) - Validation Accuracy: {:.4f}'.format(epoch, vepoch_accuracy))\n",
    "    \n",
    "    model.eval()\n",
    "    vepoch_utility_score = utility_function(df.loc[test_index], (model(ts_test).squeeze() > 0.5).cpu().numpy())\n",
    "    print('Epoch({}) - Validation Utility score: {:.4f}'.format(epoch, vepoch_utility_score))\n",
    "\n",
    "    print('\\n')\n",
    "    # Check if Early Stopping\n",
    "    #if vepoch_loss > the_last_loss:\n",
    "    if (vepoch_utility_score < the_last_utility_score) and (vepoch_loss > the_last_loss) and (vepoch_accuracy < the_last_accuracy):\n",
    "        trigger_times += 1\n",
    "        \n",
    "        print(f'Intermediate early stopping : vepoch_loss = {vepoch_loss:.4f}, the_last_loss={the_last_loss:.4f}')\n",
    "        print(f'Intermediate early stopping : vepoch_accuracy = {vepoch_accuracy:.4f}, the_last_utility_score={the_last_accuracy:.4f}')\n",
    "        print(f'Intermediate early stopping : vepoch_utility_score = {vepoch_utility_score:.4f}, the_last_utility_score={the_last_utility_score:.4f}')\n",
    "       \n",
    "        \n",
    "        if trigger_times >= patience:\n",
    "            print('Meet Early stopping!')\n",
    "            early_stopping_met = True\n",
    "            ##torch.save(model.state_dict(), f'model_{fold}.pt')\n",
    "            break\n",
    "    else:\n",
    "        trigger_times = 0\n",
    "        the_last_loss = vepoch_loss\n",
    "        the_last_utility_score = vepoch_utility_score\n",
    "        the_last_accuracy = vepoch_accuracy\n",
    "                \n",
    "        # Save model for the best version so far\n",
    "        print(f'Saving model corresponding to last_utility_score == {the_last_utility_score}')\n",
    "        torch.save(model.state_dict(), f'model_NN_V1.pt')\n",
    "\n",
    "# Update global loss\n",
    "Val_Loss += vepoch_loss * num_samples\n",
    "\n",
    "# Update global # of samples \n",
    "N_Samples += num_samples\n",
    "\n",
    "if (early_stopping_met == False):\n",
    "    print(\"Didn't meet early stopping : saving final model\")\n",
    "    # Save model if don't meet early stopping\n",
    "    torch.save(model.state_dict(), f'model_NN_V1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "accuracy_score(ts_test_y.cpu().numpy(), (model(ts_test).squeeze() > 0.5).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "utility_function(df.loc[test_index], (model(ts_test).squeeze() > 0.5).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = model = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(len(FEATURES_LIST_TOTRAIN), 130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 50),\n",
    "    nn.BatchNorm1d(50),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(50, 1),\n",
    "    nn.Sigmoid(),\n",
    ").double().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load.load_state_dict(torch.load(f'model_NN_V1.pt',map_location=torch.device('cuda')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load.eval()\n",
    "accuracy_score(ts_test_y.cpu().numpy(), (model_load(ts_test).squeeze() > 0.5).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load.eval()\n",
    "utility_function(df.loc[test_index], (model_load(ts_test).squeeze() > 0.5).cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec batch size = 6044 et \n",
    "model = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(len(FEATURES_LIST_TOTRAIN), 130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 50),\n",
    "    nn.BatchNorm1d(50),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(50, 1),\n",
    "    nn.Sigmoid(),\n",
    ").double().to('cuda')\n",
    "\n",
    "Intermediate early stopping : vepoch_utility_score = 128.0983, the_last_utility_score=131.5957\n",
    "Epoch(7) - Training Loss: 0.6906\n",
    "Epoch(7) - Validation Loss: 0.6923\n",
    "Epoch(7) - Validation Accuracy: 0.5147\n",
    "Epoch(7) - Validation Utility score: 245.5967\n",
    "\n",
    "\n",
    "Epoch(8) - Training Loss: 0.6904\n",
    "Epoch(8) - Validation Loss: 0.6921\n",
    "Epoch(8) - Validation Accuracy: 0.5147\n",
    "Epoch(8) - Validation Utility score: 162.9482\n",
    "\n",
    "\n",
    "Intermediate early stopping : vepoch_utility_score = 162.9482, the_last_utility_score=245.5967\n",
    "Epoch(9) - Training Loss: 0.6903\n",
    "Epoch(9) - Validation Loss: 0.6920\n",
    "Epoch(9) - Validation Accuracy: 0.5152\n",
    "Epoch(9) - Validation Utility score: 146.1629\n",
    "\n",
    "\n",
    "Intermediate early stopping : vepoch_utility_score = 146.1629, the_last_utility_score=245.5967\n",
    "Epoch(10) - Training Loss: 0.6900\n",
    "Epoch(10) - Validation Loss: 0.6919\n",
    "Epoch(10) - Validation Accuracy: 0.5157\n",
    "Epoch(10) - Validation Utility score: 191.5377\n",
    "\n",
    "\n",
    "Intermediate early stopping : vepoch_utility_score = 191.5377, the_last_utility_score=245.5967\n",
    "Meet Early stopping!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2Ã¨me run avec batch size 8192 :\n",
    "\n",
    "\n",
    "Intermediate early stopping : vepoch_utility_score = 133.6765, the_last_utility_score=194.0163\n",
    "Epoch(10) - Training Loss: 0.6902\n",
    "Epoch(10) - Validation Loss: 0.6922\n",
    "Epoch(10) - Validation Accuracy: 0.5141\n",
    "Epoch(10) - Validation Utility score: 161.7182\n",
    "\n",
    "\n",
    "Intermediate early stopping : vepoch_utility_score = 161.7182, the_last_utility_score=194.0163\n",
    "Epoch(11) - Training Loss: 0.6900\n",
    "Epoch(11) - Validation Loss: 0.6922\n",
    "Epoch(11) - Validation Accuracy: 0.5142\n",
    "Epoch(11) - Validation Utility score: 136.3106\n",
    "\n",
    "\n",
    "Intermediate early stopping : vepoch_utility_score = 136.3106, the_last_utility_score=194.0163\n",
    "Meet Early stopping!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sum of model parameters:')\n",
    "[print(p.sum()) for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sum of model parameters:')\n",
    "[p for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
