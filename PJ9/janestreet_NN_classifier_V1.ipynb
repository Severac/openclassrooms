{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch classifier notebook\n",
    "\n",
    "V1 : only 1 split. First implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "DATASET_INPUT_FILE = 'train.csv'\n",
    "\n",
    "FEATURES_LIST_TOTRAIN = ['feature_'+str(i) for i in range(130)]\n",
    "\n",
    "#pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deterministic Behavior\n",
    "seed = 42\n",
    "#os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "# Torch RNG\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "# Python RNG\n",
    "np.random.seed(seed)\n",
    "#random.seed(seed)\n",
    "# CuDA Determinism\n",
    "torch.backends.cudnn.deterministic = True\n",
    "#torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50000\n",
    "#BATCH_SIZE = 80000\n",
    "NUM_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "\n",
    "# modified code for group gaps; source\n",
    "# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\n",
    "class PurgedGroupTimeSeriesSplit(_BaseKFold):\n",
    "    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n",
    "    Allows for a gap in groups to avoid potentially leaking info from\n",
    "    train into test if the model has windowed or lag features.\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals according to a\n",
    "    third-party provided group.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    The same group will not appear in two different folds (the number of\n",
    "    distinct groups has to be at least equal to the number of folds).\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of splits. Must be at least 2.\n",
    "    max_train_group_size : int, default=Inf\n",
    "        Maximum group size for a single training set.\n",
    "    group_gap : int, default=None\n",
    "        Gap between train and test\n",
    "    max_test_group_size : int, default=Inf\n",
    "        We discard this number of groups from the end of each train split\n",
    "    \"\"\"\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self,\n",
    "                 n_splits=5,\n",
    "                 *,\n",
    "                 max_train_group_size=np.inf,\n",
    "                 max_test_group_size=np.inf,\n",
    "                 group_gap=None,\n",
    "                 verbose=False\n",
    "                 ):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_group_size = max_train_group_size\n",
    "        self.group_gap = group_gap\n",
    "        self.max_test_group_size = max_test_group_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        group_gap = self.group_gap\n",
    "        max_test_group_size = self.max_test_group_size\n",
    "        max_train_group_size = self.max_train_group_size\n",
    "        n_folds = n_splits + 1\n",
    "        group_dict = {}\n",
    "        u, ind = np.unique(groups, return_index=True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_samples = _num_samples(X)\n",
    "        n_groups = _num_samples(unique_groups)\n",
    "        for idx in np.arange(n_samples):\n",
    "            if (groups[idx] in group_dict):\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "\n",
    "        group_test_size = min(n_groups // n_folds, max_test_group_size)\n",
    "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
    "                                  n_groups, group_test_size)\n",
    "        for group_test_start in group_test_starts:\n",
    "            train_array = []\n",
    "            test_array = []\n",
    "\n",
    "            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n",
    "            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n",
    "                train_array_tmp = group_dict[train_group_idx]\n",
    "                \n",
    "                train_array = np.sort(np.unique(\n",
    "                                      np.concatenate((train_array,\n",
    "                                                      train_array_tmp)),\n",
    "                                      axis=None), axis=None)\n",
    "\n",
    "            train_end = train_array.size\n",
    " \n",
    "            for test_group_idx in unique_groups[group_test_start:\n",
    "                                                group_test_start +\n",
    "                                                group_test_size]:\n",
    "                test_array_tmp = group_dict[test_group_idx]\n",
    "                test_array = np.sort(np.unique(\n",
    "                                              np.concatenate((test_array,\n",
    "                                                              test_array_tmp)),\n",
    "                                     axis=None), axis=None)\n",
    "\n",
    "            test_array  = test_array[group_gap:]\n",
    "            \n",
    "            \n",
    "            if self.verbose > 0:\n",
    "                    pass\n",
    "                    \n",
    "            yield [int(i) for i in train_array], [int(i) for i in test_array]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function accounts for variable instance counts in each split by dividing utility_pi by number of instances (but this has been removed)\n",
    "# It also does some copy of dataframe to prevent memory overwrite\n",
    "def utility_function(df_test, df_test_predictions):\n",
    "    df_test_copy = df_test.copy(deep=True)\n",
    "    df_test_copy.loc[:, 'utility_pj'] = df_test_copy['weight'] * df_test_copy['resp'] * df_test_predictions\n",
    "    #df_test_utility_pi = df_test_copy.groupby('date')['utility_pj'].sum() / df_test_copy.groupby('date')['utility_pj'].count()\n",
    "    df_test_utility_pi = df_test_copy.groupby('date')['utility_pj'].sum()\n",
    "\n",
    "    nb_unique_dates = df_test_utility_pi.shape[0]\n",
    "    t = (df_test_utility_pi.sum() / np.sqrt(df_test_utility_pi.pow(2).sum())) * (np.sqrt(250 / np.abs(nb_unique_dates)))\n",
    "    u = min(max(t, 0), 6) * df_test_utility_pi.sum()\n",
    "    del df_test_copy\n",
    "    \n",
    "    return(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.device"
      ]
     },
     "execution_count": 814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 3090'"
      ]
     },
     "execution_count": 817,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "    \n",
    "df = pd.read_csv(DATASET_INPUT_FILE)\n",
    "df['resp_positive'] = ((df['resp'])>0)*1  # Target to predict\n",
    "\n",
    "print('Data loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = PurgedGroupTimeSeriesSplit(\n",
    "    n_splits=5,\n",
    "    #n_splits=5,\n",
    "    #max_train_group_size=150,\n",
    "    max_train_group_size=180,\n",
    "    group_gap=20,\n",
    "    max_test_group_size=60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index, test_index = next(cv.split(df, (df['resp'] > 0)*1, df['date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         0\n",
       "2         1\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "877448    1\n",
       "877449    1\n",
       "877450    0\n",
       "877451    1\n",
       "877452    1\n",
       "Name: resp, Length: 877453, dtype: int8"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.loc[train_index, 'resp'] > 0).astype(np.byte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mean = df.loc[:, FEATURES_LIST_TOTRAIN].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130,)"
      ]
     },
     "execution_count": 823,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(f_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_train = torch.tensor(df.loc[train_index, FEATURES_LIST_TOTRAIN].to_numpy(), device='cuda')\n",
    "ts_test = torch.tensor(df.loc[test_index, FEATURES_LIST_TOTRAIN].to_numpy(), device='cuda')\n",
    "ts_train_y = torch.tensor((df.loc[train_index, 'resp'] > 0).astype(np.byte).to_numpy(), device='cuda')\n",
    "ts_test_y = torch.tensor((df.loc[test_index, 'resp'] > 0).astype(np.byte).to_numpy(), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 826,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(ts_train, ts_train_y)\n",
    "test_dataset = torch.utils.data.TensorDataset(ts_test, ts_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(len(FEATURES_LIST_TOTRAIN), 130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 50),\n",
    "    nn.BatchNorm1d(50),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(50, 1),\n",
    "    nn.Sigmoid(),\n",
    ").double().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of model parameters:\n",
      "tensor(-2.9913, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-0.2815, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(2.6361, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-0.1894, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(130., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(8.0037, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-0.0797, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(130., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(6.2058, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-0.2718, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(130., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(4.1956, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(0.2314, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(130., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(1.3469, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-0.3594, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(50., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-0.1091, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(0.1388, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Sum of model parameters:')\n",
    "[print(p.sum()) for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.2, inplace=False)\n",
       "  (1): Linear(in_features=130, out_features=130, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.2, inplace=False)\n",
       "  (4): Linear(in_features=130, out_features=130, bias=True)\n",
       "  (5): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ReLU()\n",
       "  (7): Dropout(p=0.2, inplace=False)\n",
       "  (8): Linear(in_features=130, out_features=130, bias=True)\n",
       "  (9): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU()\n",
       "  (11): Dropout(p=0.2, inplace=False)\n",
       "  (12): Linear(in_features=130, out_features=130, bias=True)\n",
       "  (13): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): ReLU()\n",
       "  (15): Dropout(p=0.2, inplace=False)\n",
       "  (16): Linear(in_features=130, out_features=130, bias=True)\n",
       "  (17): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (18): ReLU()\n",
       "  (19): Dropout(p=0.2, inplace=False)\n",
       "  (20): Linear(in_features=130, out_features=50, bias=True)\n",
       "  (21): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (22): ReLU()\n",
       "  (23): Dropout(p=0.2, inplace=False)\n",
       "  (24): Linear(in_features=50, out_features=1, bias=True)\n",
       "  (25): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 831,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Sequential(\n",
       "  (0): Dropout(p=0.2, inplace=False)\n",
       "  (1): Linear(in_features=130, out_features=130, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.2, inplace=False)\n",
       "  (4): Linear(in_features=130, out_features=130, bias=True)\n",
       "  (5): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ReLU()\n",
       "  (7): Dropout(p=0.2, inplace=False)\n",
       "  (8): Linear(in_features=130, out_features=130, bias=True)\n",
       "  (9): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU()\n",
       "  (11): Dropout(p=0.2, inplace=False)\n",
       "  (12): Linear(in_features=130, out_features=130, bias=True)\n",
       "  (13): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): ReLU()\n",
       "  (15): Dropout(p=0.2, inplace=False)\n",
       "  (16): Linear(in_features=130, out_features=130, bias=True)\n",
       "  (17): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (18): ReLU()\n",
       "  (19): Dropout(p=0.2, inplace=False)\n",
       "  (20): Linear(in_features=130, out_features=50, bias=True)\n",
       "  (21): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (22): ReLU()\n",
       "  (23): Dropout(p=0.2, inplace=False)\n",
       "  (24): Linear(in_features=50, out_features=1, bias=True)\n",
       "  (25): Sigmoid()\n",
       ")>"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(92891,\n",
       " [16900,\n",
       "  130,\n",
       "  16900,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  16900,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  16900,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  16900,\n",
       "  130,\n",
       "  130,\n",
       "  130,\n",
       "  6500,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  1])"
      ]
     },
     "execution_count": 833,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of parameters :')\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "loss_fn = nn.BCELoss().to('cuda')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Validation Accuracy: 0.5035\n",
      "Start Validation Utility: -0.0000\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "start_accuracy = accuracy_score(ts_test_y.cpu().numpy(), (model(ts_test).squeeze() > 0.5).cpu().numpy())\n",
    "start_utility_score = utility_function(df.loc[test_index], (model(ts_test).squeeze() > 0.5).cpu().numpy())\n",
    "print('Start Validation Accuracy: {:.4f}'.format(start_accuracy))\n",
    "print('Start Validation Utility: {:.4f}'.format(start_utility_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(0) - Training Loss: 0.6990\n",
      "Epoch(0) - Validation Loss: 0.6933\n",
      "Epoch(0) - Validation Accuracy: 0.5035\n",
      "Epoch(0) - Validation Utility score: -0.0000\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == -0.0\n",
      "Epoch(1) - Training Loss: 0.6947\n",
      "Epoch(1) - Validation Loss: 0.6926\n",
      "Epoch(1) - Validation Accuracy: 0.5105\n",
      "Epoch(1) - Validation Utility score: 6.7237\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 6.723662620373936\n",
      "Epoch(2) - Training Loss: 0.6936\n",
      "Epoch(2) - Validation Loss: 0.6925\n",
      "Epoch(2) - Validation Accuracy: 0.5129\n",
      "Epoch(2) - Validation Utility score: 48.1673\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 48.16727546938743\n",
      "Epoch(3) - Training Loss: 0.6929\n",
      "Epoch(3) - Validation Loss: 0.6923\n",
      "Epoch(3) - Validation Accuracy: 0.5133\n",
      "Epoch(3) - Validation Utility score: 76.8659\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 76.86586892469407\n",
      "Epoch(4) - Training Loss: 0.6922\n",
      "Epoch(4) - Validation Loss: 0.6922\n",
      "Epoch(4) - Validation Accuracy: 0.5139\n",
      "Epoch(4) - Validation Utility score: 117.3329\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 117.332928538922\n",
      "Epoch(5) - Training Loss: 0.6919\n",
      "Epoch(5) - Validation Loss: 0.6921\n",
      "Epoch(5) - Validation Accuracy: 0.5144\n",
      "Epoch(5) - Validation Utility score: 99.4700\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 99.4700134227081\n",
      "Epoch(6) - Training Loss: 0.6914\n",
      "Epoch(6) - Validation Loss: 0.6921\n",
      "Epoch(6) - Validation Accuracy: 0.5144\n",
      "Epoch(6) - Validation Utility score: 107.5734\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 107.57338092225963\n",
      "Epoch(7) - Training Loss: 0.6912\n",
      "Epoch(7) - Validation Loss: 0.6921\n",
      "Epoch(7) - Validation Accuracy: 0.5140\n",
      "Epoch(7) - Validation Utility score: 114.5794\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 114.57940024223899\n",
      "Epoch(8) - Training Loss: 0.6910\n",
      "Epoch(8) - Validation Loss: 0.6921\n",
      "Epoch(8) - Validation Accuracy: 0.5144\n",
      "Epoch(8) - Validation Utility score: 101.9747\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 101.97466684841444\n",
      "Epoch(9) - Training Loss: 0.6907\n",
      "Epoch(9) - Validation Loss: 0.6921\n",
      "Epoch(9) - Validation Accuracy: 0.5146\n",
      "Epoch(9) - Validation Utility score: 103.6680\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 103.6680310537769\n",
      "Epoch(10) - Training Loss: 0.6906\n",
      "Epoch(10) - Validation Loss: 0.6920\n",
      "Epoch(10) - Validation Accuracy: 0.5147\n",
      "Epoch(10) - Validation Utility score: 78.7017\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 78.70169273469567\n",
      "Epoch(11) - Training Loss: 0.6905\n",
      "Epoch(11) - Validation Loss: 0.6920\n",
      "Epoch(11) - Validation Accuracy: 0.5146\n",
      "Epoch(11) - Validation Utility score: 67.6534\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 67.65344770487827\n",
      "Epoch(12) - Training Loss: 0.6903\n",
      "Epoch(12) - Validation Loss: 0.6920\n",
      "Epoch(12) - Validation Accuracy: 0.5147\n",
      "Epoch(12) - Validation Utility score: 104.1704\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 104.170422979231\n",
      "Epoch(13) - Training Loss: 0.6901\n",
      "Epoch(13) - Validation Loss: 0.6920\n",
      "Epoch(13) - Validation Accuracy: 0.5148\n",
      "Epoch(13) - Validation Utility score: 148.5604\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 148.56039059895477\n",
      "Epoch(14) - Training Loss: 0.6902\n",
      "Epoch(14) - Validation Loss: 0.6919\n",
      "Epoch(14) - Validation Accuracy: 0.5156\n",
      "Epoch(14) - Validation Utility score: 132.6083\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 132.60829686615193\n",
      "Epoch(15) - Training Loss: 0.6898\n",
      "Epoch(15) - Validation Loss: 0.6920\n",
      "Epoch(15) - Validation Accuracy: 0.5156\n",
      "Epoch(15) - Validation Utility score: 166.4008\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 166.40078082690997\n",
      "Epoch(16) - Training Loss: 0.6897\n",
      "Epoch(16) - Validation Loss: 0.6919\n",
      "Epoch(16) - Validation Accuracy: 0.5157\n",
      "Epoch(16) - Validation Utility score: 184.3120\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 184.31199210402355\n",
      "Epoch(17) - Training Loss: 0.6895\n",
      "Epoch(17) - Validation Loss: 0.6920\n",
      "Epoch(17) - Validation Accuracy: 0.5167\n",
      "Epoch(17) - Validation Utility score: 220.8268\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 220.82680451368054\n",
      "Epoch(18) - Training Loss: 0.6893\n",
      "Epoch(18) - Validation Loss: 0.6919\n",
      "Epoch(18) - Validation Accuracy: 0.5168\n",
      "Epoch(18) - Validation Utility score: 177.7566\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 177.75655638332378\n",
      "Epoch(19) - Training Loss: 0.6891\n",
      "Epoch(19) - Validation Loss: 0.6920\n",
      "Epoch(19) - Validation Accuracy: 0.5171\n",
      "Epoch(19) - Validation Utility score: 217.4093\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 217.40934020476325\n",
      "Epoch(20) - Training Loss: 0.6891\n",
      "Epoch(20) - Validation Loss: 0.6920\n",
      "Epoch(20) - Validation Accuracy: 0.5165\n",
      "Epoch(20) - Validation Utility score: 182.0106\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 182.0105930313264\n",
      "Epoch(21) - Training Loss: 0.6890\n",
      "Epoch(21) - Validation Loss: 0.6920\n",
      "Epoch(21) - Validation Accuracy: 0.5170\n",
      "Epoch(21) - Validation Utility score: 189.0548\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 189.05482859734238\n",
      "Epoch(22) - Training Loss: 0.6889\n",
      "Epoch(22) - Validation Loss: 0.6920\n",
      "Epoch(22) - Validation Accuracy: 0.5165\n",
      "Epoch(22) - Validation Utility score: 197.2251\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 197.2250742178851\n",
      "Epoch(23) - Training Loss: 0.6886\n",
      "Epoch(23) - Validation Loss: 0.6919\n",
      "Epoch(23) - Validation Accuracy: 0.5173\n",
      "Epoch(23) - Validation Utility score: 197.3189\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 197.31893568088398\n",
      "Epoch(24) - Training Loss: 0.6886\n",
      "Epoch(24) - Validation Loss: 0.6920\n",
      "Epoch(24) - Validation Accuracy: 0.5174\n",
      "Epoch(24) - Validation Utility score: 207.6932\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 207.69317606035412\n",
      "Epoch(25) - Training Loss: 0.6883\n",
      "Epoch(25) - Validation Loss: 0.6920\n",
      "Epoch(25) - Validation Accuracy: 0.5168\n",
      "Epoch(25) - Validation Utility score: 195.0559\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 195.05592201788042\n",
      "Epoch(26) - Training Loss: 0.6882\n",
      "Epoch(26) - Validation Loss: 0.6921\n",
      "Epoch(26) - Validation Accuracy: 0.5175\n",
      "Epoch(26) - Validation Utility score: 162.5751\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 162.57513520706428\n",
      "Epoch(27) - Training Loss: 0.6881\n",
      "Epoch(27) - Validation Loss: 0.6919\n",
      "Epoch(27) - Validation Accuracy: 0.5180\n",
      "Epoch(27) - Validation Utility score: 244.6189\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 244.618910525535\n",
      "Epoch(28) - Training Loss: 0.6881\n",
      "Epoch(28) - Validation Loss: 0.6919\n",
      "Epoch(28) - Validation Accuracy: 0.5179\n",
      "Epoch(28) - Validation Utility score: 234.9614\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 234.96139650293733\n",
      "Epoch(29) - Training Loss: 0.6880\n",
      "Epoch(29) - Validation Loss: 0.6918\n",
      "Epoch(29) - Validation Accuracy: 0.5184\n",
      "Epoch(29) - Validation Utility score: 326.2529\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 326.25286744899347\n",
      "Epoch(30) - Training Loss: 0.6878\n",
      "Epoch(30) - Validation Loss: 0.6920\n",
      "Epoch(30) - Validation Accuracy: 0.5177\n",
      "Epoch(30) - Validation Utility score: 189.2186\n",
      "\n",
      "\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6918\n",
      "Intermediate early stopping : vepoch_accuracy = 0.5177, the_last_utility_score=0.5184\n",
      "Intermediate early stopping : vepoch_utility_score = 189.2186, the_last_utility_score=326.2529\n",
      "Epoch(31) - Training Loss: 0.6877\n",
      "Epoch(31) - Validation Loss: 0.6919\n",
      "Epoch(31) - Validation Accuracy: 0.5187\n",
      "Epoch(31) - Validation Utility score: 281.9376\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 281.93759365823473\n",
      "Epoch(32) - Training Loss: 0.6876\n",
      "Epoch(32) - Validation Loss: 0.6920\n",
      "Epoch(32) - Validation Accuracy: 0.5187\n",
      "Epoch(32) - Validation Utility score: 271.4583\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 271.4583410258806\n",
      "Epoch(33) - Training Loss: 0.6874\n",
      "Epoch(33) - Validation Loss: 0.6919\n",
      "Epoch(33) - Validation Accuracy: 0.5188\n",
      "Epoch(33) - Validation Utility score: 382.8547\n",
      "\n",
      "\n",
      "Saving model corresponding to last_utility_score == 382.8546584753976\n",
      "Epoch(34) - Training Loss: 0.6873\n",
      "Epoch(34) - Validation Loss: 0.6919\n",
      "Epoch(34) - Validation Accuracy: 0.5182\n",
      "Epoch(34) - Validation Utility score: 329.9781\n",
      "\n",
      "\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "Intermediate early stopping : vepoch_accuracy = 0.5182, the_last_utility_score=0.5188\n",
      "Intermediate early stopping : vepoch_utility_score = 329.9781, the_last_utility_score=382.8547\n",
      "Epoch(35) - Training Loss: 0.6873\n",
      "Epoch(35) - Validation Loss: 0.6920\n",
      "Epoch(35) - Validation Accuracy: 0.5178\n",
      "Epoch(35) - Validation Utility score: 327.6237\n",
      "\n",
      "\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "Intermediate early stopping : vepoch_accuracy = 0.5178, the_last_utility_score=0.5188\n",
      "Intermediate early stopping : vepoch_utility_score = 327.6237, the_last_utility_score=382.8547\n",
      "Epoch(36) - Training Loss: 0.6871\n",
      "Epoch(36) - Validation Loss: 0.6919\n",
      "Epoch(36) - Validation Accuracy: 0.5184\n",
      "Epoch(36) - Validation Utility score: 357.2452\n",
      "\n",
      "\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "Intermediate early stopping : vepoch_accuracy = 0.5184, the_last_utility_score=0.5188\n",
      "Intermediate early stopping : vepoch_utility_score = 357.2452, the_last_utility_score=382.8547\n",
      "Meet Early stopping!\n"
     ]
    }
   ],
   "source": [
    "the_last_loss = 100\n",
    "the_last_utility_score = 1\n",
    "the_last_accuracy = 1\n",
    "trigger_times=0\n",
    "running_loss = 0\n",
    "patience=3\n",
    "\n",
    "Val_Loss = 0\n",
    "N_Samples = 0\n",
    "early_stopping_met = False\n",
    "\n",
    "for epoch in range(NUM_EPOCHS): \n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch[0], batch[1]\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels.unsqueeze(-1).double())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # update local train loss\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    # update global train loss\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print('Epoch({}) - Training Loss: {:.4f}'.format(epoch, epoch_loss))\n",
    "\n",
    "    # Validation \n",
    "    model.eval()\n",
    "    vrunning_loss = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    for batch in test_loader:\n",
    "        inputs, labels = batch[0], batch[1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels.unsqueeze(-1).double())\n",
    "\n",
    "        vrunning_loss += loss.item() * inputs.size(0)\n",
    "        num_samples += labels.size(0)\n",
    "\n",
    "    # update epoch loss\n",
    "    vepoch_loss = vrunning_loss/num_samples\n",
    "    print('Epoch({}) - Validation Loss: {:.4f}'.format(epoch, vepoch_loss))\n",
    "\n",
    "    #print(f'Sum of model parameters ({epoch}):')\n",
    "    #[print(p.sum()) for p in model.parameters()]\n",
    "\n",
    "    model.eval()\n",
    "    vepoch_accuracy = accuracy_score(ts_test_y.cpu().numpy(), (model(ts_test).squeeze() > 0.5).cpu().numpy())\n",
    "    print('Epoch({}) - Validation Accuracy: {:.4f}'.format(epoch, vepoch_accuracy))\n",
    "    \n",
    "    model.eval()\n",
    "    vepoch_utility_score = utility_function(df.loc[test_index], (model(ts_test).squeeze() > 0.5).cpu().numpy())\n",
    "    print('Epoch({}) - Validation Utility score: {:.4f}'.format(epoch, vepoch_utility_score))\n",
    "\n",
    "    print('\\n')\n",
    "    # Check if Early Stopping\n",
    "    #if vepoch_loss > the_last_loss:\n",
    "    if (vepoch_utility_score < the_last_utility_score) and (vepoch_loss > the_last_loss) and (vepoch_accuracy < the_last_accuracy):\n",
    "        trigger_times += 1\n",
    "        \n",
    "        print(f'Intermediate early stopping : vepoch_loss = {vepoch_loss:.4f}, the_last_loss={the_last_loss:.4f}')\n",
    "        print(f'Intermediate early stopping : vepoch_accuracy = {vepoch_accuracy:.4f}, the_last_utility_score={the_last_accuracy:.4f}')\n",
    "        print(f'Intermediate early stopping : vepoch_utility_score = {vepoch_utility_score:.4f}, the_last_utility_score={the_last_utility_score:.4f}')\n",
    "       \n",
    "        \n",
    "        if trigger_times >= patience:\n",
    "            print('Meet Early stopping!')\n",
    "            early_stopping_met = True\n",
    "            ##torch.save(model.state_dict(), f'model_{fold}.pt')\n",
    "            break\n",
    "    else:\n",
    "        trigger_times = 0\n",
    "        the_last_loss = vepoch_loss\n",
    "        the_last_utility_score = vepoch_utility_score\n",
    "        the_last_accuracy = vepoch_accuracy\n",
    "                \n",
    "        # Save model for the best version so far\n",
    "        print(f'Saving model corresponding to last_utility_score == {the_last_utility_score}')\n",
    "        torch.save(model.state_dict(), f'model_NN_V1.pt')\n",
    "\n",
    "# Update global loss\n",
    "Val_Loss += vepoch_loss * num_samples\n",
    "\n",
    "# Update global # of samples \n",
    "N_Samples += num_samples\n",
    "\n",
    "if (early_stopping_met == False):\n",
    "    print(\"Didn't meet early stopping : saving final model\")\n",
    "    # Save model if don't meet early stopping\n",
    "    torch.save(model.state_dict(), f'model_NN_V1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5184294686548762"
      ]
     },
     "execution_count": 837,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "accuracy_score(ts_test_y.cpu().numpy(), (model(ts_test).squeeze() > 0.5).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357.2452212823584"
      ]
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "utility_function(df.loc[test_index], (model(ts_test).squeeze() > 0.5).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5188456055176666\n",
      "382.8546584753976\n"
     ]
    }
   ],
   "source": [
    "model_load = model = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(len(FEATURES_LIST_TOTRAIN), 130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 50),\n",
    "    nn.BatchNorm1d(50),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(50, 1),\n",
    "    nn.Sigmoid(),\n",
    ").double().to('cuda')\n",
    "\n",
    "model_load.load_state_dict(torch.load(f'model_NN_V1.pt',map_location=torch.device('cuda')))\n",
    "\n",
    "model_load.eval()\n",
    "print(accuracy_score(ts_test_y.cpu().numpy(), (model_load(ts_test).squeeze() > 0.5).cpu().numpy()))\n",
    "\n",
    "model_load.eval()\n",
    "print(utility_function(df.loc[test_index], (model_load(ts_test).squeeze() > 0.5).cpu().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec batch size = 6044 et \n",
    "model = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(len(FEATURES_LIST_TOTRAIN), 130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 130),\n",
    "    nn.BatchNorm1d(130),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(130, 50),\n",
    "    nn.BatchNorm1d(50),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(50, 1),\n",
    "    nn.Sigmoid(),\n",
    ").double().to('cuda')\n",
    "\n",
    "Intermediate early stopping : vepoch_utility_score = 128.0983, the_last_utility_score=131.5957\n",
    "Epoch(7) - Training Loss: 0.6906\n",
    "Epoch(7) - Validation Loss: 0.6923\n",
    "Epoch(7) - Validation Accuracy: 0.5147\n",
    "Epoch(7) - Validation Utility score: 245.5967\n",
    "\n",
    "\n",
    "Epoch(8) - Training Loss: 0.6904\n",
    "Epoch(8) - Validation Loss: 0.6921\n",
    "Epoch(8) - Validation Accuracy: 0.5147\n",
    "Epoch(8) - Validation Utility score: 162.9482\n",
    "\n",
    "\n",
    "Intermediate early stopping : vepoch_utility_score = 162.9482, the_last_utility_score=245.5967\n",
    "Epoch(9) - Training Loss: 0.6903\n",
    "Epoch(9) - Validation Loss: 0.6920\n",
    "Epoch(9) - Validation Accuracy: 0.5152\n",
    "Epoch(9) - Validation Utility score: 146.1629\n",
    "\n",
    "\n",
    "Intermediate early stopping : vepoch_utility_score = 146.1629, the_last_utility_score=245.5967\n",
    "Epoch(10) - Training Loss: 0.6900\n",
    "Epoch(10) - Validation Loss: 0.6919\n",
    "Epoch(10) - Validation Accuracy: 0.5157\n",
    "Epoch(10) - Validation Utility score: 191.5377\n",
    "\n",
    "\n",
    "Intermediate early stopping : vepoch_utility_score = 191.5377, the_last_utility_score=245.5967\n",
    "Meet Early stopping!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2ème run avec batch size 8192 :\n",
    "\n",
    "\n",
    "Intermediate early stopping : vepoch_utility_score = 133.6765, the_last_utility_score=194.0163\n",
    "Epoch(10) - Training Loss: 0.6902\n",
    "Epoch(10) - Validation Loss: 0.6922\n",
    "Epoch(10) - Validation Accuracy: 0.5141\n",
    "Epoch(10) - Validation Utility score: 161.7182\n",
    "\n",
    "\n",
    "Intermediate early stopping : vepoch_utility_score = 161.7182, the_last_utility_score=194.0163\n",
    "Epoch(11) - Training Loss: 0.6900\n",
    "Epoch(11) - Validation Loss: 0.6922\n",
    "Epoch(11) - Validation Accuracy: 0.5142\n",
    "Epoch(11) - Validation Utility score: 136.3106\n",
    "\n",
    "\n",
    "Intermediate early stopping : vepoch_utility_score = 136.3106, the_last_utility_score=194.0163\n",
    "Meet Early stopping!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of model parameters:\n",
      "tensor(-77.0748, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-7.1288, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-12.7468, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-0.1894, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(129.6140, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-7.1847, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(39.0240, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-0.0797, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(129.8299, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-4.0530, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(46.3394, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-0.2718, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(129.7822, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-3.0717, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(34.9708, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(0.2314, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(129.4479, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-2.5661, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-28.8080, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-0.3594, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(48.3809, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-0.7809, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(-0.2589, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(0.1079, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Sum of model parameters:')\n",
    "[print(p.sum()) for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of model parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0161,  0.0879,  ...,  0.0803,  0.0186],\n",
       "         [ 0.1345,  0.0196,  ...,  0.0633,  0.0787],\n",
       "         ...,\n",
       "         [ 0.0061, -0.0443,  ..., -0.0733,  0.0786],\n",
       "         [ 0.0146, -0.0315,  ..., -0.1127, -0.0540]], device='cuda:0',\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0430, -0.0533, -0.0495, -0.0217,  0.0245, -0.1638, -0.1184, -0.1330,\n",
       "          0.0312, -0.0488, -0.0379, -0.0844, -0.0895, -0.0281, -0.0104,  0.0630,\n",
       "          0.0059, -0.1001, -0.0905, -0.0264, -0.0459, -0.0207, -0.0172, -0.0699,\n",
       "         -0.1050, -0.0674, -0.0201, -0.0491,  0.0290, -0.1968, -0.0520, -0.0009,\n",
       "          0.0009, -0.1044, -0.0959,  0.0296, -0.0534, -0.0558,  0.0324, -0.1846,\n",
       "         -0.0567, -0.0983, -0.0479, -0.0418, -0.0534, -0.0140,  0.0372, -0.1144,\n",
       "          0.0133, -0.0573, -0.0297, -0.1046, -0.0251, -0.0887, -0.0135, -0.0677,\n",
       "         -0.0429, -0.0746,  0.0447, -0.0500, -0.0244, -0.1086, -0.0643, -0.1600,\n",
       "         -0.0531, -0.0510,  0.0194, -0.1586, -0.1131, -0.1527, -0.0751, -0.1484,\n",
       "         -0.0635, -0.0644, -0.0037,  0.0145, -0.0632, -0.0971, -0.0763, -0.1095,\n",
       "         -0.0670, -0.0189, -0.0582, -0.1644, -0.0790,  0.0382, -0.1267, -0.1614,\n",
       "         -0.0102, -0.0299, -0.1043, -0.0815, -0.0784, -0.1079, -0.0406, -0.0309,\n",
       "          0.0332,  0.0079,  0.0863, -0.0508, -0.0451, -0.0533, -0.0904, -0.0460,\n",
       "          0.0739,  0.0075, -0.0752, -0.1715, -0.1109, -0.0004, -0.0330, -0.0532,\n",
       "         -0.2094, -0.0598,  0.0010, -0.0925,  0.0121, -0.0061, -0.0391, -0.1361,\n",
       "         -0.0614, -0.0969,  0.0390,  0.0133, -0.0564,  0.0019, -0.1156, -0.0586,\n",
       "         -0.0912, -0.0713], device='cuda:0', dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0233,  0.0759,  ...,  0.0388, -0.0320],\n",
       "         [-0.0957, -0.0099,  ..., -0.0484, -0.1054],\n",
       "         ...,\n",
       "         [ 0.0182, -0.0028,  ...,  0.0673, -0.0349],\n",
       "         [-0.0633, -0.0695,  ...,  0.0383, -0.0667]], device='cuda:0',\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0063, -0.0246,  0.0359, -0.0188,  0.0282, -0.0593, -0.0113,  0.0829,\n",
       "         -0.0526, -0.0128, -0.0058,  0.0106, -0.0354,  0.0315, -0.0248,  0.0101,\n",
       "          0.0805,  0.0772, -0.0258, -0.0489, -0.0539, -0.0142,  0.0044,  0.0262,\n",
       "         -0.0321,  0.0422, -0.0049,  0.0222,  0.0837,  0.0035,  0.0031, -0.0239,\n",
       "          0.0630, -0.0760, -0.0422,  0.0129,  0.0504, -0.0867, -0.0136,  0.0172,\n",
       "          0.0755,  0.0404,  0.0779, -0.0164, -0.0850,  0.0094,  0.0581,  0.0019,\n",
       "          0.0146,  0.0851, -0.0820,  0.0147,  0.0266,  0.0169, -0.0223, -0.0375,\n",
       "          0.0501,  0.0219,  0.0245, -0.0027, -0.0573,  0.0377, -0.0473, -0.0557,\n",
       "         -0.0412, -0.0716, -0.0715, -0.0095, -0.0861,  0.0641, -0.0676,  0.0323,\n",
       "          0.0363, -0.0347,  0.0181,  0.0822, -0.0824,  0.0017,  0.0589,  0.0821,\n",
       "          0.0242,  0.0771, -0.0469,  0.0796,  0.0128, -0.0563,  0.0526,  0.0710,\n",
       "         -0.0733,  0.0458,  0.0229,  0.0747, -0.0832,  0.0447,  0.0842, -0.0271,\n",
       "          0.0278, -0.0780,  0.0209, -0.0620, -0.0836,  0.0393,  0.0477,  0.0487,\n",
       "          0.0655, -0.0233, -0.0643,  0.0506,  0.0711, -0.0667, -0.0742, -0.0540,\n",
       "         -0.0519,  0.0568, -0.0813,  0.0302,  0.0137, -0.0623, -0.0760,  0.0617,\n",
       "         -0.0571, -0.0587,  0.0111, -0.0807, -0.0047, -0.0220, -0.0318, -0.0834,\n",
       "         -0.0582,  0.0650], device='cuda:0', dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1.0149, 0.9800, 1.0364, 0.9735, 1.0037, 0.9760, 0.9760, 0.9825, 0.9707,\n",
       "         0.9770, 1.0204, 1.0265, 0.9806, 1.0191, 0.9817, 0.9813, 0.9709, 1.0083,\n",
       "         0.9915, 1.0035, 0.9937, 0.9558, 0.9905, 1.0500, 1.0164, 1.0289, 1.0072,\n",
       "         1.0286, 1.0291, 1.0165, 0.9998, 0.9611, 1.0096, 1.0225, 1.0006, 1.0101,\n",
       "         0.9516, 0.9768, 1.0129, 1.0102, 0.9757, 1.0130, 1.0068, 1.0237, 0.9660,\n",
       "         1.0094, 1.0117, 0.9949, 0.9637, 0.9801, 0.9921, 0.9915, 0.9956, 1.0486,\n",
       "         0.9614, 0.9835, 1.0027, 0.9756, 1.0013, 1.0043, 1.0085, 0.9787, 1.0096,\n",
       "         0.9825, 0.9913, 1.0047, 1.0059, 1.0202, 0.9812, 1.0015, 0.9658, 0.9843,\n",
       "         1.0336, 0.9944, 0.9803, 0.9839, 1.0093, 1.0409, 0.9966, 0.9744, 0.9848,\n",
       "         0.9745, 1.0036, 1.0045, 1.0246, 1.0524, 0.9912, 1.0160, 0.9969, 1.0240,\n",
       "         0.9775, 0.9897, 1.0011, 0.9603, 0.9806, 0.9957, 0.9861, 0.9889, 1.0725,\n",
       "         1.0145, 1.0048, 0.9936, 0.9851, 1.0185, 1.0034, 0.9927, 0.9615, 0.9940,\n",
       "         0.9976, 0.9981, 1.0019, 0.9848, 0.9891, 0.9902, 0.9929, 0.9569, 1.0119,\n",
       "         0.9914, 0.9939, 0.9985, 1.0118, 1.0000, 0.9597, 1.0009, 1.0168, 0.9714,\n",
       "         0.9814, 1.0098, 0.9830, 0.9833], device='cuda:0', dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0627, -0.0123, -0.0196, -0.0652, -0.0180, -0.0935, -0.0654, -0.0786,\n",
       "         -0.0304, -0.0796, -0.1106, -0.0261, -0.0662, -0.0240, -0.0330, -0.0159,\n",
       "         -0.0223, -0.0690, -0.0685, -0.1175, -0.0707, -0.0827, -0.0403, -0.0402,\n",
       "         -0.0446, -0.0453, -0.0440, -0.0675, -0.0752, -0.0414, -0.0633, -0.0986,\n",
       "         -0.0418, -0.0126, -0.0125, -0.0453, -0.1002, -0.1139, -0.0325, -0.1189,\n",
       "         -0.1316, -0.0459, -0.0570, -0.0750, -0.0849, -0.0911, -0.0780, -0.0106,\n",
       "         -0.0578, -0.0046,  0.0021, -0.0310, -0.0016, -0.0808, -0.0307, -0.0351,\n",
       "         -0.0684, -0.0123, -0.0281, -0.0246, -0.0974, -0.0323, -0.1069, -0.0579,\n",
       "         -0.0471, -0.0591, -0.0398, -0.0926, -0.0435, -0.0639, -0.0821, -0.0389,\n",
       "         -0.0444, -0.0722, -0.0658, -0.1002, -0.0567, -0.0308, -0.0337, -0.0468,\n",
       "         -0.0486, -0.0861, -0.0594, -0.0771, -0.0013, -0.0759, -0.0243, -0.0340,\n",
       "         -0.0218, -0.0868, -0.0776, -0.0108, -0.0130, -0.0832, -0.0681, -0.0263,\n",
       "         -0.0467, -0.0572, -0.0744, -0.0364, -0.0918, -0.0807, -0.1064, -0.0540,\n",
       "         -0.0986, -0.0498, -0.0432, -0.0591, -0.0474, -0.0709, -0.0549, -0.0434,\n",
       "          0.0062, -0.1191, -0.0524, -0.0744, -0.0886, -0.0882, -0.0478, -0.0369,\n",
       "         -0.0334, -0.0530, -0.0195, -0.0480, -0.0238, -0.0375, -0.0598, -0.0264,\n",
       "         -0.1067, -0.0368], device='cuda:0', dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0771,  0.0183,  ...,  0.0337, -0.0400],\n",
       "         [-0.0756,  0.0130,  ..., -0.0174,  0.0770],\n",
       "         ...,\n",
       "         [ 0.0654, -0.0905,  ..., -0.0422, -0.0692],\n",
       "         [ 0.0340,  0.0330,  ..., -0.0172,  0.0188]], device='cuda:0',\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0780,  0.0195,  0.0723,  0.0768,  0.0264,  0.0075, -0.0235, -0.0630,\n",
       "          0.0488,  0.0003, -0.0361, -0.0219, -0.0509, -0.0074,  0.0500,  0.0708,\n",
       "         -0.0567,  0.0139, -0.0347, -0.0828,  0.0490,  0.0702,  0.0740,  0.0753,\n",
       "         -0.0309,  0.0190,  0.0297, -0.0607,  0.0781, -0.0755,  0.0031, -0.0279,\n",
       "          0.0387,  0.0675,  0.0086, -0.0405,  0.0679, -0.0857, -0.0066, -0.0790,\n",
       "         -0.0022,  0.0640,  0.0406, -0.0415, -0.0438,  0.0294, -0.0540, -0.0744,\n",
       "          0.0689,  0.0255, -0.0670, -0.0807,  0.0298, -0.0271, -0.0466,  0.0870,\n",
       "          0.0436,  0.0671,  0.0141, -0.0020, -0.0574,  0.0351, -0.0277, -0.0091,\n",
       "          0.0047,  0.0661,  0.0327, -0.0862,  0.0013,  0.0637, -0.0052,  0.0737,\n",
       "         -0.0374, -0.0644,  0.0796, -0.0312,  0.0649,  0.0661, -0.0580, -0.0788,\n",
       "         -0.0104, -0.0490,  0.0641,  0.0432,  0.0744, -0.0398,  0.0168,  0.0020,\n",
       "         -0.0643, -0.0428,  0.0405,  0.0069,  0.0776,  0.0068,  0.0258,  0.0313,\n",
       "         -0.0589, -0.0658, -0.0554, -0.0314,  0.0279, -0.0470, -0.0698, -0.0257,\n",
       "         -0.0746, -0.0073, -0.0826, -0.0107, -0.0678, -0.0803,  0.0630,  0.0853,\n",
       "         -0.0614,  0.0139, -0.0735, -0.0611, -0.0776, -0.0639,  0.0851,  0.0222,\n",
       "          0.0393, -0.0512,  0.0362,  0.0311,  0.0260,  0.0062, -0.0424,  0.0323,\n",
       "          0.0692, -0.0168], device='cuda:0', dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1.0067, 0.9912, 1.0312, 0.9982, 1.0147, 0.9784, 1.0101, 0.9768, 1.0384,\n",
       "         0.9719, 1.0249, 0.9989, 0.9769, 1.0049, 0.9730, 0.9898, 1.0046, 1.0260,\n",
       "         0.9636, 1.0053, 1.0140, 1.0043, 1.0136, 1.0188, 1.0077, 1.0195, 0.9651,\n",
       "         1.0065, 0.9636, 0.9871, 0.9830, 0.9950, 0.9880, 0.9998, 1.0080, 0.9807,\n",
       "         0.9977, 1.0081, 0.9927, 1.0046, 0.9715, 0.9947, 0.9983, 1.0062, 1.0090,\n",
       "         1.0044, 1.0167, 1.0124, 0.9996, 1.0005, 1.0069, 0.9589, 0.9944, 0.9860,\n",
       "         1.0110, 1.0163, 1.0018, 0.9727, 0.9693, 0.9949, 1.0018, 1.0178, 0.9768,\n",
       "         0.9916, 0.9923, 1.0242, 0.9816, 0.9924, 0.9778, 0.9973, 0.9732, 0.9937,\n",
       "         0.9863, 0.9637, 1.0270, 1.0587, 1.0087, 1.0087, 0.9937, 0.9914, 0.9954,\n",
       "         0.9857, 1.0304, 0.9920, 1.0155, 0.9923, 1.0264, 0.9914, 1.0205, 0.9970,\n",
       "         0.9789, 0.9745, 1.0352, 0.9614, 1.0125, 1.0097, 0.9644, 0.9987, 0.9887,\n",
       "         0.9967, 1.0043, 1.0023, 1.0348, 1.0027, 0.9997, 1.0003, 1.0447, 1.0023,\n",
       "         1.0222, 0.9844, 0.9975, 1.0156, 0.9827, 0.9660, 0.9835, 1.0094, 1.0149,\n",
       "         1.0155, 1.0026, 1.0237, 0.9839, 1.0027, 1.0304, 1.0060, 0.9992, 0.9798,\n",
       "         0.9694, 0.9795, 0.9991, 0.9763], device='cuda:0', dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-3.3993e-02, -8.0701e-02, -4.1771e-03, -8.0741e-03, -1.4351e-02,\n",
       "         -4.5556e-02,  2.0721e-02, -4.0629e-02, -3.8457e-02, -3.3841e-02,\n",
       "         -3.5669e-03, -4.8062e-02, -7.7311e-02, -1.9235e-02, -2.1269e-02,\n",
       "         -1.4258e-02, -5.8903e-02, -4.7422e-02, -2.8806e-02, -1.9483e-02,\n",
       "         -7.4241e-02, -4.8592e-02, -6.2341e-02, -2.1786e-02, -1.4113e-02,\n",
       "         -2.3180e-02, -9.6699e-02, -1.8102e-02, -3.8526e-02, -1.4986e-02,\n",
       "         -1.4365e-02, -5.5331e-02, -1.8928e-02,  1.8427e-02, -6.6160e-02,\n",
       "         -3.8945e-02, -2.2014e-02,  9.5238e-03, -2.6322e-02, -2.7589e-02,\n",
       "         -4.8480e-02, -1.2999e-03, -4.1895e-02, -1.2575e-02, -3.4707e-02,\n",
       "         -2.4169e-02, -3.2970e-02, -2.8665e-02, -4.8080e-02, -2.5464e-02,\n",
       "         -4.8562e-02, -2.4434e-03, -1.5270e-02, -6.5671e-02, -1.0813e-02,\n",
       "         -2.8795e-02, -3.5389e-02, -5.2746e-02, -3.1496e-02, -1.2447e-02,\n",
       "          1.6064e-02, -6.8427e-02, -4.0362e-02, -1.6515e-03, -4.2649e-02,\n",
       "         -8.8869e-03,  5.2449e-03, -8.6946e-02, -5.8222e-02, -8.8675e-03,\n",
       "         -6.6459e-02, -1.0051e-01, -7.7705e-02, -3.2007e-02, -3.3711e-02,\n",
       "          1.3554e-02,  1.2717e-02, -5.8957e-02, -4.2334e-02, -6.4433e-02,\n",
       "         -2.0752e-02, -3.1485e-02, -2.1722e-02, -2.6602e-02, -4.7315e-02,\n",
       "         -5.0187e-02,  5.5888e-03, -6.8580e-03, -2.5533e-02, -3.3880e-02,\n",
       "         -4.3198e-02, -7.3510e-03, -5.5132e-03, -3.1852e-02, -8.4835e-02,\n",
       "          3.5154e-03, -7.2921e-02, -8.0560e-03, -4.2974e-02, -4.8143e-02,\n",
       "         -1.2857e-02, -7.9886e-04, -1.0725e-02, -1.1356e-02, -1.5706e-03,\n",
       "         -5.2075e-02, -6.1552e-02, -2.7548e-02, -2.6678e-02, -2.0010e-02,\n",
       "         -4.0245e-02, -4.0943e-02, -2.9557e-02, -1.0547e-01,  1.9548e-05,\n",
       "         -2.2663e-02, -2.8617e-02, -2.7249e-02, -7.4151e-03, -6.8274e-02,\n",
       "         -2.7147e-02,  1.3809e-02, -2.6817e-02, -1.4640e-02, -6.3171e-02,\n",
       "         -3.2824e-02, -3.4957e-02, -2.6527e-02, -1.5889e-02, -1.1003e-02],\n",
       "        device='cuda:0', dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0858,  0.0166,  ...,  0.0388,  0.0668],\n",
       "         [ 0.1036, -0.0542,  ..., -0.0254, -0.0526],\n",
       "         ...,\n",
       "         [ 0.0865, -0.0483,  ...,  0.0592,  0.0297],\n",
       "         [-0.0523,  0.0089,  ..., -0.0449, -0.0921]], device='cuda:0',\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0211, -0.0733, -0.0527,  0.0354, -0.0578, -0.0305,  0.0481,  0.0735,\n",
       "          0.0592, -0.0146,  0.0089,  0.0805, -0.0159,  0.0848, -0.0020,  0.0796,\n",
       "         -0.0597,  0.0197, -0.0312, -0.0779, -0.0526,  0.0107, -0.0110, -0.0463,\n",
       "          0.0765, -0.0521,  0.0069,  0.0570,  0.0443, -0.0794,  0.0562,  0.0257,\n",
       "         -0.0731, -0.0511,  0.0202,  0.0361, -0.0741, -0.0649,  0.0148, -0.0026,\n",
       "          0.0275,  0.0345, -0.0194, -0.0415,  0.0754,  0.0736, -0.0748, -0.0087,\n",
       "          0.0582, -0.0655,  0.0537, -0.0072, -0.0768,  0.0187,  0.0502,  0.0238,\n",
       "         -0.0743,  0.0521, -0.0769, -0.0712, -0.0294, -0.0003,  0.0264,  0.0455,\n",
       "         -0.0851,  0.0365,  0.0361, -0.0675, -0.0706,  0.0676,  0.0307, -0.0803,\n",
       "         -0.0633,  0.0325, -0.0023, -0.0148, -0.0038, -0.0303,  0.0593, -0.0241,\n",
       "         -0.0573,  0.0587,  0.0190, -0.0787, -0.0841,  0.0275, -0.0715, -0.0299,\n",
       "          0.0691,  0.0875, -0.0494, -0.0061,  0.0343,  0.0594,  0.0219,  0.0872,\n",
       "         -0.0354, -0.0050,  0.0836, -0.0394, -0.0876,  0.0359, -0.0621, -0.0505,\n",
       "          0.0715,  0.0669,  0.0486,  0.0598, -0.0851,  0.0243,  0.0225,  0.0825,\n",
       "         -0.0857, -0.0260, -0.0661, -0.0614, -0.0577, -0.0476,  0.0136,  0.0489,\n",
       "         -0.0665,  0.0643,  0.0669, -0.0372, -0.0474, -0.0652,  0.0876,  0.0448,\n",
       "         -0.0410,  0.0349], device='cuda:0', dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1.0334, 0.9847, 1.0283, 1.0053, 1.0048, 0.9746, 0.9849, 1.0322, 1.0218,\n",
       "         0.9860, 1.0068, 1.0096, 0.9860, 0.9976, 0.9770, 1.0021, 1.0144, 0.9806,\n",
       "         0.9822, 0.9734, 0.9947, 1.0212, 0.9933, 0.9907, 0.9886, 0.9808, 1.0138,\n",
       "         1.0169, 0.9992, 0.9944, 1.0004, 1.0132, 0.9760, 1.0202, 1.0049, 0.9988,\n",
       "         0.9904, 1.0035, 0.9991, 1.0234, 1.0073, 0.9830, 0.9844, 0.9846, 1.0149,\n",
       "         1.0149, 1.0109, 0.9964, 0.9655, 1.0058, 0.9871, 0.9815, 1.0171, 0.9996,\n",
       "         0.9865, 0.9784, 0.9903, 0.9932, 0.9690, 1.0009, 0.9805, 1.0038, 1.0030,\n",
       "         0.9864, 0.9925, 0.9896, 0.9698, 0.9659, 1.0033, 0.9620, 0.9959, 1.0160,\n",
       "         1.0104, 0.9893, 1.0208, 1.0118, 0.9975, 1.0097, 0.9933, 1.0055, 1.0117,\n",
       "         0.9894, 1.0002, 0.9635, 0.9760, 1.0123, 1.0060, 0.9928, 1.0148, 0.9965,\n",
       "         0.9840, 0.9954, 1.0219, 0.9903, 1.0327, 1.0049, 0.9666, 1.0177, 1.0317,\n",
       "         0.9875, 1.0245, 1.0027, 0.9874, 0.9967, 0.9898, 1.0097, 0.9843, 1.0126,\n",
       "         0.9900, 0.9774, 0.9963, 1.0108, 1.0316, 1.0026, 0.9726, 1.0249, 0.9930,\n",
       "         1.0071, 1.0171, 0.9708, 1.0157, 0.9920, 0.9931, 0.9874, 0.9911, 0.9927,\n",
       "         1.0259, 1.0078, 1.0010, 0.9900], device='cuda:0', dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0037, -0.0255, -0.0136,  0.0085, -0.0337, -0.0089, -0.0493, -0.0209,\n",
       "         -0.0039, -0.0600, -0.0162, -0.0450, -0.0255, -0.0170, -0.0109,  0.0065,\n",
       "         -0.0162, -0.0291, -0.0086, -0.1020, -0.0067, -0.0028, -0.0180,  0.0034,\n",
       "         -0.0245, -0.0044, -0.0036, -0.0317, -0.0526, -0.0107,  0.0019,  0.0018,\n",
       "         -0.0736, -0.0128,  0.0355, -0.0044, -0.0195, -0.0809, -0.0246,  0.0263,\n",
       "         -0.0099, -0.0589,  0.0042,  0.0109, -0.0156, -0.0587, -0.0478, -0.0469,\n",
       "         -0.0336, -0.0035, -0.0433, -0.0176,  0.0134, -0.0319, -0.0150, -0.0330,\n",
       "         -0.0532, -0.0276, -0.0362, -0.0197, -0.0180, -0.0587,  0.0231, -0.0307,\n",
       "         -0.0273, -0.0289, -0.0404, -0.0285, -0.0248, -0.0512, -0.0505, -0.0495,\n",
       "         -0.0040, -0.0063, -0.0395, -0.0210, -0.0042, -0.0441,  0.0066, -0.0123,\n",
       "         -0.0201, -0.0487, -0.0407, -0.0407,  0.0029, -0.0249, -0.0329, -0.0725,\n",
       "         -0.0572, -0.0159, -0.0673, -0.0176, -0.0478, -0.0224, -0.0394, -0.0157,\n",
       "         -0.0341,  0.0016, -0.0127, -0.0119, -0.0319,  0.0265, -0.0165, -0.0019,\n",
       "         -0.0516, -0.0172, -0.0031, -0.0568,  0.0166, -0.0643,  0.0012, -0.0576,\n",
       "         -0.0534,  0.0078, -0.0286, -0.0533, -0.0238, -0.0048, -0.0226, -0.0568,\n",
       "          0.0018, -0.0030, -0.0261, -0.0420,  0.0046, -0.0455,  0.0170, -0.0133,\n",
       "         -0.0136, -0.0307], device='cuda:0', dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0753, -0.0532,  ...,  0.0416,  0.0388],\n",
       "         [ 0.0831,  0.0589,  ..., -0.0139, -0.0175],\n",
       "         ...,\n",
       "         [ 0.0082,  0.0042,  ..., -0.0192, -0.0268],\n",
       "         [-0.0631, -0.0309,  ..., -0.0505,  0.0201]], device='cuda:0',\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0434,  0.0169, -0.0643, -0.0376, -0.0569, -0.0158, -0.0398, -0.0160,\n",
       "          0.0625, -0.0422,  0.0401, -0.0458, -0.0283, -0.0484,  0.0707, -0.0370,\n",
       "          0.0418,  0.0289,  0.0658,  0.0040,  0.0172,  0.0815, -0.0323, -0.0664,\n",
       "         -0.0069,  0.0020, -0.0606, -0.0162,  0.0638, -0.0666,  0.0761, -0.0610,\n",
       "         -0.0560, -0.0808,  0.0081, -0.0266, -0.0669,  0.0540,  0.0060, -0.0234,\n",
       "          0.0551,  0.0575, -0.0612,  0.0774, -0.0446, -0.0698, -0.0286, -0.0199,\n",
       "         -0.0209,  0.0201, -0.0045, -0.0033, -0.0569,  0.0867, -0.0395, -0.0745,\n",
       "          0.0607,  0.0395,  0.0294, -0.0467,  0.0269,  0.0260, -0.0839, -0.0465,\n",
       "         -0.0311,  0.0805,  0.0871, -0.0351,  0.0535, -0.0321,  0.0183, -0.0720,\n",
       "          0.0036,  0.0246, -0.0680,  0.0033, -0.0627,  0.0670, -0.0059,  0.0591,\n",
       "          0.0870, -0.0153, -0.0684,  0.0592, -0.0401, -0.0124,  0.0687, -0.0627,\n",
       "          0.0159, -0.0071,  0.0783,  0.0086,  0.0270,  0.0648,  0.0187, -0.0389,\n",
       "          0.0661,  0.0654,  0.0137,  0.0185,  0.0468,  0.0804,  0.0828,  0.0527,\n",
       "         -0.0420, -0.0722,  0.0570,  0.0717, -0.0293, -0.0147, -0.0085, -0.0576,\n",
       "         -0.0393,  0.0223,  0.0311,  0.0382, -0.0070, -0.0827, -0.0450,  0.0185,\n",
       "          0.0684,  0.0017,  0.0525, -0.0856,  0.0820,  0.0854,  0.0711, -0.0585,\n",
       "         -0.0853, -0.0056], device='cuda:0', dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1.0059, 0.9681, 1.0341, 1.0255, 1.0265, 0.9961, 1.0153, 0.9934, 1.0044,\n",
       "         0.9884, 1.0267, 0.9774, 1.0069, 0.9664, 0.9785, 1.0010, 0.9870, 1.0195,\n",
       "         0.9800, 1.0083, 1.0053, 0.9647, 0.9674, 0.9721, 0.9893, 0.9870, 0.9649,\n",
       "         1.0093, 0.9685, 0.9505, 1.0173, 1.0222, 1.0100, 1.0479, 1.0013, 0.9769,\n",
       "         0.9850, 0.9315, 0.9753, 0.9833, 1.0011, 1.0143, 0.9769, 0.9920, 0.9917,\n",
       "         0.9649, 1.0009, 0.9649, 0.9966, 0.9552, 1.0065, 1.0144, 1.0089, 1.0053,\n",
       "         0.9865, 1.0154, 0.9792, 1.0053, 1.0351, 1.0059, 0.9982, 0.9895, 0.9979,\n",
       "         0.9866, 0.9729, 0.9818, 0.9816, 0.9749, 1.0245, 1.0184, 0.9774, 0.9930,\n",
       "         0.9866, 1.0175, 0.9973, 0.9993, 0.9924, 1.0104, 0.9924, 0.9805, 1.0105,\n",
       "         1.0094, 1.0095, 1.0144, 0.9887, 1.0132, 0.9957, 0.9987, 1.0304, 0.9921,\n",
       "         0.9747, 1.0294, 0.9694, 0.9829, 0.9922, 0.9708, 0.9997, 1.0319, 0.9794,\n",
       "         1.0072, 0.9701, 1.0301, 0.9754, 1.0080, 0.9898, 0.9868, 0.9846, 0.9924,\n",
       "         1.0493, 1.0295, 0.9831, 1.0021, 0.9883, 0.9752, 1.0218, 0.9843, 0.9918,\n",
       "         0.9937, 1.0101, 0.9793, 0.9748, 0.9891, 1.0254, 1.0067, 1.0183, 0.9762,\n",
       "         1.0032, 0.9945, 1.0065, 0.9738], device='cuda:0', dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0209, -0.0402,  0.0081, -0.0554, -0.0231,  0.0322, -0.0651, -0.0019,\n",
       "          0.0434,  0.0184, -0.0058, -0.0578, -0.0092, -0.0476, -0.0290, -0.0111,\n",
       "          0.0056, -0.0224, -0.0405, -0.0372,  0.0140, -0.0345, -0.0601, -0.0118,\n",
       "         -0.0252, -0.0009, -0.0589,  0.0209, -0.0414, -0.0682, -0.0136,  0.0095,\n",
       "         -0.0112, -0.0528, -0.0133, -0.0337, -0.0254, -0.0403, -0.0357, -0.0312,\n",
       "          0.0108, -0.0336, -0.0428, -0.0351, -0.0329, -0.0273, -0.0322, -0.0474,\n",
       "          0.0281, -0.0493,  0.0054, -0.0391,  0.0217,  0.0168, -0.0266, -0.0261,\n",
       "         -0.0336, -0.0232,  0.0210, -0.0073, -0.0448,  0.0444, -0.0093, -0.0454,\n",
       "          0.0071,  0.0336, -0.0265, -0.0441, -0.0036,  0.0089, -0.0459, -0.0460,\n",
       "         -0.0344,  0.0323, -0.0467, -0.0951, -0.0702, -0.0734, -0.0081, -0.0198,\n",
       "         -0.0735,  0.0135, -0.0323, -0.0381,  0.0303, -0.0500,  0.0122,  0.0148,\n",
       "         -0.0146,  0.0228, -0.0413, -0.0905, -0.0233, -0.0185, -0.0264,  0.0049,\n",
       "         -0.0074,  0.0165, -0.0281, -0.0055, -0.0045, -0.0216, -0.0087, -0.0566,\n",
       "         -0.0296,  0.0361, -0.0191, -0.0323, -0.0776, -0.0698,  0.0041,  0.0086,\n",
       "         -0.0109, -0.0430, -0.0320, -0.0621, -0.0634, -0.0013,  0.0098, -0.0241,\n",
       "         -0.0320, -0.0164,  0.0119, -0.0220, -0.0041,  0.0138,  0.0485, -0.0207,\n",
       "          0.0229, -0.0222], device='cuda:0', dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0321,  0.0044,  ..., -0.0351, -0.0555],\n",
       "         [-0.0607,  0.0075,  ...,  0.0023, -0.0496],\n",
       "         ...,\n",
       "         [ 0.0157, -0.0738,  ...,  0.0267, -0.0417],\n",
       "         [-0.0229,  0.0528,  ...,  0.0488, -0.0666]], device='cuda:0',\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0556, -0.0424,  0.0563, -0.0418, -0.0493,  0.0815,  0.0651, -0.0512,\n",
       "         -0.0727,  0.0162,  0.0357, -0.0551,  0.0219,  0.0262,  0.0790, -0.0725,\n",
       "          0.0340,  0.0309, -0.0216, -0.0350,  0.0219,  0.0806,  0.0331, -0.0730,\n",
       "         -0.0626, -0.0159, -0.0565, -0.0235, -0.0079, -0.0535, -0.0329, -0.0223,\n",
       "         -0.0509,  0.0320,  0.0667, -0.0487, -0.0137,  0.0268, -0.0849, -0.0333,\n",
       "          0.0286, -0.0184, -0.0581,  0.0541,  0.0173, -0.0302,  0.0703,  0.0201,\n",
       "         -0.0657, -0.0082], device='cuda:0', dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.9730, 0.9707, 0.9681, 0.9719, 0.9774, 0.9908, 0.9462, 0.9727, 0.9300,\n",
       "         0.9664, 0.9825, 0.9571, 0.9666, 0.9823, 0.9924, 0.9535, 0.9617, 0.9845,\n",
       "         0.9524, 0.9933, 0.9886, 0.9617, 0.9853, 0.9855, 0.9626, 0.9780, 0.9799,\n",
       "         0.9822, 0.9694, 0.9953, 0.9215, 0.9673, 0.9592, 0.9807, 0.9782, 0.9570,\n",
       "         0.9561, 0.9454, 0.9632, 0.9525, 0.9758, 0.9808, 0.9591, 0.9557, 0.9627,\n",
       "         0.9659, 0.9813, 0.9212, 0.9407, 0.9745], device='cuda:0',\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0033, -0.0071, -0.0055,  0.0009, -0.0409,  0.0310, -0.0275, -0.0045,\n",
       "          0.0036, -0.0170,  0.0182, -0.0220, -0.0069,  0.0236,  0.0265, -0.0189,\n",
       "         -0.0503, -0.0316, -0.0317,  0.0068,  0.0229, -0.0391, -0.0420, -0.0104,\n",
       "         -0.0327, -0.0087,  0.0032,  0.0027, -0.0284,  0.0082, -0.0525,  0.0209,\n",
       "         -0.0451, -0.0189, -0.0140,  0.0276, -0.0656, -0.0646, -0.0479, -0.0367,\n",
       "         -0.0203, -0.0230, -0.0435, -0.0335, -0.0513, -0.0064,  0.0145,  0.0095,\n",
       "         -0.0408, -0.0080], device='cuda:0', dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0181, -0.0576, -0.0604, -0.0404,  0.0017, -0.0142,  0.0083,  0.0200,\n",
       "          -0.0176, -0.0630, -0.0333, -0.0954,  0.0372, -0.0041, -0.0200, -0.0802,\n",
       "           0.0075,  0.0046, -0.0010, -0.0183, -0.0366,  0.0425, -0.0006, -0.0044,\n",
       "           0.0494, -0.0415, -0.0572, -0.0019,  0.0224,  0.0113,  0.0144, -0.0056,\n",
       "           0.0820,  0.0167,  0.0166, -0.0116,  0.0476, -0.0691,  0.0724,  0.0456,\n",
       "           0.0421,  0.0026,  0.0878, -0.0717,  0.0558, -0.0423, -0.0515, -0.0165,\n",
       "           0.0129, -0.0626]], device='cuda:0', dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1079], device='cuda:0', dtype=torch.float64, requires_grad=True)]"
      ]
     },
     "execution_count": 841,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Sum of model parameters:')\n",
    "[p for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
