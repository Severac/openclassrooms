{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch classifier notebook\n",
    "\n",
    "V1 : only 1 split. First implementation  \n",
    "All folds V1 : with all folds  \n",
    "All folds V2 : add activation stats plot  \n",
    "All folds V2.1 : back to  best MLP found so far, and backport fix of activation layers stats. Add weight decay and scheduler (fit one cycle) code\n",
    "\n",
    "All folds autoencoder MLP V1  \n",
    "All folds autoencoder MLP V2 : with weights and biases  \n",
    "All folds autoencoder MLP V3 : replace MLP with xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#import torch.optim as optim\n",
    "import torch_optimizer as optim  # Custom optimizers (not officially pytorch) : to use RAdam https://pypi.org/project/torch-optimizer/#radam\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as utils\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import io\n",
    "import PIL.Image\n",
    "\n",
    "import datetime\n",
    "\n",
    "import faiss\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "DATASET_INPUT_FILE = 'train.csv'\n",
    "\n",
    "#FEATURES_LIST_TOTRAIN = ['feature_'+str(i) for i in range(130)] + ['cross_41_42_43', 'cross_1_2']\n",
    "FEATURES_LIST_TOTRAIN = ['feature_'+str(i) for i in range(130)]\n",
    "\n",
    "# For custom non-overlaped folds generation\n",
    "TRAIN_PERCENT = 0.70  \n",
    "TEST_PERCENT = 0.30\n",
    "\n",
    "# If subsplit of training set : percentage of second training set  \n",
    "TRAIN1_PERCENT = 0.20  \n",
    "\n",
    "ACT_N = False  # Add N previous predictions to input of MLP <= Does not work, logic is not right\n",
    "ACT_N_SIZE = 5\n",
    "\n",
    "CLUSTERING = False\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deterministic Behavior\n",
    "seed = 42\n",
    "#os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "# Torch RNG\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "# Python RNG\n",
    "np.random.seed(seed)\n",
    "#random.seed(seed)\n",
    "# CuDA Determinism\n",
    "torch.backends.cudnn.deterministic = True\n",
    "#torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_SWEEP = True\n",
    "DO_SINGLE_TRAIN = False\n",
    "#BATCH_SIZE = 50000\n",
    "#BATCH_SIZE = 4096 # Gave once better results than 50000\n",
    "#BATCH_SIZE = 2048\n",
    "\n",
    "#BATCH_SIZE = 300000\n",
    "\n",
    "#BATCH_SIZE = 4096\n",
    "#BATCH_SIZE = 8192\n",
    "#BATCH_SIZE = 32768\n",
    "BATCH_SIZE = 8192\n",
    "WEIGHT_DECAY = 1e-4 # Remettre à 1e-5\n",
    "LEARNING_RATE = 1e-4\n",
    "DROPOUT = 0.7\n",
    "\n",
    "EARLY_STOPPING = True\n",
    "\n",
    "NUM_EPOCHS = 1000\n",
    "#NUM_EPOCHS = 36\n",
    "\n",
    "MODEL_FILE = f'model_NN_allfolds_V1.pt'\n",
    "\n",
    "BATCH_SIZE_AE = 40960\n",
    "NUM_EPOCHS_AE = 1000\n",
    "LEARNING_RATE_AE = 1e-3\n",
    "WEIGHT_DECAY_AE = 1e-4\n",
    "MODEL_FILE_AE = f'model_NN_AE_allfolds_V1.pt'\n",
    "\n",
    "RETRAIN_MODEl_AE = False\n",
    "\n",
    "MODEL_COMMENT_AE = f'All folds MLP autoenc, 2 layers 64 32, good model reloaded, batch size {BATCH_SIZE_AE}, lr={LEARNING_RATE_AE}, patience 5, standard scale, weight decay {WEIGHT_DECAY_AE}, dropout 0.5, with cross features, no scheduler, no std scale'\n",
    "MODEL_COMMENT = f'All folds MLP with autoenc (noise 0.01)), 3 layers 130, 200 and 100, good model reloaded, batch size {BATCH_SIZE}, lr={LEARNING_RATE}, patience 5, standard scale, weight decay {WEIGHT_DECAY}, 0.7 dropout, without cross features, no scheduler, no std scale'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sweep_config = {\n",
    "    'method': 'bayes', #grid, random, bayes\n",
    "    'metric': {\n",
    "      'name': 'Best utility',\n",
    "      'goal': 'maximize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "        'batch_size': {\n",
    "            'values': [524288, 262144, 131072, 65536, 32768, 16384, 8192, 4096, 2048, 1024, 512]\n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            #'values': [1e-2, 1e-3, 1e-4, 3e-4, 1e-5]\n",
    "            #'values': [1e-2, 1e-3, 1e-4]\n",
    "            'values': [1e-2, 1e-3]\n",
    "        },\n",
    "\n",
    "        'weight_decay': {\n",
    "            'values': [1e-2, 1e-3, 1e-4, 1e-5]\n",
    "        },\n",
    "    \n",
    "        'use_autoenc': {\n",
    "            'values': ['encoder-decoder', 'encoder', 'encoder-only', 'None']\n",
    "            #'values': ['encoder-decoder', 'None']\n",
    "        },\n",
    "        \n",
    "        'activation_function': {\n",
    "            'values': ['relu', 'leakyrelu']\n",
    "        },\n",
    "        \n",
    "    }\n",
    "}\n",
    "'''\n",
    "\n",
    "sweep_config = {\n",
    "    'method': 'bayes', #grid, random, bayes\n",
    "    'metric': {\n",
    "      'name': 'Best utility',\n",
    "      'goal': 'maximize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "        'batch_size': {\n",
    "            'min': 4096,\n",
    "            'max': 65536,\n",
    "            'distribution': 'int_uniform',\n",
    "        },\n",
    "        'dropout': {\n",
    "            'min': 0.3,\n",
    "            'max': 0.5,\n",
    "            'distribution': 'uniform',\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'min': 0.0005,\n",
    "            'max': 0.002,\n",
    "            'distribution': 'uniform',\n",
    "        },\n",
    "\n",
    "        'weight_decay': {\n",
    "            'min': 0.00001,\n",
    "            'max': 0.0002,\n",
    "            'distribution': 'uniform',\n",
    "\n",
    "        },\n",
    "    \n",
    "        'use_autoenc': {\n",
    "            'values': ['encoder', 'encoder-only']\n",
    "            #'values': ['encoder-decoder', 'None']\n",
    "        },\n",
    "        \n",
    "        'activation_function': {\n",
    "            'values': ['leakyrelu']\n",
    "        },\n",
    "        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfboyer\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyStandardScale(tensor, mean, std):\n",
    "    return((tensor - mean) / std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "\n",
    "# modified code for group gaps; source\n",
    "# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\n",
    "class PurgedGroupTimeSeriesSplit(_BaseKFold):\n",
    "    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n",
    "    Allows for a gap in groups to avoid potentially leaking info from\n",
    "    train into test if the model has windowed or lag features.\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals according to a\n",
    "    third-party provided group.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    The same group will not appear in two different folds (the number of\n",
    "    distinct groups has to be at least equal to the number of folds).\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of splits. Must be at least 2.\n",
    "    max_train_group_size : int, default=Inf\n",
    "        Maximum group size for a single training set.\n",
    "    group_gap : int, default=None\n",
    "        Gap between train and test\n",
    "    max_test_group_size : int, default=Inf\n",
    "        We discard this number of groups from the end of each train split\n",
    "    \"\"\"\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self,\n",
    "                 n_splits=5,\n",
    "                 *,\n",
    "                 max_train_group_size=np.inf,\n",
    "                 max_test_group_size=np.inf,\n",
    "                 group_gap=None,\n",
    "                 verbose=False\n",
    "                 ):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_group_size = max_train_group_size\n",
    "        self.group_gap = group_gap\n",
    "        self.max_test_group_size = max_test_group_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        group_gap = self.group_gap\n",
    "        max_test_group_size = self.max_test_group_size\n",
    "        max_train_group_size = self.max_train_group_size\n",
    "        n_folds = n_splits + 1\n",
    "        group_dict = {}\n",
    "        u, ind = np.unique(groups, return_index=True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_samples = _num_samples(X)\n",
    "        n_groups = _num_samples(unique_groups)\n",
    "        for idx in np.arange(n_samples):\n",
    "            if (groups[idx] in group_dict):\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "\n",
    "        group_test_size = min(n_groups // n_folds, max_test_group_size)\n",
    "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
    "                                  n_groups, group_test_size)\n",
    "        for group_test_start in group_test_starts:\n",
    "            train_array = []\n",
    "            test_array = []\n",
    "\n",
    "            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n",
    "            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n",
    "                train_array_tmp = group_dict[train_group_idx]\n",
    "                \n",
    "                train_array = np.sort(np.unique(\n",
    "                                      np.concatenate((train_array,\n",
    "                                                      train_array_tmp)),\n",
    "                                      axis=None), axis=None)\n",
    "\n",
    "            train_end = train_array.size\n",
    " \n",
    "            for test_group_idx in unique_groups[group_test_start:\n",
    "                                                group_test_start +\n",
    "                                                group_test_size]:\n",
    "                test_array_tmp = group_dict[test_group_idx]\n",
    "                test_array = np.sort(np.unique(\n",
    "                                              np.concatenate((test_array,\n",
    "                                                              test_array_tmp)),\n",
    "                                     axis=None), axis=None)\n",
    "\n",
    "            test_array  = test_array[group_gap:]\n",
    "            \n",
    "            \n",
    "            if self.verbose > 0:\n",
    "                    pass\n",
    "                    \n",
    "            yield [int(i) for i in train_array], [int(i) for i in test_array]\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "    \n",
    "# this is code slightly modified from the sklearn docs here:\n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py\n",
    "def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "    \n",
    "    cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "    jet = plt.cm.get_cmap('jet', 256)\n",
    "    seq = np.linspace(0, 1, 256)\n",
    "    _ = np.random.shuffle(seq)   # inplace\n",
    "    cmap_data = ListedColormap(jet(seq))\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                   c=indices, marker='_', lw=lw, cmap=cmap_cv,\n",
    "                   vmin=-.2, vmax=1.2)\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(range(len(X)), [ii + 1.5] * len(X),\n",
    "               c=y, marker='_', lw=lw, cmap=plt.cm.Set3)\n",
    "\n",
    "    ax.scatter(range(len(X)), [ii + 2.5] * len(X),\n",
    "               c=group, marker='_', lw=lw, cmap=cmap_data)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + ['target', 'day']\n",
    "    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Sample index', ylabel=\"CV iteration\",\n",
    "           ylim=[n_splits+2.2, -.2], xlim=[0, len(y)])\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_cv_indices_custom(cv_custom, X, y, group, ax, n_splits, lw=10):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "    \n",
    "    cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "    jet = plt.cm.get_cmap('jet', 256)\n",
    "    seq = np.linspace(0, 1, 256)\n",
    "    _ = np.random.shuffle(seq)   # inplace\n",
    "    cmap_data = ListedColormap(jet(seq))\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv_custom):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                   c=indices, marker='_', lw=lw, cmap=cmap_cv,\n",
    "                   vmin=-.2, vmax=1.2)\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(range(len(X)), [ii + 1.5] * len(X),\n",
    "               c=y, marker='_', lw=lw, cmap=plt.cm.Set3)\n",
    "\n",
    "    ax.scatter(range(len(X)), [ii + 2.5] * len(X),\n",
    "               c=group, marker='_', lw=lw, cmap=cmap_data)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + ['target', 'day']\n",
    "    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Sample index', ylabel=\"CV iteration\",\n",
    "           ylim=[n_splits+2.2, -.2], xlim=[0, len(y)])\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function accounts for variable instance counts in each split by dividing utility_pi by number of instances (but this has been removed)\n",
    "# It also does some copy of dataframe to prevent memory overwrite\n",
    "def utility_function(df_test, df_test_predictions):\n",
    "    df_test_copy = df_test.copy(deep=True)\n",
    "    df_test_copy.loc[:, 'utility_pj'] = df_test_copy['weight'] * df_test_copy['resp'] * df_test_predictions\n",
    "    #df_test_utility_pi = df_test_copy.groupby('date')['utility_pj'].sum() / df_test_copy.groupby('date')['utility_pj'].count()\n",
    "    df_test_utility_pi = df_test_copy.groupby('date')['utility_pj'].sum()\n",
    "\n",
    "    nb_unique_dates = df_test_utility_pi.shape[0]\n",
    "\n",
    "    if (np.sqrt(df_test_utility_pi.pow(2).sum()) == 0):\n",
    "        t = 0\n",
    "\n",
    "    else:\n",
    "        t = (df_test_utility_pi.sum() / np.sqrt(df_test_utility_pi.pow(2).sum())) * (np.sqrt(250 / np.abs(nb_unique_dates)))\n",
    "\n",
    "    u = min(max(t, 0), 6) * df_test_utility_pi.sum()\n",
    "    del df_test_copy\n",
    "    \n",
    "    return(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "# The aim of this function is to return closest date from an index\n",
    "# So that split indices correspond to start or end of a new day\n",
    "# myList contains list of instances that correspond to start of a new da\n",
    "\n",
    "def take_closest(myList, myNumber):\n",
    "    \"\"\"\n",
    "    Assumes myList is sorted. Returns closest value to myNumber.\n",
    "\n",
    "    If two numbers are equally close, return the smallest number.\n",
    "    \"\"\"\n",
    "    pos = bisect_left(myList, myNumber)\n",
    "    if pos == 0:\n",
    "        return myList[0]\n",
    "    if pos == len(myList):\n",
    "        return myList[-1]\n",
    "    before = myList[pos - 1]\n",
    "    after = myList[pos]\n",
    "    if after - myNumber < myNumber - before:\n",
    "       return after\n",
    "    else:\n",
    "       return before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOutputActivationStats:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "        \n",
    "    def __call__(self, module, module_in, module_out):\n",
    "        #self.outputs.append(module_out)\n",
    "        #print('Save output callback :')\n",
    "        #print(module)\n",
    "        #print({'mean': module_out.mean().item(), 'std': module_out.std().item(),'near_zero': (module_out<=0.05).long().sum().item()/module_out.numel()})\n",
    "        self.outputs.append({'mean': module_out.mean().item(), 'std': module_out.std().item(),'near_zero': (module_out<=0.05).long().sum().item()/module_out.numel()})\n",
    "        \n",
    "    def clear(self):\n",
    "        self.outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(1, 1)\n",
    "#\n",
    "#plot_cv_indices(cv, df.loc[:, FEATURES_LIST_TOTRAIN], (df['resp'] > 0), df['date'], \n",
    "#                         ax, 5, lw=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.device"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 3090'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "    \n",
    "df = pd.read_csv(DATASET_INPUT_FILE)\n",
    "df['resp_positive'] = ((df['resp'])>0)*1  # Target to predict\n",
    "\n",
    "print('Data loaded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['cross_41_42_43'] = df['feature_41'] + df['feature_42'] + df['feature_43']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['cross_1_2'] = df['feature_1'] / (df['feature_2'] + 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non overlap fold generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_indexes_list = df.groupby('date')['ts_id'].first().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train_split_size = int((df.shape[0] // 5) * TRAIN_PERCENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_test_split_size = int((df.shape[0] // 5) * TEST_PERCENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_start_indexes = [take_closest(date_indexes_list, (base_train_split_size + base_test_split_size)*fold_indice) for fold_indice in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_split_start_indexes = [take_closest(date_indexes_list, (base_train_split_size + base_test_split_size)*fold_indice) for fold_indice in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 477711, 958233, 1435933, 1913985]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split_start_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2390490"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll have 5 folds of 3 subsets each (2 training sets and 1 test set per fold)\n",
    "# (1st training set of each fold will be used for 1st model, ie auto encoder)\n",
    "\n",
    "NB_FOLDS = 5\n",
    "last_index = df.shape[0] - 1\n",
    "\n",
    "cv_table = []\n",
    "\n",
    "for fold_indice in range(NB_FOLDS):\n",
    "    fold_train_start_index = train_split_start_indexes[fold_indice]\n",
    "    \n",
    "    if (fold_indice == NB_FOLDS - 1):    \n",
    "        nextfold_train_start_index = last_index\n",
    "        \n",
    "    else:\n",
    "        nextfold_train_start_index = train_split_start_indexes[fold_indice + 1]\n",
    "    \n",
    "    fold_test_start_index = take_closest(date_indexes_list, int(TRAIN_PERCENT * (nextfold_train_start_index - fold_train_start_index) + fold_train_start_index  ))\n",
    "    fold_train2_start_index = take_closest(date_indexes_list, int(TRAIN1_PERCENT * (fold_test_start_index - fold_train_start_index) + fold_train_start_index  ))\n",
    "    \n",
    "    cv_table.append(fold_train_start_index)\n",
    "    cv_table.append(fold_train2_start_index)\n",
    "    cv_table.append(fold_test_start_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_table.append(last_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 66091,\n",
       " 336609,\n",
       " 477711,\n",
       " 546983,\n",
       " 815783,\n",
       " 958233,\n",
       " 1024471,\n",
       " 1290282,\n",
       " 1435933,\n",
       " 1505171,\n",
       " 1771833,\n",
       " 1913985,\n",
       " 1980610,\n",
       " 2248510,\n",
       " 2390490]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 66091,\n",
       " 336609,\n",
       " 477711,\n",
       " 546983,\n",
       " 815783,\n",
       " 958233,\n",
       " 1024471,\n",
       " 1290282,\n",
       " 1435933,\n",
       " 1505171,\n",
       " 1771833,\n",
       " 1913985,\n",
       " 1980610,\n",
       " 2248510,\n",
       " 2390490]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_tuples = []\n",
    "\n",
    "for i in range(0, NB_FOLDS*3, 3):\n",
    "    cv_tuples.append([df.loc[cv_table[i]:cv_table[i+1]-1, :].index.to_list(), df.loc[cv_table[i+1]:cv_table[i+2]-1, :].index.to_list(),\n",
    "                      df.loc[cv_table[i+2]:cv_table[i+3]-1, :].index.to_list()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141102"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv_tuples[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_tuples_generator = iter(cv_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "#plot_cv_indices_custom(cv_tuples_generator, df.loc[:, FEATURES_LIST_TOTRAIN], (df['resp'] > 0), df['date'], \n",
    "#                         ax, 5, lw=20); \n",
    "\n",
    "#cv_tuples_generator = iter(cv_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of training set :\n",
    "#train_sets_table =  [cv_tuples[i][0] for i in range(5)]\n",
    "#sum([len(train_set_table) for train_set_table in train_sets_table])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our old time series split (with overlap : required 1 neural network trained per split)\n",
    "# But in this script it's not needed because we're training 1 unique network, with a different fold strategy (non overlaped)\n",
    "#cv = PurgedGroupTimeSeriesSplit(\n",
    "#    n_splits=5,\n",
    "#    max_train_group_size=180,\n",
    "#    group_gap=20,\n",
    "#    max_test_group_size=60\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_index, test_index = next(cv.split(df, (df['resp'] > 0)*1, df['date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(df.loc[train_index, 'resp'] > 0).astype(np.byte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mean = df.loc[:, FEATURES_LIST_TOTRAIN].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130,)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(f_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Sum of model parameters:')\n",
    "#[print(p.sum()) for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writer = SummaryWriter()\n",
    "\n",
    "#writer.add_text('test', 'test:'  + str(model).replace('\\n', '<BR>'))\n",
    "\n",
    "#writer.flush()\n",
    "#writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#str([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_list = []\n",
    "\n",
    "for fold, (train1_index, train2_index, test_index) in enumerate(cv_tuples_generator):\n",
    "    folds_list.append((train1_index, train2_index, test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_list_train1 = [folds_list[i][0] for i in range(5)]\n",
    "folds_list_train1_flat = [folds_list_train1_item for sublist in folds_list_train1 for folds_list_train1_item in sublist]\n",
    "folds_list_train1_unique = list(set(folds_list_train1_flat))\n",
    "\n",
    "folds_list_train2 = [folds_list[i][1] for i in range(5)]\n",
    "folds_list_train2_flat = [folds_list_train2_item for sublist in folds_list_train2 for folds_list_train2_item in sublist]\n",
    "folds_list_train2_unique = list(set(folds_list_train2_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337464"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds_list_train1_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1339691"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds_list_train2_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337464"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([len(folds_list_train1_item) for folds_list_train1_item in folds_list_train1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1339691"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([len(folds_list_train2_item) for folds_list_train2_item in folds_list_train2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337464"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds_list_train1_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_list_test = [folds_list[i][2] for i in range(5)]\n",
    "folds_list_test_flat = [folds_list_test_item for sublist in folds_list_test for folds_list_test_item in sublist]\n",
    "folds_list_test_unique = set(folds_list_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "713335"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([len(folds_list_test_item) for folds_list_test_item in folds_list_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "713335"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds_list_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2390490"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds_list_train1_flat) + len(folds_list_train2_flat) + len(folds_list_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141980, 130)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[folds_list_test[4], FEATURES_LIST_TOTRAIN].to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00880718,  0.39574469,  0.33059838,  0.00919269,  0.00341737,\n",
       "       -0.00498373, -0.01455459,  0.05534631,  0.02511896,  0.2646538 ,\n",
       "        0.16705702,  0.09489698,  0.04450428,  0.15251293,  0.07996651,\n",
       "        0.22166532,  0.12827658,  0.12181565,  0.10958852,  0.29772963,\n",
       "        0.26463247,  0.1881408 ,  0.17251055,  0.25474009,  0.23267903,\n",
       "        0.29794049,  0.2685417 ,  0.13985131,  0.16285107,  0.33060734,\n",
       "        0.34385913,  0.22684687,  0.25190658,  0.31637359,  0.3359838 ,\n",
       "        0.35284181,  0.36773315,  0.02650339,  0.0186391 ,  0.04320553,\n",
       "        0.05298663,  0.45417433,  0.37762691,  0.41617323,  0.43927675,\n",
       "        0.48651095,  0.49207956,  0.36839975,  0.50144387,  0.54379067,\n",
       "        0.53074971,  0.45673965,  0.05646874,  0.38900233,  0.37690587,\n",
       "        0.77549302,  0.92466193,  0.78590429,  0.80847667,  0.89895923,\n",
       "        0.55335406,  0.55554392,  0.55922873,  0.56139559,  0.44231975,\n",
       "        0.61884351,  0.61715568,  0.59770334,  0.59814018,  0.37738388,\n",
       "        0.23893403,  0.30802914,  0.00410365, -0.03220141, -0.00163732,\n",
       "       -0.01991575, -0.03158872, -0.0931838 , -0.00806526, -0.03578937,\n",
       "       -0.00251814, -0.01489434, -0.03498338, -0.10154564,  0.39337805,\n",
       "        0.54162178,  0.39241949,  0.42814332,  0.49755557,  0.39935045,\n",
       "        0.43319566,  0.52353302,  0.42238168,  0.42206715,  0.43484953,\n",
       "        0.4547188 ,  0.39837193,  0.5421566 ,  0.39730999,  0.42589424,\n",
       "        0.48653787,  0.41054099,  0.43399339,  0.48391166,  0.41683186,\n",
       "        0.41979739,  0.46144612,  0.455339  ,  0.39499643,  0.38242161,\n",
       "        0.39000896,  0.391784  ,  0.38065447,  0.40349802,  0.43203717,\n",
       "        0.37668634,  0.42790068,  0.42074866,  0.39520648,  0.44651147,\n",
       "        0.36161378,  0.29991827,  0.37089359,  0.30351037,  0.36007002,\n",
       "        0.27782367,  0.3742626 ,  0.25712366,  0.37390404,  0.268233  ])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(folds_list_train1_unique + folds_list_train2_unique), FEATURES_LIST_TOTRAIN].to_numpy().mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1677155"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(folds_list_train1_unique + folds_list_train2_unique)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0088,  0.3957,  0.3306,  0.0092,  0.0034, -0.0050, -0.0146,  0.0553,\n",
       "         0.0251,  0.2647,  0.1671,  0.0949,  0.0445,  0.1525,  0.0800,  0.2217,\n",
       "         0.1283,  0.1218,  0.1096,  0.2977,  0.2646,  0.1881,  0.1725,  0.2547,\n",
       "         0.2327,  0.2979,  0.2685,  0.1399,  0.1629,  0.3306,  0.3439,  0.2268,\n",
       "         0.2519,  0.3164,  0.3360,  0.3528,  0.3677,  0.0265,  0.0186,  0.0432,\n",
       "         0.0530,  0.4542,  0.3776,  0.4162,  0.4393,  0.4865,  0.4921,  0.3684,\n",
       "         0.5014,  0.5438,  0.5307,  0.4567,  0.0565,  0.3890,  0.3769,  0.7755,\n",
       "         0.9247,  0.7859,  0.8085,  0.8990,  0.5534,  0.5555,  0.5592,  0.5614,\n",
       "         0.4423,  0.6188,  0.6172,  0.5977,  0.5981,  0.3774,  0.2389,  0.3080,\n",
       "         0.0041, -0.0322, -0.0016, -0.0199, -0.0316, -0.0932, -0.0081, -0.0358,\n",
       "        -0.0025, -0.0149, -0.0350, -0.1015,  0.3934,  0.5416,  0.3924,  0.4281,\n",
       "         0.4976,  0.3994,  0.4332,  0.5235,  0.4224,  0.4221,  0.4348,  0.4547,\n",
       "         0.3984,  0.5422,  0.3973,  0.4259,  0.4865,  0.4105,  0.4340,  0.4839,\n",
       "         0.4168,  0.4198,  0.4614,  0.4553,  0.3950,  0.3824,  0.3900,  0.3918,\n",
       "         0.3807,  0.4035,  0.4320,  0.3767,  0.4279,  0.4207,  0.3952,  0.4465,\n",
       "         0.3616,  0.2999,  0.3709,  0.3035,  0.3601,  0.2778,  0.3743,  0.2571,\n",
       "         0.3739,  0.2682], dtype=torch.float64)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.tensor(df.loc[(folds_list_train1_unique + folds_list_train2_unique), FEATURES_LIST_TOTRAIN].to_numpy(), device='cpu'), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.8386e-03,  3.8558e-01,  3.5769e-01,  8.9192e-03,  4.1501e-03,\n",
       "        -3.7146e-03, -1.2589e-02,  5.1777e-02,  2.6828e-02,  2.4881e-01,\n",
       "         1.8235e-01,  8.9122e-02,  4.9486e-02,  1.4311e-01,  8.9027e-02,\n",
       "         2.1168e-01,  1.4630e-01,  1.2122e-01,  1.1358e-01,  2.9381e-01,\n",
       "         2.6877e-01,  1.8691e-01,  1.7698e-01,  2.5244e-01,  2.3856e-01,\n",
       "         2.9407e-01,  2.7318e-01,  1.3548e-01,  1.6088e-01,  3.2189e-01,\n",
       "         3.4253e-01,  2.2056e-01,  2.5013e-01,  3.0822e-01,  3.3535e-01,\n",
       "         3.4145e-01,  3.6583e-01,  2.9320e-02,  2.2892e-02,  4.0022e-02,\n",
       "         5.0750e-02,  4.4505e-01,  3.6018e-01,  3.4603e-01,  4.1153e-01,\n",
       "         4.3803e-01,  4.7612e-01,  3.4787e-01,  4.9963e-01,  5.6400e-01,\n",
       "         5.1226e-01,  4.5739e-01,  4.5744e-02,  3.6270e-01,  3.5887e-01,\n",
       "         6.5260e-01,  8.0495e-01,  6.6135e-01,  6.7981e-01,  7.6259e-01,\n",
       "         5.5640e-01,  5.5817e-01,  5.4554e-01,  5.4678e-01,  4.3506e-01,\n",
       "         6.0757e-01,  6.0850e-01,  5.9519e-01,  5.9594e-01,  3.6954e-01,\n",
       "         2.4337e-01,  3.3227e-01,  5.3933e-03, -3.2868e-02, -2.0445e-04,\n",
       "        -1.9092e-02, -3.1898e-02, -7.6800e-02, -6.0595e-03, -3.5435e-02,\n",
       "        -2.0995e-03, -1.4418e-02, -3.4615e-02, -8.0085e-02,  3.9822e-01,\n",
       "         5.5782e-01,  4.0240e-01,  4.4445e-01,  5.1409e-01,  4.0052e-01,\n",
       "         4.1025e-01,  5.2051e-01,  4.0508e-01,  4.0883e-01,  4.2889e-01,\n",
       "         4.1763e-01,  4.0227e-01,  5.5909e-01,  4.0711e-01,  4.3686e-01,\n",
       "         5.0012e-01,  4.0856e-01,  4.0506e-01,  4.8141e-01,  4.0166e-01,\n",
       "         4.0706e-01,  4.5305e-01,  4.1501e-01,  3.9999e-01,  4.1654e-01,\n",
       "         4.0074e-01,  4.0688e-01,  4.1228e-01,  4.0264e-01,  4.0711e-01,\n",
       "         3.7342e-01,  4.0443e-01,  4.0103e-01,  3.8582e-01,  4.1560e-01,\n",
       "         3.3513e-01,  2.6878e-01,  3.4355e-01,  2.8000e-01,  3.3515e-01,\n",
       "         2.4488e-01,  3.3918e-01,  2.3238e-01,  3.4256e-01,  2.4562e-01],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(f_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training KMeans clusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaissKMeans:\n",
    "    def __init__(self, n_clusters=8, n_init=10, max_iter=300):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.n_init = n_init\n",
    "        self.max_iter = max_iter\n",
    "        self.kmeans = None\n",
    "        self.cluster_centers_ = None\n",
    "        self.inertia_ = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.kmeans = faiss.Kmeans(d=X.shape[1],\n",
    "                                   k=self.n_clusters,\n",
    "                                   niter=self.max_iter,\n",
    "                                   nredo=self.n_init)\n",
    "        self.kmeans.train(X.astype(np.float32))\n",
    "        self.cluster_centers_ = self.kmeans.centroids\n",
    "        self.inertia_ = self.kmeans.obj[-1]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.kmeans.index.search(X.astype(np.float32), 1)[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forclustering = df.loc[folds_list_train1_unique, FEATURES_LIST_TOTRAIN].astype({'feature_0': np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forclustering = np.copy(df_forclustering[FEATURES_LIST_TOTRAIN].to_numpy(), order='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CLUSTERS = 5\n",
    "\n",
    "clusterer = FaissKMeans(n_clusters=NB_CLUSTERS, n_init=10, max_iter=3000)\n",
    "clusterer.fit(df_forclustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df.loc[:, FEATURES_LIST_TOTRAIN].astype({'feature_0': np.float32})\n",
    "df_full = np.copy(df_full[FEATURES_LIST_TOTRAIN].to_numpy(), order='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_clusters = clusterer.predict(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster'] = y_clusters + 1  # +1 to avoid cluster indice 0 (less practical for gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (CLUSTERING == True):\n",
    "    FEATURES_LIST_TOTRAIN = FEATURES_LIST_TOTRAIN + ['cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['red', 'blue', 'orange', 'brown', 'black']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "#ax = axes.ravel()\n",
    "#fig.tight_layout(pad=10.0)\n",
    "\n",
    "ax.set_xlabel('Cluster', fontsize=18)\n",
    "ax.set_ylabel('Number of values in cluster', fontsize=18)\n",
    "ax.set_title('Number of values by cluster', fontsize=18)\n",
    "\n",
    "df.loc[folds_list_train2_unique, :].groupby(by='cluster')['resp'].count().plot.bar(figsize=(15,5), ax=ax, color=colors);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "#ax = axes.ravel()\n",
    "#fig.tight_layout(pad=10.0)\n",
    "\n",
    "ax.set_xlabel('Cluster', fontsize=18)\n",
    "ax.set_ylabel('Mean value of resp in cluster', fontsize=18)\n",
    "ax.set_title('resp mean by cluster : train 1', fontsize=18)\n",
    "\n",
    "df.loc[folds_list_train1_unique, :].groupby(by='cluster')['resp'].mean().plot.bar(figsize=(15,5), ax=ax, color=colors);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "#ax = axes.ravel()\n",
    "#fig.tight_layout(pad=10.0)\n",
    "\n",
    "ax.set_xlabel('Cluster', fontsize=18)\n",
    "ax.set_ylabel('Mean value of resp in cluster', fontsize=18)\n",
    "ax.set_title('resp mean by cluster : train 2', fontsize=18)\n",
    "\n",
    "df.loc[folds_list_train2_unique, :].groupby(by='cluster')['resp'].mean().plot.bar(figsize=(15,5), ax=ax, color=colors);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training XGB model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training XGB model that predicts resp n-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBClassifier_wrapper(BaseEstimator, ClassifierMixin):  \n",
    "    ''' Params passed as dictionnary to __init__, for example :\n",
    "        params_space = {\n",
    "       'features': FEATURES_LIST_TOTRAIN, \n",
    "        'random_state': 42,\n",
    "        'max_depth': 12,\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.01,\n",
    "        'subsample': 0.9,\n",
    "        'colsample_bytree': 0.3,\n",
    "        'tree_method': 'gpu_hist'\n",
    "        }\n",
    "    '''\n",
    "    def __init__(self, params):\n",
    "        self.fitted = False\n",
    "        \n",
    "        self.features = list(params['features'])\n",
    "        self.random_state = params['random_state']\n",
    "        self.max_depth = params['max_depth']\n",
    "        self.n_estimators = params['n_estimators']\n",
    "        self.learning_rate = params['learning_rate']\n",
    "        self.subsample = params['subsample']\n",
    "        self.colsample_bytree = params['colsample_bytree']\n",
    "        self.gamma = params['gamma']\n",
    "        self.tree_method = params['tree_method']  \n",
    "        \n",
    "        #print('Features assigned :')\n",
    "        #print(self.features)\n",
    "\n",
    "        self.model_internal = XGBClassifier(\n",
    "            random_state= self.random_state,\n",
    "            max_depth= self.max_depth,\n",
    "            n_estimators= self.n_estimators,\n",
    "            learning_rate= self.learning_rate,\n",
    "            subsample= self.subsample,\n",
    "            colsample_bytree= self.colsample_bytree,\n",
    "            tree_method= self.tree_method,\n",
    "            gamma = self.gamma,\n",
    "            #objective= 'binary:logistic',\n",
    "            #disable_default_eval_metric=True,\n",
    "            )\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print('Model used for fitting:')\n",
    "        print(self.model_internal)\n",
    "        self.model_internal.fit(X[self.features], y)\n",
    "        \n",
    "        self.fitted = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        if (self.fitted == True):\n",
    "            print('predict called')\n",
    "            return(self.model_internal.predict(X[self.features]))\n",
    "        \n",
    "        else:\n",
    "            print('You must fit model first')\n",
    "            return(None)\n",
    "\n",
    "    def predict_proba(self, X, y=None):\n",
    "        if (self.fitted == True):\n",
    "            print('predict proba called')\n",
    "            return(self.model_internal.predict_proba(X[self.features]))\n",
    "        \n",
    "        else:\n",
    "            print('You must fit model first')\n",
    "            return(None)\n",
    "        \n",
    "\n",
    "    #def set_params(self, **parameters):\n",
    "    #    for parameter, value in parameters.items():\n",
    "    #        setattr(self, parameter, value)\n",
    "\n",
    "        \n",
    "    def score(self, X, y=None):        \n",
    "        print('Type of X:')\n",
    "        print(type(X))\n",
    "        \n",
    "        print('Shape of X:')\n",
    "        print(X.shape)\n",
    "        \n",
    "        print('Type of y:')\n",
    "        print(type(y))\n",
    "        \n",
    "        print('model fitted ?')\n",
    "        print(self.fitted) # Usually returns yes at this point when called by cross_val_score\n",
    "        \n",
    "        if y is None:\n",
    "            print('y is None')\n",
    "            y_preds = pd.Series(self.model_internal.predict(X.reset_index(drop=True)[self.features]))\n",
    "            \n",
    "        else: # cross_val_score goes there\n",
    "            print('y is not None')\n",
    "            y_preds = pd.Series(y)\n",
    "        \n",
    "        return(utility_function(X.reset_index(drop=True), y_preds)) \n",
    "    \n",
    "    def accuracy_score(self, X, y=None):\n",
    "        if y is None:\n",
    "            print('y is None in accuracy_score method : pass predictions as y to avoid launching predict')\n",
    "            y_preds = pd.Series(self.model_internal.predict(X.reset_index(drop=True)[self.features]))\n",
    "            \n",
    "        else: # cross_val_score goes there\n",
    "            #print('y is not None')\n",
    "            y_preds = pd.Series(y)\n",
    "            \n",
    "        return(accuracy_score(X['resp_positive'], y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:45:15] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.2, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=12,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=500, n_jobs=24, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.9,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate label of current step\n",
    "y_train1_resp_positive = (df.loc[folds_list_train1_unique, 'resp'] > 0).astype(np.byte)\n",
    "\n",
    "# Shift values of resp to get resp of step n-1\n",
    "y_train1_resp_n1_positive = y_train1_resp_positive.shift(1, fill_value=0)\n",
    "\n",
    "\n",
    "model_n1 = XGBClassifier(\n",
    "    random_state= 42,\n",
    "    max_depth= 12,\n",
    "    n_estimators= 500,\n",
    "    learning_rate= 0.01,\n",
    "    subsample= 0.9,\n",
    "    colsample_bytree= 0.2,\n",
    "    #tree_method= 'gpu_hist',\n",
    "    gamma = None,\n",
    "    )\n",
    "\n",
    "model_n1.fit(df.loc[folds_list_train1_unique, FEATURES_LIST_TOTRAIN], y_train1_resp_n1_positive, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train xgb main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapped = XGBClassifier_wrapper({\n",
    "   'features': ['feature_'+str(i) for i in range(130)] + ['resp_n1_predict'], \n",
    "    'random_state': 42,\n",
    "    'max_depth': 10,\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.02,\n",
    "    'subsample': 0.5,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'gamma': None,\n",
    "    'tree_method': 'gpu_hist'        \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used for fitting:\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.6, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.02, max_delta_step=None, max_depth=10,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=42, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=0.5, tree_method='gpu_hist',\n",
      "              validate_parameters=None, verbosity=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:09:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/sklearn/base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier_wrapper(params=None)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2_predictions_resp_n1 = model_n1.predict(df.loc[folds_list_train2_unique, FEATURES_LIST_TOTRAIN])\n",
    "df.loc[folds_list_train2_unique, 'resp_n1_predict'] = pd.DataFrame(train2_predictions_resp_n1, index=folds_list_train2_unique, columns=['resp_n1_predict'])\n",
    "        \n",
    "model_wrapped.fit(df.loc[folds_list_train2_unique], (df.loc[folds_list_train2_unique]['resp'] > 0).astype(np.byte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision/Recall of resp n-1\n",
      "Precision score for resp n-1: 0.5051726105497034\n",
      "Recall score for resp n-1: 0.641329495577563\n"
     ]
    }
   ],
   "source": [
    "precision_n1 = precision_score((df.loc[folds_list_train2_unique]['resp'] > 0).astype(np.byte).shift(1, fill_value=0), df.loc[folds_list_train2_unique, 'resp_n1_predict'])\n",
    "recall_n1 = recall_score((df.loc[folds_list_train2_unique]['resp'] > 0).astype(np.byte).shift(1, fill_value=0), df.loc[folds_list_train2_unique, 'resp_n1_predict'])\n",
    "\n",
    "print(f'Precision/Recall of resp n-1')\n",
    "print(f'Precision score for resp n-1: {precision_n1}')\n",
    "print(f'Recall score for resp n-1: {recall_n1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict called\n",
      "Type of X:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X:\n",
      "(141102, 141)\n",
      "Type of y:\n",
      "<class 'numpy.ndarray'>\n",
      "model fitted ?\n",
      "True\n",
      "y is not None\n",
      "Feature importances for split 12:\n",
      "                 Importance  % feat importance cumulé\n",
      "feature_45         0.014291                  0.014291\n",
      "feature_42         0.014124                  0.028416\n",
      "feature_43         0.014109                  0.042525\n",
      "feature_41         0.013462                  0.055986\n",
      "feature_44         0.012669                  0.068655\n",
      "feature_63         0.012291                  0.080946\n",
      "feature_39         0.012206                  0.093152\n",
      "feature_27         0.011925                  0.105077\n",
      "feature_61         0.011572                  0.116649\n",
      "feature_6          0.011355                  0.128004\n",
      "feature_62         0.011309                  0.139313\n",
      "feature_60         0.011234                  0.150546\n",
      "feature_5          0.011116                  0.161662\n",
      "feature_40         0.010649                  0.172311\n",
      "feature_3          0.010419                  0.182731\n",
      "feature_107        0.010224                  0.192954\n",
      "feature_83         0.010221                  0.203175\n",
      "feature_4          0.010072                  0.213247\n",
      "feature_38         0.010030                  0.223278\n",
      "feature_37         0.009828                  0.233105\n",
      "feature_119        0.009614                  0.242719\n",
      "feature_77         0.009463                  0.252182\n",
      "feature_64         0.009280                  0.261461\n",
      "feature_120        0.009280                  0.270741\n",
      "feature_95         0.009156                  0.279897\n",
      "feature_55         0.009137                  0.289034\n",
      "feature_124        0.009069                  0.298103\n",
      "feature_114        0.008962                  0.307065\n",
      "feature_102        0.008805                  0.315870\n",
      "feature_121        0.008646                  0.324516\n",
      "feature_113        0.008618                  0.333133\n",
      "feature_90         0.008552                  0.341685\n",
      "feature_89         0.008469                  0.350155\n",
      "feature_68         0.008411                  0.358566\n",
      "feature_57         0.008334                  0.366901\n",
      "feature_125        0.008255                  0.375156\n",
      "feature_66         0.008230                  0.383386\n",
      "feature_20         0.008149                  0.391535\n",
      "feature_71         0.008127                  0.399662\n",
      "feature_126        0.008094                  0.407756\n",
      "feature_108        0.008068                  0.415824\n",
      "feature_101        0.008041                  0.423866\n",
      "feature_28         0.007862                  0.431728\n",
      "feature_0          0.007856                  0.439584\n",
      "feature_84         0.007694                  0.447279\n",
      "feature_67         0.007562                  0.454840\n",
      "feature_70         0.007446                  0.462286\n",
      "feature_18         0.007435                  0.469721\n",
      "feature_8          0.007431                  0.477152\n",
      "feature_96         0.007418                  0.484571\n",
      "feature_116        0.007368                  0.491939\n",
      "feature_65         0.007366                  0.499305\n",
      "feature_26         0.007360                  0.506665\n",
      "feature_69         0.007325                  0.513989\n",
      "feature_58         0.007303                  0.521292\n",
      "feature_78         0.007302                  0.528594\n",
      "feature_104        0.007296                  0.535890\n",
      "feature_127        0.007270                  0.543160\n",
      "feature_92         0.007154                  0.550314\n",
      "feature_31         0.007102                  0.557416\n",
      "feature_50         0.007082                  0.564498\n",
      "feature_59         0.007008                  0.571506\n",
      "feature_17         0.006893                  0.578399\n",
      "feature_53         0.006892                  0.585290\n",
      "feature_110        0.006884                  0.592174\n",
      "feature_7          0.006875                  0.599050\n",
      "feature_24         0.006868                  0.605918\n",
      "feature_72         0.006840                  0.612758\n",
      "feature_128        0.006835                  0.619593\n",
      "feature_36         0.006713                  0.626306\n",
      "feature_48         0.006697                  0.633003\n",
      "feature_23         0.006679                  0.639682\n",
      "feature_98         0.006679                  0.646361\n",
      "feature_47         0.006655                  0.653015\n",
      "feature_33         0.006652                  0.659667\n",
      "feature_32         0.006625                  0.666292\n",
      "feature_86         0.006615                  0.672907\n",
      "feature_35         0.006607                  0.679514\n",
      "feature_129        0.006607                  0.686121\n",
      "feature_22         0.006546                  0.692667\n",
      "feature_51         0.006537                  0.699204\n",
      "feature_34         0.006533                  0.705737\n",
      "feature_111        0.006494                  0.712230\n",
      "feature_46         0.006472                  0.718703\n",
      "feature_10         0.006464                  0.725166\n",
      "feature_12         0.006463                  0.731629\n",
      "feature_54         0.006449                  0.738078\n",
      "feature_117        0.006437                  0.744515\n",
      "feature_49         0.006428                  0.750943\n",
      "feature_122        0.006424                  0.757368\n",
      "feature_56         0.006399                  0.763767\n",
      "feature_30         0.006374                  0.770141\n",
      "feature_25         0.006359                  0.776500\n",
      "feature_123        0.006289                  0.782789\n",
      "feature_80         0.006273                  0.789062\n",
      "feature_9          0.006245                  0.795307\n",
      "feature_21         0.006244                  0.801550\n",
      "feature_2          0.006220                  0.807771\n",
      "feature_109        0.006169                  0.813940\n",
      "feature_105        0.006151                  0.820091\n",
      "feature_1          0.006140                  0.826231\n",
      "feature_99         0.006133                  0.832364\n",
      "feature_29         0.006119                  0.838483\n",
      "feature_19         0.006105                  0.844588\n",
      "feature_11         0.006068                  0.850656\n",
      "feature_93         0.006029                  0.856685\n",
      "feature_85         0.006021                  0.862706\n",
      "feature_115        0.006012                  0.868718\n",
      "feature_118        0.005999                  0.874717\n",
      "feature_112        0.005924                  0.880641\n",
      "feature_87         0.005923                  0.886563\n",
      "feature_16         0.005909                  0.892472\n",
      "feature_94         0.005881                  0.898353\n",
      "feature_91         0.005869                  0.904222\n",
      "feature_52         0.005848                  0.910070\n",
      "feature_88         0.005838                  0.915909\n",
      "feature_100        0.005834                  0.921743\n",
      "feature_14         0.005833                  0.927576\n",
      "feature_106        0.005807                  0.933383\n",
      "feature_13         0.005797                  0.939180\n",
      "feature_103        0.005779                  0.944959\n",
      "feature_74         0.005777                  0.950736\n",
      "feature_81         0.005777                  0.956512\n",
      "feature_97         0.005759                  0.962271\n",
      "feature_82         0.005734                  0.968005\n",
      "feature_79         0.005641                  0.973645\n",
      "feature_75         0.005636                  0.979282\n",
      "feature_73         0.005608                  0.984890\n",
      "feature_76         0.005549                  0.990438\n",
      "feature_15         0.005536                  0.995975\n",
      "resp_n1_predict    0.004025                  1.000000\n",
      "predict called\n",
      "Type of X:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X:\n",
      "(142450, 141)\n",
      "Type of y:\n",
      "<class 'numpy.ndarray'>\n",
      "model fitted ?\n",
      "True\n",
      "y is not None\n",
      "Feature importances for split 12:\n",
      "                 Importance  % feat importance cumulé\n",
      "feature_45         0.014291                  0.014291\n",
      "feature_42         0.014124                  0.028416\n",
      "feature_43         0.014109                  0.042525\n",
      "feature_41         0.013462                  0.055986\n",
      "feature_44         0.012669                  0.068655\n",
      "feature_63         0.012291                  0.080946\n",
      "feature_39         0.012206                  0.093152\n",
      "feature_27         0.011925                  0.105077\n",
      "feature_61         0.011572                  0.116649\n",
      "feature_6          0.011355                  0.128004\n",
      "feature_62         0.011309                  0.139313\n",
      "feature_60         0.011234                  0.150546\n",
      "feature_5          0.011116                  0.161662\n",
      "feature_40         0.010649                  0.172311\n",
      "feature_3          0.010419                  0.182731\n",
      "feature_107        0.010224                  0.192954\n",
      "feature_83         0.010221                  0.203175\n",
      "feature_4          0.010072                  0.213247\n",
      "feature_38         0.010030                  0.223278\n",
      "feature_37         0.009828                  0.233105\n",
      "feature_119        0.009614                  0.242719\n",
      "feature_77         0.009463                  0.252182\n",
      "feature_64         0.009280                  0.261461\n",
      "feature_120        0.009280                  0.270741\n",
      "feature_95         0.009156                  0.279897\n",
      "feature_55         0.009137                  0.289034\n",
      "feature_124        0.009069                  0.298103\n",
      "feature_114        0.008962                  0.307065\n",
      "feature_102        0.008805                  0.315870\n",
      "feature_121        0.008646                  0.324516\n",
      "feature_113        0.008618                  0.333133\n",
      "feature_90         0.008552                  0.341685\n",
      "feature_89         0.008469                  0.350155\n",
      "feature_68         0.008411                  0.358566\n",
      "feature_57         0.008334                  0.366901\n",
      "feature_125        0.008255                  0.375156\n",
      "feature_66         0.008230                  0.383386\n",
      "feature_20         0.008149                  0.391535\n",
      "feature_71         0.008127                  0.399662\n",
      "feature_126        0.008094                  0.407756\n",
      "feature_108        0.008068                  0.415824\n",
      "feature_101        0.008041                  0.423866\n",
      "feature_28         0.007862                  0.431728\n",
      "feature_0          0.007856                  0.439584\n",
      "feature_84         0.007694                  0.447279\n",
      "feature_67         0.007562                  0.454840\n",
      "feature_70         0.007446                  0.462286\n",
      "feature_18         0.007435                  0.469721\n",
      "feature_8          0.007431                  0.477152\n",
      "feature_96         0.007418                  0.484571\n",
      "feature_116        0.007368                  0.491939\n",
      "feature_65         0.007366                  0.499305\n",
      "feature_26         0.007360                  0.506665\n",
      "feature_69         0.007325                  0.513989\n",
      "feature_58         0.007303                  0.521292\n",
      "feature_78         0.007302                  0.528594\n",
      "feature_104        0.007296                  0.535890\n",
      "feature_127        0.007270                  0.543160\n",
      "feature_92         0.007154                  0.550314\n",
      "feature_31         0.007102                  0.557416\n",
      "feature_50         0.007082                  0.564498\n",
      "feature_59         0.007008                  0.571506\n",
      "feature_17         0.006893                  0.578399\n",
      "feature_53         0.006892                  0.585290\n",
      "feature_110        0.006884                  0.592174\n",
      "feature_7          0.006875                  0.599050\n",
      "feature_24         0.006868                  0.605918\n",
      "feature_72         0.006840                  0.612758\n",
      "feature_128        0.006835                  0.619593\n",
      "feature_36         0.006713                  0.626306\n",
      "feature_48         0.006697                  0.633003\n",
      "feature_23         0.006679                  0.639682\n",
      "feature_98         0.006679                  0.646361\n",
      "feature_47         0.006655                  0.653015\n",
      "feature_33         0.006652                  0.659667\n",
      "feature_32         0.006625                  0.666292\n",
      "feature_86         0.006615                  0.672907\n",
      "feature_35         0.006607                  0.679514\n",
      "feature_129        0.006607                  0.686121\n",
      "feature_22         0.006546                  0.692667\n",
      "feature_51         0.006537                  0.699204\n",
      "feature_34         0.006533                  0.705737\n",
      "feature_111        0.006494                  0.712230\n",
      "feature_46         0.006472                  0.718703\n",
      "feature_10         0.006464                  0.725166\n",
      "feature_12         0.006463                  0.731629\n",
      "feature_54         0.006449                  0.738078\n",
      "feature_117        0.006437                  0.744515\n",
      "feature_49         0.006428                  0.750943\n",
      "feature_122        0.006424                  0.757368\n",
      "feature_56         0.006399                  0.763767\n",
      "feature_30         0.006374                  0.770141\n",
      "feature_25         0.006359                  0.776500\n",
      "feature_123        0.006289                  0.782789\n",
      "feature_80         0.006273                  0.789062\n",
      "feature_9          0.006245                  0.795307\n",
      "feature_21         0.006244                  0.801550\n",
      "feature_2          0.006220                  0.807771\n",
      "feature_109        0.006169                  0.813940\n",
      "feature_105        0.006151                  0.820091\n",
      "feature_1          0.006140                  0.826231\n",
      "feature_99         0.006133                  0.832364\n",
      "feature_29         0.006119                  0.838483\n",
      "feature_19         0.006105                  0.844588\n",
      "feature_11         0.006068                  0.850656\n",
      "feature_93         0.006029                  0.856685\n",
      "feature_85         0.006021                  0.862706\n",
      "feature_115        0.006012                  0.868718\n",
      "feature_118        0.005999                  0.874717\n",
      "feature_112        0.005924                  0.880641\n",
      "feature_87         0.005923                  0.886563\n",
      "feature_16         0.005909                  0.892472\n",
      "feature_94         0.005881                  0.898353\n",
      "feature_91         0.005869                  0.904222\n",
      "feature_52         0.005848                  0.910070\n",
      "feature_88         0.005838                  0.915909\n",
      "feature_100        0.005834                  0.921743\n",
      "feature_14         0.005833                  0.927576\n",
      "feature_106        0.005807                  0.933383\n",
      "feature_13         0.005797                  0.939180\n",
      "feature_103        0.005779                  0.944959\n",
      "feature_74         0.005777                  0.950736\n",
      "feature_81         0.005777                  0.956512\n",
      "feature_97         0.005759                  0.962271\n",
      "feature_82         0.005734                  0.968005\n",
      "feature_79         0.005641                  0.973645\n",
      "feature_75         0.005636                  0.979282\n",
      "feature_73         0.005608                  0.984890\n",
      "feature_76         0.005549                  0.990438\n",
      "feature_15         0.005536                  0.995975\n",
      "resp_n1_predict    0.004025                  1.000000\n",
      "predict called\n",
      "Type of X:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X:\n",
      "(145651, 141)\n",
      "Type of y:\n",
      "<class 'numpy.ndarray'>\n",
      "model fitted ?\n",
      "True\n",
      "y is not None\n",
      "Feature importances for split 12:\n",
      "                 Importance  % feat importance cumulé\n",
      "feature_45         0.014291                  0.014291\n",
      "feature_42         0.014124                  0.028416\n",
      "feature_43         0.014109                  0.042525\n",
      "feature_41         0.013462                  0.055986\n",
      "feature_44         0.012669                  0.068655\n",
      "feature_63         0.012291                  0.080946\n",
      "feature_39         0.012206                  0.093152\n",
      "feature_27         0.011925                  0.105077\n",
      "feature_61         0.011572                  0.116649\n",
      "feature_6          0.011355                  0.128004\n",
      "feature_62         0.011309                  0.139313\n",
      "feature_60         0.011234                  0.150546\n",
      "feature_5          0.011116                  0.161662\n",
      "feature_40         0.010649                  0.172311\n",
      "feature_3          0.010419                  0.182731\n",
      "feature_107        0.010224                  0.192954\n",
      "feature_83         0.010221                  0.203175\n",
      "feature_4          0.010072                  0.213247\n",
      "feature_38         0.010030                  0.223278\n",
      "feature_37         0.009828                  0.233105\n",
      "feature_119        0.009614                  0.242719\n",
      "feature_77         0.009463                  0.252182\n",
      "feature_64         0.009280                  0.261461\n",
      "feature_120        0.009280                  0.270741\n",
      "feature_95         0.009156                  0.279897\n",
      "feature_55         0.009137                  0.289034\n",
      "feature_124        0.009069                  0.298103\n",
      "feature_114        0.008962                  0.307065\n",
      "feature_102        0.008805                  0.315870\n",
      "feature_121        0.008646                  0.324516\n",
      "feature_113        0.008618                  0.333133\n",
      "feature_90         0.008552                  0.341685\n",
      "feature_89         0.008469                  0.350155\n",
      "feature_68         0.008411                  0.358566\n",
      "feature_57         0.008334                  0.366901\n",
      "feature_125        0.008255                  0.375156\n",
      "feature_66         0.008230                  0.383386\n",
      "feature_20         0.008149                  0.391535\n",
      "feature_71         0.008127                  0.399662\n",
      "feature_126        0.008094                  0.407756\n",
      "feature_108        0.008068                  0.415824\n",
      "feature_101        0.008041                  0.423866\n",
      "feature_28         0.007862                  0.431728\n",
      "feature_0          0.007856                  0.439584\n",
      "feature_84         0.007694                  0.447279\n",
      "feature_67         0.007562                  0.454840\n",
      "feature_70         0.007446                  0.462286\n",
      "feature_18         0.007435                  0.469721\n",
      "feature_8          0.007431                  0.477152\n",
      "feature_96         0.007418                  0.484571\n",
      "feature_116        0.007368                  0.491939\n",
      "feature_65         0.007366                  0.499305\n",
      "feature_26         0.007360                  0.506665\n",
      "feature_69         0.007325                  0.513989\n",
      "feature_58         0.007303                  0.521292\n",
      "feature_78         0.007302                  0.528594\n",
      "feature_104        0.007296                  0.535890\n",
      "feature_127        0.007270                  0.543160\n",
      "feature_92         0.007154                  0.550314\n",
      "feature_31         0.007102                  0.557416\n",
      "feature_50         0.007082                  0.564498\n",
      "feature_59         0.007008                  0.571506\n",
      "feature_17         0.006893                  0.578399\n",
      "feature_53         0.006892                  0.585290\n",
      "feature_110        0.006884                  0.592174\n",
      "feature_7          0.006875                  0.599050\n",
      "feature_24         0.006868                  0.605918\n",
      "feature_72         0.006840                  0.612758\n",
      "feature_128        0.006835                  0.619593\n",
      "feature_36         0.006713                  0.626306\n",
      "feature_48         0.006697                  0.633003\n",
      "feature_23         0.006679                  0.639682\n",
      "feature_98         0.006679                  0.646361\n",
      "feature_47         0.006655                  0.653015\n",
      "feature_33         0.006652                  0.659667\n",
      "feature_32         0.006625                  0.666292\n",
      "feature_86         0.006615                  0.672907\n",
      "feature_35         0.006607                  0.679514\n",
      "feature_129        0.006607                  0.686121\n",
      "feature_22         0.006546                  0.692667\n",
      "feature_51         0.006537                  0.699204\n",
      "feature_34         0.006533                  0.705737\n",
      "feature_111        0.006494                  0.712230\n",
      "feature_46         0.006472                  0.718703\n",
      "feature_10         0.006464                  0.725166\n",
      "feature_12         0.006463                  0.731629\n",
      "feature_54         0.006449                  0.738078\n",
      "feature_117        0.006437                  0.744515\n",
      "feature_49         0.006428                  0.750943\n",
      "feature_122        0.006424                  0.757368\n",
      "feature_56         0.006399                  0.763767\n",
      "feature_30         0.006374                  0.770141\n",
      "feature_25         0.006359                  0.776500\n",
      "feature_123        0.006289                  0.782789\n",
      "feature_80         0.006273                  0.789062\n",
      "feature_9          0.006245                  0.795307\n",
      "feature_21         0.006244                  0.801550\n",
      "feature_2          0.006220                  0.807771\n",
      "feature_109        0.006169                  0.813940\n",
      "feature_105        0.006151                  0.820091\n",
      "feature_1          0.006140                  0.826231\n",
      "feature_99         0.006133                  0.832364\n",
      "feature_29         0.006119                  0.838483\n",
      "feature_19         0.006105                  0.844588\n",
      "feature_11         0.006068                  0.850656\n",
      "feature_93         0.006029                  0.856685\n",
      "feature_85         0.006021                  0.862706\n",
      "feature_115        0.006012                  0.868718\n",
      "feature_118        0.005999                  0.874717\n",
      "feature_112        0.005924                  0.880641\n",
      "feature_87         0.005923                  0.886563\n",
      "feature_16         0.005909                  0.892472\n",
      "feature_94         0.005881                  0.898353\n",
      "feature_91         0.005869                  0.904222\n",
      "feature_52         0.005848                  0.910070\n",
      "feature_88         0.005838                  0.915909\n",
      "feature_100        0.005834                  0.921743\n",
      "feature_14         0.005833                  0.927576\n",
      "feature_106        0.005807                  0.933383\n",
      "feature_13         0.005797                  0.939180\n",
      "feature_103        0.005779                  0.944959\n",
      "feature_74         0.005777                  0.950736\n",
      "feature_81         0.005777                  0.956512\n",
      "feature_97         0.005759                  0.962271\n",
      "feature_82         0.005734                  0.968005\n",
      "feature_79         0.005641                  0.973645\n",
      "feature_75         0.005636                  0.979282\n",
      "feature_73         0.005608                  0.984890\n",
      "feature_76         0.005549                  0.990438\n",
      "feature_15         0.005536                  0.995975\n",
      "resp_n1_predict    0.004025                  1.000000\n",
      "predict called\n",
      "Type of X:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X:\n",
      "(142152, 141)\n",
      "Type of y:\n",
      "<class 'numpy.ndarray'>\n",
      "model fitted ?\n",
      "True\n",
      "y is not None\n",
      "Feature importances for split 12:\n",
      "                 Importance  % feat importance cumulé\n",
      "feature_45         0.014291                  0.014291\n",
      "feature_42         0.014124                  0.028416\n",
      "feature_43         0.014109                  0.042525\n",
      "feature_41         0.013462                  0.055986\n",
      "feature_44         0.012669                  0.068655\n",
      "feature_63         0.012291                  0.080946\n",
      "feature_39         0.012206                  0.093152\n",
      "feature_27         0.011925                  0.105077\n",
      "feature_61         0.011572                  0.116649\n",
      "feature_6          0.011355                  0.128004\n",
      "feature_62         0.011309                  0.139313\n",
      "feature_60         0.011234                  0.150546\n",
      "feature_5          0.011116                  0.161662\n",
      "feature_40         0.010649                  0.172311\n",
      "feature_3          0.010419                  0.182731\n",
      "feature_107        0.010224                  0.192954\n",
      "feature_83         0.010221                  0.203175\n",
      "feature_4          0.010072                  0.213247\n",
      "feature_38         0.010030                  0.223278\n",
      "feature_37         0.009828                  0.233105\n",
      "feature_119        0.009614                  0.242719\n",
      "feature_77         0.009463                  0.252182\n",
      "feature_64         0.009280                  0.261461\n",
      "feature_120        0.009280                  0.270741\n",
      "feature_95         0.009156                  0.279897\n",
      "feature_55         0.009137                  0.289034\n",
      "feature_124        0.009069                  0.298103\n",
      "feature_114        0.008962                  0.307065\n",
      "feature_102        0.008805                  0.315870\n",
      "feature_121        0.008646                  0.324516\n",
      "feature_113        0.008618                  0.333133\n",
      "feature_90         0.008552                  0.341685\n",
      "feature_89         0.008469                  0.350155\n",
      "feature_68         0.008411                  0.358566\n",
      "feature_57         0.008334                  0.366901\n",
      "feature_125        0.008255                  0.375156\n",
      "feature_66         0.008230                  0.383386\n",
      "feature_20         0.008149                  0.391535\n",
      "feature_71         0.008127                  0.399662\n",
      "feature_126        0.008094                  0.407756\n",
      "feature_108        0.008068                  0.415824\n",
      "feature_101        0.008041                  0.423866\n",
      "feature_28         0.007862                  0.431728\n",
      "feature_0          0.007856                  0.439584\n",
      "feature_84         0.007694                  0.447279\n",
      "feature_67         0.007562                  0.454840\n",
      "feature_70         0.007446                  0.462286\n",
      "feature_18         0.007435                  0.469721\n",
      "feature_8          0.007431                  0.477152\n",
      "feature_96         0.007418                  0.484571\n",
      "feature_116        0.007368                  0.491939\n",
      "feature_65         0.007366                  0.499305\n",
      "feature_26         0.007360                  0.506665\n",
      "feature_69         0.007325                  0.513989\n",
      "feature_58         0.007303                  0.521292\n",
      "feature_78         0.007302                  0.528594\n",
      "feature_104        0.007296                  0.535890\n",
      "feature_127        0.007270                  0.543160\n",
      "feature_92         0.007154                  0.550314\n",
      "feature_31         0.007102                  0.557416\n",
      "feature_50         0.007082                  0.564498\n",
      "feature_59         0.007008                  0.571506\n",
      "feature_17         0.006893                  0.578399\n",
      "feature_53         0.006892                  0.585290\n",
      "feature_110        0.006884                  0.592174\n",
      "feature_7          0.006875                  0.599050\n",
      "feature_24         0.006868                  0.605918\n",
      "feature_72         0.006840                  0.612758\n",
      "feature_128        0.006835                  0.619593\n",
      "feature_36         0.006713                  0.626306\n",
      "feature_48         0.006697                  0.633003\n",
      "feature_23         0.006679                  0.639682\n",
      "feature_98         0.006679                  0.646361\n",
      "feature_47         0.006655                  0.653015\n",
      "feature_33         0.006652                  0.659667\n",
      "feature_32         0.006625                  0.666292\n",
      "feature_86         0.006615                  0.672907\n",
      "feature_35         0.006607                  0.679514\n",
      "feature_129        0.006607                  0.686121\n",
      "feature_22         0.006546                  0.692667\n",
      "feature_51         0.006537                  0.699204\n",
      "feature_34         0.006533                  0.705737\n",
      "feature_111        0.006494                  0.712230\n",
      "feature_46         0.006472                  0.718703\n",
      "feature_10         0.006464                  0.725166\n",
      "feature_12         0.006463                  0.731629\n",
      "feature_54         0.006449                  0.738078\n",
      "feature_117        0.006437                  0.744515\n",
      "feature_49         0.006428                  0.750943\n",
      "feature_122        0.006424                  0.757368\n",
      "feature_56         0.006399                  0.763767\n",
      "feature_30         0.006374                  0.770141\n",
      "feature_25         0.006359                  0.776500\n",
      "feature_123        0.006289                  0.782789\n",
      "feature_80         0.006273                  0.789062\n",
      "feature_9          0.006245                  0.795307\n",
      "feature_21         0.006244                  0.801550\n",
      "feature_2          0.006220                  0.807771\n",
      "feature_109        0.006169                  0.813940\n",
      "feature_105        0.006151                  0.820091\n",
      "feature_1          0.006140                  0.826231\n",
      "feature_99         0.006133                  0.832364\n",
      "feature_29         0.006119                  0.838483\n",
      "feature_19         0.006105                  0.844588\n",
      "feature_11         0.006068                  0.850656\n",
      "feature_93         0.006029                  0.856685\n",
      "feature_85         0.006021                  0.862706\n",
      "feature_115        0.006012                  0.868718\n",
      "feature_118        0.005999                  0.874717\n",
      "feature_112        0.005924                  0.880641\n",
      "feature_87         0.005923                  0.886563\n",
      "feature_16         0.005909                  0.892472\n",
      "feature_94         0.005881                  0.898353\n",
      "feature_91         0.005869                  0.904222\n",
      "feature_52         0.005848                  0.910070\n",
      "feature_88         0.005838                  0.915909\n",
      "feature_100        0.005834                  0.921743\n",
      "feature_14         0.005833                  0.927576\n",
      "feature_106        0.005807                  0.933383\n",
      "feature_13         0.005797                  0.939180\n",
      "feature_103        0.005779                  0.944959\n",
      "feature_74         0.005777                  0.950736\n",
      "feature_81         0.005777                  0.956512\n",
      "feature_97         0.005759                  0.962271\n",
      "feature_82         0.005734                  0.968005\n",
      "feature_79         0.005641                  0.973645\n",
      "feature_75         0.005636                  0.979282\n",
      "feature_73         0.005608                  0.984890\n",
      "feature_76         0.005549                  0.990438\n",
      "feature_15         0.005536                  0.995975\n",
      "resp_n1_predict    0.004025                  1.000000\n",
      "predict called\n",
      "Type of X:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X:\n",
      "(141980, 141)\n",
      "Type of y:\n",
      "<class 'numpy.ndarray'>\n",
      "model fitted ?\n",
      "True\n",
      "y is not None\n",
      "Feature importances for split 12:\n",
      "                 Importance  % feat importance cumulé\n",
      "feature_45         0.014291                  0.014291\n",
      "feature_42         0.014124                  0.028416\n",
      "feature_43         0.014109                  0.042525\n",
      "feature_41         0.013462                  0.055986\n",
      "feature_44         0.012669                  0.068655\n",
      "feature_63         0.012291                  0.080946\n",
      "feature_39         0.012206                  0.093152\n",
      "feature_27         0.011925                  0.105077\n",
      "feature_61         0.011572                  0.116649\n",
      "feature_6          0.011355                  0.128004\n",
      "feature_62         0.011309                  0.139313\n",
      "feature_60         0.011234                  0.150546\n",
      "feature_5          0.011116                  0.161662\n",
      "feature_40         0.010649                  0.172311\n",
      "feature_3          0.010419                  0.182731\n",
      "feature_107        0.010224                  0.192954\n",
      "feature_83         0.010221                  0.203175\n",
      "feature_4          0.010072                  0.213247\n",
      "feature_38         0.010030                  0.223278\n",
      "feature_37         0.009828                  0.233105\n",
      "feature_119        0.009614                  0.242719\n",
      "feature_77         0.009463                  0.252182\n",
      "feature_64         0.009280                  0.261461\n",
      "feature_120        0.009280                  0.270741\n",
      "feature_95         0.009156                  0.279897\n",
      "feature_55         0.009137                  0.289034\n",
      "feature_124        0.009069                  0.298103\n",
      "feature_114        0.008962                  0.307065\n",
      "feature_102        0.008805                  0.315870\n",
      "feature_121        0.008646                  0.324516\n",
      "feature_113        0.008618                  0.333133\n",
      "feature_90         0.008552                  0.341685\n",
      "feature_89         0.008469                  0.350155\n",
      "feature_68         0.008411                  0.358566\n",
      "feature_57         0.008334                  0.366901\n",
      "feature_125        0.008255                  0.375156\n",
      "feature_66         0.008230                  0.383386\n",
      "feature_20         0.008149                  0.391535\n",
      "feature_71         0.008127                  0.399662\n",
      "feature_126        0.008094                  0.407756\n",
      "feature_108        0.008068                  0.415824\n",
      "feature_101        0.008041                  0.423866\n",
      "feature_28         0.007862                  0.431728\n",
      "feature_0          0.007856                  0.439584\n",
      "feature_84         0.007694                  0.447279\n",
      "feature_67         0.007562                  0.454840\n",
      "feature_70         0.007446                  0.462286\n",
      "feature_18         0.007435                  0.469721\n",
      "feature_8          0.007431                  0.477152\n",
      "feature_96         0.007418                  0.484571\n",
      "feature_116        0.007368                  0.491939\n",
      "feature_65         0.007366                  0.499305\n",
      "feature_26         0.007360                  0.506665\n",
      "feature_69         0.007325                  0.513989\n",
      "feature_58         0.007303                  0.521292\n",
      "feature_78         0.007302                  0.528594\n",
      "feature_104        0.007296                  0.535890\n",
      "feature_127        0.007270                  0.543160\n",
      "feature_92         0.007154                  0.550314\n",
      "feature_31         0.007102                  0.557416\n",
      "feature_50         0.007082                  0.564498\n",
      "feature_59         0.007008                  0.571506\n",
      "feature_17         0.006893                  0.578399\n",
      "feature_53         0.006892                  0.585290\n",
      "feature_110        0.006884                  0.592174\n",
      "feature_7          0.006875                  0.599050\n",
      "feature_24         0.006868                  0.605918\n",
      "feature_72         0.006840                  0.612758\n",
      "feature_128        0.006835                  0.619593\n",
      "feature_36         0.006713                  0.626306\n",
      "feature_48         0.006697                  0.633003\n",
      "feature_23         0.006679                  0.639682\n",
      "feature_98         0.006679                  0.646361\n",
      "feature_47         0.006655                  0.653015\n",
      "feature_33         0.006652                  0.659667\n",
      "feature_32         0.006625                  0.666292\n",
      "feature_86         0.006615                  0.672907\n",
      "feature_35         0.006607                  0.679514\n",
      "feature_129        0.006607                  0.686121\n",
      "feature_22         0.006546                  0.692667\n",
      "feature_51         0.006537                  0.699204\n",
      "feature_34         0.006533                  0.705737\n",
      "feature_111        0.006494                  0.712230\n",
      "feature_46         0.006472                  0.718703\n",
      "feature_10         0.006464                  0.725166\n",
      "feature_12         0.006463                  0.731629\n",
      "feature_54         0.006449                  0.738078\n",
      "feature_117        0.006437                  0.744515\n",
      "feature_49         0.006428                  0.750943\n",
      "feature_122        0.006424                  0.757368\n",
      "feature_56         0.006399                  0.763767\n",
      "feature_30         0.006374                  0.770141\n",
      "feature_25         0.006359                  0.776500\n",
      "feature_123        0.006289                  0.782789\n",
      "feature_80         0.006273                  0.789062\n",
      "feature_9          0.006245                  0.795307\n",
      "feature_21         0.006244                  0.801550\n",
      "feature_2          0.006220                  0.807771\n",
      "feature_109        0.006169                  0.813940\n",
      "feature_105        0.006151                  0.820091\n",
      "feature_1          0.006140                  0.826231\n",
      "feature_99         0.006133                  0.832364\n",
      "feature_29         0.006119                  0.838483\n",
      "feature_19         0.006105                  0.844588\n",
      "feature_11         0.006068                  0.850656\n",
      "feature_93         0.006029                  0.856685\n",
      "feature_85         0.006021                  0.862706\n",
      "feature_115        0.006012                  0.868718\n",
      "feature_118        0.005999                  0.874717\n",
      "feature_112        0.005924                  0.880641\n",
      "feature_87         0.005923                  0.886563\n",
      "feature_16         0.005909                  0.892472\n",
      "feature_94         0.005881                  0.898353\n",
      "feature_91         0.005869                  0.904222\n",
      "feature_52         0.005848                  0.910070\n",
      "feature_88         0.005838                  0.915909\n",
      "feature_100        0.005834                  0.921743\n",
      "feature_14         0.005833                  0.927576\n",
      "feature_106        0.005807                  0.933383\n",
      "feature_13         0.005797                  0.939180\n",
      "feature_103        0.005779                  0.944959\n",
      "feature_74         0.005777                  0.950736\n",
      "feature_81         0.005777                  0.956512\n",
      "feature_97         0.005759                  0.962271\n",
      "feature_82         0.005734                  0.968005\n",
      "feature_79         0.005641                  0.973645\n",
      "feature_75         0.005636                  0.979282\n",
      "feature_73         0.005608                  0.984890\n",
      "feature_76         0.005549                  0.990438\n",
      "feature_15         0.005536                  0.995975\n",
      "resp_n1_predict    0.004025                  1.000000\n",
      "{'utility_score': 2220.2233472739963, 'utility_scores': [98.25101783384773, 900.8701790502922, -0.0, 0.4453615853177138, 1220.6567888045388], 'utility_score_std': 514.848559103147, 'accuracy_scores': [0.5193973154172159, 0.5205967005967006, 0.5094644046384852, 0.5159758568293095, 0.5272784899281588]}\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for fold_indice in range(NB_FOLDS): \n",
    "    df.loc[folds_list_test[fold_indice], FEATURES_LIST_TOTRAIN]\n",
    "\n",
    "    test_predictions_resp_n1 = model_n1.predict(df.loc[folds_list_test[fold_indice], FEATURES_LIST_TOTRAIN])\n",
    "    df.loc[folds_list_test[fold_indice], 'resp_n1_predict'] = pd.DataFrame(test_predictions_resp_n1, index=folds_list_test[fold_indice], columns=['resp_n1_predict'])\n",
    "    test_predictions = model_wrapped.predict(df.loc[folds_list_test[fold_indice]])\n",
    "\n",
    "    scores.append(model_wrapped.score(df.loc[folds_list_test[fold_indice]], test_predictions))\n",
    "    accuracy_scores.append(model_wrapped.accuracy_score(df.loc[folds_list_test[fold_indice]], test_predictions))  \n",
    "\n",
    "    df_featimportance = pd.DataFrame(model_wrapped.model_internal.feature_importances_, index=df[model_wrapped.features].columns, columns=['Importance']).sort_values(by='Importance', ascending=False)\n",
    "    df_featimportance_cumulated = pd.concat([df_featimportance, pd.DataFrame({'% feat importance cumulé' : (df_featimportance['Importance'] / df_featimportance['Importance'].sum()).cumsum()})], axis=1)\n",
    "    print(f'Feature importances for split {fold_indice}:')\n",
    "    print(df_featimportance_cumulated)\n",
    "\n",
    "print({'utility_score': sum(scores), 'utility_scores': scores, 'utility_score_std': np.std(scores), 'accuracy_scores': accuracy_scores})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "avec resp n-1 predict :   \n",
    "{'utility_score': 2220.2233472739963, 'utility_scores': [98.25101783384773, 900.8701790502922, -0.0, 0.4453615853177138, 1220.6567888045388], 'utility_score_std': 514.848559103147, 'accuracy_scores': [0.5193973154172159, 0.5205967005967006, 0.5094644046384852, 0.5159758568293095, 0.5272784899281588]}\n",
    "\n",
    "sans resp n-1 predict :\n",
    "{'utility_score': 2210.0027063381485, 'utility_scores': [93.2897168336882, 954.4061873586404, -0.0, 11.77975627326354, 1150.5270458725563], 'utility_score_std': 503.3136189838432, 'accuracy_scores': [0.5196949724312908, 0.5218041418041418, 0.5108306843070078, 0.5164542180201475, 0.5262360895900831]}  \n",
    "\n",
    "sans resp n-1 predict mais avec cluster en entrée :\n",
    "{'utility_score': 1843.4582433367275, 'utility_scores': [92.97847070444716, 575.5300947961299, -0.0, 4.662222031689218, 1170.2874558044612], 'utility_score_std': 453.829636002962, 'accuracy_scores': [0.5191350937619594, 0.5202878202878203, 0.5089632065691275, 0.5165034610839102, 0.527764473869559]}    \n",
    "\n",
    "Avec autoencoder (couche cachée) as input :  \n",
    "{'utility_score': 1835.9160062792303, 'utility_scores': [56.12364094625926, 620.7855166503907, -0.0, -0.0, 1159.0068486825803], 'utility_score_std': 459.9356215007981, 'accuracy_scores': [0.5207013366217347, 0.5192488592488592, 0.5096497792668777, 0.5098978558163093, 0.5204747147485561]}  \n",
    "\n",
    "Avec prédiction du bin en input :\n",
    "{'utility_score': 1984.7216513367114, 'utility_scores': [12.194987258447853, 768.0975152431711, -0.0, 4.648166944291761, 1199.7809818908006], 'utility_score_std': 498.3562007124659, 'accuracy_scores': [0.5184192995138269, 0.519003159003159, 0.5105148608660428, 0.5153216275536046, 0.5257078461755177]}\n",
    "\n",
    "Avec prédiction du fold en input (sans resp n-1) :\n",
    "{'utility_score': 1843.4582433367275, 'utility_scores': [92.97847070444716, 575.5300947961299, -0.0, 4.662222031689218, 1170.2874558044612], 'utility_score_std': 453.829636002962, 'accuracy_scores': [0.5191350937619594, 0.5202878202878203, 0.5089632065691275, 0.5165034610839102, 0.527764473869559]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['resp_n1_predict'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train xgb main model without resp n-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapped = XGBClassifier_wrapper({\n",
    "   'features': FEATURES_LIST_TOTRAIN, \n",
    "    'random_state': 42,\n",
    "    'max_depth': 10,\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.02,\n",
    "    'subsample': 0.5,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'gamma': None,\n",
    "    'tree_method': 'gpu_hist'        \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used for fitting:\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.6, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.02, max_delta_step=None, max_depth=10,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=42, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=0.5, tree_method='gpu_hist',\n",
      "              validate_parameters=None, verbosity=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:20:16] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/sklearn/base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier_wrapper(params=None)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapped.fit(df.loc[folds_list_train2_unique], (df.loc[folds_list_train2_unique]['resp'] > 0).astype(np.byte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict called\n",
      "Type of X:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X:\n",
      "(141102, 140)\n",
      "Type of y:\n",
      "<class 'numpy.ndarray'>\n",
      "model fitted ?\n",
      "True\n",
      "y is not None\n",
      "Feature importances for split 0:\n",
      "             Importance  % feat importance cumulé\n",
      "feature_43     0.014191                  0.014191\n",
      "feature_45     0.014148                  0.028339\n",
      "feature_42     0.014084                  0.042423\n",
      "feature_41     0.013654                  0.056077\n",
      "feature_44     0.012552                  0.068629\n",
      "feature_39     0.012326                  0.080955\n",
      "feature_27     0.012271                  0.093226\n",
      "feature_63     0.012136                  0.105362\n",
      "feature_61     0.011630                  0.116991\n",
      "feature_62     0.011258                  0.128249\n",
      "feature_6      0.011253                  0.139503\n",
      "feature_5      0.011222                  0.150724\n",
      "feature_60     0.011064                  0.161788\n",
      "feature_40     0.010715                  0.172503\n",
      "feature_3      0.010545                  0.183049\n",
      "feature_107    0.010245                  0.193293\n",
      "feature_83     0.010159                  0.203453\n",
      "feature_4      0.010119                  0.213572\n",
      "feature_38     0.010076                  0.223648\n",
      "feature_37     0.009838                  0.233486\n",
      "feature_119    0.009583                  0.243069\n",
      "feature_77     0.009543                  0.252612\n",
      "feature_64     0.009340                  0.261951\n",
      "feature_120    0.009165                  0.271116\n",
      "feature_55     0.009143                  0.280259\n",
      "feature_124    0.009123                  0.289382\n",
      "feature_114    0.009117                  0.298500\n",
      "feature_95     0.008972                  0.307472\n",
      "feature_121    0.008813                  0.316284\n",
      "feature_102    0.008771                  0.325055\n",
      "feature_113    0.008654                  0.333708\n",
      "feature_90     0.008631                  0.342340\n",
      "feature_57     0.008589                  0.350928\n",
      "feature_68     0.008428                  0.359356\n",
      "feature_66     0.008373                  0.367730\n",
      "feature_89     0.008313                  0.376043\n",
      "feature_125    0.008307                  0.384349\n",
      "feature_126    0.008180                  0.392530\n",
      "feature_20     0.008082                  0.400611\n",
      "feature_101    0.008052                  0.408663\n",
      "feature_71     0.008016                  0.416679\n",
      "feature_28     0.007773                  0.424452\n",
      "feature_108    0.007726                  0.432178\n",
      "feature_67     0.007595                  0.439774\n",
      "feature_116    0.007587                  0.447361\n",
      "feature_18     0.007563                  0.454923\n",
      "feature_84     0.007535                  0.462458\n",
      "feature_65     0.007533                  0.469991\n",
      "feature_8      0.007486                  0.477477\n",
      "feature_26     0.007463                  0.484940\n",
      "feature_127    0.007321                  0.492261\n",
      "feature_70     0.007315                  0.499576\n",
      "feature_96     0.007304                  0.506880\n",
      "feature_58     0.007301                  0.514181\n",
      "feature_92     0.007282                  0.521463\n",
      "feature_104    0.007273                  0.528735\n",
      "feature_69     0.007248                  0.535983\n",
      "feature_78     0.007149                  0.543131\n",
      "feature_31     0.007144                  0.550276\n",
      "feature_7      0.007029                  0.557305\n",
      "feature_53     0.006951                  0.564257\n",
      "feature_59     0.006923                  0.571180\n",
      "feature_110    0.006918                  0.578098\n",
      "feature_17     0.006885                  0.584983\n",
      "feature_50     0.006862                  0.591845\n",
      "feature_72     0.006811                  0.598657\n",
      "feature_33     0.006747                  0.605404\n",
      "feature_35     0.006740                  0.612144\n",
      "feature_128    0.006723                  0.618867\n",
      "feature_98     0.006723                  0.625590\n",
      "feature_36     0.006685                  0.632275\n",
      "feature_24     0.006660                  0.638935\n",
      "feature_23     0.006629                  0.645564\n",
      "feature_86     0.006597                  0.652161\n",
      "feature_22     0.006594                  0.658755\n",
      "feature_34     0.006574                  0.665329\n",
      "feature_47     0.006572                  0.671901\n",
      "feature_32     0.006565                  0.678466\n",
      "feature_48     0.006520                  0.684986\n",
      "feature_12     0.006509                  0.691495\n",
      "feature_49     0.006496                  0.697992\n",
      "feature_129    0.006495                  0.704487\n",
      "feature_25     0.006494                  0.710980\n",
      "feature_30     0.006470                  0.717451\n",
      "feature_51     0.006461                  0.723912\n",
      "feature_54     0.006451                  0.730363\n",
      "feature_122    0.006438                  0.736801\n",
      "feature_10     0.006414                  0.743215\n",
      "feature_56     0.006359                  0.749574\n",
      "feature_111    0.006335                  0.755909\n",
      "feature_80     0.006278                  0.762187\n",
      "feature_19     0.006264                  0.768451\n",
      "feature_21     0.006263                  0.774714\n",
      "feature_123    0.006262                  0.780976\n",
      "feature_117    0.006256                  0.787232\n",
      "feature_105    0.006249                  0.793481\n",
      "feature_46     0.006237                  0.799718\n",
      "feature_99     0.006183                  0.805900\n",
      "feature_1      0.006166                  0.812067\n",
      "feature_109    0.006165                  0.818232\n",
      "feature_0      0.006151                  0.824383\n",
      "feature_9      0.006145                  0.830528\n",
      "feature_11     0.006139                  0.836667\n",
      "feature_2      0.006134                  0.842801\n",
      "feature_93     0.006080                  0.848881\n",
      "feature_87     0.006014                  0.854896\n",
      "feature_85     0.005998                  0.860894\n",
      "feature_14     0.005967                  0.866861\n",
      "feature_29     0.005967                  0.872828\n",
      "feature_81     0.005950                  0.878778\n",
      "feature_13     0.005939                  0.884717\n",
      "feature_94     0.005936                  0.890653\n",
      "feature_16     0.005933                  0.896586\n",
      "feature_115    0.005895                  0.902481\n",
      "feature_106    0.005895                  0.908376\n",
      "feature_74     0.005874                  0.914249\n",
      "feature_118    0.005866                  0.920116\n",
      "feature_91     0.005852                  0.925968\n",
      "feature_112    0.005852                  0.931819\n",
      "feature_88     0.005820                  0.937639\n",
      "feature_75     0.005819                  0.943458\n",
      "feature_103    0.005747                  0.949205\n",
      "feature_79     0.005731                  0.954936\n",
      "feature_100    0.005726                  0.960662\n",
      "feature_97     0.005657                  0.966319\n",
      "feature_76     0.005653                  0.971972\n",
      "feature_52     0.005634                  0.977606\n",
      "cluster        0.005633                  0.983239\n",
      "feature_73     0.005604                  0.988844\n",
      "feature_82     0.005594                  0.994437\n",
      "feature_15     0.005563                  1.000000\n",
      "predict called\n",
      "Type of X:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X:\n",
      "(142450, 140)\n",
      "Type of y:\n",
      "<class 'numpy.ndarray'>\n",
      "model fitted ?\n",
      "True\n",
      "y is not None\n",
      "Feature importances for split 1:\n",
      "             Importance  % feat importance cumulé\n",
      "feature_43     0.014191                  0.014191\n",
      "feature_45     0.014148                  0.028339\n",
      "feature_42     0.014084                  0.042423\n",
      "feature_41     0.013654                  0.056077\n",
      "feature_44     0.012552                  0.068629\n",
      "feature_39     0.012326                  0.080955\n",
      "feature_27     0.012271                  0.093226\n",
      "feature_63     0.012136                  0.105362\n",
      "feature_61     0.011630                  0.116991\n",
      "feature_62     0.011258                  0.128249\n",
      "feature_6      0.011253                  0.139503\n",
      "feature_5      0.011222                  0.150724\n",
      "feature_60     0.011064                  0.161788\n",
      "feature_40     0.010715                  0.172503\n",
      "feature_3      0.010545                  0.183049\n",
      "feature_107    0.010245                  0.193293\n",
      "feature_83     0.010159                  0.203453\n",
      "feature_4      0.010119                  0.213572\n",
      "feature_38     0.010076                  0.223648\n",
      "feature_37     0.009838                  0.233486\n",
      "feature_119    0.009583                  0.243069\n",
      "feature_77     0.009543                  0.252612\n",
      "feature_64     0.009340                  0.261951\n",
      "feature_120    0.009165                  0.271116\n",
      "feature_55     0.009143                  0.280259\n",
      "feature_124    0.009123                  0.289382\n",
      "feature_114    0.009117                  0.298500\n",
      "feature_95     0.008972                  0.307472\n",
      "feature_121    0.008813                  0.316284\n",
      "feature_102    0.008771                  0.325055\n",
      "feature_113    0.008654                  0.333708\n",
      "feature_90     0.008631                  0.342340\n",
      "feature_57     0.008589                  0.350928\n",
      "feature_68     0.008428                  0.359356\n",
      "feature_66     0.008373                  0.367730\n",
      "feature_89     0.008313                  0.376043\n",
      "feature_125    0.008307                  0.384349\n",
      "feature_126    0.008180                  0.392530\n",
      "feature_20     0.008082                  0.400611\n",
      "feature_101    0.008052                  0.408663\n",
      "feature_71     0.008016                  0.416679\n",
      "feature_28     0.007773                  0.424452\n",
      "feature_108    0.007726                  0.432178\n",
      "feature_67     0.007595                  0.439774\n",
      "feature_116    0.007587                  0.447361\n",
      "feature_18     0.007563                  0.454923\n",
      "feature_84     0.007535                  0.462458\n",
      "feature_65     0.007533                  0.469991\n",
      "feature_8      0.007486                  0.477477\n",
      "feature_26     0.007463                  0.484940\n",
      "feature_127    0.007321                  0.492261\n",
      "feature_70     0.007315                  0.499576\n",
      "feature_96     0.007304                  0.506880\n",
      "feature_58     0.007301                  0.514181\n",
      "feature_92     0.007282                  0.521463\n",
      "feature_104    0.007273                  0.528735\n",
      "feature_69     0.007248                  0.535983\n",
      "feature_78     0.007149                  0.543131\n",
      "feature_31     0.007144                  0.550276\n",
      "feature_7      0.007029                  0.557305\n",
      "feature_53     0.006951                  0.564257\n",
      "feature_59     0.006923                  0.571180\n",
      "feature_110    0.006918                  0.578098\n",
      "feature_17     0.006885                  0.584983\n",
      "feature_50     0.006862                  0.591845\n",
      "feature_72     0.006811                  0.598657\n",
      "feature_33     0.006747                  0.605404\n",
      "feature_35     0.006740                  0.612144\n",
      "feature_128    0.006723                  0.618867\n",
      "feature_98     0.006723                  0.625590\n",
      "feature_36     0.006685                  0.632275\n",
      "feature_24     0.006660                  0.638935\n",
      "feature_23     0.006629                  0.645564\n",
      "feature_86     0.006597                  0.652161\n",
      "feature_22     0.006594                  0.658755\n",
      "feature_34     0.006574                  0.665329\n",
      "feature_47     0.006572                  0.671901\n",
      "feature_32     0.006565                  0.678466\n",
      "feature_48     0.006520                  0.684986\n",
      "feature_12     0.006509                  0.691495\n",
      "feature_49     0.006496                  0.697992\n",
      "feature_129    0.006495                  0.704487\n",
      "feature_25     0.006494                  0.710980\n",
      "feature_30     0.006470                  0.717451\n",
      "feature_51     0.006461                  0.723912\n",
      "feature_54     0.006451                  0.730363\n",
      "feature_122    0.006438                  0.736801\n",
      "feature_10     0.006414                  0.743215\n",
      "feature_56     0.006359                  0.749574\n",
      "feature_111    0.006335                  0.755909\n",
      "feature_80     0.006278                  0.762187\n",
      "feature_19     0.006264                  0.768451\n",
      "feature_21     0.006263                  0.774714\n",
      "feature_123    0.006262                  0.780976\n",
      "feature_117    0.006256                  0.787232\n",
      "feature_105    0.006249                  0.793481\n",
      "feature_46     0.006237                  0.799718\n",
      "feature_99     0.006183                  0.805900\n",
      "feature_1      0.006166                  0.812067\n",
      "feature_109    0.006165                  0.818232\n",
      "feature_0      0.006151                  0.824383\n",
      "feature_9      0.006145                  0.830528\n",
      "feature_11     0.006139                  0.836667\n",
      "feature_2      0.006134                  0.842801\n",
      "feature_93     0.006080                  0.848881\n",
      "feature_87     0.006014                  0.854896\n",
      "feature_85     0.005998                  0.860894\n",
      "feature_14     0.005967                  0.866861\n",
      "feature_29     0.005967                  0.872828\n",
      "feature_81     0.005950                  0.878778\n",
      "feature_13     0.005939                  0.884717\n",
      "feature_94     0.005936                  0.890653\n",
      "feature_16     0.005933                  0.896586\n",
      "feature_115    0.005895                  0.902481\n",
      "feature_106    0.005895                  0.908376\n",
      "feature_74     0.005874                  0.914249\n",
      "feature_118    0.005866                  0.920116\n",
      "feature_91     0.005852                  0.925968\n",
      "feature_112    0.005852                  0.931819\n",
      "feature_88     0.005820                  0.937639\n",
      "feature_75     0.005819                  0.943458\n",
      "feature_103    0.005747                  0.949205\n",
      "feature_79     0.005731                  0.954936\n",
      "feature_100    0.005726                  0.960662\n",
      "feature_97     0.005657                  0.966319\n",
      "feature_76     0.005653                  0.971972\n",
      "feature_52     0.005634                  0.977606\n",
      "cluster        0.005633                  0.983239\n",
      "feature_73     0.005604                  0.988844\n",
      "feature_82     0.005594                  0.994437\n",
      "feature_15     0.005563                  1.000000\n",
      "predict called\n",
      "Type of X:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X:\n",
      "(145651, 140)\n",
      "Type of y:\n",
      "<class 'numpy.ndarray'>\n",
      "model fitted ?\n",
      "True\n",
      "y is not None\n",
      "Feature importances for split 2:\n",
      "             Importance  % feat importance cumulé\n",
      "feature_43     0.014191                  0.014191\n",
      "feature_45     0.014148                  0.028339\n",
      "feature_42     0.014084                  0.042423\n",
      "feature_41     0.013654                  0.056077\n",
      "feature_44     0.012552                  0.068629\n",
      "feature_39     0.012326                  0.080955\n",
      "feature_27     0.012271                  0.093226\n",
      "feature_63     0.012136                  0.105362\n",
      "feature_61     0.011630                  0.116991\n",
      "feature_62     0.011258                  0.128249\n",
      "feature_6      0.011253                  0.139503\n",
      "feature_5      0.011222                  0.150724\n",
      "feature_60     0.011064                  0.161788\n",
      "feature_40     0.010715                  0.172503\n",
      "feature_3      0.010545                  0.183049\n",
      "feature_107    0.010245                  0.193293\n",
      "feature_83     0.010159                  0.203453\n",
      "feature_4      0.010119                  0.213572\n",
      "feature_38     0.010076                  0.223648\n",
      "feature_37     0.009838                  0.233486\n",
      "feature_119    0.009583                  0.243069\n",
      "feature_77     0.009543                  0.252612\n",
      "feature_64     0.009340                  0.261951\n",
      "feature_120    0.009165                  0.271116\n",
      "feature_55     0.009143                  0.280259\n",
      "feature_124    0.009123                  0.289382\n",
      "feature_114    0.009117                  0.298500\n",
      "feature_95     0.008972                  0.307472\n",
      "feature_121    0.008813                  0.316284\n",
      "feature_102    0.008771                  0.325055\n",
      "feature_113    0.008654                  0.333708\n",
      "feature_90     0.008631                  0.342340\n",
      "feature_57     0.008589                  0.350928\n",
      "feature_68     0.008428                  0.359356\n",
      "feature_66     0.008373                  0.367730\n",
      "feature_89     0.008313                  0.376043\n",
      "feature_125    0.008307                  0.384349\n",
      "feature_126    0.008180                  0.392530\n",
      "feature_20     0.008082                  0.400611\n",
      "feature_101    0.008052                  0.408663\n",
      "feature_71     0.008016                  0.416679\n",
      "feature_28     0.007773                  0.424452\n",
      "feature_108    0.007726                  0.432178\n",
      "feature_67     0.007595                  0.439774\n",
      "feature_116    0.007587                  0.447361\n",
      "feature_18     0.007563                  0.454923\n",
      "feature_84     0.007535                  0.462458\n",
      "feature_65     0.007533                  0.469991\n",
      "feature_8      0.007486                  0.477477\n",
      "feature_26     0.007463                  0.484940\n",
      "feature_127    0.007321                  0.492261\n",
      "feature_70     0.007315                  0.499576\n",
      "feature_96     0.007304                  0.506880\n",
      "feature_58     0.007301                  0.514181\n",
      "feature_92     0.007282                  0.521463\n",
      "feature_104    0.007273                  0.528735\n",
      "feature_69     0.007248                  0.535983\n",
      "feature_78     0.007149                  0.543131\n",
      "feature_31     0.007144                  0.550276\n",
      "feature_7      0.007029                  0.557305\n",
      "feature_53     0.006951                  0.564257\n",
      "feature_59     0.006923                  0.571180\n",
      "feature_110    0.006918                  0.578098\n",
      "feature_17     0.006885                  0.584983\n",
      "feature_50     0.006862                  0.591845\n",
      "feature_72     0.006811                  0.598657\n",
      "feature_33     0.006747                  0.605404\n",
      "feature_35     0.006740                  0.612144\n",
      "feature_128    0.006723                  0.618867\n",
      "feature_98     0.006723                  0.625590\n",
      "feature_36     0.006685                  0.632275\n",
      "feature_24     0.006660                  0.638935\n",
      "feature_23     0.006629                  0.645564\n",
      "feature_86     0.006597                  0.652161\n",
      "feature_22     0.006594                  0.658755\n",
      "feature_34     0.006574                  0.665329\n",
      "feature_47     0.006572                  0.671901\n",
      "feature_32     0.006565                  0.678466\n",
      "feature_48     0.006520                  0.684986\n",
      "feature_12     0.006509                  0.691495\n",
      "feature_49     0.006496                  0.697992\n",
      "feature_129    0.006495                  0.704487\n",
      "feature_25     0.006494                  0.710980\n",
      "feature_30     0.006470                  0.717451\n",
      "feature_51     0.006461                  0.723912\n",
      "feature_54     0.006451                  0.730363\n",
      "feature_122    0.006438                  0.736801\n",
      "feature_10     0.006414                  0.743215\n",
      "feature_56     0.006359                  0.749574\n",
      "feature_111    0.006335                  0.755909\n",
      "feature_80     0.006278                  0.762187\n",
      "feature_19     0.006264                  0.768451\n",
      "feature_21     0.006263                  0.774714\n",
      "feature_123    0.006262                  0.780976\n",
      "feature_117    0.006256                  0.787232\n",
      "feature_105    0.006249                  0.793481\n",
      "feature_46     0.006237                  0.799718\n",
      "feature_99     0.006183                  0.805900\n",
      "feature_1      0.006166                  0.812067\n",
      "feature_109    0.006165                  0.818232\n",
      "feature_0      0.006151                  0.824383\n",
      "feature_9      0.006145                  0.830528\n",
      "feature_11     0.006139                  0.836667\n",
      "feature_2      0.006134                  0.842801\n",
      "feature_93     0.006080                  0.848881\n",
      "feature_87     0.006014                  0.854896\n",
      "feature_85     0.005998                  0.860894\n",
      "feature_14     0.005967                  0.866861\n",
      "feature_29     0.005967                  0.872828\n",
      "feature_81     0.005950                  0.878778\n",
      "feature_13     0.005939                  0.884717\n",
      "feature_94     0.005936                  0.890653\n",
      "feature_16     0.005933                  0.896586\n",
      "feature_115    0.005895                  0.902481\n",
      "feature_106    0.005895                  0.908376\n",
      "feature_74     0.005874                  0.914249\n",
      "feature_118    0.005866                  0.920116\n",
      "feature_91     0.005852                  0.925968\n",
      "feature_112    0.005852                  0.931819\n",
      "feature_88     0.005820                  0.937639\n",
      "feature_75     0.005819                  0.943458\n",
      "feature_103    0.005747                  0.949205\n",
      "feature_79     0.005731                  0.954936\n",
      "feature_100    0.005726                  0.960662\n",
      "feature_97     0.005657                  0.966319\n",
      "feature_76     0.005653                  0.971972\n",
      "feature_52     0.005634                  0.977606\n",
      "cluster        0.005633                  0.983239\n",
      "feature_73     0.005604                  0.988844\n",
      "feature_82     0.005594                  0.994437\n",
      "feature_15     0.005563                  1.000000\n",
      "predict called\n",
      "Type of X:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X:\n",
      "(142152, 140)\n",
      "Type of y:\n",
      "<class 'numpy.ndarray'>\n",
      "model fitted ?\n",
      "True\n",
      "y is not None\n",
      "Feature importances for split 3:\n",
      "             Importance  % feat importance cumulé\n",
      "feature_43     0.014191                  0.014191\n",
      "feature_45     0.014148                  0.028339\n",
      "feature_42     0.014084                  0.042423\n",
      "feature_41     0.013654                  0.056077\n",
      "feature_44     0.012552                  0.068629\n",
      "feature_39     0.012326                  0.080955\n",
      "feature_27     0.012271                  0.093226\n",
      "feature_63     0.012136                  0.105362\n",
      "feature_61     0.011630                  0.116991\n",
      "feature_62     0.011258                  0.128249\n",
      "feature_6      0.011253                  0.139503\n",
      "feature_5      0.011222                  0.150724\n",
      "feature_60     0.011064                  0.161788\n",
      "feature_40     0.010715                  0.172503\n",
      "feature_3      0.010545                  0.183049\n",
      "feature_107    0.010245                  0.193293\n",
      "feature_83     0.010159                  0.203453\n",
      "feature_4      0.010119                  0.213572\n",
      "feature_38     0.010076                  0.223648\n",
      "feature_37     0.009838                  0.233486\n",
      "feature_119    0.009583                  0.243069\n",
      "feature_77     0.009543                  0.252612\n",
      "feature_64     0.009340                  0.261951\n",
      "feature_120    0.009165                  0.271116\n",
      "feature_55     0.009143                  0.280259\n",
      "feature_124    0.009123                  0.289382\n",
      "feature_114    0.009117                  0.298500\n",
      "feature_95     0.008972                  0.307472\n",
      "feature_121    0.008813                  0.316284\n",
      "feature_102    0.008771                  0.325055\n",
      "feature_113    0.008654                  0.333708\n",
      "feature_90     0.008631                  0.342340\n",
      "feature_57     0.008589                  0.350928\n",
      "feature_68     0.008428                  0.359356\n",
      "feature_66     0.008373                  0.367730\n",
      "feature_89     0.008313                  0.376043\n",
      "feature_125    0.008307                  0.384349\n",
      "feature_126    0.008180                  0.392530\n",
      "feature_20     0.008082                  0.400611\n",
      "feature_101    0.008052                  0.408663\n",
      "feature_71     0.008016                  0.416679\n",
      "feature_28     0.007773                  0.424452\n",
      "feature_108    0.007726                  0.432178\n",
      "feature_67     0.007595                  0.439774\n",
      "feature_116    0.007587                  0.447361\n",
      "feature_18     0.007563                  0.454923\n",
      "feature_84     0.007535                  0.462458\n",
      "feature_65     0.007533                  0.469991\n",
      "feature_8      0.007486                  0.477477\n",
      "feature_26     0.007463                  0.484940\n",
      "feature_127    0.007321                  0.492261\n",
      "feature_70     0.007315                  0.499576\n",
      "feature_96     0.007304                  0.506880\n",
      "feature_58     0.007301                  0.514181\n",
      "feature_92     0.007282                  0.521463\n",
      "feature_104    0.007273                  0.528735\n",
      "feature_69     0.007248                  0.535983\n",
      "feature_78     0.007149                  0.543131\n",
      "feature_31     0.007144                  0.550276\n",
      "feature_7      0.007029                  0.557305\n",
      "feature_53     0.006951                  0.564257\n",
      "feature_59     0.006923                  0.571180\n",
      "feature_110    0.006918                  0.578098\n",
      "feature_17     0.006885                  0.584983\n",
      "feature_50     0.006862                  0.591845\n",
      "feature_72     0.006811                  0.598657\n",
      "feature_33     0.006747                  0.605404\n",
      "feature_35     0.006740                  0.612144\n",
      "feature_128    0.006723                  0.618867\n",
      "feature_98     0.006723                  0.625590\n",
      "feature_36     0.006685                  0.632275\n",
      "feature_24     0.006660                  0.638935\n",
      "feature_23     0.006629                  0.645564\n",
      "feature_86     0.006597                  0.652161\n",
      "feature_22     0.006594                  0.658755\n",
      "feature_34     0.006574                  0.665329\n",
      "feature_47     0.006572                  0.671901\n",
      "feature_32     0.006565                  0.678466\n",
      "feature_48     0.006520                  0.684986\n",
      "feature_12     0.006509                  0.691495\n",
      "feature_49     0.006496                  0.697992\n",
      "feature_129    0.006495                  0.704487\n",
      "feature_25     0.006494                  0.710980\n",
      "feature_30     0.006470                  0.717451\n",
      "feature_51     0.006461                  0.723912\n",
      "feature_54     0.006451                  0.730363\n",
      "feature_122    0.006438                  0.736801\n",
      "feature_10     0.006414                  0.743215\n",
      "feature_56     0.006359                  0.749574\n",
      "feature_111    0.006335                  0.755909\n",
      "feature_80     0.006278                  0.762187\n",
      "feature_19     0.006264                  0.768451\n",
      "feature_21     0.006263                  0.774714\n",
      "feature_123    0.006262                  0.780976\n",
      "feature_117    0.006256                  0.787232\n",
      "feature_105    0.006249                  0.793481\n",
      "feature_46     0.006237                  0.799718\n",
      "feature_99     0.006183                  0.805900\n",
      "feature_1      0.006166                  0.812067\n",
      "feature_109    0.006165                  0.818232\n",
      "feature_0      0.006151                  0.824383\n",
      "feature_9      0.006145                  0.830528\n",
      "feature_11     0.006139                  0.836667\n",
      "feature_2      0.006134                  0.842801\n",
      "feature_93     0.006080                  0.848881\n",
      "feature_87     0.006014                  0.854896\n",
      "feature_85     0.005998                  0.860894\n",
      "feature_14     0.005967                  0.866861\n",
      "feature_29     0.005967                  0.872828\n",
      "feature_81     0.005950                  0.878778\n",
      "feature_13     0.005939                  0.884717\n",
      "feature_94     0.005936                  0.890653\n",
      "feature_16     0.005933                  0.896586\n",
      "feature_115    0.005895                  0.902481\n",
      "feature_106    0.005895                  0.908376\n",
      "feature_74     0.005874                  0.914249\n",
      "feature_118    0.005866                  0.920116\n",
      "feature_91     0.005852                  0.925968\n",
      "feature_112    0.005852                  0.931819\n",
      "feature_88     0.005820                  0.937639\n",
      "feature_75     0.005819                  0.943458\n",
      "feature_103    0.005747                  0.949205\n",
      "feature_79     0.005731                  0.954936\n",
      "feature_100    0.005726                  0.960662\n",
      "feature_97     0.005657                  0.966319\n",
      "feature_76     0.005653                  0.971972\n",
      "feature_52     0.005634                  0.977606\n",
      "cluster        0.005633                  0.983239\n",
      "feature_73     0.005604                  0.988844\n",
      "feature_82     0.005594                  0.994437\n",
      "feature_15     0.005563                  1.000000\n",
      "predict called\n",
      "Type of X:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X:\n",
      "(141980, 140)\n",
      "Type of y:\n",
      "<class 'numpy.ndarray'>\n",
      "model fitted ?\n",
      "True\n",
      "y is not None\n",
      "Feature importances for split 4:\n",
      "             Importance  % feat importance cumulé\n",
      "feature_43     0.014191                  0.014191\n",
      "feature_45     0.014148                  0.028339\n",
      "feature_42     0.014084                  0.042423\n",
      "feature_41     0.013654                  0.056077\n",
      "feature_44     0.012552                  0.068629\n",
      "feature_39     0.012326                  0.080955\n",
      "feature_27     0.012271                  0.093226\n",
      "feature_63     0.012136                  0.105362\n",
      "feature_61     0.011630                  0.116991\n",
      "feature_62     0.011258                  0.128249\n",
      "feature_6      0.011253                  0.139503\n",
      "feature_5      0.011222                  0.150724\n",
      "feature_60     0.011064                  0.161788\n",
      "feature_40     0.010715                  0.172503\n",
      "feature_3      0.010545                  0.183049\n",
      "feature_107    0.010245                  0.193293\n",
      "feature_83     0.010159                  0.203453\n",
      "feature_4      0.010119                  0.213572\n",
      "feature_38     0.010076                  0.223648\n",
      "feature_37     0.009838                  0.233486\n",
      "feature_119    0.009583                  0.243069\n",
      "feature_77     0.009543                  0.252612\n",
      "feature_64     0.009340                  0.261951\n",
      "feature_120    0.009165                  0.271116\n",
      "feature_55     0.009143                  0.280259\n",
      "feature_124    0.009123                  0.289382\n",
      "feature_114    0.009117                  0.298500\n",
      "feature_95     0.008972                  0.307472\n",
      "feature_121    0.008813                  0.316284\n",
      "feature_102    0.008771                  0.325055\n",
      "feature_113    0.008654                  0.333708\n",
      "feature_90     0.008631                  0.342340\n",
      "feature_57     0.008589                  0.350928\n",
      "feature_68     0.008428                  0.359356\n",
      "feature_66     0.008373                  0.367730\n",
      "feature_89     0.008313                  0.376043\n",
      "feature_125    0.008307                  0.384349\n",
      "feature_126    0.008180                  0.392530\n",
      "feature_20     0.008082                  0.400611\n",
      "feature_101    0.008052                  0.408663\n",
      "feature_71     0.008016                  0.416679\n",
      "feature_28     0.007773                  0.424452\n",
      "feature_108    0.007726                  0.432178\n",
      "feature_67     0.007595                  0.439774\n",
      "feature_116    0.007587                  0.447361\n",
      "feature_18     0.007563                  0.454923\n",
      "feature_84     0.007535                  0.462458\n",
      "feature_65     0.007533                  0.469991\n",
      "feature_8      0.007486                  0.477477\n",
      "feature_26     0.007463                  0.484940\n",
      "feature_127    0.007321                  0.492261\n",
      "feature_70     0.007315                  0.499576\n",
      "feature_96     0.007304                  0.506880\n",
      "feature_58     0.007301                  0.514181\n",
      "feature_92     0.007282                  0.521463\n",
      "feature_104    0.007273                  0.528735\n",
      "feature_69     0.007248                  0.535983\n",
      "feature_78     0.007149                  0.543131\n",
      "feature_31     0.007144                  0.550276\n",
      "feature_7      0.007029                  0.557305\n",
      "feature_53     0.006951                  0.564257\n",
      "feature_59     0.006923                  0.571180\n",
      "feature_110    0.006918                  0.578098\n",
      "feature_17     0.006885                  0.584983\n",
      "feature_50     0.006862                  0.591845\n",
      "feature_72     0.006811                  0.598657\n",
      "feature_33     0.006747                  0.605404\n",
      "feature_35     0.006740                  0.612144\n",
      "feature_128    0.006723                  0.618867\n",
      "feature_98     0.006723                  0.625590\n",
      "feature_36     0.006685                  0.632275\n",
      "feature_24     0.006660                  0.638935\n",
      "feature_23     0.006629                  0.645564\n",
      "feature_86     0.006597                  0.652161\n",
      "feature_22     0.006594                  0.658755\n",
      "feature_34     0.006574                  0.665329\n",
      "feature_47     0.006572                  0.671901\n",
      "feature_32     0.006565                  0.678466\n",
      "feature_48     0.006520                  0.684986\n",
      "feature_12     0.006509                  0.691495\n",
      "feature_49     0.006496                  0.697992\n",
      "feature_129    0.006495                  0.704487\n",
      "feature_25     0.006494                  0.710980\n",
      "feature_30     0.006470                  0.717451\n",
      "feature_51     0.006461                  0.723912\n",
      "feature_54     0.006451                  0.730363\n",
      "feature_122    0.006438                  0.736801\n",
      "feature_10     0.006414                  0.743215\n",
      "feature_56     0.006359                  0.749574\n",
      "feature_111    0.006335                  0.755909\n",
      "feature_80     0.006278                  0.762187\n",
      "feature_19     0.006264                  0.768451\n",
      "feature_21     0.006263                  0.774714\n",
      "feature_123    0.006262                  0.780976\n",
      "feature_117    0.006256                  0.787232\n",
      "feature_105    0.006249                  0.793481\n",
      "feature_46     0.006237                  0.799718\n",
      "feature_99     0.006183                  0.805900\n",
      "feature_1      0.006166                  0.812067\n",
      "feature_109    0.006165                  0.818232\n",
      "feature_0      0.006151                  0.824383\n",
      "feature_9      0.006145                  0.830528\n",
      "feature_11     0.006139                  0.836667\n",
      "feature_2      0.006134                  0.842801\n",
      "feature_93     0.006080                  0.848881\n",
      "feature_87     0.006014                  0.854896\n",
      "feature_85     0.005998                  0.860894\n",
      "feature_14     0.005967                  0.866861\n",
      "feature_29     0.005967                  0.872828\n",
      "feature_81     0.005950                  0.878778\n",
      "feature_13     0.005939                  0.884717\n",
      "feature_94     0.005936                  0.890653\n",
      "feature_16     0.005933                  0.896586\n",
      "feature_115    0.005895                  0.902481\n",
      "feature_106    0.005895                  0.908376\n",
      "feature_74     0.005874                  0.914249\n",
      "feature_118    0.005866                  0.920116\n",
      "feature_91     0.005852                  0.925968\n",
      "feature_112    0.005852                  0.931819\n",
      "feature_88     0.005820                  0.937639\n",
      "feature_75     0.005819                  0.943458\n",
      "feature_103    0.005747                  0.949205\n",
      "feature_79     0.005731                  0.954936\n",
      "feature_100    0.005726                  0.960662\n",
      "feature_97     0.005657                  0.966319\n",
      "feature_76     0.005653                  0.971972\n",
      "feature_52     0.005634                  0.977606\n",
      "cluster        0.005633                  0.983239\n",
      "feature_73     0.005604                  0.988844\n",
      "feature_82     0.005594                  0.994437\n",
      "feature_15     0.005563                  1.000000\n",
      "{'utility_score': 1843.4582433367275, 'utility_scores': [92.97847070444716, 575.5300947961299, -0.0, 4.662222031689218, 1170.2874558044612], 'utility_score_std': 453.829636002962, 'accuracy_scores': [0.5191350937619594, 0.5202878202878203, 0.5089632065691275, 0.5165034610839102, 0.527764473869559]}\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for fold_indice in range(NB_FOLDS): \n",
    "    test_predictions = model_wrapped.predict(df.loc[folds_list_test[fold_indice]])\n",
    "\n",
    "    scores.append(model_wrapped.score(df.loc[folds_list_test[fold_indice]], test_predictions))\n",
    "    accuracy_scores.append(model_wrapped.accuracy_score(df.loc[folds_list_test[fold_indice]], test_predictions))  \n",
    "\n",
    "    df_featimportance = pd.DataFrame(model_wrapped.model_internal.feature_importances_, index=df[model_wrapped.features].columns, columns=['Importance']).sort_values(by='Importance', ascending=False)\n",
    "    df_featimportance_cumulated = pd.concat([df_featimportance, pd.DataFrame({'% feat importance cumulé' : (df_featimportance['Importance'] / df_featimportance['Importance'].sum()).cumsum()})], axis=1)\n",
    "    print(f'Feature importances for split {fold_indice}:')\n",
    "    print(df_featimportance_cumulated)\n",
    "\n",
    "print({'utility_score': sum(scores), 'utility_scores': scores, 'utility_score_std': np.std(scores), 'accuracy_scores': accuracy_scores})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model AE loaded\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)  \n",
    "\n",
    "ENCODER_SIZE = 32\n",
    "    \n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder,self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            #nn.Dropout(0.5),  # Noise layer\n",
    "            nn.Linear(len(FEATURES_LIST_TOTRAIN), 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, ENCODER_SIZE),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(             \n",
    "            nn.Linear(ENCODER_SIZE, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, len(FEATURES_LIST_TOTRAIN)),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        if self.training:\n",
    "            x = x + 0.01 * torch.randn(x.shape[0], x.shape[1]).double(). to('cuda')  # 0.01 = noise variance\n",
    "            \n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x        \n",
    "\n",
    "model = AutoEncoder().double().to('cuda')\n",
    "    \n",
    "#print('Number of model parameters :')\n",
    "#numel_list = [p.numel() for p in model.parameters()]\n",
    "#sum(numel_list), numel_list\n",
    "    \n",
    "if (RETRAIN_MODEl_AE == False):\n",
    "    model_AE = model\n",
    "    model_AE.load_state_dict(torch.load(MODEL_FILE_AE,map_location=torch.device('cuda')))\n",
    "    print('Model AE loaded')\n",
    "\n",
    "else:    \n",
    "    print('Training started')\n",
    "    patience=5\n",
    "\n",
    "    utility_scores = [None] * 5\n",
    "    accuracy_scores = [None] * 5\n",
    "\n",
    "    today = datetime.datetime.now()\n",
    "    now_str = today.strftime(\"%b%d_%H-%M-%S\")\n",
    "    tensorboard_dir_AE = 'runs_AE/' + now_str\n",
    "    writer = SummaryWriter(log_dir=tensorboard_dir_AE)\n",
    "\n",
    "    ts_train = torch.tensor(df.loc[folds_list_train1_unique, FEATURES_LIST_TOTRAIN].to_numpy(), device='cuda')\n",
    "    #ts_train_y = torch.tensor((df.loc[folds_list_train_unique, 'resp'] > 0).astype(np.byte).to_numpy(), device='cuda')\n",
    "\n",
    "    # Normalize data\n",
    "    ts_train_mean = torch.mean(ts_train, axis=0)\n",
    "    ts_train_std = torch.std(ts_train, axis=0)\n",
    "    #ts_train_mean = torch.tensor(f_mean)\n",
    "    # If you want to use Standard scale : calculate mean from f_mean and std scale from whole dataset\n",
    "    #ts_train = pyStandardScale(ts_train, ts_train_mean, ts_train_std)\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(ts_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE_AE, shuffle=True)\n",
    "\n",
    "    ts_test = [None] * 5\n",
    "    #ts_test_y = [None] * 5    \n",
    "    test_dataset = [None] * 5\n",
    "    test_loader = [None] * 5\n",
    "\n",
    "    for fold_indice in range(5):\n",
    "        ts_test[fold_indice] = torch.tensor(df.loc[folds_list_test[fold_indice], FEATURES_LIST_TOTRAIN].to_numpy(), device='cuda')\n",
    "        #ts_test_y[fold_indice] = torch.tensor((df.loc[folds_list_test[fold_indice], 'resp'] > 0).astype(np.byte).to_numpy(), device='cuda')\n",
    "\n",
    "        # Normalize\n",
    "        #ts_test[fold_indice] = pyStandardScale(ts_test[fold_indice], ts_train_mean, ts_train_std)\n",
    "\n",
    "        test_dataset[fold_indice] = torch.utils.data.TensorDataset(ts_test[fold_indice])\n",
    "        test_loader[fold_indice] = torch.utils.data.DataLoader(test_dataset[fold_indice], batch_size=BATCH_SIZE_AE)\n",
    "\n",
    "    loss_fn = nn.MSELoss().to('cuda')\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE_AE, weight_decay=WEIGHT_DECAY_AE) \n",
    "\n",
    "    scheduler = None\n",
    "    #scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3,\n",
    "    #                                                         max_lr=1e-4, epochs=NUM_EPOCHS, steps_per_epoch=len(train_loader))\n",
    "\n",
    "    #model.eval()\n",
    "    #start_accuracy = accuracy_score(ts_test_y.cpu().numpy(), (model(ts_test).squeeze() > 0.5).cpu().numpy())\n",
    "    #start_utility_score = utility_function(df.loc[test_index], (model(ts_test).squeeze() > 0.5).cpu().numpy())\n",
    "    #print('Start Validation Accuracy: {:.4f}'.format(start_accuracy))\n",
    "    #print('Start Validation Utility: {:.4f}'.format(start_utility_score))\n",
    "\n",
    "    Val_Loss = 0\n",
    "    N_Samples = 0\n",
    "\n",
    "    the_last_loss = 10000\n",
    "    the_last_utility_score = 0\n",
    "    the_last_accuracy = 0\n",
    "    trigger_times=0\n",
    "    early_stopping_met = False\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS_AE): \n",
    "        running_loss = 0.0        \n",
    "\n",
    "        ### Call back to save activation stats (mean, std dev and near 0 values after activation functions)\n",
    "        # Setting hook for activation layers stats\n",
    "\n",
    "        hook_handles = []\n",
    "        save_output_activation_stats = []\n",
    "\n",
    "        for layer in model.modules():\n",
    "            if ('activation' in str(type(layer))):\n",
    "                save_output_activation_stats_1layer = SaveOutputActivationStats()\n",
    "                handle = layer.register_forward_hook(save_output_activation_stats_1layer)\n",
    "                save_output_activation_stats.append(save_output_activation_stats_1layer)\n",
    "                hook_handles.append(handle)    \n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for batch in train_loader:\n",
    "            #inputs, labels = batch[0], batch[1]\n",
    "            inputs = batch[0].to('cuda')\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, inputs.double())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if scheduler:\n",
    "                    scheduler.step()\n",
    "\n",
    "        # update local train loss\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # update global train loss\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print('Epoch({}) - Training Loss: {:.4f}'.format(epoch, epoch_loss))\n",
    "\n",
    "        writer.add_scalar(f\"Global train/loss\", epoch_loss, epoch)\n",
    "\n",
    "        # Write activation stats graphs\n",
    "        for layer_number,save_output_activation_stats_layer in enumerate(save_output_activation_stats):\n",
    "            df_stats_layer = pd.DataFrame(save_output_activation_stats_layer.outputs)\n",
    "\n",
    "            fig, ax = plt.subplots(1, 3, figsize=(25, 4))\n",
    "\n",
    "            ax[0].set_title(f'Layer {layer_number} : Mean activation value', fontsize=16)\n",
    "            ax[0].set_xlabel('Batch instances')\n",
    "            ax[0].set_ylabel('Mean')\n",
    "            ax[0].plot(range(df_stats_layer.shape[0]), df_stats_layer['mean'])\n",
    "\n",
    "            ax[1].set_title(f'Layer {layer_number} : Std deviation activation value', fontsize=16)\n",
    "            ax[1].set_xlabel('Batch instances')\n",
    "            ax[1].set_ylabel('Standard deviation')\n",
    "            ax[1].plot(range(df_stats_layer.shape[0]), df_stats_layer['std'])\n",
    "\n",
    "            ax[2].set_title(f'Layer {layer_number} : Percentage of activation values near zero', fontsize=16)\n",
    "            ax[2].set_xlabel('Batch instances')\n",
    "            ax[2].set_ylabel('Percentage')\n",
    "            ax[2].plot(range(df_stats_layer.shape[0]), df_stats_layer['near_zero']);\n",
    "\n",
    "            plot_buf = io.BytesIO()\n",
    "            plt.savefig(plot_buf, format='jpeg')\n",
    "            plt.close()\n",
    "\n",
    "            plot_buf.seek(0)\n",
    "            image = PIL.Image.open(plot_buf)\n",
    "            image = transforms.ToTensor()(image)\n",
    "            writer.add_image(\"Train activation stats/Activation stats layer \" + str(layer_number), image, epoch)\n",
    "\n",
    "        # Validation \n",
    "        model.eval()\n",
    "\n",
    "        vrunning_loss = [None] * 5\n",
    "        num_samples = [None] * 5\n",
    "        vepoch_loss_folds = [None] * 5\n",
    "        vepoch_accuracy_folds = [None] * 5\n",
    "        vepoch_utility_score_folds = [None] * 5\n",
    "\n",
    "        for fold_indice in range(5):    \n",
    "            vrunning_loss[fold_indice] = 0.0\n",
    "            num_samples[fold_indice] = 0\n",
    "\n",
    "            for batch in test_loader[fold_indice]:\n",
    "                inputs = batch[0].to('cuda')\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = loss_fn(outputs, inputs.double())\n",
    "\n",
    "                vrunning_loss[fold_indice] += loss.item() * inputs.size(0)\n",
    "                num_samples[fold_indice] += inputs.size(0)\n",
    "\n",
    "                vepoch_loss_folds[fold_indice] = vrunning_loss[fold_indice] / num_samples[fold_indice]\n",
    "\n",
    "            print('Epoch({}) - Fold {} - Validation Loss : {:.4f}'.format(epoch, fold_indice, vepoch_loss_folds[fold_indice]))        \n",
    "\n",
    "        # update epoch loss\n",
    "        vepoch_loss = sum(vepoch_loss_folds) / len(vepoch_loss_folds)\n",
    "        print('Epoch({}) - GLOBAL - Validation Loss: {:.4f}'.format(epoch, vepoch_loss))\n",
    "\n",
    "        #print(f'Sum of model parameters ({epoch}):')\n",
    "        #[print(p.sum()) for p in model.parameters()]\n",
    "\n",
    "        writer.add_scalar(\"Global valid/Loss\", vepoch_loss, epoch)\n",
    "\n",
    "        for fold_indice in range(5):\n",
    "            writer.add_scalar(\"Fold valid Loss/Loss fold \"+str(fold_indice), vepoch_loss_folds[fold_indice], epoch)        \n",
    "\n",
    "        writer.flush()\n",
    "\n",
    "        # Check if Early Stopping\n",
    "\n",
    "        if (vepoch_loss > the_last_loss):\n",
    "            if (EARLY_STOPPING == True):\n",
    "                trigger_times += 1\n",
    "\n",
    "                print(f'Intermediate early stopping : vepoch_loss = {vepoch_loss:.4f}, the_last_loss={the_last_loss:.4f}')\n",
    "\n",
    "                if trigger_times >= patience:\n",
    "                    print('Meet Early stopping!')\n",
    "                    early_stopping_met = True\n",
    "                    ##torch.save(model.state_dict(), f'model_{fold}.pt')\n",
    "                    break\n",
    "        else:\n",
    "            trigger_times = 0\n",
    "            the_last_loss = vepoch_loss\n",
    "\n",
    "            the_best_epoch = epoch\n",
    "\n",
    "            # Save model for the best version so far\n",
    "            print(f'Saving model corresponding to last_loss == {the_last_loss}')\n",
    "            torch.save(model.state_dict(), MODEL_FILE_AE)\n",
    "\n",
    "        print('\\n')\n",
    "\n",
    "    if (early_stopping_met == False):\n",
    "        print(\"Didn't meet early stopping : saving final model\")\n",
    "        # Save model if don't meet early stopping\n",
    "        torch.save(model.state_dict(), MODEL_FILE_AE)\n",
    "\n",
    "    writer.add_text(f\"Global valid/Loss\", f\"Best loss: {the_last_loss}\", the_best_epoch)\n",
    "\n",
    "    scores_results = {'Loss': the_last_loss, 'Loss folds': vepoch_loss_folds, 'Loss_std': np.std(vepoch_loss_folds)}\n",
    "\n",
    "    writer.add_text('Final score', str(scores_results))\n",
    "    writer.add_text('Batch size', str(BATCH_SIZE_AE))\n",
    "    writer.add_text('Patience', str(patience))\n",
    "    writer.add_text('Number of epochs', str(NUM_EPOCHS_AE))\n",
    "    writer.add_text('Best epoch', str(the_best_epoch))\n",
    "    writer.add_text('Number of parameters per layer', str([p.numel() for p in model.parameters()]))\n",
    "    writer.add_text('Model architecture', str(model).replace('\\n', '<BR>'))\n",
    "    writer.add_text('Comment', MODEL_COMMENT_AE)\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    print('Training summary:')\n",
    "    print(scores_results)\n",
    "\n",
    "    model_AE = model\n",
    "    model_AE.eval()\n",
    "    print('Training ended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33611383846199827"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[FEATURES_LIST_TOTRAIN].mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2131970672255052"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.08 / df[FEATURES_LIST_TOTRAIN].mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts_train.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fn(ts_train[0:5, :], model_AE(ts_train[0:5, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_AE(ts_train[0:5, :])[0, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts_train[0, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fn(ts_train[50, 5], model_AE(ts_train[:, :])[50, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training XGB with auto encoder as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train xgb main model without resp n-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapped = XGBClassifier_wrapper({\n",
    "   'features': [i for i in range(0,32)], \n",
    "    'random_state': 42,\n",
    "    'max_depth': 10,\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.02,\n",
    "    'subsample': 0.5,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'gamma': None,\n",
    "    'tree_method': 'gpu_hist'        \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                0          1          2   ...         29         30         31\n",
       " 0         4.920520  10.393370   2.848430  ...   6.706162   7.553328   3.229464\n",
       " 1        13.425105  13.004536  11.671365  ...   9.275853  12.335581  10.960831\n",
       " 2         6.196855  19.288076  11.200149  ...  14.050742  12.413522  11.058138\n",
       " 3        14.453975  16.254791  10.539001  ...   6.403368  13.586235  10.107546\n",
       " 4         2.861047   6.505847   3.192688  ...   5.661924   2.876822   3.475592\n",
       " ...            ...        ...        ...  ...        ...        ...        ...\n",
       " 1339686  13.649236   8.577240  14.118822  ...  16.139911  13.834152   5.142769\n",
       " 1339687  13.432552   6.213704  15.470038  ...   7.540236  12.079553  11.455648\n",
       " 1339688  12.401143   9.138115  20.421107  ...   8.705382  18.215061  14.264449\n",
       " 1339689  12.546768  12.319803  12.883993  ...   7.110584  11.400167   5.871154\n",
       " 1339690   6.624428   8.917270   8.063125  ...   2.729992   9.744542  10.512251\n",
       " \n",
       " [1339691 rows x 32 columns],\n",
       " (1339691,))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model_AE.encoder(torch.tensor(df.loc[folds_list_train2_unique, FEATURES_LIST_TOTRAIN].to_numpy()).to('cuda')).detach().cpu().numpy()), (df.loc[folds_list_train2_unique]['resp'] > 0).astype(np.byte).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used for fitting:\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.6, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.02, max_delta_step=None, max_depth=10,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=42, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=0.5, tree_method='gpu_hist',\n",
      "              validate_parameters=None, verbosity=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:49:30] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/sklearn/base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier_wrapper(params=None)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapped.fit(pd.DataFrame(model_AE.encoder(torch.tensor(df.loc[folds_list_train2_unique, FEATURES_LIST_TOTRAIN].to_numpy()).to('cuda')).detach().cpu().numpy()), (df.loc[folds_list_train2_unique]['resp'] > 0).astype(np.byte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict called\n",
      "Type of X:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X:\n",
      "(141102, 140)\n",
      "Type of y:\n",
      "<class 'numpy.ndarray'>\n",
      "model fitted ?\n",
      "True\n",
      "y is not None\n",
      "predict called\n",
      "Type of X:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X:\n",
      "(142450, 140)\n",
      "Type of y:\n",
      "<class 'numpy.ndarray'>\n",
      "model fitted ?\n",
      "True\n",
      "y is not None\n",
      "predict called\n",
      "Type of X:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X:\n",
      "(145651, 140)\n",
      "Type of y:\n",
      "<class 'numpy.ndarray'>\n",
      "model fitted ?\n",
      "True\n",
      "y is not None\n",
      "predict called\n",
      "Type of X:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X:\n",
      "(142152, 140)\n",
      "Type of y:\n",
      "<class 'numpy.ndarray'>\n",
      "model fitted ?\n",
      "True\n",
      "y is not None\n",
      "predict called\n",
      "Type of X:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X:\n",
      "(141980, 140)\n",
      "Type of y:\n",
      "<class 'numpy.ndarray'>\n",
      "model fitted ?\n",
      "True\n",
      "y is not None\n",
      "{'utility_score': 1725.7596423065593, 'utility_scores': [81.13126092286532, 441.2875757847862, -0.0, -0.0, 1203.3408055989078], 'utility_score_std': 459.06357552251154, 'accuracy_scores': [0.5189933523266856, 0.5173183573183573, 0.5093545530068452, 0.5097782655185998, 0.5206789688688548]}\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for fold_indice in range(NB_FOLDS): \n",
    "    test_predictions = model_wrapped.predict(\n",
    "        pd.DataFrame(\n",
    "            model_AE.encoder(\n",
    "                torch.tensor(\n",
    "                    df.loc[folds_list_test[fold_indice], FEATURES_LIST_TOTRAIN].to_numpy()).to('cuda')).detach().cpu().numpy()))\n",
    "\n",
    "    scores.append(model_wrapped.score(df.loc[folds_list_test[fold_indice]], test_predictions))\n",
    "    accuracy_scores.append(model_wrapped.accuracy_score(df.loc[folds_list_test[fold_indice]], test_predictions))  \n",
    "\n",
    "    #df_featimportance = pd.DataFrame(model_wrapped.model_internal.feature_importances_, index=df[model_wrapped.features].columns, columns=['Importance']).sort_values(by='Importance', ascending=False)\n",
    "    #df_featimportance_cumulated = pd.concat([df_featimportance, pd.DataFrame({'% feat importance cumulé' : (df_featimportance['Importance'] / df_featimportance['Importance'].sum()).cumsum()})], axis=1)\n",
    "    #print(f'Feature importances for split {fold_indice}:')\n",
    "    #print(df_featimportance_cumulated)\n",
    "\n",
    "print({'utility_score': sum(scores), 'utility_scores': scores, 'utility_score_std': np.std(scores), 'accuracy_scores': accuracy_scores})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model that predicts original fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_indexes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_indice in range(NB_FOLDS):\n",
    "    fold_indexes.append([item for sublist in folds_list[fold_indice] for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_number, fold_indexes_1fold in enumerate(fold_indexes):\n",
    "    df.loc[fold_indexes_1fold, 'fold_number'] = str(int(fold_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.shape[0] - 1, 'fold_number'] = str(int(NB_FOLDS - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    480522\n",
       "3    478052\n",
       "0    477711\n",
       "2    477700\n",
       "4    476506\n",
       "Name: fold_number, dtype: int64"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fold_number'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_0</th>\n",
       "      <th>fold_1</th>\n",
       "      <th>fold_2</th>\n",
       "      <th>fold_3</th>\n",
       "      <th>fold_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390486</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390487</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390488</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390489</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390490</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2390491 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold_0  fold_1  fold_2  fold_3  fold_4\n",
       "0             1       0       0       0       0\n",
       "1             1       0       0       0       0\n",
       "2             1       0       0       0       0\n",
       "3             1       0       0       0       0\n",
       "4             1       0       0       0       0\n",
       "...         ...     ...     ...     ...     ...\n",
       "2390486       0       0       0       0       1\n",
       "2390487       0       0       0       0       1\n",
       "2390488       0       0       0       0       1\n",
       "2390489       0       0       0       0       1\n",
       "2390490       0       0       0       0       1\n",
       "\n",
       "[2390491 rows x 5 columns]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df['fold_number'], prefix = 'fold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.concat([df, pd.get_dummies(df['fold_number'], prefix = 'fold')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(columns=['fold_number'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model that predicts fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:18:33] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.6, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.02, max_delta_step=0, max_depth=10,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=500, n_jobs=24, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=42, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=0.5,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = XGBClassifier(\n",
    "    random_state= 42,\n",
    "    max_depth= 10,\n",
    "    n_estimators= 500,\n",
    "    learning_rate= 0.02,\n",
    "    subsample= 0.5,\n",
    "    colsample_bytree= 0.6,\n",
    "    #tree_method= 'gpu_hist',\n",
    "    gamma = None,\n",
    "    #objective= 'binary:logistic',\n",
    "    #disable_default_eval_metric=True,\n",
    "    )\n",
    "\n",
    "#model_xgb.fit(df.loc[folds_list_train1_unique, FEATURES_LIST_TOTRAIN], df.loc[folds_list_train1_unique, ['fold_'+str(i) for i in range(NB_FOLDS)]])\n",
    "model_xgb.fit(df.loc[folds_list_train1_unique, FEATURES_LIST_TOTRAIN], df.loc[folds_list_train1_unique, 'fold_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    142450\n",
       "Name: fold_number, dtype: int64"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[folds_list_test[1]]['fold_number'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    96385\n",
       "3    17526\n",
       "4    14765\n",
       "2    12426\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model_xgb.predict(df.loc[folds_list_test[0], FEATURES_LIST_TOTRAIN])).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    35215\n",
       "2    34951\n",
       "4    29050\n",
       "1    27376\n",
       "0    15858\n",
       "dtype: int64"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model_xgb.predict(df.loc[folds_list_test[1], FEATURES_LIST_TOTRAIN])).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    42796\n",
       "3    41676\n",
       "2    29645\n",
       "1    16244\n",
       "0    15290\n",
       "dtype: int64"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model_xgb.predict(df.loc[folds_list_test[2], FEATURES_LIST_TOTRAIN])).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    54846\n",
       "3    42485\n",
       "2    19802\n",
       "1    12533\n",
       "0    12486\n",
       "dtype: int64"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model_xgb.predict(df.loc[folds_list_test[3], FEATURES_LIST_TOTRAIN])).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    55967\n",
       "3    39535\n",
       "2    19066\n",
       "0    13932\n",
       "1    13480\n",
       "dtype: int64"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model_xgb.predict(df.loc[folds_list_test[4], FEATURES_LIST_TOTRAIN])).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    38850\n",
       "1    31809\n",
       "3    26110\n",
       "2    23367\n",
       "4    20966\n",
       "dtype: int64"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model_xgb.predict(df.loc[folds_list_test[0], FEATURES_LIST_TOTRAIN])).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    49310\n",
       "0    45465\n",
       "3    34088\n",
       "2    13287\n",
       "1        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model_xgb.predict(df.loc[folds_list_test[3], FEATURES_LIST_TOTRAIN])).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    54846\n",
       "3    42485\n",
       "2    19802\n",
       "1    12533\n",
       "0    12486\n",
       "dtype: int64"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model_xgb.predict(df.loc[folds_list_test[3], FEATURES_LIST_TOTRAIN])).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0293662 , 0.37885183, 0.2805159 , 0.25006837, 0.06119769],\n",
       "       [0.20258942, 0.69615513, 0.02438318, 0.02802538, 0.04884687],\n",
       "       [0.15609673, 0.68387717, 0.05710347, 0.04347701, 0.05944564],\n",
       "       ...,\n",
       "       [0.30444545, 0.15901743, 0.1415554 , 0.15136194, 0.24361981],\n",
       "       [0.12920362, 0.09120552, 0.2841637 , 0.25671333, 0.23871385],\n",
       "       [0.0745948 , 0.35374162, 0.2404547 , 0.13292678, 0.1982821 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.predict_proba(df.loc[folds_list_test[1], FEATURES_LIST_TOTRAIN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances for split 0:\n",
      "             Importance  % feat importance cumulé\n",
      "feature_43     0.028931                  0.028931\n",
      "feature_45     0.024954                  0.053885\n",
      "feature_42     0.023798                  0.077683\n",
      "feature_44     0.020929                  0.098612\n",
      "feature_124    0.020257                  0.118869\n",
      "feature_63     0.019910                  0.138779\n",
      "feature_41     0.018935                  0.157714\n",
      "feature_62     0.018388                  0.176102\n",
      "feature_61     0.018351                  0.194452\n",
      "feature_60     0.016976                  0.211428\n",
      "feature_66     0.015612                  0.227039\n",
      "feature_68     0.015347                  0.242387\n",
      "feature_71     0.015198                  0.257585\n",
      "feature_69     0.013856                  0.271441\n",
      "feature_83     0.013442                  0.284883\n",
      "feature_55     0.013339                  0.298222\n",
      "feature_120    0.013229                  0.311451\n",
      "feature_77     0.012573                  0.324024\n",
      "feature_70     0.011938                  0.335962\n",
      "feature_5      0.011872                  0.347834\n",
      "feature_6      0.011124                  0.358958\n",
      "feature_126    0.010827                  0.369785\n",
      "feature_119    0.010609                  0.380394\n",
      "feature_125    0.010575                  0.390969\n",
      "feature_95     0.010481                  0.401450\n",
      "feature_121    0.010463                  0.411913\n",
      "feature_57     0.010213                  0.422125\n",
      "feature_107    0.009685                  0.431810\n",
      "feature_64     0.009276                  0.441087\n",
      "feature_108    0.009061                  0.450147\n",
      "feature_47     0.008990                  0.459137\n",
      "feature_113    0.008598                  0.467735\n",
      "feature_37     0.008554                  0.476289\n",
      "feature_101    0.008422                  0.484711\n",
      "feature_114    0.008422                  0.493133\n",
      "feature_39     0.008361                  0.501494\n",
      "feature_58     0.008321                  0.509815\n",
      "feature_67     0.008268                  0.518084\n",
      "feature_38     0.008108                  0.526192\n",
      "feature_40     0.008093                  0.534284\n",
      "feature_4      0.008091                  0.542375\n",
      "feature_89     0.008019                  0.550394\n",
      "feature_65     0.007955                  0.558350\n",
      "feature_96     0.007675                  0.566024\n",
      "feature_128    0.007542                  0.573566\n",
      "feature_102    0.007368                  0.580934\n",
      "feature_110    0.007352                  0.588286\n",
      "feature_127    0.007305                  0.595591\n",
      "feature_90     0.007304                  0.602895\n",
      "feature_109    0.007012                  0.609907\n",
      "feature_54     0.006925                  0.616832\n",
      "feature_56     0.006873                  0.623705\n",
      "feature_3      0.006868                  0.630573\n",
      "feature_53     0.006855                  0.637427\n",
      "feature_84     0.006758                  0.644185\n",
      "feature_49     0.006629                  0.650814\n",
      "feature_26     0.006164                  0.656978\n",
      "feature_116    0.006163                  0.663141\n",
      "feature_112    0.006095                  0.669236\n",
      "feature_115    0.006018                  0.675254\n",
      "feature_98     0.005973                  0.681227\n",
      "feature_129    0.005873                  0.687101\n",
      "feature_111    0.005789                  0.692890\n",
      "feature_59     0.005778                  0.698668\n",
      "feature_122    0.005740                  0.704409\n",
      "feature_25     0.005698                  0.710106\n",
      "feature_10     0.005596                  0.715702\n",
      "feature_30     0.005592                  0.721294\n",
      "feature_86     0.005590                  0.726884\n",
      "feature_123    0.005553                  0.732436\n",
      "feature_36     0.005540                  0.737976\n",
      "feature_104    0.005493                  0.743469\n",
      "feature_118    0.005361                  0.748831\n",
      "feature_92     0.005321                  0.754152\n",
      "feature_23     0.005320                  0.759472\n",
      "feature_20     0.005311                  0.764783\n",
      "feature_46     0.005157                  0.769939\n",
      "feature_72     0.005139                  0.775079\n",
      "feature_35     0.005069                  0.780148\n",
      "feature_78     0.005053                  0.785200\n",
      "feature_24     0.004988                  0.790188\n",
      "feature_117    0.004967                  0.795155\n",
      "feature_48     0.004883                  0.800038\n",
      "feature_0      0.004856                  0.804894\n",
      "feature_17     0.004774                  0.809668\n",
      "feature_51     0.004760                  0.814428\n",
      "feature_34     0.004758                  0.819185\n",
      "feature_9      0.004750                  0.823935\n",
      "feature_33     0.004721                  0.828656\n",
      "feature_18     0.004714                  0.833370\n",
      "feature_99     0.004650                  0.838020\n",
      "feature_85     0.004624                  0.842645\n",
      "feature_28     0.004597                  0.847242\n",
      "feature_27     0.004596                  0.851838\n",
      "feature_50     0.004576                  0.856414\n",
      "feature_97     0.004478                  0.860891\n",
      "feature_88     0.004434                  0.865325\n",
      "feature_2      0.004427                  0.869752\n",
      "feature_76     0.004417                  0.874170\n",
      "feature_22     0.004401                  0.878571\n",
      "feature_16     0.004380                  0.882950\n",
      "feature_29     0.004363                  0.887313\n",
      "feature_19     0.004358                  0.891671\n",
      "feature_32     0.004319                  0.895990\n",
      "feature_100    0.004316                  0.900305\n",
      "feature_87     0.004283                  0.904588\n",
      "feature_74     0.004262                  0.908850\n",
      "feature_91     0.004226                  0.913077\n",
      "feature_94     0.004217                  0.917294\n",
      "feature_1      0.004214                  0.921508\n",
      "feature_21     0.004201                  0.925710\n",
      "feature_73     0.004160                  0.929870\n",
      "feature_105    0.004115                  0.933985\n",
      "feature_103    0.004098                  0.938083\n",
      "feature_8      0.004092                  0.942175\n",
      "feature_106    0.004088                  0.946264\n",
      "feature_31     0.004069                  0.950332\n",
      "feature_75     0.004055                  0.954387\n",
      "feature_15     0.004027                  0.958414\n",
      "feature_52     0.004025                  0.962440\n",
      "feature_93     0.004022                  0.966461\n",
      "feature_80     0.003955                  0.970416\n",
      "feature_82     0.003902                  0.974318\n",
      "feature_12     0.003868                  0.978186\n",
      "feature_14     0.003829                  0.982016\n",
      "feature_81     0.003800                  0.985815\n",
      "feature_79     0.003715                  0.989530\n",
      "feature_7      0.003562                  0.993092\n",
      "feature_13     0.003471                  0.996563\n",
      "feature_11     0.003437                  1.000000\n",
      "Feature importances for split 1:\n",
      "             Importance  % feat importance cumulé\n",
      "feature_43     0.028931                  0.028931\n",
      "feature_45     0.024954                  0.053885\n",
      "feature_42     0.023798                  0.077683\n",
      "feature_44     0.020929                  0.098612\n",
      "feature_124    0.020257                  0.118869\n",
      "feature_63     0.019910                  0.138779\n",
      "feature_41     0.018935                  0.157714\n",
      "feature_62     0.018388                  0.176102\n",
      "feature_61     0.018351                  0.194452\n",
      "feature_60     0.016976                  0.211428\n",
      "feature_66     0.015612                  0.227039\n",
      "feature_68     0.015347                  0.242387\n",
      "feature_71     0.015198                  0.257585\n",
      "feature_69     0.013856                  0.271441\n",
      "feature_83     0.013442                  0.284883\n",
      "feature_55     0.013339                  0.298222\n",
      "feature_120    0.013229                  0.311451\n",
      "feature_77     0.012573                  0.324024\n",
      "feature_70     0.011938                  0.335962\n",
      "feature_5      0.011872                  0.347834\n",
      "feature_6      0.011124                  0.358958\n",
      "feature_126    0.010827                  0.369785\n",
      "feature_119    0.010609                  0.380394\n",
      "feature_125    0.010575                  0.390969\n",
      "feature_95     0.010481                  0.401450\n",
      "feature_121    0.010463                  0.411913\n",
      "feature_57     0.010213                  0.422125\n",
      "feature_107    0.009685                  0.431810\n",
      "feature_64     0.009276                  0.441087\n",
      "feature_108    0.009061                  0.450147\n",
      "feature_47     0.008990                  0.459137\n",
      "feature_113    0.008598                  0.467735\n",
      "feature_37     0.008554                  0.476289\n",
      "feature_101    0.008422                  0.484711\n",
      "feature_114    0.008422                  0.493133\n",
      "feature_39     0.008361                  0.501494\n",
      "feature_58     0.008321                  0.509815\n",
      "feature_67     0.008268                  0.518084\n",
      "feature_38     0.008108                  0.526192\n",
      "feature_40     0.008093                  0.534284\n",
      "feature_4      0.008091                  0.542375\n",
      "feature_89     0.008019                  0.550394\n",
      "feature_65     0.007955                  0.558350\n",
      "feature_96     0.007675                  0.566024\n",
      "feature_128    0.007542                  0.573566\n",
      "feature_102    0.007368                  0.580934\n",
      "feature_110    0.007352                  0.588286\n",
      "feature_127    0.007305                  0.595591\n",
      "feature_90     0.007304                  0.602895\n",
      "feature_109    0.007012                  0.609907\n",
      "feature_54     0.006925                  0.616832\n",
      "feature_56     0.006873                  0.623705\n",
      "feature_3      0.006868                  0.630573\n",
      "feature_53     0.006855                  0.637427\n",
      "feature_84     0.006758                  0.644185\n",
      "feature_49     0.006629                  0.650814\n",
      "feature_26     0.006164                  0.656978\n",
      "feature_116    0.006163                  0.663141\n",
      "feature_112    0.006095                  0.669236\n",
      "feature_115    0.006018                  0.675254\n",
      "feature_98     0.005973                  0.681227\n",
      "feature_129    0.005873                  0.687101\n",
      "feature_111    0.005789                  0.692890\n",
      "feature_59     0.005778                  0.698668\n",
      "feature_122    0.005740                  0.704409\n",
      "feature_25     0.005698                  0.710106\n",
      "feature_10     0.005596                  0.715702\n",
      "feature_30     0.005592                  0.721294\n",
      "feature_86     0.005590                  0.726884\n",
      "feature_123    0.005553                  0.732436\n",
      "feature_36     0.005540                  0.737976\n",
      "feature_104    0.005493                  0.743469\n",
      "feature_118    0.005361                  0.748831\n",
      "feature_92     0.005321                  0.754152\n",
      "feature_23     0.005320                  0.759472\n",
      "feature_20     0.005311                  0.764783\n",
      "feature_46     0.005157                  0.769939\n",
      "feature_72     0.005139                  0.775079\n",
      "feature_35     0.005069                  0.780148\n",
      "feature_78     0.005053                  0.785200\n",
      "feature_24     0.004988                  0.790188\n",
      "feature_117    0.004967                  0.795155\n",
      "feature_48     0.004883                  0.800038\n",
      "feature_0      0.004856                  0.804894\n",
      "feature_17     0.004774                  0.809668\n",
      "feature_51     0.004760                  0.814428\n",
      "feature_34     0.004758                  0.819185\n",
      "feature_9      0.004750                  0.823935\n",
      "feature_33     0.004721                  0.828656\n",
      "feature_18     0.004714                  0.833370\n",
      "feature_99     0.004650                  0.838020\n",
      "feature_85     0.004624                  0.842645\n",
      "feature_28     0.004597                  0.847242\n",
      "feature_27     0.004596                  0.851838\n",
      "feature_50     0.004576                  0.856414\n",
      "feature_97     0.004478                  0.860891\n",
      "feature_88     0.004434                  0.865325\n",
      "feature_2      0.004427                  0.869752\n",
      "feature_76     0.004417                  0.874170\n",
      "feature_22     0.004401                  0.878571\n",
      "feature_16     0.004380                  0.882950\n",
      "feature_29     0.004363                  0.887313\n",
      "feature_19     0.004358                  0.891671\n",
      "feature_32     0.004319                  0.895990\n",
      "feature_100    0.004316                  0.900305\n",
      "feature_87     0.004283                  0.904588\n",
      "feature_74     0.004262                  0.908850\n",
      "feature_91     0.004226                  0.913077\n",
      "feature_94     0.004217                  0.917294\n",
      "feature_1      0.004214                  0.921508\n",
      "feature_21     0.004201                  0.925710\n",
      "feature_73     0.004160                  0.929870\n",
      "feature_105    0.004115                  0.933985\n",
      "feature_103    0.004098                  0.938083\n",
      "feature_8      0.004092                  0.942175\n",
      "feature_106    0.004088                  0.946264\n",
      "feature_31     0.004069                  0.950332\n",
      "feature_75     0.004055                  0.954387\n",
      "feature_15     0.004027                  0.958414\n",
      "feature_52     0.004025                  0.962440\n",
      "feature_93     0.004022                  0.966461\n",
      "feature_80     0.003955                  0.970416\n",
      "feature_82     0.003902                  0.974318\n",
      "feature_12     0.003868                  0.978186\n",
      "feature_14     0.003829                  0.982016\n",
      "feature_81     0.003800                  0.985815\n",
      "feature_79     0.003715                  0.989530\n",
      "feature_7      0.003562                  0.993092\n",
      "feature_13     0.003471                  0.996563\n",
      "feature_11     0.003437                  1.000000\n",
      "Feature importances for split 2:\n",
      "             Importance  % feat importance cumulé\n",
      "feature_43     0.028931                  0.028931\n",
      "feature_45     0.024954                  0.053885\n",
      "feature_42     0.023798                  0.077683\n",
      "feature_44     0.020929                  0.098612\n",
      "feature_124    0.020257                  0.118869\n",
      "feature_63     0.019910                  0.138779\n",
      "feature_41     0.018935                  0.157714\n",
      "feature_62     0.018388                  0.176102\n",
      "feature_61     0.018351                  0.194452\n",
      "feature_60     0.016976                  0.211428\n",
      "feature_66     0.015612                  0.227039\n",
      "feature_68     0.015347                  0.242387\n",
      "feature_71     0.015198                  0.257585\n",
      "feature_69     0.013856                  0.271441\n",
      "feature_83     0.013442                  0.284883\n",
      "feature_55     0.013339                  0.298222\n",
      "feature_120    0.013229                  0.311451\n",
      "feature_77     0.012573                  0.324024\n",
      "feature_70     0.011938                  0.335962\n",
      "feature_5      0.011872                  0.347834\n",
      "feature_6      0.011124                  0.358958\n",
      "feature_126    0.010827                  0.369785\n",
      "feature_119    0.010609                  0.380394\n",
      "feature_125    0.010575                  0.390969\n",
      "feature_95     0.010481                  0.401450\n",
      "feature_121    0.010463                  0.411913\n",
      "feature_57     0.010213                  0.422125\n",
      "feature_107    0.009685                  0.431810\n",
      "feature_64     0.009276                  0.441087\n",
      "feature_108    0.009061                  0.450147\n",
      "feature_47     0.008990                  0.459137\n",
      "feature_113    0.008598                  0.467735\n",
      "feature_37     0.008554                  0.476289\n",
      "feature_101    0.008422                  0.484711\n",
      "feature_114    0.008422                  0.493133\n",
      "feature_39     0.008361                  0.501494\n",
      "feature_58     0.008321                  0.509815\n",
      "feature_67     0.008268                  0.518084\n",
      "feature_38     0.008108                  0.526192\n",
      "feature_40     0.008093                  0.534284\n",
      "feature_4      0.008091                  0.542375\n",
      "feature_89     0.008019                  0.550394\n",
      "feature_65     0.007955                  0.558350\n",
      "feature_96     0.007675                  0.566024\n",
      "feature_128    0.007542                  0.573566\n",
      "feature_102    0.007368                  0.580934\n",
      "feature_110    0.007352                  0.588286\n",
      "feature_127    0.007305                  0.595591\n",
      "feature_90     0.007304                  0.602895\n",
      "feature_109    0.007012                  0.609907\n",
      "feature_54     0.006925                  0.616832\n",
      "feature_56     0.006873                  0.623705\n",
      "feature_3      0.006868                  0.630573\n",
      "feature_53     0.006855                  0.637427\n",
      "feature_84     0.006758                  0.644185\n",
      "feature_49     0.006629                  0.650814\n",
      "feature_26     0.006164                  0.656978\n",
      "feature_116    0.006163                  0.663141\n",
      "feature_112    0.006095                  0.669236\n",
      "feature_115    0.006018                  0.675254\n",
      "feature_98     0.005973                  0.681227\n",
      "feature_129    0.005873                  0.687101\n",
      "feature_111    0.005789                  0.692890\n",
      "feature_59     0.005778                  0.698668\n",
      "feature_122    0.005740                  0.704409\n",
      "feature_25     0.005698                  0.710106\n",
      "feature_10     0.005596                  0.715702\n",
      "feature_30     0.005592                  0.721294\n",
      "feature_86     0.005590                  0.726884\n",
      "feature_123    0.005553                  0.732436\n",
      "feature_36     0.005540                  0.737976\n",
      "feature_104    0.005493                  0.743469\n",
      "feature_118    0.005361                  0.748831\n",
      "feature_92     0.005321                  0.754152\n",
      "feature_23     0.005320                  0.759472\n",
      "feature_20     0.005311                  0.764783\n",
      "feature_46     0.005157                  0.769939\n",
      "feature_72     0.005139                  0.775079\n",
      "feature_35     0.005069                  0.780148\n",
      "feature_78     0.005053                  0.785200\n",
      "feature_24     0.004988                  0.790188\n",
      "feature_117    0.004967                  0.795155\n",
      "feature_48     0.004883                  0.800038\n",
      "feature_0      0.004856                  0.804894\n",
      "feature_17     0.004774                  0.809668\n",
      "feature_51     0.004760                  0.814428\n",
      "feature_34     0.004758                  0.819185\n",
      "feature_9      0.004750                  0.823935\n",
      "feature_33     0.004721                  0.828656\n",
      "feature_18     0.004714                  0.833370\n",
      "feature_99     0.004650                  0.838020\n",
      "feature_85     0.004624                  0.842645\n",
      "feature_28     0.004597                  0.847242\n",
      "feature_27     0.004596                  0.851838\n",
      "feature_50     0.004576                  0.856414\n",
      "feature_97     0.004478                  0.860891\n",
      "feature_88     0.004434                  0.865325\n",
      "feature_2      0.004427                  0.869752\n",
      "feature_76     0.004417                  0.874170\n",
      "feature_22     0.004401                  0.878571\n",
      "feature_16     0.004380                  0.882950\n",
      "feature_29     0.004363                  0.887313\n",
      "feature_19     0.004358                  0.891671\n",
      "feature_32     0.004319                  0.895990\n",
      "feature_100    0.004316                  0.900305\n",
      "feature_87     0.004283                  0.904588\n",
      "feature_74     0.004262                  0.908850\n",
      "feature_91     0.004226                  0.913077\n",
      "feature_94     0.004217                  0.917294\n",
      "feature_1      0.004214                  0.921508\n",
      "feature_21     0.004201                  0.925710\n",
      "feature_73     0.004160                  0.929870\n",
      "feature_105    0.004115                  0.933985\n",
      "feature_103    0.004098                  0.938083\n",
      "feature_8      0.004092                  0.942175\n",
      "feature_106    0.004088                  0.946264\n",
      "feature_31     0.004069                  0.950332\n",
      "feature_75     0.004055                  0.954387\n",
      "feature_15     0.004027                  0.958414\n",
      "feature_52     0.004025                  0.962440\n",
      "feature_93     0.004022                  0.966461\n",
      "feature_80     0.003955                  0.970416\n",
      "feature_82     0.003902                  0.974318\n",
      "feature_12     0.003868                  0.978186\n",
      "feature_14     0.003829                  0.982016\n",
      "feature_81     0.003800                  0.985815\n",
      "feature_79     0.003715                  0.989530\n",
      "feature_7      0.003562                  0.993092\n",
      "feature_13     0.003471                  0.996563\n",
      "feature_11     0.003437                  1.000000\n",
      "Feature importances for split 3:\n",
      "             Importance  % feat importance cumulé\n",
      "feature_43     0.028931                  0.028931\n",
      "feature_45     0.024954                  0.053885\n",
      "feature_42     0.023798                  0.077683\n",
      "feature_44     0.020929                  0.098612\n",
      "feature_124    0.020257                  0.118869\n",
      "feature_63     0.019910                  0.138779\n",
      "feature_41     0.018935                  0.157714\n",
      "feature_62     0.018388                  0.176102\n",
      "feature_61     0.018351                  0.194452\n",
      "feature_60     0.016976                  0.211428\n",
      "feature_66     0.015612                  0.227039\n",
      "feature_68     0.015347                  0.242387\n",
      "feature_71     0.015198                  0.257585\n",
      "feature_69     0.013856                  0.271441\n",
      "feature_83     0.013442                  0.284883\n",
      "feature_55     0.013339                  0.298222\n",
      "feature_120    0.013229                  0.311451\n",
      "feature_77     0.012573                  0.324024\n",
      "feature_70     0.011938                  0.335962\n",
      "feature_5      0.011872                  0.347834\n",
      "feature_6      0.011124                  0.358958\n",
      "feature_126    0.010827                  0.369785\n",
      "feature_119    0.010609                  0.380394\n",
      "feature_125    0.010575                  0.390969\n",
      "feature_95     0.010481                  0.401450\n",
      "feature_121    0.010463                  0.411913\n",
      "feature_57     0.010213                  0.422125\n",
      "feature_107    0.009685                  0.431810\n",
      "feature_64     0.009276                  0.441087\n",
      "feature_108    0.009061                  0.450147\n",
      "feature_47     0.008990                  0.459137\n",
      "feature_113    0.008598                  0.467735\n",
      "feature_37     0.008554                  0.476289\n",
      "feature_101    0.008422                  0.484711\n",
      "feature_114    0.008422                  0.493133\n",
      "feature_39     0.008361                  0.501494\n",
      "feature_58     0.008321                  0.509815\n",
      "feature_67     0.008268                  0.518084\n",
      "feature_38     0.008108                  0.526192\n",
      "feature_40     0.008093                  0.534284\n",
      "feature_4      0.008091                  0.542375\n",
      "feature_89     0.008019                  0.550394\n",
      "feature_65     0.007955                  0.558350\n",
      "feature_96     0.007675                  0.566024\n",
      "feature_128    0.007542                  0.573566\n",
      "feature_102    0.007368                  0.580934\n",
      "feature_110    0.007352                  0.588286\n",
      "feature_127    0.007305                  0.595591\n",
      "feature_90     0.007304                  0.602895\n",
      "feature_109    0.007012                  0.609907\n",
      "feature_54     0.006925                  0.616832\n",
      "feature_56     0.006873                  0.623705\n",
      "feature_3      0.006868                  0.630573\n",
      "feature_53     0.006855                  0.637427\n",
      "feature_84     0.006758                  0.644185\n",
      "feature_49     0.006629                  0.650814\n",
      "feature_26     0.006164                  0.656978\n",
      "feature_116    0.006163                  0.663141\n",
      "feature_112    0.006095                  0.669236\n",
      "feature_115    0.006018                  0.675254\n",
      "feature_98     0.005973                  0.681227\n",
      "feature_129    0.005873                  0.687101\n",
      "feature_111    0.005789                  0.692890\n",
      "feature_59     0.005778                  0.698668\n",
      "feature_122    0.005740                  0.704409\n",
      "feature_25     0.005698                  0.710106\n",
      "feature_10     0.005596                  0.715702\n",
      "feature_30     0.005592                  0.721294\n",
      "feature_86     0.005590                  0.726884\n",
      "feature_123    0.005553                  0.732436\n",
      "feature_36     0.005540                  0.737976\n",
      "feature_104    0.005493                  0.743469\n",
      "feature_118    0.005361                  0.748831\n",
      "feature_92     0.005321                  0.754152\n",
      "feature_23     0.005320                  0.759472\n",
      "feature_20     0.005311                  0.764783\n",
      "feature_46     0.005157                  0.769939\n",
      "feature_72     0.005139                  0.775079\n",
      "feature_35     0.005069                  0.780148\n",
      "feature_78     0.005053                  0.785200\n",
      "feature_24     0.004988                  0.790188\n",
      "feature_117    0.004967                  0.795155\n",
      "feature_48     0.004883                  0.800038\n",
      "feature_0      0.004856                  0.804894\n",
      "feature_17     0.004774                  0.809668\n",
      "feature_51     0.004760                  0.814428\n",
      "feature_34     0.004758                  0.819185\n",
      "feature_9      0.004750                  0.823935\n",
      "feature_33     0.004721                  0.828656\n",
      "feature_18     0.004714                  0.833370\n",
      "feature_99     0.004650                  0.838020\n",
      "feature_85     0.004624                  0.842645\n",
      "feature_28     0.004597                  0.847242\n",
      "feature_27     0.004596                  0.851838\n",
      "feature_50     0.004576                  0.856414\n",
      "feature_97     0.004478                  0.860891\n",
      "feature_88     0.004434                  0.865325\n",
      "feature_2      0.004427                  0.869752\n",
      "feature_76     0.004417                  0.874170\n",
      "feature_22     0.004401                  0.878571\n",
      "feature_16     0.004380                  0.882950\n",
      "feature_29     0.004363                  0.887313\n",
      "feature_19     0.004358                  0.891671\n",
      "feature_32     0.004319                  0.895990\n",
      "feature_100    0.004316                  0.900305\n",
      "feature_87     0.004283                  0.904588\n",
      "feature_74     0.004262                  0.908850\n",
      "feature_91     0.004226                  0.913077\n",
      "feature_94     0.004217                  0.917294\n",
      "feature_1      0.004214                  0.921508\n",
      "feature_21     0.004201                  0.925710\n",
      "feature_73     0.004160                  0.929870\n",
      "feature_105    0.004115                  0.933985\n",
      "feature_103    0.004098                  0.938083\n",
      "feature_8      0.004092                  0.942175\n",
      "feature_106    0.004088                  0.946264\n",
      "feature_31     0.004069                  0.950332\n",
      "feature_75     0.004055                  0.954387\n",
      "feature_15     0.004027                  0.958414\n",
      "feature_52     0.004025                  0.962440\n",
      "feature_93     0.004022                  0.966461\n",
      "feature_80     0.003955                  0.970416\n",
      "feature_82     0.003902                  0.974318\n",
      "feature_12     0.003868                  0.978186\n",
      "feature_14     0.003829                  0.982016\n",
      "feature_81     0.003800                  0.985815\n",
      "feature_79     0.003715                  0.989530\n",
      "feature_7      0.003562                  0.993092\n",
      "feature_13     0.003471                  0.996563\n",
      "feature_11     0.003437                  1.000000\n",
      "Feature importances for split 4:\n",
      "             Importance  % feat importance cumulé\n",
      "feature_43     0.028931                  0.028931\n",
      "feature_45     0.024954                  0.053885\n",
      "feature_42     0.023798                  0.077683\n",
      "feature_44     0.020929                  0.098612\n",
      "feature_124    0.020257                  0.118869\n",
      "feature_63     0.019910                  0.138779\n",
      "feature_41     0.018935                  0.157714\n",
      "feature_62     0.018388                  0.176102\n",
      "feature_61     0.018351                  0.194452\n",
      "feature_60     0.016976                  0.211428\n",
      "feature_66     0.015612                  0.227039\n",
      "feature_68     0.015347                  0.242387\n",
      "feature_71     0.015198                  0.257585\n",
      "feature_69     0.013856                  0.271441\n",
      "feature_83     0.013442                  0.284883\n",
      "feature_55     0.013339                  0.298222\n",
      "feature_120    0.013229                  0.311451\n",
      "feature_77     0.012573                  0.324024\n",
      "feature_70     0.011938                  0.335962\n",
      "feature_5      0.011872                  0.347834\n",
      "feature_6      0.011124                  0.358958\n",
      "feature_126    0.010827                  0.369785\n",
      "feature_119    0.010609                  0.380394\n",
      "feature_125    0.010575                  0.390969\n",
      "feature_95     0.010481                  0.401450\n",
      "feature_121    0.010463                  0.411913\n",
      "feature_57     0.010213                  0.422125\n",
      "feature_107    0.009685                  0.431810\n",
      "feature_64     0.009276                  0.441087\n",
      "feature_108    0.009061                  0.450147\n",
      "feature_47     0.008990                  0.459137\n",
      "feature_113    0.008598                  0.467735\n",
      "feature_37     0.008554                  0.476289\n",
      "feature_101    0.008422                  0.484711\n",
      "feature_114    0.008422                  0.493133\n",
      "feature_39     0.008361                  0.501494\n",
      "feature_58     0.008321                  0.509815\n",
      "feature_67     0.008268                  0.518084\n",
      "feature_38     0.008108                  0.526192\n",
      "feature_40     0.008093                  0.534284\n",
      "feature_4      0.008091                  0.542375\n",
      "feature_89     0.008019                  0.550394\n",
      "feature_65     0.007955                  0.558350\n",
      "feature_96     0.007675                  0.566024\n",
      "feature_128    0.007542                  0.573566\n",
      "feature_102    0.007368                  0.580934\n",
      "feature_110    0.007352                  0.588286\n",
      "feature_127    0.007305                  0.595591\n",
      "feature_90     0.007304                  0.602895\n",
      "feature_109    0.007012                  0.609907\n",
      "feature_54     0.006925                  0.616832\n",
      "feature_56     0.006873                  0.623705\n",
      "feature_3      0.006868                  0.630573\n",
      "feature_53     0.006855                  0.637427\n",
      "feature_84     0.006758                  0.644185\n",
      "feature_49     0.006629                  0.650814\n",
      "feature_26     0.006164                  0.656978\n",
      "feature_116    0.006163                  0.663141\n",
      "feature_112    0.006095                  0.669236\n",
      "feature_115    0.006018                  0.675254\n",
      "feature_98     0.005973                  0.681227\n",
      "feature_129    0.005873                  0.687101\n",
      "feature_111    0.005789                  0.692890\n",
      "feature_59     0.005778                  0.698668\n",
      "feature_122    0.005740                  0.704409\n",
      "feature_25     0.005698                  0.710106\n",
      "feature_10     0.005596                  0.715702\n",
      "feature_30     0.005592                  0.721294\n",
      "feature_86     0.005590                  0.726884\n",
      "feature_123    0.005553                  0.732436\n",
      "feature_36     0.005540                  0.737976\n",
      "feature_104    0.005493                  0.743469\n",
      "feature_118    0.005361                  0.748831\n",
      "feature_92     0.005321                  0.754152\n",
      "feature_23     0.005320                  0.759472\n",
      "feature_20     0.005311                  0.764783\n",
      "feature_46     0.005157                  0.769939\n",
      "feature_72     0.005139                  0.775079\n",
      "feature_35     0.005069                  0.780148\n",
      "feature_78     0.005053                  0.785200\n",
      "feature_24     0.004988                  0.790188\n",
      "feature_117    0.004967                  0.795155\n",
      "feature_48     0.004883                  0.800038\n",
      "feature_0      0.004856                  0.804894\n",
      "feature_17     0.004774                  0.809668\n",
      "feature_51     0.004760                  0.814428\n",
      "feature_34     0.004758                  0.819185\n",
      "feature_9      0.004750                  0.823935\n",
      "feature_33     0.004721                  0.828656\n",
      "feature_18     0.004714                  0.833370\n",
      "feature_99     0.004650                  0.838020\n",
      "feature_85     0.004624                  0.842645\n",
      "feature_28     0.004597                  0.847242\n",
      "feature_27     0.004596                  0.851838\n",
      "feature_50     0.004576                  0.856414\n",
      "feature_97     0.004478                  0.860891\n",
      "feature_88     0.004434                  0.865325\n",
      "feature_2      0.004427                  0.869752\n",
      "feature_76     0.004417                  0.874170\n",
      "feature_22     0.004401                  0.878571\n",
      "feature_16     0.004380                  0.882950\n",
      "feature_29     0.004363                  0.887313\n",
      "feature_19     0.004358                  0.891671\n",
      "feature_32     0.004319                  0.895990\n",
      "feature_100    0.004316                  0.900305\n",
      "feature_87     0.004283                  0.904588\n",
      "feature_74     0.004262                  0.908850\n",
      "feature_91     0.004226                  0.913077\n",
      "feature_94     0.004217                  0.917294\n",
      "feature_1      0.004214                  0.921508\n",
      "feature_21     0.004201                  0.925710\n",
      "feature_73     0.004160                  0.929870\n",
      "feature_105    0.004115                  0.933985\n",
      "feature_103    0.004098                  0.938083\n",
      "feature_8      0.004092                  0.942175\n",
      "feature_106    0.004088                  0.946264\n",
      "feature_31     0.004069                  0.950332\n",
      "feature_75     0.004055                  0.954387\n",
      "feature_15     0.004027                  0.958414\n",
      "feature_52     0.004025                  0.962440\n",
      "feature_93     0.004022                  0.966461\n",
      "feature_80     0.003955                  0.970416\n",
      "feature_82     0.003902                  0.974318\n",
      "feature_12     0.003868                  0.978186\n",
      "feature_14     0.003829                  0.982016\n",
      "feature_81     0.003800                  0.985815\n",
      "feature_79     0.003715                  0.989530\n",
      "feature_7      0.003562                  0.993092\n",
      "feature_13     0.003471                  0.996563\n",
      "feature_11     0.003437                  1.000000\n",
      "{'accuracy_scores': [0.2753327380193052, 0.1921797121797122, 0.20353447624801752, 0.298870223422815, 0.3941893224397803]}\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for fold_indice in range(NB_FOLDS): \n",
    "    test_predictions = model_xgb.predict(df.loc[folds_list_test[fold_indice], FEATURES_LIST_TOTRAIN])\n",
    "\n",
    "    accuracy_scores.append(accuracy_score(df.loc[folds_list_test[fold_indice], 'fold_number'], test_predictions))  \n",
    "\n",
    "    df_featimportance = pd.DataFrame(model_xgb.feature_importances_, index=df[FEATURES_LIST_TOTRAIN].columns, columns=['Importance']).sort_values(by='Importance', ascending=False)\n",
    "    df_featimportance_cumulated = pd.concat([df_featimportance, pd.DataFrame({'% feat importance cumulé' : (df_featimportance['Importance'] / df_featimportance['Importance'].sum()).cumsum()})], axis=1)\n",
    "    print(f'Feature importances for split {fold_indice}:')\n",
    "    print(df_featimportance_cumulated)\n",
    "\n",
    "print({'accuracy_scores': accuracy_scores})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores with training on train2 on test sets : {'accuracy_scores': [0.36075321398704485, 0.30245700245700247, 0.2717798024043776, 0.26939473239912204, 0.4842724327370052]}   \n",
    "Scores with training on train1 on test sets : {'accuracy_scores': [0.6830874119431334, 7.02000702000702e-06, 0.16245683174162895, 0.26211379368563226, 0.3551626989716862]}  \n",
    "\n",
    "Scores with bin indexes matching folds index, with training on train1 :\n",
    "{'accuracy_scores': [0.2753327380193052, 0.1921797121797122, 0.20353447624801752, 0.298870223422815, 0.3941893224397803]}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances for split 0:\n",
      "             Importance  % feat importance cumulé\n",
      "feature_43     0.028931                  0.028931\n",
      "feature_45     0.024954                  0.053885\n",
      "feature_42     0.023798                  0.077683\n",
      "feature_44     0.020929                  0.098612\n",
      "feature_124    0.020257                  0.118869\n",
      "feature_63     0.019910                  0.138779\n",
      "feature_41     0.018935                  0.157714\n",
      "feature_62     0.018388                  0.176102\n",
      "feature_61     0.018351                  0.194452\n",
      "feature_60     0.016976                  0.211428\n",
      "feature_66     0.015612                  0.227039\n",
      "feature_68     0.015347                  0.242387\n",
      "feature_71     0.015198                  0.257585\n",
      "feature_69     0.013856                  0.271441\n",
      "feature_83     0.013442                  0.284883\n",
      "feature_55     0.013339                  0.298222\n",
      "feature_120    0.013229                  0.311451\n",
      "feature_77     0.012573                  0.324024\n",
      "feature_70     0.011938                  0.335962\n",
      "feature_5      0.011872                  0.347834\n",
      "feature_6      0.011124                  0.358958\n",
      "feature_126    0.010827                  0.369785\n",
      "feature_119    0.010609                  0.380394\n",
      "feature_125    0.010575                  0.390969\n",
      "feature_95     0.010481                  0.401450\n",
      "feature_121    0.010463                  0.411913\n",
      "feature_57     0.010213                  0.422125\n",
      "feature_107    0.009685                  0.431810\n",
      "feature_64     0.009276                  0.441087\n",
      "feature_108    0.009061                  0.450147\n",
      "feature_47     0.008990                  0.459137\n",
      "feature_113    0.008598                  0.467735\n",
      "feature_37     0.008554                  0.476289\n",
      "feature_101    0.008422                  0.484711\n",
      "feature_114    0.008422                  0.493133\n",
      "feature_39     0.008361                  0.501494\n",
      "feature_58     0.008321                  0.509815\n",
      "feature_67     0.008268                  0.518084\n",
      "feature_38     0.008108                  0.526192\n",
      "feature_40     0.008093                  0.534284\n",
      "feature_4      0.008091                  0.542375\n",
      "feature_89     0.008019                  0.550394\n",
      "feature_65     0.007955                  0.558350\n",
      "feature_96     0.007675                  0.566024\n",
      "feature_128    0.007542                  0.573566\n",
      "feature_102    0.007368                  0.580934\n",
      "feature_110    0.007352                  0.588286\n",
      "feature_127    0.007305                  0.595591\n",
      "feature_90     0.007304                  0.602895\n",
      "feature_109    0.007012                  0.609907\n",
      "feature_54     0.006925                  0.616832\n",
      "feature_56     0.006873                  0.623705\n",
      "feature_3      0.006868                  0.630573\n",
      "feature_53     0.006855                  0.637427\n",
      "feature_84     0.006758                  0.644185\n",
      "feature_49     0.006629                  0.650814\n",
      "feature_26     0.006164                  0.656978\n",
      "feature_116    0.006163                  0.663141\n",
      "feature_112    0.006095                  0.669236\n",
      "feature_115    0.006018                  0.675254\n",
      "feature_98     0.005973                  0.681227\n",
      "feature_129    0.005873                  0.687101\n",
      "feature_111    0.005789                  0.692890\n",
      "feature_59     0.005778                  0.698668\n",
      "feature_122    0.005740                  0.704409\n",
      "feature_25     0.005698                  0.710106\n",
      "feature_10     0.005596                  0.715702\n",
      "feature_30     0.005592                  0.721294\n",
      "feature_86     0.005590                  0.726884\n",
      "feature_123    0.005553                  0.732436\n",
      "feature_36     0.005540                  0.737976\n",
      "feature_104    0.005493                  0.743469\n",
      "feature_118    0.005361                  0.748831\n",
      "feature_92     0.005321                  0.754152\n",
      "feature_23     0.005320                  0.759472\n",
      "feature_20     0.005311                  0.764783\n",
      "feature_46     0.005157                  0.769939\n",
      "feature_72     0.005139                  0.775079\n",
      "feature_35     0.005069                  0.780148\n",
      "feature_78     0.005053                  0.785200\n",
      "feature_24     0.004988                  0.790188\n",
      "feature_117    0.004967                  0.795155\n",
      "feature_48     0.004883                  0.800038\n",
      "feature_0      0.004856                  0.804894\n",
      "feature_17     0.004774                  0.809668\n",
      "feature_51     0.004760                  0.814428\n",
      "feature_34     0.004758                  0.819185\n",
      "feature_9      0.004750                  0.823935\n",
      "feature_33     0.004721                  0.828656\n",
      "feature_18     0.004714                  0.833370\n",
      "feature_99     0.004650                  0.838020\n",
      "feature_85     0.004624                  0.842645\n",
      "feature_28     0.004597                  0.847242\n",
      "feature_27     0.004596                  0.851838\n",
      "feature_50     0.004576                  0.856414\n",
      "feature_97     0.004478                  0.860891\n",
      "feature_88     0.004434                  0.865325\n",
      "feature_2      0.004427                  0.869752\n",
      "feature_76     0.004417                  0.874170\n",
      "feature_22     0.004401                  0.878571\n",
      "feature_16     0.004380                  0.882950\n",
      "feature_29     0.004363                  0.887313\n",
      "feature_19     0.004358                  0.891671\n",
      "feature_32     0.004319                  0.895990\n",
      "feature_100    0.004316                  0.900305\n",
      "feature_87     0.004283                  0.904588\n",
      "feature_74     0.004262                  0.908850\n",
      "feature_91     0.004226                  0.913077\n",
      "feature_94     0.004217                  0.917294\n",
      "feature_1      0.004214                  0.921508\n",
      "feature_21     0.004201                  0.925710\n",
      "feature_73     0.004160                  0.929870\n",
      "feature_105    0.004115                  0.933985\n",
      "feature_103    0.004098                  0.938083\n",
      "feature_8      0.004092                  0.942175\n",
      "feature_106    0.004088                  0.946264\n",
      "feature_31     0.004069                  0.950332\n",
      "feature_75     0.004055                  0.954387\n",
      "feature_15     0.004027                  0.958414\n",
      "feature_52     0.004025                  0.962440\n",
      "feature_93     0.004022                  0.966461\n",
      "feature_80     0.003955                  0.970416\n",
      "feature_82     0.003902                  0.974318\n",
      "feature_12     0.003868                  0.978186\n",
      "feature_14     0.003829                  0.982016\n",
      "feature_81     0.003800                  0.985815\n",
      "feature_79     0.003715                  0.989530\n",
      "feature_7      0.003562                  0.993092\n",
      "feature_13     0.003471                  0.996563\n",
      "feature_11     0.003437                  1.000000\n",
      "Feature importances for split 1:\n",
      "             Importance  % feat importance cumulé\n",
      "feature_43     0.028931                  0.028931\n",
      "feature_45     0.024954                  0.053885\n",
      "feature_42     0.023798                  0.077683\n",
      "feature_44     0.020929                  0.098612\n",
      "feature_124    0.020257                  0.118869\n",
      "feature_63     0.019910                  0.138779\n",
      "feature_41     0.018935                  0.157714\n",
      "feature_62     0.018388                  0.176102\n",
      "feature_61     0.018351                  0.194452\n",
      "feature_60     0.016976                  0.211428\n",
      "feature_66     0.015612                  0.227039\n",
      "feature_68     0.015347                  0.242387\n",
      "feature_71     0.015198                  0.257585\n",
      "feature_69     0.013856                  0.271441\n",
      "feature_83     0.013442                  0.284883\n",
      "feature_55     0.013339                  0.298222\n",
      "feature_120    0.013229                  0.311451\n",
      "feature_77     0.012573                  0.324024\n",
      "feature_70     0.011938                  0.335962\n",
      "feature_5      0.011872                  0.347834\n",
      "feature_6      0.011124                  0.358958\n",
      "feature_126    0.010827                  0.369785\n",
      "feature_119    0.010609                  0.380394\n",
      "feature_125    0.010575                  0.390969\n",
      "feature_95     0.010481                  0.401450\n",
      "feature_121    0.010463                  0.411913\n",
      "feature_57     0.010213                  0.422125\n",
      "feature_107    0.009685                  0.431810\n",
      "feature_64     0.009276                  0.441087\n",
      "feature_108    0.009061                  0.450147\n",
      "feature_47     0.008990                  0.459137\n",
      "feature_113    0.008598                  0.467735\n",
      "feature_37     0.008554                  0.476289\n",
      "feature_101    0.008422                  0.484711\n",
      "feature_114    0.008422                  0.493133\n",
      "feature_39     0.008361                  0.501494\n",
      "feature_58     0.008321                  0.509815\n",
      "feature_67     0.008268                  0.518084\n",
      "feature_38     0.008108                  0.526192\n",
      "feature_40     0.008093                  0.534284\n",
      "feature_4      0.008091                  0.542375\n",
      "feature_89     0.008019                  0.550394\n",
      "feature_65     0.007955                  0.558350\n",
      "feature_96     0.007675                  0.566024\n",
      "feature_128    0.007542                  0.573566\n",
      "feature_102    0.007368                  0.580934\n",
      "feature_110    0.007352                  0.588286\n",
      "feature_127    0.007305                  0.595591\n",
      "feature_90     0.007304                  0.602895\n",
      "feature_109    0.007012                  0.609907\n",
      "feature_54     0.006925                  0.616832\n",
      "feature_56     0.006873                  0.623705\n",
      "feature_3      0.006868                  0.630573\n",
      "feature_53     0.006855                  0.637427\n",
      "feature_84     0.006758                  0.644185\n",
      "feature_49     0.006629                  0.650814\n",
      "feature_26     0.006164                  0.656978\n",
      "feature_116    0.006163                  0.663141\n",
      "feature_112    0.006095                  0.669236\n",
      "feature_115    0.006018                  0.675254\n",
      "feature_98     0.005973                  0.681227\n",
      "feature_129    0.005873                  0.687101\n",
      "feature_111    0.005789                  0.692890\n",
      "feature_59     0.005778                  0.698668\n",
      "feature_122    0.005740                  0.704409\n",
      "feature_25     0.005698                  0.710106\n",
      "feature_10     0.005596                  0.715702\n",
      "feature_30     0.005592                  0.721294\n",
      "feature_86     0.005590                  0.726884\n",
      "feature_123    0.005553                  0.732436\n",
      "feature_36     0.005540                  0.737976\n",
      "feature_104    0.005493                  0.743469\n",
      "feature_118    0.005361                  0.748831\n",
      "feature_92     0.005321                  0.754152\n",
      "feature_23     0.005320                  0.759472\n",
      "feature_20     0.005311                  0.764783\n",
      "feature_46     0.005157                  0.769939\n",
      "feature_72     0.005139                  0.775079\n",
      "feature_35     0.005069                  0.780148\n",
      "feature_78     0.005053                  0.785200\n",
      "feature_24     0.004988                  0.790188\n",
      "feature_117    0.004967                  0.795155\n",
      "feature_48     0.004883                  0.800038\n",
      "feature_0      0.004856                  0.804894\n",
      "feature_17     0.004774                  0.809668\n",
      "feature_51     0.004760                  0.814428\n",
      "feature_34     0.004758                  0.819185\n",
      "feature_9      0.004750                  0.823935\n",
      "feature_33     0.004721                  0.828656\n",
      "feature_18     0.004714                  0.833370\n",
      "feature_99     0.004650                  0.838020\n",
      "feature_85     0.004624                  0.842645\n",
      "feature_28     0.004597                  0.847242\n",
      "feature_27     0.004596                  0.851838\n",
      "feature_50     0.004576                  0.856414\n",
      "feature_97     0.004478                  0.860891\n",
      "feature_88     0.004434                  0.865325\n",
      "feature_2      0.004427                  0.869752\n",
      "feature_76     0.004417                  0.874170\n",
      "feature_22     0.004401                  0.878571\n",
      "feature_16     0.004380                  0.882950\n",
      "feature_29     0.004363                  0.887313\n",
      "feature_19     0.004358                  0.891671\n",
      "feature_32     0.004319                  0.895990\n",
      "feature_100    0.004316                  0.900305\n",
      "feature_87     0.004283                  0.904588\n",
      "feature_74     0.004262                  0.908850\n",
      "feature_91     0.004226                  0.913077\n",
      "feature_94     0.004217                  0.917294\n",
      "feature_1      0.004214                  0.921508\n",
      "feature_21     0.004201                  0.925710\n",
      "feature_73     0.004160                  0.929870\n",
      "feature_105    0.004115                  0.933985\n",
      "feature_103    0.004098                  0.938083\n",
      "feature_8      0.004092                  0.942175\n",
      "feature_106    0.004088                  0.946264\n",
      "feature_31     0.004069                  0.950332\n",
      "feature_75     0.004055                  0.954387\n",
      "feature_15     0.004027                  0.958414\n",
      "feature_52     0.004025                  0.962440\n",
      "feature_93     0.004022                  0.966461\n",
      "feature_80     0.003955                  0.970416\n",
      "feature_82     0.003902                  0.974318\n",
      "feature_12     0.003868                  0.978186\n",
      "feature_14     0.003829                  0.982016\n",
      "feature_81     0.003800                  0.985815\n",
      "feature_79     0.003715                  0.989530\n",
      "feature_7      0.003562                  0.993092\n",
      "feature_13     0.003471                  0.996563\n",
      "feature_11     0.003437                  1.000000\n",
      "Feature importances for split 2:\n",
      "             Importance  % feat importance cumulé\n",
      "feature_43     0.028931                  0.028931\n",
      "feature_45     0.024954                  0.053885\n",
      "feature_42     0.023798                  0.077683\n",
      "feature_44     0.020929                  0.098612\n",
      "feature_124    0.020257                  0.118869\n",
      "feature_63     0.019910                  0.138779\n",
      "feature_41     0.018935                  0.157714\n",
      "feature_62     0.018388                  0.176102\n",
      "feature_61     0.018351                  0.194452\n",
      "feature_60     0.016976                  0.211428\n",
      "feature_66     0.015612                  0.227039\n",
      "feature_68     0.015347                  0.242387\n",
      "feature_71     0.015198                  0.257585\n",
      "feature_69     0.013856                  0.271441\n",
      "feature_83     0.013442                  0.284883\n",
      "feature_55     0.013339                  0.298222\n",
      "feature_120    0.013229                  0.311451\n",
      "feature_77     0.012573                  0.324024\n",
      "feature_70     0.011938                  0.335962\n",
      "feature_5      0.011872                  0.347834\n",
      "feature_6      0.011124                  0.358958\n",
      "feature_126    0.010827                  0.369785\n",
      "feature_119    0.010609                  0.380394\n",
      "feature_125    0.010575                  0.390969\n",
      "feature_95     0.010481                  0.401450\n",
      "feature_121    0.010463                  0.411913\n",
      "feature_57     0.010213                  0.422125\n",
      "feature_107    0.009685                  0.431810\n",
      "feature_64     0.009276                  0.441087\n",
      "feature_108    0.009061                  0.450147\n",
      "feature_47     0.008990                  0.459137\n",
      "feature_113    0.008598                  0.467735\n",
      "feature_37     0.008554                  0.476289\n",
      "feature_101    0.008422                  0.484711\n",
      "feature_114    0.008422                  0.493133\n",
      "feature_39     0.008361                  0.501494\n",
      "feature_58     0.008321                  0.509815\n",
      "feature_67     0.008268                  0.518084\n",
      "feature_38     0.008108                  0.526192\n",
      "feature_40     0.008093                  0.534284\n",
      "feature_4      0.008091                  0.542375\n",
      "feature_89     0.008019                  0.550394\n",
      "feature_65     0.007955                  0.558350\n",
      "feature_96     0.007675                  0.566024\n",
      "feature_128    0.007542                  0.573566\n",
      "feature_102    0.007368                  0.580934\n",
      "feature_110    0.007352                  0.588286\n",
      "feature_127    0.007305                  0.595591\n",
      "feature_90     0.007304                  0.602895\n",
      "feature_109    0.007012                  0.609907\n",
      "feature_54     0.006925                  0.616832\n",
      "feature_56     0.006873                  0.623705\n",
      "feature_3      0.006868                  0.630573\n",
      "feature_53     0.006855                  0.637427\n",
      "feature_84     0.006758                  0.644185\n",
      "feature_49     0.006629                  0.650814\n",
      "feature_26     0.006164                  0.656978\n",
      "feature_116    0.006163                  0.663141\n",
      "feature_112    0.006095                  0.669236\n",
      "feature_115    0.006018                  0.675254\n",
      "feature_98     0.005973                  0.681227\n",
      "feature_129    0.005873                  0.687101\n",
      "feature_111    0.005789                  0.692890\n",
      "feature_59     0.005778                  0.698668\n",
      "feature_122    0.005740                  0.704409\n",
      "feature_25     0.005698                  0.710106\n",
      "feature_10     0.005596                  0.715702\n",
      "feature_30     0.005592                  0.721294\n",
      "feature_86     0.005590                  0.726884\n",
      "feature_123    0.005553                  0.732436\n",
      "feature_36     0.005540                  0.737976\n",
      "feature_104    0.005493                  0.743469\n",
      "feature_118    0.005361                  0.748831\n",
      "feature_92     0.005321                  0.754152\n",
      "feature_23     0.005320                  0.759472\n",
      "feature_20     0.005311                  0.764783\n",
      "feature_46     0.005157                  0.769939\n",
      "feature_72     0.005139                  0.775079\n",
      "feature_35     0.005069                  0.780148\n",
      "feature_78     0.005053                  0.785200\n",
      "feature_24     0.004988                  0.790188\n",
      "feature_117    0.004967                  0.795155\n",
      "feature_48     0.004883                  0.800038\n",
      "feature_0      0.004856                  0.804894\n",
      "feature_17     0.004774                  0.809668\n",
      "feature_51     0.004760                  0.814428\n",
      "feature_34     0.004758                  0.819185\n",
      "feature_9      0.004750                  0.823935\n",
      "feature_33     0.004721                  0.828656\n",
      "feature_18     0.004714                  0.833370\n",
      "feature_99     0.004650                  0.838020\n",
      "feature_85     0.004624                  0.842645\n",
      "feature_28     0.004597                  0.847242\n",
      "feature_27     0.004596                  0.851838\n",
      "feature_50     0.004576                  0.856414\n",
      "feature_97     0.004478                  0.860891\n",
      "feature_88     0.004434                  0.865325\n",
      "feature_2      0.004427                  0.869752\n",
      "feature_76     0.004417                  0.874170\n",
      "feature_22     0.004401                  0.878571\n",
      "feature_16     0.004380                  0.882950\n",
      "feature_29     0.004363                  0.887313\n",
      "feature_19     0.004358                  0.891671\n",
      "feature_32     0.004319                  0.895990\n",
      "feature_100    0.004316                  0.900305\n",
      "feature_87     0.004283                  0.904588\n",
      "feature_74     0.004262                  0.908850\n",
      "feature_91     0.004226                  0.913077\n",
      "feature_94     0.004217                  0.917294\n",
      "feature_1      0.004214                  0.921508\n",
      "feature_21     0.004201                  0.925710\n",
      "feature_73     0.004160                  0.929870\n",
      "feature_105    0.004115                  0.933985\n",
      "feature_103    0.004098                  0.938083\n",
      "feature_8      0.004092                  0.942175\n",
      "feature_106    0.004088                  0.946264\n",
      "feature_31     0.004069                  0.950332\n",
      "feature_75     0.004055                  0.954387\n",
      "feature_15     0.004027                  0.958414\n",
      "feature_52     0.004025                  0.962440\n",
      "feature_93     0.004022                  0.966461\n",
      "feature_80     0.003955                  0.970416\n",
      "feature_82     0.003902                  0.974318\n",
      "feature_12     0.003868                  0.978186\n",
      "feature_14     0.003829                  0.982016\n",
      "feature_81     0.003800                  0.985815\n",
      "feature_79     0.003715                  0.989530\n",
      "feature_7      0.003562                  0.993092\n",
      "feature_13     0.003471                  0.996563\n",
      "feature_11     0.003437                  1.000000\n",
      "Feature importances for split 3:\n",
      "             Importance  % feat importance cumulé\n",
      "feature_43     0.028931                  0.028931\n",
      "feature_45     0.024954                  0.053885\n",
      "feature_42     0.023798                  0.077683\n",
      "feature_44     0.020929                  0.098612\n",
      "feature_124    0.020257                  0.118869\n",
      "feature_63     0.019910                  0.138779\n",
      "feature_41     0.018935                  0.157714\n",
      "feature_62     0.018388                  0.176102\n",
      "feature_61     0.018351                  0.194452\n",
      "feature_60     0.016976                  0.211428\n",
      "feature_66     0.015612                  0.227039\n",
      "feature_68     0.015347                  0.242387\n",
      "feature_71     0.015198                  0.257585\n",
      "feature_69     0.013856                  0.271441\n",
      "feature_83     0.013442                  0.284883\n",
      "feature_55     0.013339                  0.298222\n",
      "feature_120    0.013229                  0.311451\n",
      "feature_77     0.012573                  0.324024\n",
      "feature_70     0.011938                  0.335962\n",
      "feature_5      0.011872                  0.347834\n",
      "feature_6      0.011124                  0.358958\n",
      "feature_126    0.010827                  0.369785\n",
      "feature_119    0.010609                  0.380394\n",
      "feature_125    0.010575                  0.390969\n",
      "feature_95     0.010481                  0.401450\n",
      "feature_121    0.010463                  0.411913\n",
      "feature_57     0.010213                  0.422125\n",
      "feature_107    0.009685                  0.431810\n",
      "feature_64     0.009276                  0.441087\n",
      "feature_108    0.009061                  0.450147\n",
      "feature_47     0.008990                  0.459137\n",
      "feature_113    0.008598                  0.467735\n",
      "feature_37     0.008554                  0.476289\n",
      "feature_101    0.008422                  0.484711\n",
      "feature_114    0.008422                  0.493133\n",
      "feature_39     0.008361                  0.501494\n",
      "feature_58     0.008321                  0.509815\n",
      "feature_67     0.008268                  0.518084\n",
      "feature_38     0.008108                  0.526192\n",
      "feature_40     0.008093                  0.534284\n",
      "feature_4      0.008091                  0.542375\n",
      "feature_89     0.008019                  0.550394\n",
      "feature_65     0.007955                  0.558350\n",
      "feature_96     0.007675                  0.566024\n",
      "feature_128    0.007542                  0.573566\n",
      "feature_102    0.007368                  0.580934\n",
      "feature_110    0.007352                  0.588286\n",
      "feature_127    0.007305                  0.595591\n",
      "feature_90     0.007304                  0.602895\n",
      "feature_109    0.007012                  0.609907\n",
      "feature_54     0.006925                  0.616832\n",
      "feature_56     0.006873                  0.623705\n",
      "feature_3      0.006868                  0.630573\n",
      "feature_53     0.006855                  0.637427\n",
      "feature_84     0.006758                  0.644185\n",
      "feature_49     0.006629                  0.650814\n",
      "feature_26     0.006164                  0.656978\n",
      "feature_116    0.006163                  0.663141\n",
      "feature_112    0.006095                  0.669236\n",
      "feature_115    0.006018                  0.675254\n",
      "feature_98     0.005973                  0.681227\n",
      "feature_129    0.005873                  0.687101\n",
      "feature_111    0.005789                  0.692890\n",
      "feature_59     0.005778                  0.698668\n",
      "feature_122    0.005740                  0.704409\n",
      "feature_25     0.005698                  0.710106\n",
      "feature_10     0.005596                  0.715702\n",
      "feature_30     0.005592                  0.721294\n",
      "feature_86     0.005590                  0.726884\n",
      "feature_123    0.005553                  0.732436\n",
      "feature_36     0.005540                  0.737976\n",
      "feature_104    0.005493                  0.743469\n",
      "feature_118    0.005361                  0.748831\n",
      "feature_92     0.005321                  0.754152\n",
      "feature_23     0.005320                  0.759472\n",
      "feature_20     0.005311                  0.764783\n",
      "feature_46     0.005157                  0.769939\n",
      "feature_72     0.005139                  0.775079\n",
      "feature_35     0.005069                  0.780148\n",
      "feature_78     0.005053                  0.785200\n",
      "feature_24     0.004988                  0.790188\n",
      "feature_117    0.004967                  0.795155\n",
      "feature_48     0.004883                  0.800038\n",
      "feature_0      0.004856                  0.804894\n",
      "feature_17     0.004774                  0.809668\n",
      "feature_51     0.004760                  0.814428\n",
      "feature_34     0.004758                  0.819185\n",
      "feature_9      0.004750                  0.823935\n",
      "feature_33     0.004721                  0.828656\n",
      "feature_18     0.004714                  0.833370\n",
      "feature_99     0.004650                  0.838020\n",
      "feature_85     0.004624                  0.842645\n",
      "feature_28     0.004597                  0.847242\n",
      "feature_27     0.004596                  0.851838\n",
      "feature_50     0.004576                  0.856414\n",
      "feature_97     0.004478                  0.860891\n",
      "feature_88     0.004434                  0.865325\n",
      "feature_2      0.004427                  0.869752\n",
      "feature_76     0.004417                  0.874170\n",
      "feature_22     0.004401                  0.878571\n",
      "feature_16     0.004380                  0.882950\n",
      "feature_29     0.004363                  0.887313\n",
      "feature_19     0.004358                  0.891671\n",
      "feature_32     0.004319                  0.895990\n",
      "feature_100    0.004316                  0.900305\n",
      "feature_87     0.004283                  0.904588\n",
      "feature_74     0.004262                  0.908850\n",
      "feature_91     0.004226                  0.913077\n",
      "feature_94     0.004217                  0.917294\n",
      "feature_1      0.004214                  0.921508\n",
      "feature_21     0.004201                  0.925710\n",
      "feature_73     0.004160                  0.929870\n",
      "feature_105    0.004115                  0.933985\n",
      "feature_103    0.004098                  0.938083\n",
      "feature_8      0.004092                  0.942175\n",
      "feature_106    0.004088                  0.946264\n",
      "feature_31     0.004069                  0.950332\n",
      "feature_75     0.004055                  0.954387\n",
      "feature_15     0.004027                  0.958414\n",
      "feature_52     0.004025                  0.962440\n",
      "feature_93     0.004022                  0.966461\n",
      "feature_80     0.003955                  0.970416\n",
      "feature_82     0.003902                  0.974318\n",
      "feature_12     0.003868                  0.978186\n",
      "feature_14     0.003829                  0.982016\n",
      "feature_81     0.003800                  0.985815\n",
      "feature_79     0.003715                  0.989530\n",
      "feature_7      0.003562                  0.993092\n",
      "feature_13     0.003471                  0.996563\n",
      "feature_11     0.003437                  1.000000\n",
      "Feature importances for split 4:\n",
      "             Importance  % feat importance cumulé\n",
      "feature_43     0.028931                  0.028931\n",
      "feature_45     0.024954                  0.053885\n",
      "feature_42     0.023798                  0.077683\n",
      "feature_44     0.020929                  0.098612\n",
      "feature_124    0.020257                  0.118869\n",
      "feature_63     0.019910                  0.138779\n",
      "feature_41     0.018935                  0.157714\n",
      "feature_62     0.018388                  0.176102\n",
      "feature_61     0.018351                  0.194452\n",
      "feature_60     0.016976                  0.211428\n",
      "feature_66     0.015612                  0.227039\n",
      "feature_68     0.015347                  0.242387\n",
      "feature_71     0.015198                  0.257585\n",
      "feature_69     0.013856                  0.271441\n",
      "feature_83     0.013442                  0.284883\n",
      "feature_55     0.013339                  0.298222\n",
      "feature_120    0.013229                  0.311451\n",
      "feature_77     0.012573                  0.324024\n",
      "feature_70     0.011938                  0.335962\n",
      "feature_5      0.011872                  0.347834\n",
      "feature_6      0.011124                  0.358958\n",
      "feature_126    0.010827                  0.369785\n",
      "feature_119    0.010609                  0.380394\n",
      "feature_125    0.010575                  0.390969\n",
      "feature_95     0.010481                  0.401450\n",
      "feature_121    0.010463                  0.411913\n",
      "feature_57     0.010213                  0.422125\n",
      "feature_107    0.009685                  0.431810\n",
      "feature_64     0.009276                  0.441087\n",
      "feature_108    0.009061                  0.450147\n",
      "feature_47     0.008990                  0.459137\n",
      "feature_113    0.008598                  0.467735\n",
      "feature_37     0.008554                  0.476289\n",
      "feature_101    0.008422                  0.484711\n",
      "feature_114    0.008422                  0.493133\n",
      "feature_39     0.008361                  0.501494\n",
      "feature_58     0.008321                  0.509815\n",
      "feature_67     0.008268                  0.518084\n",
      "feature_38     0.008108                  0.526192\n",
      "feature_40     0.008093                  0.534284\n",
      "feature_4      0.008091                  0.542375\n",
      "feature_89     0.008019                  0.550394\n",
      "feature_65     0.007955                  0.558350\n",
      "feature_96     0.007675                  0.566024\n",
      "feature_128    0.007542                  0.573566\n",
      "feature_102    0.007368                  0.580934\n",
      "feature_110    0.007352                  0.588286\n",
      "feature_127    0.007305                  0.595591\n",
      "feature_90     0.007304                  0.602895\n",
      "feature_109    0.007012                  0.609907\n",
      "feature_54     0.006925                  0.616832\n",
      "feature_56     0.006873                  0.623705\n",
      "feature_3      0.006868                  0.630573\n",
      "feature_53     0.006855                  0.637427\n",
      "feature_84     0.006758                  0.644185\n",
      "feature_49     0.006629                  0.650814\n",
      "feature_26     0.006164                  0.656978\n",
      "feature_116    0.006163                  0.663141\n",
      "feature_112    0.006095                  0.669236\n",
      "feature_115    0.006018                  0.675254\n",
      "feature_98     0.005973                  0.681227\n",
      "feature_129    0.005873                  0.687101\n",
      "feature_111    0.005789                  0.692890\n",
      "feature_59     0.005778                  0.698668\n",
      "feature_122    0.005740                  0.704409\n",
      "feature_25     0.005698                  0.710106\n",
      "feature_10     0.005596                  0.715702\n",
      "feature_30     0.005592                  0.721294\n",
      "feature_86     0.005590                  0.726884\n",
      "feature_123    0.005553                  0.732436\n",
      "feature_36     0.005540                  0.737976\n",
      "feature_104    0.005493                  0.743469\n",
      "feature_118    0.005361                  0.748831\n",
      "feature_92     0.005321                  0.754152\n",
      "feature_23     0.005320                  0.759472\n",
      "feature_20     0.005311                  0.764783\n",
      "feature_46     0.005157                  0.769939\n",
      "feature_72     0.005139                  0.775079\n",
      "feature_35     0.005069                  0.780148\n",
      "feature_78     0.005053                  0.785200\n",
      "feature_24     0.004988                  0.790188\n",
      "feature_117    0.004967                  0.795155\n",
      "feature_48     0.004883                  0.800038\n",
      "feature_0      0.004856                  0.804894\n",
      "feature_17     0.004774                  0.809668\n",
      "feature_51     0.004760                  0.814428\n",
      "feature_34     0.004758                  0.819185\n",
      "feature_9      0.004750                  0.823935\n",
      "feature_33     0.004721                  0.828656\n",
      "feature_18     0.004714                  0.833370\n",
      "feature_99     0.004650                  0.838020\n",
      "feature_85     0.004624                  0.842645\n",
      "feature_28     0.004597                  0.847242\n",
      "feature_27     0.004596                  0.851838\n",
      "feature_50     0.004576                  0.856414\n",
      "feature_97     0.004478                  0.860891\n",
      "feature_88     0.004434                  0.865325\n",
      "feature_2      0.004427                  0.869752\n",
      "feature_76     0.004417                  0.874170\n",
      "feature_22     0.004401                  0.878571\n",
      "feature_16     0.004380                  0.882950\n",
      "feature_29     0.004363                  0.887313\n",
      "feature_19     0.004358                  0.891671\n",
      "feature_32     0.004319                  0.895990\n",
      "feature_100    0.004316                  0.900305\n",
      "feature_87     0.004283                  0.904588\n",
      "feature_74     0.004262                  0.908850\n",
      "feature_91     0.004226                  0.913077\n",
      "feature_94     0.004217                  0.917294\n",
      "feature_1      0.004214                  0.921508\n",
      "feature_21     0.004201                  0.925710\n",
      "feature_73     0.004160                  0.929870\n",
      "feature_105    0.004115                  0.933985\n",
      "feature_103    0.004098                  0.938083\n",
      "feature_8      0.004092                  0.942175\n",
      "feature_106    0.004088                  0.946264\n",
      "feature_31     0.004069                  0.950332\n",
      "feature_75     0.004055                  0.954387\n",
      "feature_15     0.004027                  0.958414\n",
      "feature_52     0.004025                  0.962440\n",
      "feature_93     0.004022                  0.966461\n",
      "feature_80     0.003955                  0.970416\n",
      "feature_82     0.003902                  0.974318\n",
      "feature_12     0.003868                  0.978186\n",
      "feature_14     0.003829                  0.982016\n",
      "feature_81     0.003800                  0.985815\n",
      "feature_79     0.003715                  0.989530\n",
      "feature_7      0.003562                  0.993092\n",
      "feature_13     0.003471                  0.996563\n",
      "feature_11     0.003437                  1.000000\n",
      "{'accuracy_scores': [0.31393283973692443, 0.31393283973692443, 0.31393283973692443, 0.31393283973692443, 0.31393283973692443]}\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for fold_indice in range(NB_FOLDS): \n",
    "    test_predictions = model_xgb.predict(df.loc[folds_list_train2_unique, FEATURES_LIST_TOTRAIN])\n",
    "\n",
    "    accuracy_scores.append(accuracy_score(df.loc[folds_list_train2_unique, 'fold_number'], test_predictions))  \n",
    "\n",
    "    df_featimportance = pd.DataFrame(model_xgb.feature_importances_, index=df[FEATURES_LIST_TOTRAIN].columns, columns=['Importance']).sort_values(by='Importance', ascending=False)\n",
    "    df_featimportance_cumulated = pd.concat([df_featimportance, pd.DataFrame({'% feat importance cumulé' : (df_featimportance['Importance'] / df_featimportance['Importance'].sum()).cumsum()})], axis=1)\n",
    "    print(f'Feature importances for split {fold_indice}:')\n",
    "    print(df_featimportance_cumulated)\n",
    "\n",
    "print({'accuracy_scores': accuracy_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74261016, 0.21811517, 0.0123332 , 0.01326843, 0.0136731 ],\n",
       "       [0.09510097, 0.16958879, 0.21119231, 0.29204583, 0.23207211],\n",
       "       [0.42501253, 0.26984364, 0.11358389, 0.10173181, 0.08982816],\n",
       "       ...,\n",
       "       [0.08701544, 0.24431483, 0.08493751, 0.06240717, 0.52132505],\n",
       "       [0.09015974, 0.55284935, 0.1024383 , 0.10849357, 0.14605905],\n",
       "       [0.2902496 , 0.31208447, 0.09574225, 0.07115116, 0.23077255]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.predict_proba(df.loc[folds_list_test[0], FEATURES_LIST_TOTRAIN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                0\n",
       "1                1\n",
       "2                2\n",
       "3                3\n",
       "4                4\n",
       "            ...   \n",
       "2390486    2390486\n",
       "2390487    2390487\n",
       "2390488    2390488\n",
       "2390489    2390489\n",
       "2390490    2390490\n",
       "Name: ts_id, Length: 2390491, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ts_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train XGBoost with bin prediction as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapped = XGBClassifier_wrapper({\n",
    "   'features': ['feature_'+str(i) for i in range(130)] + [4], \n",
    "    'random_state': 42,\n",
    "    'max_depth': 10,\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.02,\n",
    "    'subsample': 0.5,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'gamma': None,\n",
    "    #'tree_method': 'gpu_hist'        \n",
    "    'tree_method': 'hist'        \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0.461488\n",
       "1          0.234588\n",
       "2          0.399935\n",
       "3          0.264698\n",
       "4          0.281896\n",
       "             ...   \n",
       "1339686    0.621705\n",
       "1339687    0.552255\n",
       "1339688    0.511799\n",
       "1339689    0.511681\n",
       "1339690    0.182789\n",
       "Name: 4, Length: 1339691, dtype: float32"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model_xgb.predict_proba(df.loc[folds_list_train2_unique, FEATURES_LIST_TOTRAIN]))[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "      <th>feature_25</th>\n",
       "      <th>feature_26</th>\n",
       "      <th>feature_27</th>\n",
       "      <th>feature_28</th>\n",
       "      <th>feature_29</th>\n",
       "      <th>feature_30</th>\n",
       "      <th>feature_31</th>\n",
       "      <th>feature_32</th>\n",
       "      <th>feature_33</th>\n",
       "      <th>feature_34</th>\n",
       "      <th>feature_35</th>\n",
       "      <th>feature_36</th>\n",
       "      <th>feature_37</th>\n",
       "      <th>feature_38</th>\n",
       "      <th>feature_39</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_91</th>\n",
       "      <th>feature_92</th>\n",
       "      <th>feature_93</th>\n",
       "      <th>feature_94</th>\n",
       "      <th>feature_95</th>\n",
       "      <th>feature_96</th>\n",
       "      <th>feature_97</th>\n",
       "      <th>feature_98</th>\n",
       "      <th>feature_99</th>\n",
       "      <th>feature_100</th>\n",
       "      <th>feature_101</th>\n",
       "      <th>feature_102</th>\n",
       "      <th>feature_103</th>\n",
       "      <th>feature_104</th>\n",
       "      <th>feature_105</th>\n",
       "      <th>feature_106</th>\n",
       "      <th>feature_107</th>\n",
       "      <th>feature_108</th>\n",
       "      <th>feature_109</th>\n",
       "      <th>feature_110</th>\n",
       "      <th>feature_111</th>\n",
       "      <th>feature_112</th>\n",
       "      <th>feature_113</th>\n",
       "      <th>feature_114</th>\n",
       "      <th>feature_115</th>\n",
       "      <th>feature_116</th>\n",
       "      <th>feature_117</th>\n",
       "      <th>feature_118</th>\n",
       "      <th>feature_119</th>\n",
       "      <th>feature_120</th>\n",
       "      <th>feature_121</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-0.072435</td>\n",
       "      <td>0.907384</td>\n",
       "      <td>-0.016093</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.029670</td>\n",
       "      <td>0.059841</td>\n",
       "      <td>0.051777</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>-0.681273</td>\n",
       "      <td>0.145058</td>\n",
       "      <td>0.089122</td>\n",
       "      <td>0.049486</td>\n",
       "      <td>-0.318060</td>\n",
       "      <td>0.177395</td>\n",
       "      <td>-0.387883</td>\n",
       "      <td>0.265970</td>\n",
       "      <td>0.121219</td>\n",
       "      <td>0.113582</td>\n",
       "      <td>-0.224800</td>\n",
       "      <td>-0.374792</td>\n",
       "      <td>0.186911</td>\n",
       "      <td>0.176979</td>\n",
       "      <td>-0.160198</td>\n",
       "      <td>-0.278648</td>\n",
       "      <td>-0.225653</td>\n",
       "      <td>-0.369068</td>\n",
       "      <td>0.135483</td>\n",
       "      <td>0.160876</td>\n",
       "      <td>0.661321</td>\n",
       "      <td>1.519214</td>\n",
       "      <td>0.220560</td>\n",
       "      <td>0.250131</td>\n",
       "      <td>0.658498</td>\n",
       "      <td>1.218648</td>\n",
       "      <td>0.857525</td>\n",
       "      <td>1.479359</td>\n",
       "      <td>-0.039736</td>\n",
       "      <td>-0.056528</td>\n",
       "      <td>0.074542</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.416468</td>\n",
       "      <td>0.405081</td>\n",
       "      <td>-1.128115</td>\n",
       "      <td>-0.549991</td>\n",
       "      <td>-4.182615</td>\n",
       "      <td>0.402268</td>\n",
       "      <td>-1.338859</td>\n",
       "      <td>0.407107</td>\n",
       "      <td>-0.948048</td>\n",
       "      <td>-1.194013</td>\n",
       "      <td>-3.201351</td>\n",
       "      <td>0.405063</td>\n",
       "      <td>-0.940190</td>\n",
       "      <td>0.401656</td>\n",
       "      <td>-1.198852</td>\n",
       "      <td>-1.781693</td>\n",
       "      <td>-5.437945</td>\n",
       "      <td>0.399993</td>\n",
       "      <td>-1.669268</td>\n",
       "      <td>0.400736</td>\n",
       "      <td>-1.213217</td>\n",
       "      <td>-2.136375</td>\n",
       "      <td>-4.487282</td>\n",
       "      <td>0.407112</td>\n",
       "      <td>-2.441342</td>\n",
       "      <td>0.404433</td>\n",
       "      <td>-3.570573</td>\n",
       "      <td>-2.775455</td>\n",
       "      <td>-3.574643</td>\n",
       "      <td>0.335127</td>\n",
       "      <td>0.268776</td>\n",
       "      <td>-0.861141</td>\n",
       "      <td>-0.448878</td>\n",
       "      <td>-0.079883</td>\n",
       "      <td>2.029881</td>\n",
       "      <td>-0.084642</td>\n",
       "      <td>1.558818</td>\n",
       "      <td>-0.414970</td>\n",
       "      <td>0.621065</td>\n",
       "      <td>0.461488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.174792</td>\n",
       "      <td>1.584499</td>\n",
       "      <td>0.766387</td>\n",
       "      <td>1.285158</td>\n",
       "      <td>1.033984</td>\n",
       "      <td>1.783279</td>\n",
       "      <td>0.051777</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>1.499297</td>\n",
       "      <td>3.039524</td>\n",
       "      <td>0.089122</td>\n",
       "      <td>0.049486</td>\n",
       "      <td>2.179933</td>\n",
       "      <td>3.854239</td>\n",
       "      <td>1.073459</td>\n",
       "      <td>3.557826</td>\n",
       "      <td>0.121219</td>\n",
       "      <td>0.113582</td>\n",
       "      <td>2.837238</td>\n",
       "      <td>6.450960</td>\n",
       "      <td>0.186911</td>\n",
       "      <td>0.176979</td>\n",
       "      <td>2.645067</td>\n",
       "      <td>6.021124</td>\n",
       "      <td>3.025080</td>\n",
       "      <td>6.477267</td>\n",
       "      <td>0.135483</td>\n",
       "      <td>0.160876</td>\n",
       "      <td>-1.549399</td>\n",
       "      <td>-3.364569</td>\n",
       "      <td>0.220560</td>\n",
       "      <td>0.250131</td>\n",
       "      <td>-1.248018</td>\n",
       "      <td>-1.997793</td>\n",
       "      <td>-2.341352</td>\n",
       "      <td>-3.340664</td>\n",
       "      <td>0.935119</td>\n",
       "      <td>1.838518</td>\n",
       "      <td>-0.116732</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.515613</td>\n",
       "      <td>0.405081</td>\n",
       "      <td>-1.746285</td>\n",
       "      <td>-1.086886</td>\n",
       "      <td>-4.600595</td>\n",
       "      <td>0.402268</td>\n",
       "      <td>1.725111</td>\n",
       "      <td>0.407107</td>\n",
       "      <td>0.404081</td>\n",
       "      <td>1.060356</td>\n",
       "      <td>-1.730015</td>\n",
       "      <td>0.405063</td>\n",
       "      <td>0.271722</td>\n",
       "      <td>0.401656</td>\n",
       "      <td>-0.506093</td>\n",
       "      <td>-0.066825</td>\n",
       "      <td>-3.363314</td>\n",
       "      <td>0.399993</td>\n",
       "      <td>0.447638</td>\n",
       "      <td>0.400736</td>\n",
       "      <td>-0.274187</td>\n",
       "      <td>0.089311</td>\n",
       "      <td>-3.009552</td>\n",
       "      <td>0.407112</td>\n",
       "      <td>-1.137017</td>\n",
       "      <td>0.404433</td>\n",
       "      <td>-2.259732</td>\n",
       "      <td>-1.529622</td>\n",
       "      <td>-2.734496</td>\n",
       "      <td>0.335127</td>\n",
       "      <td>0.268776</td>\n",
       "      <td>4.642717</td>\n",
       "      <td>9.312244</td>\n",
       "      <td>3.284553</td>\n",
       "      <td>9.277431</td>\n",
       "      <td>4.822461</td>\n",
       "      <td>8.383666</td>\n",
       "      <td>5.002473</td>\n",
       "      <td>8.955219</td>\n",
       "      <td>0.234588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.709714</td>\n",
       "      <td>2.118171</td>\n",
       "      <td>-0.369931</td>\n",
       "      <td>-0.348596</td>\n",
       "      <td>0.296622</td>\n",
       "      <td>0.299438</td>\n",
       "      <td>0.051777</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>4.099429</td>\n",
       "      <td>3.917516</td>\n",
       "      <td>0.089122</td>\n",
       "      <td>0.049486</td>\n",
       "      <td>0.905728</td>\n",
       "      <td>0.962811</td>\n",
       "      <td>0.972802</td>\n",
       "      <td>1.657130</td>\n",
       "      <td>0.121219</td>\n",
       "      <td>0.113582</td>\n",
       "      <td>-2.210135</td>\n",
       "      <td>-3.089197</td>\n",
       "      <td>0.186911</td>\n",
       "      <td>0.176979</td>\n",
       "      <td>-2.131960</td>\n",
       "      <td>-3.041092</td>\n",
       "      <td>-2.693373</td>\n",
       "      <td>-3.462676</td>\n",
       "      <td>0.135483</td>\n",
       "      <td>0.160876</td>\n",
       "      <td>3.995880</td>\n",
       "      <td>5.789276</td>\n",
       "      <td>0.220560</td>\n",
       "      <td>0.250131</td>\n",
       "      <td>2.773185</td>\n",
       "      <td>3.504804</td>\n",
       "      <td>4.771656</td>\n",
       "      <td>5.519368</td>\n",
       "      <td>-0.471290</td>\n",
       "      <td>-0.537007</td>\n",
       "      <td>0.320031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241151</td>\n",
       "      <td>0.405081</td>\n",
       "      <td>-0.809838</td>\n",
       "      <td>-0.144045</td>\n",
       "      <td>-4.735334</td>\n",
       "      <td>0.402268</td>\n",
       "      <td>-1.338859</td>\n",
       "      <td>0.407107</td>\n",
       "      <td>0.871935</td>\n",
       "      <td>2.064282</td>\n",
       "      <td>-2.039274</td>\n",
       "      <td>0.405063</td>\n",
       "      <td>-0.940190</td>\n",
       "      <td>0.401656</td>\n",
       "      <td>-1.033695</td>\n",
       "      <td>-0.793241</td>\n",
       "      <td>-5.210143</td>\n",
       "      <td>0.399993</td>\n",
       "      <td>4.677016</td>\n",
       "      <td>0.400736</td>\n",
       "      <td>1.737405</td>\n",
       "      <td>4.957136</td>\n",
       "      <td>-2.705760</td>\n",
       "      <td>0.407112</td>\n",
       "      <td>-1.461705</td>\n",
       "      <td>0.404433</td>\n",
       "      <td>-2.498941</td>\n",
       "      <td>-1.440037</td>\n",
       "      <td>-4.057961</td>\n",
       "      <td>0.335127</td>\n",
       "      <td>0.268776</td>\n",
       "      <td>2.973217</td>\n",
       "      <td>-0.526521</td>\n",
       "      <td>2.396610</td>\n",
       "      <td>-1.310793</td>\n",
       "      <td>3.476880</td>\n",
       "      <td>-0.869526</td>\n",
       "      <td>3.239294</td>\n",
       "      <td>-0.649711</td>\n",
       "      <td>0.399935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.502757</td>\n",
       "      <td>3.113217</td>\n",
       "      <td>-1.373139</td>\n",
       "      <td>-1.416024</td>\n",
       "      <td>-0.851737</td>\n",
       "      <td>-0.893714</td>\n",
       "      <td>0.051777</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>3.011988</td>\n",
       "      <td>2.916267</td>\n",
       "      <td>0.089122</td>\n",
       "      <td>0.049486</td>\n",
       "      <td>-7.231256</td>\n",
       "      <td>-7.629690</td>\n",
       "      <td>-8.050878</td>\n",
       "      <td>-10.851798</td>\n",
       "      <td>0.121219</td>\n",
       "      <td>0.113582</td>\n",
       "      <td>2.788762</td>\n",
       "      <td>4.033585</td>\n",
       "      <td>0.186911</td>\n",
       "      <td>0.176979</td>\n",
       "      <td>2.808164</td>\n",
       "      <td>4.259403</td>\n",
       "      <td>3.785195</td>\n",
       "      <td>5.225638</td>\n",
       "      <td>0.135483</td>\n",
       "      <td>0.160876</td>\n",
       "      <td>-1.246608</td>\n",
       "      <td>-1.994695</td>\n",
       "      <td>0.220560</td>\n",
       "      <td>0.250131</td>\n",
       "      <td>-7.002472</td>\n",
       "      <td>-8.617317</td>\n",
       "      <td>-11.210966</td>\n",
       "      <td>-12.684605</td>\n",
       "      <td>0.381427</td>\n",
       "      <td>0.448411</td>\n",
       "      <td>-1.420726</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.515613</td>\n",
       "      <td>0.405081</td>\n",
       "      <td>0.866417</td>\n",
       "      <td>1.984980</td>\n",
       "      <td>-2.864662</td>\n",
       "      <td>0.402268</td>\n",
       "      <td>1.424264</td>\n",
       "      <td>0.407107</td>\n",
       "      <td>0.828548</td>\n",
       "      <td>1.324580</td>\n",
       "      <td>-1.728239</td>\n",
       "      <td>0.405063</td>\n",
       "      <td>-0.007388</td>\n",
       "      <td>0.401656</td>\n",
       "      <td>-0.358588</td>\n",
       "      <td>-0.065456</td>\n",
       "      <td>-3.535219</td>\n",
       "      <td>0.399993</td>\n",
       "      <td>0.120311</td>\n",
       "      <td>0.400736</td>\n",
       "      <td>1.794847</td>\n",
       "      <td>4.585189</td>\n",
       "      <td>-2.126851</td>\n",
       "      <td>0.407112</td>\n",
       "      <td>-1.711268</td>\n",
       "      <td>0.404433</td>\n",
       "      <td>0.343049</td>\n",
       "      <td>1.409616</td>\n",
       "      <td>-2.256591</td>\n",
       "      <td>0.335127</td>\n",
       "      <td>0.268776</td>\n",
       "      <td>3.622885</td>\n",
       "      <td>3.545477</td>\n",
       "      <td>2.138942</td>\n",
       "      <td>2.806542</td>\n",
       "      <td>3.158734</td>\n",
       "      <td>2.318425</td>\n",
       "      <td>3.398149</td>\n",
       "      <td>2.709654</td>\n",
       "      <td>0.264698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.946880</td>\n",
       "      <td>0.340473</td>\n",
       "      <td>-0.767558</td>\n",
       "      <td>-0.533843</td>\n",
       "      <td>-0.680819</td>\n",
       "      <td>-0.488935</td>\n",
       "      <td>0.051777</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>1.551766</td>\n",
       "      <td>0.660335</td>\n",
       "      <td>0.089122</td>\n",
       "      <td>0.049486</td>\n",
       "      <td>1.931099</td>\n",
       "      <td>1.211479</td>\n",
       "      <td>1.123032</td>\n",
       "      <td>0.855152</td>\n",
       "      <td>0.121219</td>\n",
       "      <td>0.113582</td>\n",
       "      <td>-1.930407</td>\n",
       "      <td>-2.149725</td>\n",
       "      <td>0.186911</td>\n",
       "      <td>0.176979</td>\n",
       "      <td>-1.902104</td>\n",
       "      <td>-2.224361</td>\n",
       "      <td>-2.381870</td>\n",
       "      <td>-2.473654</td>\n",
       "      <td>0.135483</td>\n",
       "      <td>0.160876</td>\n",
       "      <td>2.020021</td>\n",
       "      <td>2.037006</td>\n",
       "      <td>0.220560</td>\n",
       "      <td>0.250131</td>\n",
       "      <td>2.912416</td>\n",
       "      <td>2.636101</td>\n",
       "      <td>3.186550</td>\n",
       "      <td>2.560053</td>\n",
       "      <td>-1.051923</td>\n",
       "      <td>-0.909131</td>\n",
       "      <td>0.442439</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108290</td>\n",
       "      <td>0.405081</td>\n",
       "      <td>-0.851850</td>\n",
       "      <td>-0.276610</td>\n",
       "      <td>-4.070458</td>\n",
       "      <td>0.402268</td>\n",
       "      <td>-1.338859</td>\n",
       "      <td>0.407107</td>\n",
       "      <td>-0.233028</td>\n",
       "      <td>-0.267155</td>\n",
       "      <td>-1.105017</td>\n",
       "      <td>0.405063</td>\n",
       "      <td>-0.940190</td>\n",
       "      <td>0.401656</td>\n",
       "      <td>-0.922656</td>\n",
       "      <td>-0.975064</td>\n",
       "      <td>-2.516703</td>\n",
       "      <td>0.399993</td>\n",
       "      <td>-0.402877</td>\n",
       "      <td>0.400736</td>\n",
       "      <td>-0.256001</td>\n",
       "      <td>-0.244713</td>\n",
       "      <td>-2.048816</td>\n",
       "      <td>0.407112</td>\n",
       "      <td>-1.987099</td>\n",
       "      <td>0.404433</td>\n",
       "      <td>-2.363268</td>\n",
       "      <td>-1.963630</td>\n",
       "      <td>-2.128611</td>\n",
       "      <td>0.335127</td>\n",
       "      <td>0.268776</td>\n",
       "      <td>0.983045</td>\n",
       "      <td>-0.294384</td>\n",
       "      <td>1.185835</td>\n",
       "      <td>0.391676</td>\n",
       "      <td>1.792909</td>\n",
       "      <td>0.311355</td>\n",
       "      <td>1.331057</td>\n",
       "      <td>-0.075683</td>\n",
       "      <td>0.281896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339686</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.056345</td>\n",
       "      <td>-1.737907</td>\n",
       "      <td>0.505500</td>\n",
       "      <td>0.748200</td>\n",
       "      <td>0.708484</td>\n",
       "      <td>1.092987</td>\n",
       "      <td>-0.120841</td>\n",
       "      <td>-0.019308</td>\n",
       "      <td>-0.954804</td>\n",
       "      <td>-0.134921</td>\n",
       "      <td>0.009317</td>\n",
       "      <td>0.489980</td>\n",
       "      <td>0.064708</td>\n",
       "      <td>0.668747</td>\n",
       "      <td>-0.414998</td>\n",
       "      <td>0.207284</td>\n",
       "      <td>0.415589</td>\n",
       "      <td>0.976431</td>\n",
       "      <td>0.393777</td>\n",
       "      <td>0.917300</td>\n",
       "      <td>0.745153</td>\n",
       "      <td>0.887400</td>\n",
       "      <td>0.734191</td>\n",
       "      <td>1.688399</td>\n",
       "      <td>0.744480</td>\n",
       "      <td>1.579522</td>\n",
       "      <td>-0.018779</td>\n",
       "      <td>-0.069620</td>\n",
       "      <td>-0.267616</td>\n",
       "      <td>-0.510096</td>\n",
       "      <td>-0.053633</td>\n",
       "      <td>-0.189342</td>\n",
       "      <td>-0.130353</td>\n",
       "      <td>-0.237184</td>\n",
       "      <td>-0.314593</td>\n",
       "      <td>-0.466690</td>\n",
       "      <td>0.801226</td>\n",
       "      <td>1.401781</td>\n",
       "      <td>-0.124425</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.515613</td>\n",
       "      <td>0.736766</td>\n",
       "      <td>-0.679716</td>\n",
       "      <td>-1.086886</td>\n",
       "      <td>2.348918</td>\n",
       "      <td>1.302328</td>\n",
       "      <td>4.061902</td>\n",
       "      <td>2.076149</td>\n",
       "      <td>2.408293</td>\n",
       "      <td>3.325328</td>\n",
       "      <td>0.840050</td>\n",
       "      <td>3.686090</td>\n",
       "      <td>9.980197</td>\n",
       "      <td>3.938576</td>\n",
       "      <td>6.275051</td>\n",
       "      <td>10.366701</td>\n",
       "      <td>2.654053</td>\n",
       "      <td>1.074544</td>\n",
       "      <td>2.610472</td>\n",
       "      <td>0.916473</td>\n",
       "      <td>1.199919</td>\n",
       "      <td>2.487042</td>\n",
       "      <td>0.978493</td>\n",
       "      <td>2.310989</td>\n",
       "      <td>7.364301</td>\n",
       "      <td>3.290777</td>\n",
       "      <td>4.683031</td>\n",
       "      <td>6.407106</td>\n",
       "      <td>2.006850</td>\n",
       "      <td>-2.111964</td>\n",
       "      <td>-1.381768</td>\n",
       "      <td>-2.664888</td>\n",
       "      <td>-1.507184</td>\n",
       "      <td>-1.596155</td>\n",
       "      <td>-0.389234</td>\n",
       "      <td>-2.665026</td>\n",
       "      <td>-0.150872</td>\n",
       "      <td>-2.828226</td>\n",
       "      <td>-0.988578</td>\n",
       "      <td>0.621705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339687</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.056996</td>\n",
       "      <td>-1.812237</td>\n",
       "      <td>-0.924278</td>\n",
       "      <td>-1.196169</td>\n",
       "      <td>-0.213705</td>\n",
       "      <td>-0.278002</td>\n",
       "      <td>-0.090617</td>\n",
       "      <td>-0.001331</td>\n",
       "      <td>-1.182008</td>\n",
       "      <td>-0.457558</td>\n",
       "      <td>0.278413</td>\n",
       "      <td>1.037322</td>\n",
       "      <td>0.898563</td>\n",
       "      <td>1.579834</td>\n",
       "      <td>-0.639630</td>\n",
       "      <td>-0.381794</td>\n",
       "      <td>0.460556</td>\n",
       "      <td>0.984787</td>\n",
       "      <td>0.524938</td>\n",
       "      <td>1.079491</td>\n",
       "      <td>1.235870</td>\n",
       "      <td>1.325564</td>\n",
       "      <td>1.376549</td>\n",
       "      <td>2.838635</td>\n",
       "      <td>0.557296</td>\n",
       "      <td>1.077394</td>\n",
       "      <td>-0.100217</td>\n",
       "      <td>-0.296256</td>\n",
       "      <td>-0.607707</td>\n",
       "      <td>-1.263362</td>\n",
       "      <td>-0.220998</td>\n",
       "      <td>-0.715605</td>\n",
       "      <td>-0.431608</td>\n",
       "      <td>-0.740487</td>\n",
       "      <td>-0.870111</td>\n",
       "      <td>-1.263653</td>\n",
       "      <td>0.351818</td>\n",
       "      <td>0.589322</td>\n",
       "      <td>-1.200103</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.515613</td>\n",
       "      <td>-0.191956</td>\n",
       "      <td>-0.264677</td>\n",
       "      <td>-1.086886</td>\n",
       "      <td>0.682386</td>\n",
       "      <td>1.838170</td>\n",
       "      <td>5.416202</td>\n",
       "      <td>2.954495</td>\n",
       "      <td>2.971834</td>\n",
       "      <td>3.964150</td>\n",
       "      <td>1.609513</td>\n",
       "      <td>1.127442</td>\n",
       "      <td>3.833036</td>\n",
       "      <td>1.411515</td>\n",
       "      <td>2.028152</td>\n",
       "      <td>3.756484</td>\n",
       "      <td>0.737059</td>\n",
       "      <td>1.993668</td>\n",
       "      <td>3.724463</td>\n",
       "      <td>1.503378</td>\n",
       "      <td>1.768988</td>\n",
       "      <td>3.051794</td>\n",
       "      <td>2.029241</td>\n",
       "      <td>0.646945</td>\n",
       "      <td>2.718490</td>\n",
       "      <td>1.109053</td>\n",
       "      <td>1.618548</td>\n",
       "      <td>1.956388</td>\n",
       "      <td>0.536486</td>\n",
       "      <td>-1.262596</td>\n",
       "      <td>-2.730051</td>\n",
       "      <td>-0.429919</td>\n",
       "      <td>0.199522</td>\n",
       "      <td>-1.101932</td>\n",
       "      <td>-2.804399</td>\n",
       "      <td>-1.490832</td>\n",
       "      <td>-1.556948</td>\n",
       "      <td>-0.700753</td>\n",
       "      <td>-0.212120</td>\n",
       "      <td>0.552255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339688</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.503847</td>\n",
       "      <td>-1.100075</td>\n",
       "      <td>-2.913538</td>\n",
       "      <td>-4.240680</td>\n",
       "      <td>-1.644136</td>\n",
       "      <td>-2.356616</td>\n",
       "      <td>0.135332</td>\n",
       "      <td>0.386200</td>\n",
       "      <td>-0.264494</td>\n",
       "      <td>0.482585</td>\n",
       "      <td>0.443870</td>\n",
       "      <td>1.468477</td>\n",
       "      <td>-0.223897</td>\n",
       "      <td>0.223839</td>\n",
       "      <td>0.154670</td>\n",
       "      <td>1.206079</td>\n",
       "      <td>0.778559</td>\n",
       "      <td>1.683046</td>\n",
       "      <td>0.972213</td>\n",
       "      <td>2.014294</td>\n",
       "      <td>1.455546</td>\n",
       "      <td>1.596061</td>\n",
       "      <td>0.871953</td>\n",
       "      <td>1.871087</td>\n",
       "      <td>1.215859</td>\n",
       "      <td>2.382885</td>\n",
       "      <td>-0.078399</td>\n",
       "      <td>-0.244728</td>\n",
       "      <td>-0.525867</td>\n",
       "      <td>-1.095226</td>\n",
       "      <td>-0.177362</td>\n",
       "      <td>-0.596454</td>\n",
       "      <td>-0.356032</td>\n",
       "      <td>-0.627383</td>\n",
       "      <td>-0.736037</td>\n",
       "      <td>-1.085904</td>\n",
       "      <td>0.307759</td>\n",
       "      <td>0.532739</td>\n",
       "      <td>-2.667661</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044381</td>\n",
       "      <td>0.235907</td>\n",
       "      <td>-0.472144</td>\n",
       "      <td>0.253802</td>\n",
       "      <td>2.122354</td>\n",
       "      <td>5.893846</td>\n",
       "      <td>4.421612</td>\n",
       "      <td>3.992727</td>\n",
       "      <td>2.242799</td>\n",
       "      <td>4.413936</td>\n",
       "      <td>4.729392</td>\n",
       "      <td>2.794564</td>\n",
       "      <td>1.791385</td>\n",
       "      <td>1.166674</td>\n",
       "      <td>0.709058</td>\n",
       "      <td>2.628382</td>\n",
       "      <td>1.730328</td>\n",
       "      <td>5.595063</td>\n",
       "      <td>3.353163</td>\n",
       "      <td>2.447881</td>\n",
       "      <td>1.412460</td>\n",
       "      <td>4.234723</td>\n",
       "      <td>5.976995</td>\n",
       "      <td>1.930808</td>\n",
       "      <td>1.168066</td>\n",
       "      <td>1.061646</td>\n",
       "      <td>0.288447</td>\n",
       "      <td>1.607813</td>\n",
       "      <td>1.517134</td>\n",
       "      <td>-1.006585</td>\n",
       "      <td>-2.641598</td>\n",
       "      <td>0.190909</td>\n",
       "      <td>0.822403</td>\n",
       "      <td>-1.023421</td>\n",
       "      <td>-3.202535</td>\n",
       "      <td>-1.221664</td>\n",
       "      <td>-1.683171</td>\n",
       "      <td>-0.508524</td>\n",
       "      <td>-0.465144</td>\n",
       "      <td>0.511799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339689</th>\n",
       "      <td>-1</td>\n",
       "      <td>-0.891175</td>\n",
       "      <td>-0.537115</td>\n",
       "      <td>-1.667383</td>\n",
       "      <td>-2.084328</td>\n",
       "      <td>-1.204993</td>\n",
       "      <td>-1.542291</td>\n",
       "      <td>-0.257147</td>\n",
       "      <td>-0.283362</td>\n",
       "      <td>-0.737233</td>\n",
       "      <td>-0.186265</td>\n",
       "      <td>0.047414</td>\n",
       "      <td>0.343221</td>\n",
       "      <td>-1.255220</td>\n",
       "      <td>-1.020496</td>\n",
       "      <td>-0.948273</td>\n",
       "      <td>-1.095965</td>\n",
       "      <td>-0.196390</td>\n",
       "      <td>-0.388374</td>\n",
       "      <td>-0.654737</td>\n",
       "      <td>-1.125760</td>\n",
       "      <td>-0.535635</td>\n",
       "      <td>-0.438846</td>\n",
       "      <td>-0.617029</td>\n",
       "      <td>-1.140195</td>\n",
       "      <td>-0.792341</td>\n",
       "      <td>-1.281933</td>\n",
       "      <td>0.251300</td>\n",
       "      <td>0.487738</td>\n",
       "      <td>0.602909</td>\n",
       "      <td>1.108604</td>\n",
       "      <td>0.464371</td>\n",
       "      <td>0.990504</td>\n",
       "      <td>0.421657</td>\n",
       "      <td>0.615037</td>\n",
       "      <td>0.756155</td>\n",
       "      <td>1.035343</td>\n",
       "      <td>-1.952340</td>\n",
       "      <td>-2.857356</td>\n",
       "      <td>0.192883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177205</td>\n",
       "      <td>-0.776090</td>\n",
       "      <td>-0.730355</td>\n",
       "      <td>-0.181365</td>\n",
       "      <td>-1.358239</td>\n",
       "      <td>0.138346</td>\n",
       "      <td>-1.338859</td>\n",
       "      <td>-0.421212</td>\n",
       "      <td>0.041817</td>\n",
       "      <td>0.051445</td>\n",
       "      <td>0.749679</td>\n",
       "      <td>-2.016957</td>\n",
       "      <td>-0.940190</td>\n",
       "      <td>-1.126325</td>\n",
       "      <td>-0.932382</td>\n",
       "      <td>-0.938882</td>\n",
       "      <td>-1.198695</td>\n",
       "      <td>0.213771</td>\n",
       "      <td>0.895232</td>\n",
       "      <td>0.225944</td>\n",
       "      <td>0.255862</td>\n",
       "      <td>0.831870</td>\n",
       "      <td>0.844081</td>\n",
       "      <td>-1.786587</td>\n",
       "      <td>-1.550764</td>\n",
       "      <td>-1.768293</td>\n",
       "      <td>-2.143003</td>\n",
       "      <td>-1.692607</td>\n",
       "      <td>-0.934236</td>\n",
       "      <td>-1.341723</td>\n",
       "      <td>-4.607402</td>\n",
       "      <td>-0.663873</td>\n",
       "      <td>-2.311890</td>\n",
       "      <td>-1.181335</td>\n",
       "      <td>-4.885251</td>\n",
       "      <td>-1.580776</td>\n",
       "      <td>-3.207101</td>\n",
       "      <td>-0.872670</td>\n",
       "      <td>-2.332864</td>\n",
       "      <td>0.511681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339690</th>\n",
       "      <td>-1</td>\n",
       "      <td>-0.716377</td>\n",
       "      <td>-0.899515</td>\n",
       "      <td>1.218082</td>\n",
       "      <td>1.100947</td>\n",
       "      <td>0.424356</td>\n",
       "      <td>0.376625</td>\n",
       "      <td>0.468483</td>\n",
       "      <td>0.473513</td>\n",
       "      <td>-0.592671</td>\n",
       "      <td>-0.516213</td>\n",
       "      <td>-1.326483</td>\n",
       "      <td>-2.175853</td>\n",
       "      <td>-1.474398</td>\n",
       "      <td>-1.217308</td>\n",
       "      <td>0.325598</td>\n",
       "      <td>0.382527</td>\n",
       "      <td>-0.960278</td>\n",
       "      <td>-1.329177</td>\n",
       "      <td>-0.496640</td>\n",
       "      <td>-0.582520</td>\n",
       "      <td>-2.534846</td>\n",
       "      <td>-1.524883</td>\n",
       "      <td>-0.437766</td>\n",
       "      <td>-0.498266</td>\n",
       "      <td>-0.581705</td>\n",
       "      <td>-0.615341</td>\n",
       "      <td>0.582210</td>\n",
       "      <td>0.828193</td>\n",
       "      <td>0.942027</td>\n",
       "      <td>1.161996</td>\n",
       "      <td>0.652003</td>\n",
       "      <td>0.953852</td>\n",
       "      <td>1.162341</td>\n",
       "      <td>1.227461</td>\n",
       "      <td>1.821790</td>\n",
       "      <td>1.785505</td>\n",
       "      <td>-0.417598</td>\n",
       "      <td>-0.441331</td>\n",
       "      <td>1.719646</td>\n",
       "      <td>...</td>\n",
       "      <td>2.457859</td>\n",
       "      <td>-0.017084</td>\n",
       "      <td>0.784834</td>\n",
       "      <td>1.766389</td>\n",
       "      <td>-0.232150</td>\n",
       "      <td>0.993562</td>\n",
       "      <td>-1.338859</td>\n",
       "      <td>1.355855</td>\n",
       "      <td>0.735304</td>\n",
       "      <td>-1.194013</td>\n",
       "      <td>0.104551</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>-0.940190</td>\n",
       "      <td>0.241637</td>\n",
       "      <td>0.017372</td>\n",
       "      <td>-1.781693</td>\n",
       "      <td>-0.706729</td>\n",
       "      <td>1.559129</td>\n",
       "      <td>1.765860</td>\n",
       "      <td>0.833879</td>\n",
       "      <td>1.061245</td>\n",
       "      <td>2.059206</td>\n",
       "      <td>0.512595</td>\n",
       "      <td>0.117964</td>\n",
       "      <td>0.660498</td>\n",
       "      <td>0.137808</td>\n",
       "      <td>0.505856</td>\n",
       "      <td>0.821629</td>\n",
       "      <td>-0.342785</td>\n",
       "      <td>-0.181725</td>\n",
       "      <td>-1.829824</td>\n",
       "      <td>-0.046428</td>\n",
       "      <td>-1.117639</td>\n",
       "      <td>-0.256306</td>\n",
       "      <td>-2.281750</td>\n",
       "      <td>-0.056898</td>\n",
       "      <td>-1.177024</td>\n",
       "      <td>0.124740</td>\n",
       "      <td>-0.808561</td>\n",
       "      <td>0.182789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1339691 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_0  feature_1  feature_2  ...  feature_128  feature_129         4\n",
       "0               -1  -0.072435   0.907384  ...    -0.414970     0.621065  0.461488\n",
       "1                1   0.174792   1.584499  ...     5.002473     8.955219  0.234588\n",
       "2               -1   1.709714   2.118171  ...     3.239294    -0.649711  0.399935\n",
       "3                1   2.502757   3.113217  ...     3.398149     2.709654  0.264698\n",
       "4               -1   0.946880   0.340473  ...     1.331057    -0.075683  0.281896\n",
       "...            ...        ...        ...  ...          ...          ...       ...\n",
       "1339686          1  -2.056345  -1.737907  ...    -2.828226    -0.988578  0.621705\n",
       "1339687          1  -2.056996  -1.812237  ...    -0.700753    -0.212120  0.552255\n",
       "1339688          1  -1.503847  -1.100075  ...    -0.508524    -0.465144  0.511799\n",
       "1339689         -1  -0.891175  -0.537115  ...    -0.872670    -2.332864  0.511681\n",
       "1339690         -1  -0.716377  -0.899515  ...     0.124740    -0.808561  0.182789\n",
       "\n",
       "[1339691 rows x 131 columns]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df.loc[folds_list_train2_unique, FEATURES_LIST_TOTRAIN].reset_index(drop=True), pd.DataFrame(model_xgb.predict_proba(df.loc[folds_list_train2_unique, FEATURES_LIST_TOTRAIN]0))[4]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used for fitting:\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.6, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.02, max_delta_step=None, max_depth=10,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=42, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=0.5, tree_method='hist',\n",
      "              validate_parameters=None, verbosity=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:12:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/janestreet/lib/python3.8/site-packages/sklearn/base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier_wrapper(params=None)"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapped.fit(pd.concat([df.loc[folds_list_train2_unique, FEATURES_LIST_TOTRAIN].reset_index(drop=True), pd.DataFrame(model_xgb.predict_proba(df.loc[folds_list_train2_unique, FEATURES_LIST_TOTRAIN]))[4]], axis=1), (df.loc[folds_list_train2_unique]['resp'] > 0).astype(np.byte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'weight', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp',\n",
       "       'feature_0', 'feature_1', 'feature_2',\n",
       "       ...\n",
       "       'feature_123', 'feature_124', 'feature_125', 'feature_126',\n",
       "       'feature_127', 'feature_128', 'feature_129', 'ts_id', 'resp_positive',\n",
       "       'fold_number'],\n",
       "      dtype='object', length=140)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict called\n",
      "Type of X:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X:\n",
      "(141102, 140)\n",
      "Type of y:\n",
      "<class 'numpy.ndarray'>\n",
      "model fitted ?\n",
      "True\n",
      "y is not None\n",
      "Feature importances for split 0:\n",
      "             Importance  % feat importance cumulé\n",
      "feature_45     0.014024                  0.014024\n",
      "feature_42     0.013995                  0.028019\n",
      "feature_43     0.013962                  0.041982\n",
      "feature_41     0.013421                  0.055403\n",
      "feature_44     0.012373                  0.067776\n",
      "feature_63     0.012347                  0.080123\n",
      "feature_39     0.012051                  0.092174\n",
      "feature_27     0.011836                  0.104010\n",
      "feature_61     0.011470                  0.115480\n",
      "feature_5      0.011229                  0.126708\n",
      "feature_62     0.011206                  0.137914\n",
      "feature_6      0.011047                  0.148961\n",
      "feature_60     0.010782                  0.159743\n",
      "feature_40     0.010469                  0.170212\n",
      "feature_3      0.010120                  0.180332\n",
      "feature_4      0.010056                  0.190388\n",
      "feature_38     0.010022                  0.200410\n",
      "feature_83     0.009997                  0.210407\n",
      "4              0.009995                  0.220402\n",
      "feature_107    0.009907                  0.230309\n",
      "feature_119    0.009679                  0.239988\n",
      "feature_37     0.009530                  0.249518\n",
      "feature_77     0.009309                  0.258828\n",
      "feature_114    0.009164                  0.267992\n",
      "feature_124    0.009016                  0.277008\n",
      "feature_55     0.008998                  0.286006\n",
      "feature_95     0.008997                  0.295003\n",
      "feature_120    0.008920                  0.303922\n",
      "feature_64     0.008903                  0.312825\n",
      "feature_113    0.008668                  0.321493\n",
      "feature_102    0.008564                  0.330058\n",
      "feature_68     0.008490                  0.338548\n",
      "feature_121    0.008453                  0.347001\n",
      "feature_90     0.008363                  0.355365\n",
      "feature_89     0.008300                  0.363665\n",
      "feature_66     0.008215                  0.371880\n",
      "feature_57     0.008202                  0.380082\n",
      "feature_125    0.008124                  0.388206\n",
      "feature_126    0.007933                  0.396139\n",
      "feature_101    0.007916                  0.404055\n",
      "feature_71     0.007868                  0.411923\n",
      "feature_0      0.007826                  0.419749\n",
      "feature_20     0.007765                  0.427514\n",
      "feature_108    0.007745                  0.435259\n",
      "feature_78     0.007570                  0.442828\n",
      "feature_67     0.007546                  0.450374\n",
      "feature_69     0.007498                  0.457872\n",
      "feature_28     0.007477                  0.465349\n",
      "feature_84     0.007455                  0.472804\n",
      "feature_92     0.007429                  0.480233\n",
      "feature_65     0.007415                  0.487648\n",
      "feature_26     0.007384                  0.495031\n",
      "feature_18     0.007357                  0.502388\n",
      "feature_70     0.007312                  0.509701\n",
      "feature_8      0.007308                  0.517009\n",
      "feature_58     0.007237                  0.524245\n",
      "feature_127    0.007235                  0.531480\n",
      "feature_110    0.007156                  0.538636\n",
      "feature_116    0.007136                  0.545772\n",
      "feature_104    0.007088                  0.552860\n",
      "feature_17     0.007028                  0.559888\n",
      "feature_96     0.007021                  0.566909\n",
      "feature_31     0.006970                  0.573879\n",
      "feature_7      0.006960                  0.580839\n",
      "feature_128    0.006929                  0.587768\n",
      "feature_59     0.006903                  0.594671\n",
      "feature_33     0.006885                  0.601556\n",
      "feature_36     0.006867                  0.608423\n",
      "feature_24     0.006806                  0.615228\n",
      "feature_53     0.006797                  0.622026\n",
      "feature_23     0.006764                  0.628790\n",
      "feature_22     0.006741                  0.635531\n",
      "feature_49     0.006717                  0.642249\n",
      "feature_72     0.006702                  0.648951\n",
      "feature_50     0.006681                  0.655632\n",
      "feature_12     0.006677                  0.662309\n",
      "feature_98     0.006650                  0.668960\n",
      "feature_21     0.006620                  0.675579\n",
      "feature_32     0.006614                  0.682193\n",
      "feature_86     0.006606                  0.688799\n",
      "feature_30     0.006606                  0.695405\n",
      "feature_129    0.006603                  0.702008\n",
      "feature_10     0.006567                  0.708575\n",
      "feature_122    0.006532                  0.715107\n",
      "feature_25     0.006524                  0.721631\n",
      "feature_47     0.006494                  0.728125\n",
      "feature_48     0.006487                  0.734612\n",
      "feature_35     0.006478                  0.741090\n",
      "feature_34     0.006456                  0.747546\n",
      "feature_19     0.006445                  0.753991\n",
      "feature_117    0.006414                  0.760405\n",
      "feature_111    0.006383                  0.766788\n",
      "feature_80     0.006348                  0.773136\n",
      "feature_105    0.006346                  0.779482\n",
      "feature_46     0.006331                  0.785813\n",
      "feature_56     0.006298                  0.792111\n",
      "feature_54     0.006296                  0.798407\n",
      "feature_93     0.006268                  0.804676\n",
      "feature_51     0.006193                  0.810869\n",
      "feature_91     0.006153                  0.817022\n",
      "feature_123    0.006144                  0.823167\n",
      "feature_9      0.006122                  0.829289\n",
      "feature_29     0.006107                  0.835396\n",
      "feature_112    0.006097                  0.841493\n",
      "feature_109    0.006080                  0.847573\n",
      "feature_99     0.006071                  0.853644\n",
      "feature_14     0.006066                  0.859711\n",
      "feature_11     0.006057                  0.865768\n",
      "feature_87     0.006039                  0.871807\n",
      "feature_118    0.006011                  0.877818\n",
      "feature_88     0.006005                  0.883823\n",
      "feature_16     0.005987                  0.889810\n",
      "feature_2      0.005976                  0.895785\n",
      "feature_1      0.005959                  0.901744\n",
      "feature_94     0.005929                  0.907673\n",
      "feature_115    0.005928                  0.913601\n",
      "feature_73     0.005924                  0.919525\n",
      "feature_100    0.005917                  0.925442\n",
      "feature_82     0.005889                  0.931331\n",
      "feature_106    0.005848                  0.937179\n",
      "feature_81     0.005838                  0.943017\n",
      "feature_103    0.005833                  0.948850\n",
      "feature_85     0.005831                  0.954682\n",
      "feature_13     0.005819                  0.960500\n",
      "feature_79     0.005789                  0.966290\n",
      "feature_76     0.005788                  0.972077\n",
      "feature_97     0.005764                  0.977841\n",
      "feature_74     0.005666                  0.983506\n",
      "feature_75     0.005538                  0.989044\n",
      "feature_52     0.005521                  0.994565\n",
      "feature_15     0.005435                  1.000000\n",
      "predict called\n",
      "Type of X:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X:\n",
      "(142450, 140)\n",
      "Type of y:\n",
      "<class 'numpy.ndarray'>\n",
      "model fitted ?\n",
      "True\n",
      "y is not None\n",
      "Feature importances for split 1:\n",
      "             Importance  % feat importance cumulé\n",
      "feature_45     0.014024                  0.014024\n",
      "feature_42     0.013995                  0.028019\n",
      "feature_43     0.013962                  0.041982\n",
      "feature_41     0.013421                  0.055403\n",
      "feature_44     0.012373                  0.067776\n",
      "feature_63     0.012347                  0.080123\n",
      "feature_39     0.012051                  0.092174\n",
      "feature_27     0.011836                  0.104010\n",
      "feature_61     0.011470                  0.115480\n",
      "feature_5      0.011229                  0.126708\n",
      "feature_62     0.011206                  0.137914\n",
      "feature_6      0.011047                  0.148961\n",
      "feature_60     0.010782                  0.159743\n",
      "feature_40     0.010469                  0.170212\n",
      "feature_3      0.010120                  0.180332\n",
      "feature_4      0.010056                  0.190388\n",
      "feature_38     0.010022                  0.200410\n",
      "feature_83     0.009997                  0.210407\n",
      "4              0.009995                  0.220402\n",
      "feature_107    0.009907                  0.230309\n",
      "feature_119    0.009679                  0.239988\n",
      "feature_37     0.009530                  0.249518\n",
      "feature_77     0.009309                  0.258828\n",
      "feature_114    0.009164                  0.267992\n",
      "feature_124    0.009016                  0.277008\n",
      "feature_55     0.008998                  0.286006\n",
      "feature_95     0.008997                  0.295003\n",
      "feature_120    0.008920                  0.303922\n",
      "feature_64     0.008903                  0.312825\n",
      "feature_113    0.008668                  0.321493\n",
      "feature_102    0.008564                  0.330058\n",
      "feature_68     0.008490                  0.338548\n",
      "feature_121    0.008453                  0.347001\n",
      "feature_90     0.008363                  0.355365\n",
      "feature_89     0.008300                  0.363665\n",
      "feature_66     0.008215                  0.371880\n",
      "feature_57     0.008202                  0.380082\n",
      "feature_125    0.008124                  0.388206\n",
      "feature_126    0.007933                  0.396139\n",
      "feature_101    0.007916                  0.404055\n",
      "feature_71     0.007868                  0.411923\n",
      "feature_0      0.007826                  0.419749\n",
      "feature_20     0.007765                  0.427514\n",
      "feature_108    0.007745                  0.435259\n",
      "feature_78     0.007570                  0.442828\n",
      "feature_67     0.007546                  0.450374\n",
      "feature_69     0.007498                  0.457872\n",
      "feature_28     0.007477                  0.465349\n",
      "feature_84     0.007455                  0.472804\n",
      "feature_92     0.007429                  0.480233\n",
      "feature_65     0.007415                  0.487648\n",
      "feature_26     0.007384                  0.495031\n",
      "feature_18     0.007357                  0.502388\n",
      "feature_70     0.007312                  0.509701\n",
      "feature_8      0.007308                  0.517009\n",
      "feature_58     0.007237                  0.524245\n",
      "feature_127    0.007235                  0.531480\n",
      "feature_110    0.007156                  0.538636\n",
      "feature_116    0.007136                  0.545772\n",
      "feature_104    0.007088                  0.552860\n",
      "feature_17     0.007028                  0.559888\n",
      "feature_96     0.007021                  0.566909\n",
      "feature_31     0.006970                  0.573879\n",
      "feature_7      0.006960                  0.580839\n",
      "feature_128    0.006929                  0.587768\n",
      "feature_59     0.006903                  0.594671\n",
      "feature_33     0.006885                  0.601556\n",
      "feature_36     0.006867                  0.608423\n",
      "feature_24     0.006806                  0.615228\n",
      "feature_53     0.006797                  0.622026\n",
      "feature_23     0.006764                  0.628790\n",
      "feature_22     0.006741                  0.635531\n",
      "feature_49     0.006717                  0.642249\n",
      "feature_72     0.006702                  0.648951\n",
      "feature_50     0.006681                  0.655632\n",
      "feature_12     0.006677                  0.662309\n",
      "feature_98     0.006650                  0.668960\n",
      "feature_21     0.006620                  0.675579\n",
      "feature_32     0.006614                  0.682193\n",
      "feature_86     0.006606                  0.688799\n",
      "feature_30     0.006606                  0.695405\n",
      "feature_129    0.006603                  0.702008\n",
      "feature_10     0.006567                  0.708575\n",
      "feature_122    0.006532                  0.715107\n",
      "feature_25     0.006524                  0.721631\n",
      "feature_47     0.006494                  0.728125\n",
      "feature_48     0.006487                  0.734612\n",
      "feature_35     0.006478                  0.741090\n",
      "feature_34     0.006456                  0.747546\n",
      "feature_19     0.006445                  0.753991\n",
      "feature_117    0.006414                  0.760405\n",
      "feature_111    0.006383                  0.766788\n",
      "feature_80     0.006348                  0.773136\n",
      "feature_105    0.006346                  0.779482\n",
      "feature_46     0.006331                  0.785813\n",
      "feature_56     0.006298                  0.792111\n",
      "feature_54     0.006296                  0.798407\n",
      "feature_93     0.006268                  0.804676\n",
      "feature_51     0.006193                  0.810869\n",
      "feature_91     0.006153                  0.817022\n",
      "feature_123    0.006144                  0.823167\n",
      "feature_9      0.006122                  0.829289\n",
      "feature_29     0.006107                  0.835396\n",
      "feature_112    0.006097                  0.841493\n",
      "feature_109    0.006080                  0.847573\n",
      "feature_99     0.006071                  0.853644\n",
      "feature_14     0.006066                  0.859711\n",
      "feature_11     0.006057                  0.865768\n",
      "feature_87     0.006039                  0.871807\n",
      "feature_118    0.006011                  0.877818\n",
      "feature_88     0.006005                  0.883823\n",
      "feature_16     0.005987                  0.889810\n",
      "feature_2      0.005976                  0.895785\n",
      "feature_1      0.005959                  0.901744\n",
      "feature_94     0.005929                  0.907673\n",
      "feature_115    0.005928                  0.913601\n",
      "feature_73     0.005924                  0.919525\n",
      "feature_100    0.005917                  0.925442\n",
      "feature_82     0.005889                  0.931331\n",
      "feature_106    0.005848                  0.937179\n",
      "feature_81     0.005838                  0.943017\n",
      "feature_103    0.005833                  0.948850\n",
      "feature_85     0.005831                  0.954682\n",
      "feature_13     0.005819                  0.960500\n",
      "feature_79     0.005789                  0.966290\n",
      "feature_76     0.005788                  0.972077\n",
      "feature_97     0.005764                  0.977841\n",
      "feature_74     0.005666                  0.983506\n",
      "feature_75     0.005538                  0.989044\n",
      "feature_52     0.005521                  0.994565\n",
      "feature_15     0.005435                  1.000000\n",
      "predict called\n",
      "Type of X:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X:\n",
      "(145651, 140)\n",
      "Type of y:\n",
      "<class 'numpy.ndarray'>\n",
      "model fitted ?\n",
      "True\n",
      "y is not None\n",
      "Feature importances for split 2:\n",
      "             Importance  % feat importance cumulé\n",
      "feature_45     0.014024                  0.014024\n",
      "feature_42     0.013995                  0.028019\n",
      "feature_43     0.013962                  0.041982\n",
      "feature_41     0.013421                  0.055403\n",
      "feature_44     0.012373                  0.067776\n",
      "feature_63     0.012347                  0.080123\n",
      "feature_39     0.012051                  0.092174\n",
      "feature_27     0.011836                  0.104010\n",
      "feature_61     0.011470                  0.115480\n",
      "feature_5      0.011229                  0.126708\n",
      "feature_62     0.011206                  0.137914\n",
      "feature_6      0.011047                  0.148961\n",
      "feature_60     0.010782                  0.159743\n",
      "feature_40     0.010469                  0.170212\n",
      "feature_3      0.010120                  0.180332\n",
      "feature_4      0.010056                  0.190388\n",
      "feature_38     0.010022                  0.200410\n",
      "feature_83     0.009997                  0.210407\n",
      "4              0.009995                  0.220402\n",
      "feature_107    0.009907                  0.230309\n",
      "feature_119    0.009679                  0.239988\n",
      "feature_37     0.009530                  0.249518\n",
      "feature_77     0.009309                  0.258828\n",
      "feature_114    0.009164                  0.267992\n",
      "feature_124    0.009016                  0.277008\n",
      "feature_55     0.008998                  0.286006\n",
      "feature_95     0.008997                  0.295003\n",
      "feature_120    0.008920                  0.303922\n",
      "feature_64     0.008903                  0.312825\n",
      "feature_113    0.008668                  0.321493\n",
      "feature_102    0.008564                  0.330058\n",
      "feature_68     0.008490                  0.338548\n",
      "feature_121    0.008453                  0.347001\n",
      "feature_90     0.008363                  0.355365\n",
      "feature_89     0.008300                  0.363665\n",
      "feature_66     0.008215                  0.371880\n",
      "feature_57     0.008202                  0.380082\n",
      "feature_125    0.008124                  0.388206\n",
      "feature_126    0.007933                  0.396139\n",
      "feature_101    0.007916                  0.404055\n",
      "feature_71     0.007868                  0.411923\n",
      "feature_0      0.007826                  0.419749\n",
      "feature_20     0.007765                  0.427514\n",
      "feature_108    0.007745                  0.435259\n",
      "feature_78     0.007570                  0.442828\n",
      "feature_67     0.007546                  0.450374\n",
      "feature_69     0.007498                  0.457872\n",
      "feature_28     0.007477                  0.465349\n",
      "feature_84     0.007455                  0.472804\n",
      "feature_92     0.007429                  0.480233\n",
      "feature_65     0.007415                  0.487648\n",
      "feature_26     0.007384                  0.495031\n",
      "feature_18     0.007357                  0.502388\n",
      "feature_70     0.007312                  0.509701\n",
      "feature_8      0.007308                  0.517009\n",
      "feature_58     0.007237                  0.524245\n",
      "feature_127    0.007235                  0.531480\n",
      "feature_110    0.007156                  0.538636\n",
      "feature_116    0.007136                  0.545772\n",
      "feature_104    0.007088                  0.552860\n",
      "feature_17     0.007028                  0.559888\n",
      "feature_96     0.007021                  0.566909\n",
      "feature_31     0.006970                  0.573879\n",
      "feature_7      0.006960                  0.580839\n",
      "feature_128    0.006929                  0.587768\n",
      "feature_59     0.006903                  0.594671\n",
      "feature_33     0.006885                  0.601556\n",
      "feature_36     0.006867                  0.608423\n",
      "feature_24     0.006806                  0.615228\n",
      "feature_53     0.006797                  0.622026\n",
      "feature_23     0.006764                  0.628790\n",
      "feature_22     0.006741                  0.635531\n",
      "feature_49     0.006717                  0.642249\n",
      "feature_72     0.006702                  0.648951\n",
      "feature_50     0.006681                  0.655632\n",
      "feature_12     0.006677                  0.662309\n",
      "feature_98     0.006650                  0.668960\n",
      "feature_21     0.006620                  0.675579\n",
      "feature_32     0.006614                  0.682193\n",
      "feature_86     0.006606                  0.688799\n",
      "feature_30     0.006606                  0.695405\n",
      "feature_129    0.006603                  0.702008\n",
      "feature_10     0.006567                  0.708575\n",
      "feature_122    0.006532                  0.715107\n",
      "feature_25     0.006524                  0.721631\n",
      "feature_47     0.006494                  0.728125\n",
      "feature_48     0.006487                  0.734612\n",
      "feature_35     0.006478                  0.741090\n",
      "feature_34     0.006456                  0.747546\n",
      "feature_19     0.006445                  0.753991\n",
      "feature_117    0.006414                  0.760405\n",
      "feature_111    0.006383                  0.766788\n",
      "feature_80     0.006348                  0.773136\n",
      "feature_105    0.006346                  0.779482\n",
      "feature_46     0.006331                  0.785813\n",
      "feature_56     0.006298                  0.792111\n",
      "feature_54     0.006296                  0.798407\n",
      "feature_93     0.006268                  0.804676\n",
      "feature_51     0.006193                  0.810869\n",
      "feature_91     0.006153                  0.817022\n",
      "feature_123    0.006144                  0.823167\n",
      "feature_9      0.006122                  0.829289\n",
      "feature_29     0.006107                  0.835396\n",
      "feature_112    0.006097                  0.841493\n",
      "feature_109    0.006080                  0.847573\n",
      "feature_99     0.006071                  0.853644\n",
      "feature_14     0.006066                  0.859711\n",
      "feature_11     0.006057                  0.865768\n",
      "feature_87     0.006039                  0.871807\n",
      "feature_118    0.006011                  0.877818\n",
      "feature_88     0.006005                  0.883823\n",
      "feature_16     0.005987                  0.889810\n",
      "feature_2      0.005976                  0.895785\n",
      "feature_1      0.005959                  0.901744\n",
      "feature_94     0.005929                  0.907673\n",
      "feature_115    0.005928                  0.913601\n",
      "feature_73     0.005924                  0.919525\n",
      "feature_100    0.005917                  0.925442\n",
      "feature_82     0.005889                  0.931331\n",
      "feature_106    0.005848                  0.937179\n",
      "feature_81     0.005838                  0.943017\n",
      "feature_103    0.005833                  0.948850\n",
      "feature_85     0.005831                  0.954682\n",
      "feature_13     0.005819                  0.960500\n",
      "feature_79     0.005789                  0.966290\n",
      "feature_76     0.005788                  0.972077\n",
      "feature_97     0.005764                  0.977841\n",
      "feature_74     0.005666                  0.983506\n",
      "feature_75     0.005538                  0.989044\n",
      "feature_52     0.005521                  0.994565\n",
      "feature_15     0.005435                  1.000000\n",
      "predict called\n",
      "Type of X:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X:\n",
      "(142152, 140)\n",
      "Type of y:\n",
      "<class 'numpy.ndarray'>\n",
      "model fitted ?\n",
      "True\n",
      "y is not None\n",
      "Feature importances for split 3:\n",
      "             Importance  % feat importance cumulé\n",
      "feature_45     0.014024                  0.014024\n",
      "feature_42     0.013995                  0.028019\n",
      "feature_43     0.013962                  0.041982\n",
      "feature_41     0.013421                  0.055403\n",
      "feature_44     0.012373                  0.067776\n",
      "feature_63     0.012347                  0.080123\n",
      "feature_39     0.012051                  0.092174\n",
      "feature_27     0.011836                  0.104010\n",
      "feature_61     0.011470                  0.115480\n",
      "feature_5      0.011229                  0.126708\n",
      "feature_62     0.011206                  0.137914\n",
      "feature_6      0.011047                  0.148961\n",
      "feature_60     0.010782                  0.159743\n",
      "feature_40     0.010469                  0.170212\n",
      "feature_3      0.010120                  0.180332\n",
      "feature_4      0.010056                  0.190388\n",
      "feature_38     0.010022                  0.200410\n",
      "feature_83     0.009997                  0.210407\n",
      "4              0.009995                  0.220402\n",
      "feature_107    0.009907                  0.230309\n",
      "feature_119    0.009679                  0.239988\n",
      "feature_37     0.009530                  0.249518\n",
      "feature_77     0.009309                  0.258828\n",
      "feature_114    0.009164                  0.267992\n",
      "feature_124    0.009016                  0.277008\n",
      "feature_55     0.008998                  0.286006\n",
      "feature_95     0.008997                  0.295003\n",
      "feature_120    0.008920                  0.303922\n",
      "feature_64     0.008903                  0.312825\n",
      "feature_113    0.008668                  0.321493\n",
      "feature_102    0.008564                  0.330058\n",
      "feature_68     0.008490                  0.338548\n",
      "feature_121    0.008453                  0.347001\n",
      "feature_90     0.008363                  0.355365\n",
      "feature_89     0.008300                  0.363665\n",
      "feature_66     0.008215                  0.371880\n",
      "feature_57     0.008202                  0.380082\n",
      "feature_125    0.008124                  0.388206\n",
      "feature_126    0.007933                  0.396139\n",
      "feature_101    0.007916                  0.404055\n",
      "feature_71     0.007868                  0.411923\n",
      "feature_0      0.007826                  0.419749\n",
      "feature_20     0.007765                  0.427514\n",
      "feature_108    0.007745                  0.435259\n",
      "feature_78     0.007570                  0.442828\n",
      "feature_67     0.007546                  0.450374\n",
      "feature_69     0.007498                  0.457872\n",
      "feature_28     0.007477                  0.465349\n",
      "feature_84     0.007455                  0.472804\n",
      "feature_92     0.007429                  0.480233\n",
      "feature_65     0.007415                  0.487648\n",
      "feature_26     0.007384                  0.495031\n",
      "feature_18     0.007357                  0.502388\n",
      "feature_70     0.007312                  0.509701\n",
      "feature_8      0.007308                  0.517009\n",
      "feature_58     0.007237                  0.524245\n",
      "feature_127    0.007235                  0.531480\n",
      "feature_110    0.007156                  0.538636\n",
      "feature_116    0.007136                  0.545772\n",
      "feature_104    0.007088                  0.552860\n",
      "feature_17     0.007028                  0.559888\n",
      "feature_96     0.007021                  0.566909\n",
      "feature_31     0.006970                  0.573879\n",
      "feature_7      0.006960                  0.580839\n",
      "feature_128    0.006929                  0.587768\n",
      "feature_59     0.006903                  0.594671\n",
      "feature_33     0.006885                  0.601556\n",
      "feature_36     0.006867                  0.608423\n",
      "feature_24     0.006806                  0.615228\n",
      "feature_53     0.006797                  0.622026\n",
      "feature_23     0.006764                  0.628790\n",
      "feature_22     0.006741                  0.635531\n",
      "feature_49     0.006717                  0.642249\n",
      "feature_72     0.006702                  0.648951\n",
      "feature_50     0.006681                  0.655632\n",
      "feature_12     0.006677                  0.662309\n",
      "feature_98     0.006650                  0.668960\n",
      "feature_21     0.006620                  0.675579\n",
      "feature_32     0.006614                  0.682193\n",
      "feature_86     0.006606                  0.688799\n",
      "feature_30     0.006606                  0.695405\n",
      "feature_129    0.006603                  0.702008\n",
      "feature_10     0.006567                  0.708575\n",
      "feature_122    0.006532                  0.715107\n",
      "feature_25     0.006524                  0.721631\n",
      "feature_47     0.006494                  0.728125\n",
      "feature_48     0.006487                  0.734612\n",
      "feature_35     0.006478                  0.741090\n",
      "feature_34     0.006456                  0.747546\n",
      "feature_19     0.006445                  0.753991\n",
      "feature_117    0.006414                  0.760405\n",
      "feature_111    0.006383                  0.766788\n",
      "feature_80     0.006348                  0.773136\n",
      "feature_105    0.006346                  0.779482\n",
      "feature_46     0.006331                  0.785813\n",
      "feature_56     0.006298                  0.792111\n",
      "feature_54     0.006296                  0.798407\n",
      "feature_93     0.006268                  0.804676\n",
      "feature_51     0.006193                  0.810869\n",
      "feature_91     0.006153                  0.817022\n",
      "feature_123    0.006144                  0.823167\n",
      "feature_9      0.006122                  0.829289\n",
      "feature_29     0.006107                  0.835396\n",
      "feature_112    0.006097                  0.841493\n",
      "feature_109    0.006080                  0.847573\n",
      "feature_99     0.006071                  0.853644\n",
      "feature_14     0.006066                  0.859711\n",
      "feature_11     0.006057                  0.865768\n",
      "feature_87     0.006039                  0.871807\n",
      "feature_118    0.006011                  0.877818\n",
      "feature_88     0.006005                  0.883823\n",
      "feature_16     0.005987                  0.889810\n",
      "feature_2      0.005976                  0.895785\n",
      "feature_1      0.005959                  0.901744\n",
      "feature_94     0.005929                  0.907673\n",
      "feature_115    0.005928                  0.913601\n",
      "feature_73     0.005924                  0.919525\n",
      "feature_100    0.005917                  0.925442\n",
      "feature_82     0.005889                  0.931331\n",
      "feature_106    0.005848                  0.937179\n",
      "feature_81     0.005838                  0.943017\n",
      "feature_103    0.005833                  0.948850\n",
      "feature_85     0.005831                  0.954682\n",
      "feature_13     0.005819                  0.960500\n",
      "feature_79     0.005789                  0.966290\n",
      "feature_76     0.005788                  0.972077\n",
      "feature_97     0.005764                  0.977841\n",
      "feature_74     0.005666                  0.983506\n",
      "feature_75     0.005538                  0.989044\n",
      "feature_52     0.005521                  0.994565\n",
      "feature_15     0.005435                  1.000000\n",
      "predict called\n",
      "Type of X:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X:\n",
      "(141980, 140)\n",
      "Type of y:\n",
      "<class 'numpy.ndarray'>\n",
      "model fitted ?\n",
      "True\n",
      "y is not None\n",
      "Feature importances for split 4:\n",
      "             Importance  % feat importance cumulé\n",
      "feature_45     0.014024                  0.014024\n",
      "feature_42     0.013995                  0.028019\n",
      "feature_43     0.013962                  0.041982\n",
      "feature_41     0.013421                  0.055403\n",
      "feature_44     0.012373                  0.067776\n",
      "feature_63     0.012347                  0.080123\n",
      "feature_39     0.012051                  0.092174\n",
      "feature_27     0.011836                  0.104010\n",
      "feature_61     0.011470                  0.115480\n",
      "feature_5      0.011229                  0.126708\n",
      "feature_62     0.011206                  0.137914\n",
      "feature_6      0.011047                  0.148961\n",
      "feature_60     0.010782                  0.159743\n",
      "feature_40     0.010469                  0.170212\n",
      "feature_3      0.010120                  0.180332\n",
      "feature_4      0.010056                  0.190388\n",
      "feature_38     0.010022                  0.200410\n",
      "feature_83     0.009997                  0.210407\n",
      "4              0.009995                  0.220402\n",
      "feature_107    0.009907                  0.230309\n",
      "feature_119    0.009679                  0.239988\n",
      "feature_37     0.009530                  0.249518\n",
      "feature_77     0.009309                  0.258828\n",
      "feature_114    0.009164                  0.267992\n",
      "feature_124    0.009016                  0.277008\n",
      "feature_55     0.008998                  0.286006\n",
      "feature_95     0.008997                  0.295003\n",
      "feature_120    0.008920                  0.303922\n",
      "feature_64     0.008903                  0.312825\n",
      "feature_113    0.008668                  0.321493\n",
      "feature_102    0.008564                  0.330058\n",
      "feature_68     0.008490                  0.338548\n",
      "feature_121    0.008453                  0.347001\n",
      "feature_90     0.008363                  0.355365\n",
      "feature_89     0.008300                  0.363665\n",
      "feature_66     0.008215                  0.371880\n",
      "feature_57     0.008202                  0.380082\n",
      "feature_125    0.008124                  0.388206\n",
      "feature_126    0.007933                  0.396139\n",
      "feature_101    0.007916                  0.404055\n",
      "feature_71     0.007868                  0.411923\n",
      "feature_0      0.007826                  0.419749\n",
      "feature_20     0.007765                  0.427514\n",
      "feature_108    0.007745                  0.435259\n",
      "feature_78     0.007570                  0.442828\n",
      "feature_67     0.007546                  0.450374\n",
      "feature_69     0.007498                  0.457872\n",
      "feature_28     0.007477                  0.465349\n",
      "feature_84     0.007455                  0.472804\n",
      "feature_92     0.007429                  0.480233\n",
      "feature_65     0.007415                  0.487648\n",
      "feature_26     0.007384                  0.495031\n",
      "feature_18     0.007357                  0.502388\n",
      "feature_70     0.007312                  0.509701\n",
      "feature_8      0.007308                  0.517009\n",
      "feature_58     0.007237                  0.524245\n",
      "feature_127    0.007235                  0.531480\n",
      "feature_110    0.007156                  0.538636\n",
      "feature_116    0.007136                  0.545772\n",
      "feature_104    0.007088                  0.552860\n",
      "feature_17     0.007028                  0.559888\n",
      "feature_96     0.007021                  0.566909\n",
      "feature_31     0.006970                  0.573879\n",
      "feature_7      0.006960                  0.580839\n",
      "feature_128    0.006929                  0.587768\n",
      "feature_59     0.006903                  0.594671\n",
      "feature_33     0.006885                  0.601556\n",
      "feature_36     0.006867                  0.608423\n",
      "feature_24     0.006806                  0.615228\n",
      "feature_53     0.006797                  0.622026\n",
      "feature_23     0.006764                  0.628790\n",
      "feature_22     0.006741                  0.635531\n",
      "feature_49     0.006717                  0.642249\n",
      "feature_72     0.006702                  0.648951\n",
      "feature_50     0.006681                  0.655632\n",
      "feature_12     0.006677                  0.662309\n",
      "feature_98     0.006650                  0.668960\n",
      "feature_21     0.006620                  0.675579\n",
      "feature_32     0.006614                  0.682193\n",
      "feature_86     0.006606                  0.688799\n",
      "feature_30     0.006606                  0.695405\n",
      "feature_129    0.006603                  0.702008\n",
      "feature_10     0.006567                  0.708575\n",
      "feature_122    0.006532                  0.715107\n",
      "feature_25     0.006524                  0.721631\n",
      "feature_47     0.006494                  0.728125\n",
      "feature_48     0.006487                  0.734612\n",
      "feature_35     0.006478                  0.741090\n",
      "feature_34     0.006456                  0.747546\n",
      "feature_19     0.006445                  0.753991\n",
      "feature_117    0.006414                  0.760405\n",
      "feature_111    0.006383                  0.766788\n",
      "feature_80     0.006348                  0.773136\n",
      "feature_105    0.006346                  0.779482\n",
      "feature_46     0.006331                  0.785813\n",
      "feature_56     0.006298                  0.792111\n",
      "feature_54     0.006296                  0.798407\n",
      "feature_93     0.006268                  0.804676\n",
      "feature_51     0.006193                  0.810869\n",
      "feature_91     0.006153                  0.817022\n",
      "feature_123    0.006144                  0.823167\n",
      "feature_9      0.006122                  0.829289\n",
      "feature_29     0.006107                  0.835396\n",
      "feature_112    0.006097                  0.841493\n",
      "feature_109    0.006080                  0.847573\n",
      "feature_99     0.006071                  0.853644\n",
      "feature_14     0.006066                  0.859711\n",
      "feature_11     0.006057                  0.865768\n",
      "feature_87     0.006039                  0.871807\n",
      "feature_118    0.006011                  0.877818\n",
      "feature_88     0.006005                  0.883823\n",
      "feature_16     0.005987                  0.889810\n",
      "feature_2      0.005976                  0.895785\n",
      "feature_1      0.005959                  0.901744\n",
      "feature_94     0.005929                  0.907673\n",
      "feature_115    0.005928                  0.913601\n",
      "feature_73     0.005924                  0.919525\n",
      "feature_100    0.005917                  0.925442\n",
      "feature_82     0.005889                  0.931331\n",
      "feature_106    0.005848                  0.937179\n",
      "feature_81     0.005838                  0.943017\n",
      "feature_103    0.005833                  0.948850\n",
      "feature_85     0.005831                  0.954682\n",
      "feature_13     0.005819                  0.960500\n",
      "feature_79     0.005789                  0.966290\n",
      "feature_76     0.005788                  0.972077\n",
      "feature_97     0.005764                  0.977841\n",
      "feature_74     0.005666                  0.983506\n",
      "feature_75     0.005538                  0.989044\n",
      "feature_52     0.005521                  0.994565\n",
      "feature_15     0.005435                  1.000000\n",
      "{'utility_score': 2067.0424490696137, 'utility_scores': [80.81100461351588, 756.8474952433912, -0.0, 60.51893841687361, 1168.8650107958329], 'utility_score_std': 467.91529311223576, 'accuracy_scores': [0.5190713101160862, 0.5205826605826606, 0.5103294862376503, 0.5174109404018234, 0.5270249330891675]}\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for fold_indice in range(NB_FOLDS):     \n",
    "    test_predictions = model_wrapped.predict(pd.concat([df.loc[folds_list_test[fold_indice], FEATURES_LIST_TOTRAIN].reset_index(drop=True), pd.DataFrame(model_xgb.predict_proba(df.loc[folds_list_test[fold_indice], FEATURES_LIST_TOTRAIN]))], axis=1))\n",
    "\n",
    "    scores.append(model_wrapped.score(df.loc[folds_list_test[fold_indice]], test_predictions))\n",
    "    accuracy_scores.append(model_wrapped.accuracy_score(df.loc[folds_list_test[fold_indice]], test_predictions))  \n",
    "\n",
    "    df_featimportance = pd.DataFrame(model_wrapped.model_internal.feature_importances_, index=FEATURES_LIST_TOTRAIN + [4], columns=['Importance']).sort_values(by='Importance', ascending=False)\n",
    "    df_featimportance_cumulated = pd.concat([df_featimportance, pd.DataFrame({'% feat importance cumulé' : (df_featimportance['Importance'] / df_featimportance['Importance'].sum()).cumsum()})], axis=1)\n",
    "    print(f'Feature importances for split {fold_indice}:')\n",
    "    print(df_featimportance_cumulated)\n",
    "\n",
    "print({'utility_score': sum(scores), 'utility_scores': scores, 'utility_score_std': np.std(scores), 'accuracy_scores': accuracy_scores})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Score : {'utility_score': 1965.4260817446252, 'utility_scores': [-0.0, 773.0603560527992, -0.0, 17.224511476653525, 1175.1412142151726], 'utility_score_std': 491.1814195758618, 'accuracy_scores': [0.5165483125682131, 0.5191505791505792, 0.5080020047922774, 0.515377905340762, 0.526574165375405]}  \n",
    "\n",
    "Score avec uniquement feature 4 : \n",
    "{'utility_score': 2067.0424490696137, 'utility_scores': [80.81100461351588, 756.8474952433912, -0.0, 60.51893841687361, 1168.8650107958329], 'utility_score_std': 467.91529311223576, 'accuracy_scores': [0.5190713101160862, 0.5205826605826606, 0.5103294862376503, 0.5174109404018234, 0.5270249330891675]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: hq9t5iju\n",
      "Sweep URL: https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju\n"
     ]
    }
   ],
   "source": [
    "if (DO_SWEEP == True):\n",
    "    sweep_id = wandb.sweep(sweep_config, entity='fboyer', project=\"janestreet-mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    config_MLP = dict(\n",
    "        epochs=NUM_EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        weight_decay = WEIGHT_DECAY,\n",
    "        dropout = DROPOUT,\n",
    "        use_autoenc = 'None',\n",
    "        activation_function = 'leakyrelu',\n",
    "        )\n",
    "\n",
    "    if (DO_SWEEP == True):\n",
    "        #run = wandb.init()\n",
    "        #config_MLP = run.config\n",
    "        wandb.init(config=config_MLP)\n",
    "        config_MLP = wandb.config\n",
    "\n",
    "    else:\n",
    "        wandb.init(project='janestreet-mlp', config=config_MLP)\n",
    "        config_MLP = wandb.config\n",
    "\n",
    "    print('Training started')\n",
    "    patience=5\n",
    "\n",
    "    print('Run config :')\n",
    "    print(\"config:\", dict(config_MLP))\n",
    "\n",
    "    utility_scores = [None] * 5\n",
    "    accuracy_scores = [None] * 5\n",
    "\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    ts_train = torch.tensor(df.loc[folds_list_train2_unique, FEATURES_LIST_TOTRAIN].to_numpy(), device='cuda')\n",
    "    ts_train_y = torch.tensor((df.loc[folds_list_train2_unique, 'resp'] > 0).astype(np.byte).to_numpy(), device='cuda')\n",
    "\n",
    "    # Normalize data\n",
    "    ts_train_mean = torch.mean(ts_train, axis=0)\n",
    "    ts_train_std = torch.std(ts_train, axis=0)\n",
    "    #ts_train = pyStandardScale(ts_train, ts_train_mean, ts_train_std)\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(ts_train, ts_train_y)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config_MLP.batch_size, shuffle=True) # pin_memory : VOIR RESULTAT\n",
    "\n",
    "    ts_test = [None] * 5\n",
    "    ts_test_y = [None] * 5    \n",
    "    test_dataset = [None] * 5\n",
    "    test_loader = [None] * 5\n",
    "\n",
    "    for fold_indice in range(5):\n",
    "        ts_test[fold_indice] = torch.tensor(df.loc[folds_list_test[fold_indice], FEATURES_LIST_TOTRAIN].to_numpy(), device='cuda')\n",
    "        ts_test_y[fold_indice] = torch.tensor((df.loc[folds_list_test[fold_indice], 'resp'] > 0).astype(np.byte).to_numpy(), device='cuda')\n",
    "\n",
    "        # Normalize\n",
    "        #ts_test[fold_indice] = pyStandardScale(ts_test[fold_indice], ts_train_mean, ts_train_std)\n",
    "\n",
    "        test_dataset[fold_indice] = torch.utils.data.TensorDataset(ts_test[fold_indice], ts_test_y[fold_indice])\n",
    "        test_loader[fold_indice] = torch.utils.data.DataLoader(test_dataset[fold_indice], batch_size=config_MLP.batch_size)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    class MLP(nn.Module):\n",
    "        def __init__(self, AEncoder):\n",
    "        #def __init__(self):\n",
    "            super(MLP,self).__init__()\n",
    "\n",
    "            #self.act_n = torch.zeros((config_MLP.batch_size, ACT_N_SIZE))\n",
    "            if (ACT_N == True):\n",
    "                self.act_n = torch.zeros(ACT_N_SIZE, device='cuda').unsqueeze(0)\n",
    "                act_n_size = ACT_N_SIZE\n",
    "\n",
    "            else:\n",
    "                act_n_size = 0\n",
    "                \n",
    "            self.AEncoder = AEncoder\n",
    "\n",
    "            if (config_MLP.use_autoenc == 'encoder-decoder'):\n",
    "                #self.layer1 = nn.Linear(len(FEATURES_LIST_TOTRAIN) + self.AEncoder.decoder[0].in_features, 200)\n",
    "                self.layer1 = nn.Linear(len(FEATURES_LIST_TOTRAIN) * 2 + act_n_size, 200) # <= % near 0 élevé\n",
    "\n",
    "            elif (config_MLP.use_autoenc == 'encoder'):\n",
    "                self.layer1 = nn.Linear(len(FEATURES_LIST_TOTRAIN) + ENCODER_SIZE + act_n_size, 200) # <= % near 0 élevé\n",
    "\n",
    "            elif (config_MLP.use_autoenc == 'encoder-only'):\n",
    "                self.layer1 = nn.Linear(ENCODER_SIZE + act_n_size, 200) # <= % near 0 élevé\n",
    "                \n",
    "            else:\n",
    "                self.layer1 = nn.Linear(len(FEATURES_LIST_TOTRAIN) + act_n_size, 200) # <= % near 0 élevé\n",
    "\n",
    "            if (config_MLP.activation_function == 'relu'):\n",
    "                self.act1 = nn.ReLU()\n",
    "                \n",
    "            elif (config_MLP.activation_function == 'leakyrelu'):\n",
    "                self.act1 = nn.LeakyReLU()\n",
    "                \n",
    "            self.dropout1 = nn.Dropout(config_MLP.dropout)\n",
    "\n",
    "            self.layer2 = nn.Linear(200, 100)\n",
    "\n",
    "            if (config_MLP.activation_function == 'relu'):\n",
    "                self.act2 = nn.ReLU()\n",
    "                \n",
    "            elif (config_MLP.activation_function == 'leakyrelu'):\n",
    "                self.act2 = nn.LeakyReLU()\n",
    "\n",
    "            self.dropout2 = nn.Dropout(config_MLP.dropout)\n",
    "\n",
    "            self.layer3 = nn.Linear(100, 1)\n",
    "            self.act3 = nn.Sigmoid()\n",
    "\n",
    "        def encoder(self, x):\n",
    "            self.AEncoder.eval()\n",
    "\n",
    "            encoded = self.AEncoder.encoder(x)\n",
    "\n",
    "            return encoded\n",
    "\n",
    "        def encoder_decoder(self, x):\n",
    "            self.AEncoder.eval()\n",
    "\n",
    "            encoded_decoded = self.AEncoder(x)\n",
    "\n",
    "            return encoded_decoded\n",
    "\n",
    "        def forward(self,x):\n",
    "            #x_encoded = self.encoder(x)\n",
    "\n",
    "            #x = torch.cat((x, x_encoded), dim=1)\n",
    "            if (config_MLP.use_autoenc == 'encoder-decoder'):\n",
    "                x_decoded = self.encoder_decoder(x)\n",
    "                x = torch.cat((x, x_decoded), dim=1)\n",
    "\n",
    "            elif (config_MLP.use_autoenc == 'encoder'):\n",
    "                x_decoded = self.encoder(x)\n",
    "                x = torch.cat((x, x_decoded), dim=1)\n",
    "\n",
    "            elif (config_MLP.use_autoenc == 'encoder-only'):\n",
    "                x_decoded = self.encoder(x)\n",
    "                x = x_decoded\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            if (ACT_N == True):\n",
    "                x = torch.cat((x, self.act_n.expand(x.shape[0], ACT_N_SIZE)), dim=1)    \n",
    "\n",
    "            x = self.dropout1(self.act1(self.layer1(x)))\n",
    "            x = self.dropout2(self.act2(self.layer2(x)))\n",
    "\n",
    "            x = self.act3(self.layer3(x))            \n",
    "\n",
    "            # Remove oldest previously saved output (located at the end of tensor => index -1 for not selecting it) of NN and replace by new one (which is x, that we assign at start of tensor)\n",
    "            # expand() because self.act_n when first assigned has only 1 line, but here it expands to number of lines in x (batch size)\n",
    "            if (ACT_N == True):\n",
    "                self.act_n = torch.cat((x, self.act_n[:, :-1].expand(x.shape[0], ACT_N_SIZE-1)), dim=1)\n",
    "\n",
    "\n",
    "            #print('self.act_n:')\n",
    "            #print(self.act_n)\n",
    "\n",
    "            return x        \n",
    "\n",
    "    #model = MLP(model_AE)\n",
    "    model = MLP(model_AE).double().to('cuda')\n",
    "\n",
    "    for param in model.AEncoder.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    '''\n",
    "    model = nn.Sequential(\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.Linear(len(FEATURES_LIST_TOTRAIN), 200),\n",
    "            #nn.BatchNorm1d(130),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.7),\n",
    "\n",
    "            nn.Linear(200, 100),\n",
    "            #nn.BatchNorm1d(130),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.7),\n",
    "\n",
    "            nn.Linear(100, 1),\n",
    "            nn.Sigmoid(),\n",
    "        ).double().to('cuda')\n",
    "    '''\n",
    "\n",
    "    #print('Number of model parameters :')\n",
    "    #numel_list = [p.numel() for p in model.parameters()]\n",
    "    #sum(numel_list), numel_list\n",
    "\n",
    "    loss_fn = nn.BCELoss().to('cuda')\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) \n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=config_MLP.learning_rate, weight_decay=config_MLP.weight_decay) \n",
    "    optimizer = optim.RAdam(model.parameters(), lr=config_MLP.learning_rate, weight_decay=config_MLP.weight_decay) \n",
    "\n",
    "    scheduler = None\n",
    "    #scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3,\n",
    "    #                                                         max_lr=1e-4, epochs=config_MLP.epochs, steps_per_epoch=len(train_loader))\n",
    "\n",
    "    #if (DO_SWEEP == False):\n",
    "    wandb.watch(model, loss_fn, log=\"all\", log_freq=1)\n",
    "\n",
    "    model.eval()\n",
    "    #start_accuracy = accuracy_score(ts_test_y.cpu().numpy(), (model(ts_test).squeeze() > 0.5).cpu().numpy())\n",
    "    #start_utility_score = utility_function(df.loc[test_index], (model(ts_test).squeeze() > 0.5).cpu().numpy())\n",
    "    #print('Start Validation Accuracy: {:.4f}'.format(start_accuracy))\n",
    "    #print('Start Validation Utility: {:.4f}'.format(start_utility_score))\n",
    "\n",
    "\n",
    "    Val_Loss = 0\n",
    "    N_Samples = 0\n",
    "\n",
    "    the_last_loss = 100\n",
    "    the_last_utility_score = 0\n",
    "    the_last_accuracy = 0\n",
    "    trigger_times=0\n",
    "    early_stopping_met = False\n",
    "\n",
    "    for epoch in range(config_MLP.epochs): \n",
    "        running_loss = 0.0        \n",
    "\n",
    "        ### Call back to save activation stats (mean, std dev and near 0 values after activation functions)\n",
    "        # Setting hook for activation layers stats\n",
    "\n",
    "        hook_handles = []\n",
    "        save_output_activation_stats = []\n",
    "\n",
    "        for layer in model.modules():\n",
    "            if ('activation' in str(type(layer))):\n",
    "                save_output_activation_stats_1layer = SaveOutputActivationStats()\n",
    "                handle = layer.register_forward_hook(save_output_activation_stats_1layer)\n",
    "                save_output_activation_stats.append(save_output_activation_stats_1layer)\n",
    "                hook_handles.append(handle)    \n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for batch in train_loader:\n",
    "            #inputs, labels = batch[0], batch[1]\n",
    "            inputs, labels = batch[0].to('cuda'), batch[1].to('cuda')\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, labels.unsqueeze(-1).double())\n",
    "                #loss.backward(retain_graph=True)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if scheduler:\n",
    "                    scheduler.step()\n",
    "\n",
    "        # update local train loss\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # update global train loss\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print('Epoch({}) - Training Loss: {:.4f}'.format(epoch, epoch_loss))\n",
    "\n",
    "        writer.add_scalar(f\"Global train/loss\", epoch_loss, epoch)\n",
    "        wandb.log({'Global train/loss' : epoch_loss}, step=epoch)\n",
    "\n",
    "        # Write activation stats graphs\n",
    "        for layer_number,save_output_activation_stats_layer in enumerate(save_output_activation_stats):\n",
    "            df_stats_layer = pd.DataFrame(save_output_activation_stats_layer.outputs)\n",
    "\n",
    "            if ((df_stats_layer.shape[0] == 0) and (df_stats_layer.shape[1] == 0)):\n",
    "                print(f'Activation stats: No data returned for stats at layer {layer_number}')\n",
    "\n",
    "            else:\n",
    "                fig, ax = plt.subplots(1, 3, figsize=(25, 4))\n",
    "\n",
    "                ax[0].set_title(f'Layer {layer_number} : Mean activation value', fontsize=16)\n",
    "                ax[0].set_xlabel('Batch instances')\n",
    "                ax[0].set_ylabel('Mean')\n",
    "                ax[0].plot(range(df_stats_layer.shape[0]), df_stats_layer['mean'])\n",
    "\n",
    "                ax[1].set_title(f'Layer {layer_number} : Std deviation activation value', fontsize=16)\n",
    "                ax[1].set_xlabel('Batch instances')\n",
    "                ax[1].set_ylabel('Standard deviation')\n",
    "                ax[1].plot(range(df_stats_layer.shape[0]), df_stats_layer['std'])\n",
    "\n",
    "                ax[2].set_title(f'Layer {layer_number} : Percentage of activation values near zero', fontsize=16)\n",
    "                ax[2].set_xlabel('Batch instances')\n",
    "                ax[2].set_ylabel('Percentage')\n",
    "                ax[2].plot(range(df_stats_layer.shape[0]), df_stats_layer['near_zero']);\n",
    "\n",
    "                plot_buf = io.BytesIO()\n",
    "                plt.savefig(plot_buf, format='jpeg')\n",
    "                plt.close()\n",
    "\n",
    "                plot_buf.seek(0)\n",
    "                image = PIL.Image.open(plot_buf)\n",
    "                image = transforms.ToTensor()(image)\n",
    "                writer.add_image(\"Train activation stats/Activation stats layer \" + str(layer_number), image, epoch)\n",
    "                wandb.log({'Train activation stats/Activation stats layer' + str(layer_number) : wandb.Image(image)}, step=epoch)\n",
    "\n",
    "        # Validation \n",
    "        model.eval()\n",
    "\n",
    "        vrunning_loss = [None] * 5\n",
    "        num_samples = [None] * 5\n",
    "        vepoch_loss_folds = [None] * 5\n",
    "        vepoch_accuracy_folds = [None] * 5\n",
    "        vepoch_utility_score_folds = [None] * 5\n",
    "\n",
    "        for fold_indice in range(5):    \n",
    "            vrunning_loss[fold_indice] = 0.0\n",
    "            num_samples[fold_indice] = 0\n",
    "\n",
    "            for batch in test_loader[fold_indice]:\n",
    "                inputs, labels = batch[0].to('cuda'), batch[1].to('cuda')\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = loss_fn(outputs, labels.unsqueeze(-1).double())\n",
    "\n",
    "                vrunning_loss[fold_indice] += loss.item() * inputs.size(0)\n",
    "                num_samples[fold_indice] += labels.size(0)\n",
    "\n",
    "                vepoch_loss_folds[fold_indice] = vrunning_loss[fold_indice] / num_samples[fold_indice]\n",
    "\n",
    "            print('Epoch({}) - Fold {} - Validation Loss : {:.4f}'.format(epoch, fold_indice, vepoch_loss_folds[fold_indice]))\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                vepoch_accuracy_folds[fold_indice] = accuracy_score(ts_test_y[fold_indice].cpu().numpy(), (model(ts_test[fold_indice]).squeeze() > 0.5).cpu().numpy())\n",
    "                vepoch_utility_score_folds[fold_indice] = utility_function(df.loc[folds_list_test[fold_indice]], (model(ts_test[fold_indice]).squeeze() > 0.5).cpu().numpy())\n",
    "            print('Epoch({}) - Fold {} - Validation Accuracy : {:.4f}'.format(epoch, fold_indice, vepoch_accuracy_folds[fold_indice]))\n",
    "            print('Epoch({}) - Fold {} - Validation Utility score : {:.4f}'.format(epoch, fold_indice, vepoch_utility_score_folds[fold_indice]))\n",
    "\n",
    "\n",
    "        # update epoch loss\n",
    "        vepoch_loss = sum(vepoch_loss_folds) / len(vepoch_loss_folds)\n",
    "        vepoch_accuracy = sum(vepoch_accuracy_folds) / len(vepoch_accuracy_folds)\n",
    "        vepoch_utility_score = sum(vepoch_utility_score_folds) #/ len(vepoch_utility_score_folds)\n",
    "        print('Epoch({}) - GLOBAL - Validation Loss: {:.4f}'.format(epoch, vepoch_loss))\n",
    "        print('Epoch({}) - GLOBAL - Validation Accuracy: {:.4f}'.format(epoch, vepoch_accuracy))\n",
    "        print('Epoch({}) - GLOBAL - Validation Utility score: {:.4f}'.format(epoch, vepoch_utility_score))\n",
    "\n",
    "        #print(f'Sum of model parameters ({epoch}):')\n",
    "        #[print(p.sum()) for p in model.parameters()]\n",
    "\n",
    "        writer.add_scalar(\"Global valid/Loss\", vepoch_loss, epoch)\n",
    "        writer.add_scalar(\"Global valid/Accuracy\", vepoch_accuracy, epoch)\n",
    "        writer.add_scalar(\"Global valid/Utility\", vepoch_utility_score, epoch)\n",
    "        wandb.log({'Global valid/Loss' : vepoch_loss}, step=epoch)\n",
    "        wandb.log({'Global valid/Accuracy' : vepoch_accuracy}, step=epoch)\n",
    "        wandb.log({'Global valid/Utility' : vepoch_utility_score}, step=epoch)\n",
    "\n",
    "        for fold_indice in range(5):\n",
    "            writer.add_scalar(\"Fold valid Loss/Loss fold \"+str(fold_indice), vepoch_loss_folds[fold_indice], epoch)\n",
    "            writer.add_scalar(\"Fold valid Accuracy/Accuracy fold \"+str(fold_indice), vepoch_accuracy_folds[fold_indice], epoch)\n",
    "            writer.add_scalar(\"Fold valid Utility/Utility fold \"+str(fold_indice), vepoch_utility_score_folds[fold_indice], epoch)\n",
    "\n",
    "            wandb.log({\"Fold valid Loss/Loss fold \"+str(fold_indice) : vepoch_loss_folds[fold_indice]}, step=epoch)\n",
    "            wandb.log({\"Fold valid Accuracy/Accuracy fold \"+str(fold_indice) : vepoch_accuracy_folds[fold_indice]}, step=epoch)\n",
    "            wandb.log({\"Fold valid Utility/Utility fold \"+str(fold_indice) : vepoch_utility_score_folds[fold_indice]}, step=epoch)\n",
    "\n",
    "        writer.flush()\n",
    "\n",
    "        # Check if Early Stopping\n",
    "        #if vepoch_loss > the_last_loss:\n",
    "        #if (vepoch_utility_score < the_last_utility_score) and (vepoch_loss > the_last_loss) and (vepoch_accuracy < the_last_accuracy):\n",
    "\n",
    "        if (vepoch_loss > the_last_loss):\n",
    "            if (EARLY_STOPPING == True):\n",
    "                trigger_times += 1\n",
    "\n",
    "                print(f'Intermediate early stopping : vepoch_loss = {vepoch_loss:.4f}, the_last_loss={the_last_loss:.4f}')\n",
    "                #print(f'Intermediate early stopping : vepoch_accuracy = {vepoch_accuracy:.4f}, the_last_utility_score={the_last_accuracy:.4f}')\n",
    "                #print(f'Intermediate early stopping : vepoch_utility_score = {vepoch_utility_score:.4f}, the_last_utility_score={the_last_utility_score:.4f}')\n",
    "\n",
    "                if trigger_times >= patience:\n",
    "                    print('Meet Early stopping!')\n",
    "                    early_stopping_met = True\n",
    "                    ##torch.save(model.state_dict(), f'model_{fold}.pt')\n",
    "                    break\n",
    "        else:\n",
    "            trigger_times = 0\n",
    "            the_last_loss = vepoch_loss\n",
    "            the_last_utility_score = vepoch_utility_score\n",
    "            the_last_accuracy = vepoch_accuracy\n",
    "\n",
    "            the_last_utility_score_folds = vepoch_utility_score_folds\n",
    "            the_last_accuracy_folds = vepoch_accuracy_folds\n",
    "\n",
    "            the_best_epoch = epoch\n",
    "\n",
    "            # Save model for the best version so far\n",
    "            print(f'Saving model corresponding to last_utility_score == {the_last_utility_score}')\n",
    "            torch.save(model.state_dict(), MODEL_FILE)\n",
    "            #torch.onnx.export(model, batch, MODEL_FILE_ONNX)\n",
    "            #wandb.save(MODEL_FILE_ONNX)\n",
    "            wandb.log({\"Best accuracy\" : the_last_accuracy}, step=epoch)\n",
    "            wandb.log({\"Best utility\" : the_last_utility_score}, step=epoch)\n",
    "\n",
    "        print('\\n')\n",
    "\n",
    "    if (early_stopping_met == False):\n",
    "        print(\"Didn't meet early stopping : saving final model\")\n",
    "        # Save model if don't meet early stopping\n",
    "        torch.save(model.state_dict(), MODEL_FILE)\n",
    "        #torch.onnx.export(model, test_loader[0], MODEL_FILE_ONNX)\n",
    "        #wandb.save(MODEL_FILE_ONNX)\n",
    "        wandb.log({\"Best accuracy\" : the_last_accuracy}, step=epoch)\n",
    "        wandb.log({\"Best utility\" : the_last_utility_score}, step=epoch)\n",
    "\n",
    "    #utility_scores.append(the_last_utility_score)\n",
    "    #accuracy_scores.append(the_last_accuracy)\n",
    "    writer.add_text(f\"Global valid/Utility\", f\"Best utility: {the_last_utility_score}\", the_best_epoch)\n",
    "\n",
    "    scores_results = {'utility_score': the_last_utility_score, 'utility_scores': the_last_utility_score_folds, 'utility_score_std': np.std(the_last_utility_score_folds), 'accuracy_scores': the_last_accuracy_folds}\n",
    "\n",
    "    writer.add_text('Final utility score', str(scores_results))\n",
    "    writer.add_text('Batch size', str(config_MLP.batch_size))\n",
    "    writer.add_text('Patience', str(patience))\n",
    "    writer.add_text('Number of epochs', str(NUM_EPOCHS))\n",
    "    writer.add_text('Best epoch', str(the_best_epoch))\n",
    "    writer.add_text('Number of parameters per layer', str([p.numel() for p in model.parameters()]))\n",
    "    writer.add_text('Model architecture', str(model).replace('\\n', '<BR>'))\n",
    "    writer.add_text('Comment', MODEL_COMMENT)\n",
    "\n",
    "\n",
    "    wandb.run.summary['Final utility score'] = str(scores_results)\n",
    "    wandb.run.summary['Batch size'] = str(config_MLP.batch_size)\n",
    "    wandb.run.summary['Patience'] = str(patience)\n",
    "    wandb.run.summary['Number of epochs'] = str(NUM_EPOCHS)\n",
    "    wandb.run.summary['Best epoch'] = str(the_best_epoch)\n",
    "    wandb.run.summary['Number of parameters per layer'] = str([p.numel() for p in model.parameters()])\n",
    "    wandb.run.summary['Model architecture'] = str(model).replace('\\n', '<BR>')\n",
    "    wandb.log({\"Best accuracy\" : the_last_accuracy}, step=epoch)\n",
    "    wandb.log({\"Best utility\" : the_last_utility_score}, step=epoch)\n",
    "\n",
    "    #wandb.log({\"Comment\" : MODEL_COMMENT})\n",
    "    wandb.run.summary['comment'] = MODEL_COMMENT\n",
    "\n",
    "    writer.close()\n",
    "    wandb.run.finish()\n",
    "    #run.finish()\n",
    "\n",
    "    print('Training summary:')\n",
    "    print(scores_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hdxrf4l7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leakyrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 35620\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.41790098684566673\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005619817128880918\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_autoenc: encoder-only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 2.6276222867743416e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">fiery-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/hdxrf4l7\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/hdxrf4l7</a><br/>\n",
       "                Run data is saved locally in <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_035206-hdxrf4l7</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Run config :\n",
      "config: {'activation_function': 'leakyrelu', 'batch_size': 35620, 'dropout': 0.41790098684566673, 'learning_rate': 0.0005619817128880918, 'use_autoenc': 'encoder-only', 'weight_decay': 2.6276222867743416e-05, 'epochs': 1000}\n",
      "Epoch(0) - Training Loss: 0.9296\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(0) - Fold 0 - Validation Loss : 0.7124\n",
      "Epoch(0) - Fold 0 - Validation Accuracy : 0.5001\n",
      "Epoch(0) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 1 - Validation Loss : 0.7088\n",
      "Epoch(0) - Fold 1 - Validation Accuracy : 0.5052\n",
      "Epoch(0) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 2 - Validation Loss : 0.7091\n",
      "Epoch(0) - Fold 2 - Validation Accuracy : 0.4994\n",
      "Epoch(0) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 3 - Validation Loss : 0.7104\n",
      "Epoch(0) - Fold 3 - Validation Accuracy : 0.5001\n",
      "Epoch(0) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 4 - Validation Loss : 0.7112\n",
      "Epoch(0) - Fold 4 - Validation Accuracy : 0.4983\n",
      "Epoch(0) - Fold 4 - Validation Utility score : 17.0530\n",
      "Epoch(0) - GLOBAL - Validation Loss: 0.7104\n",
      "Epoch(0) - GLOBAL - Validation Accuracy: 0.5006\n",
      "Epoch(0) - GLOBAL - Validation Utility score: 17.0530\n",
      "Saving model corresponding to last_utility_score == 17.053036664252364\n",
      "\n",
      "\n",
      "Epoch(1) - Training Loss: 0.8326\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(1) - Fold 0 - Validation Loss : 0.6988\n",
      "Epoch(1) - Fold 0 - Validation Accuracy : 0.5010\n",
      "Epoch(1) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 1 - Validation Loss : 0.6982\n",
      "Epoch(1) - Fold 1 - Validation Accuracy : 0.5050\n",
      "Epoch(1) - Fold 1 - Validation Utility score : 2.3784\n",
      "Epoch(1) - Fold 2 - Validation Loss : 0.6988\n",
      "Epoch(1) - Fold 2 - Validation Accuracy : 0.4984\n",
      "Epoch(1) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 3 - Validation Loss : 0.6989\n",
      "Epoch(1) - Fold 3 - Validation Accuracy : 0.4994\n",
      "Epoch(1) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 4 - Validation Loss : 0.7000\n",
      "Epoch(1) - Fold 4 - Validation Accuracy : 0.4960\n",
      "Epoch(1) - Fold 4 - Validation Utility score : 0.0000\n",
      "Epoch(1) - GLOBAL - Validation Loss: 0.6989\n",
      "Epoch(1) - GLOBAL - Validation Accuracy: 0.5000\n",
      "Epoch(1) - GLOBAL - Validation Utility score: 2.3785\n",
      "Saving model corresponding to last_utility_score == 2.378465886602331\n",
      "\n",
      "\n",
      "Epoch(2) - Training Loss: 0.7721\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(2) - Fold 0 - Validation Loss : 0.6973\n",
      "Epoch(2) - Fold 0 - Validation Accuracy : 0.5010\n",
      "Epoch(2) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 1 - Validation Loss : 0.6968\n",
      "Epoch(2) - Fold 1 - Validation Accuracy : 0.5064\n",
      "Epoch(2) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 2 - Validation Loss : 0.6969\n",
      "Epoch(2) - Fold 2 - Validation Accuracy : 0.5015\n",
      "Epoch(2) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 3 - Validation Loss : 0.6977\n",
      "Epoch(2) - Fold 3 - Validation Accuracy : 0.5002\n",
      "Epoch(2) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 4 - Validation Loss : 0.6975\n",
      "Epoch(2) - Fold 4 - Validation Accuracy : 0.4981\n",
      "Epoch(2) - Fold 4 - Validation Utility score : 15.6830\n",
      "Epoch(2) - GLOBAL - Validation Loss: 0.6972\n",
      "Epoch(2) - GLOBAL - Validation Accuracy: 0.5015\n",
      "Epoch(2) - GLOBAL - Validation Utility score: 15.6830\n",
      "Saving model corresponding to last_utility_score == 15.683001208135957\n",
      "\n",
      "\n",
      "Epoch(3) - Training Loss: 0.7320\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(3) - Fold 0 - Validation Loss : 0.6957\n",
      "Epoch(3) - Fold 0 - Validation Accuracy : 0.5005\n",
      "Epoch(3) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 1 - Validation Loss : 0.6953\n",
      "Epoch(3) - Fold 1 - Validation Accuracy : 0.5062\n",
      "Epoch(3) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 2 - Validation Loss : 0.6957\n",
      "Epoch(3) - Fold 2 - Validation Accuracy : 0.5019\n",
      "Epoch(3) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 3 - Validation Loss : 0.6961\n",
      "Epoch(3) - Fold 3 - Validation Accuracy : 0.5001\n",
      "Epoch(3) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 4 - Validation Loss : 0.6961\n",
      "Epoch(3) - Fold 4 - Validation Accuracy : 0.4984\n",
      "Epoch(3) - Fold 4 - Validation Utility score : 15.6808\n",
      "Epoch(3) - GLOBAL - Validation Loss: 0.6958\n",
      "Epoch(3) - GLOBAL - Validation Accuracy: 0.5014\n",
      "Epoch(3) - GLOBAL - Validation Utility score: 15.6808\n",
      "Saving model corresponding to last_utility_score == 15.680769451167576\n",
      "\n",
      "\n",
      "Epoch(4) - Training Loss: 0.7094\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(4) - Fold 0 - Validation Loss : 0.6946\n",
      "Epoch(4) - Fold 0 - Validation Accuracy : 0.5004\n",
      "Epoch(4) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 1 - Validation Loss : 0.6941\n",
      "Epoch(4) - Fold 1 - Validation Accuracy : 0.5059\n",
      "Epoch(4) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 2 - Validation Loss : 0.6943\n",
      "Epoch(4) - Fold 2 - Validation Accuracy : 0.5019\n",
      "Epoch(4) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 3 - Validation Loss : 0.6945\n",
      "Epoch(4) - Fold 3 - Validation Accuracy : 0.4997\n",
      "Epoch(4) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 4 - Validation Loss : 0.6946\n",
      "Epoch(4) - Fold 4 - Validation Accuracy : 0.4988\n",
      "Epoch(4) - Fold 4 - Validation Utility score : 16.6569\n",
      "Epoch(4) - GLOBAL - Validation Loss: 0.6944\n",
      "Epoch(4) - GLOBAL - Validation Accuracy: 0.5013\n",
      "Epoch(4) - GLOBAL - Validation Utility score: 16.6569\n",
      "Saving model corresponding to last_utility_score == 16.65694471963653\n",
      "\n",
      "\n",
      "Epoch(5) - Training Loss: 0.6999\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(5) - Fold 0 - Validation Loss : 0.6941\n",
      "Epoch(5) - Fold 0 - Validation Accuracy : 0.4996\n",
      "Epoch(5) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 1 - Validation Loss : 0.6934\n",
      "Epoch(5) - Fold 1 - Validation Accuracy : 0.5065\n",
      "Epoch(5) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 2 - Validation Loss : 0.6938\n",
      "Epoch(5) - Fold 2 - Validation Accuracy : 0.5019\n",
      "Epoch(5) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 3 - Validation Loss : 0.6939\n",
      "Epoch(5) - Fold 3 - Validation Accuracy : 0.4997\n",
      "Epoch(5) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 4 - Validation Loss : 0.6941\n",
      "Epoch(5) - Fold 4 - Validation Accuracy : 0.4990\n",
      "Epoch(5) - Fold 4 - Validation Utility score : 21.0337\n",
      "Epoch(5) - GLOBAL - Validation Loss: 0.6939\n",
      "Epoch(5) - GLOBAL - Validation Accuracy: 0.5013\n",
      "Epoch(5) - GLOBAL - Validation Utility score: 21.0337\n",
      "Saving model corresponding to last_utility_score == 21.033688057238045\n",
      "\n",
      "\n",
      "Epoch(6) - Training Loss: 0.6964\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(6) - Fold 0 - Validation Loss : 0.6937\n",
      "Epoch(6) - Fold 0 - Validation Accuracy : 0.4996\n",
      "Epoch(6) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 1 - Validation Loss : 0.6931\n",
      "Epoch(6) - Fold 1 - Validation Accuracy : 0.5067\n",
      "Epoch(6) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 2 - Validation Loss : 0.6936\n",
      "Epoch(6) - Fold 2 - Validation Accuracy : 0.5025\n",
      "Epoch(6) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 3 - Validation Loss : 0.6937\n",
      "Epoch(6) - Fold 3 - Validation Accuracy : 0.5004\n",
      "Epoch(6) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 4 - Validation Loss : 0.6938\n",
      "Epoch(6) - Fold 4 - Validation Accuracy : 0.4994\n",
      "Epoch(6) - Fold 4 - Validation Utility score : 20.1152\n",
      "Epoch(6) - GLOBAL - Validation Loss: 0.6936\n",
      "Epoch(6) - GLOBAL - Validation Accuracy: 0.5017\n",
      "Epoch(6) - GLOBAL - Validation Utility score: 20.1152\n",
      "Saving model corresponding to last_utility_score == 20.11518020697446\n",
      "\n",
      "\n",
      "Epoch(7) - Training Loss: 0.6949\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(7) - Fold 0 - Validation Loss : 0.6933\n",
      "Epoch(7) - Fold 0 - Validation Accuracy : 0.5021\n",
      "Epoch(7) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(7) - Fold 1 - Validation Accuracy : 0.5091\n",
      "Epoch(7) - Fold 1 - Validation Utility score : 0.0876\n",
      "Epoch(7) - Fold 2 - Validation Loss : 0.6934\n",
      "Epoch(7) - Fold 2 - Validation Accuracy : 0.5027\n",
      "Epoch(7) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 3 - Validation Loss : 0.6935\n",
      "Epoch(7) - Fold 3 - Validation Accuracy : 0.5021\n",
      "Epoch(7) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 4 - Validation Loss : 0.6935\n",
      "Epoch(7) - Fold 4 - Validation Accuracy : 0.5003\n",
      "Epoch(7) - Fold 4 - Validation Utility score : 30.8179\n",
      "Epoch(7) - GLOBAL - Validation Loss: 0.6933\n",
      "Epoch(7) - GLOBAL - Validation Accuracy: 0.5033\n",
      "Epoch(7) - GLOBAL - Validation Utility score: 30.9055\n",
      "Saving model corresponding to last_utility_score == 30.905496824677996\n",
      "\n",
      "\n",
      "Epoch(8) - Training Loss: 0.6943\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(8) - Fold 0 - Validation Loss : 0.6933\n",
      "Epoch(8) - Fold 0 - Validation Accuracy : 0.5016\n",
      "Epoch(8) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(8) - Fold 1 - Validation Accuracy : 0.5082\n",
      "Epoch(8) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 2 - Validation Loss : 0.6934\n",
      "Epoch(8) - Fold 2 - Validation Accuracy : 0.5032\n",
      "Epoch(8) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 3 - Validation Loss : 0.6935\n",
      "Epoch(8) - Fold 3 - Validation Accuracy : 0.5016\n",
      "Epoch(8) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 4 - Validation Loss : 0.6936\n",
      "Epoch(8) - Fold 4 - Validation Accuracy : 0.4998\n",
      "Epoch(8) - Fold 4 - Validation Utility score : 31.6294\n",
      "Epoch(8) - GLOBAL - Validation Loss: 0.6933\n",
      "Epoch(8) - GLOBAL - Validation Accuracy: 0.5029\n",
      "Epoch(8) - GLOBAL - Validation Utility score: 31.6294\n",
      "Intermediate early stopping : vepoch_loss = 0.6933, the_last_loss=0.6933\n",
      "\n",
      "\n",
      "Epoch(9) - Training Loss: 0.6940\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(9) - Fold 0 - Validation Loss : 0.6934\n",
      "Epoch(9) - Fold 0 - Validation Accuracy : 0.5018\n",
      "Epoch(9) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(9) - Fold 1 - Validation Accuracy : 0.5077\n",
      "Epoch(9) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 2 - Validation Loss : 0.6934\n",
      "Epoch(9) - Fold 2 - Validation Accuracy : 0.5028\n",
      "Epoch(9) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 3 - Validation Loss : 0.6936\n",
      "Epoch(9) - Fold 3 - Validation Accuracy : 0.5016\n",
      "Epoch(9) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 4 - Validation Loss : 0.6936\n",
      "Epoch(9) - Fold 4 - Validation Accuracy : 0.5000\n",
      "Epoch(9) - Fold 4 - Validation Utility score : 29.4770\n",
      "Epoch(9) - GLOBAL - Validation Loss: 0.6934\n",
      "Epoch(9) - GLOBAL - Validation Accuracy: 0.5028\n",
      "Epoch(9) - GLOBAL - Validation Utility score: 29.4770\n",
      "Intermediate early stopping : vepoch_loss = 0.6934, the_last_loss=0.6933\n",
      "\n",
      "\n",
      "Epoch(10) - Training Loss: 0.6938\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(10) - Fold 0 - Validation Loss : 0.6932\n",
      "Epoch(10) - Fold 0 - Validation Accuracy : 0.5031\n",
      "Epoch(10) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(10) - Fold 1 - Validation Accuracy : 0.5091\n",
      "Epoch(10) - Fold 1 - Validation Utility score : 0.0072\n",
      "Epoch(10) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(10) - Fold 2 - Validation Accuracy : 0.5034\n",
      "Epoch(10) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 3 - Validation Loss : 0.6935\n",
      "Epoch(10) - Fold 3 - Validation Accuracy : 0.5029\n",
      "Epoch(10) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 4 - Validation Loss : 0.6935\n",
      "Epoch(10) - Fold 4 - Validation Accuracy : 0.5011\n",
      "Epoch(10) - Fold 4 - Validation Utility score : 39.0868\n",
      "Epoch(10) - GLOBAL - Validation Loss: 0.6932\n",
      "Epoch(10) - GLOBAL - Validation Accuracy: 0.5039\n",
      "Epoch(10) - GLOBAL - Validation Utility score: 39.0941\n",
      "Saving model corresponding to last_utility_score == 39.094073743936974\n",
      "\n",
      "\n",
      "Epoch(11) - Training Loss: 0.6936\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(11) - Fold 0 - Validation Loss : 0.6932\n",
      "Epoch(11) - Fold 0 - Validation Accuracy : 0.5033\n",
      "Epoch(11) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(11) - Fold 1 - Validation Accuracy : 0.5089\n",
      "Epoch(11) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(11) - Fold 2 - Validation Accuracy : 0.5029\n",
      "Epoch(11) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 3 - Validation Loss : 0.6935\n",
      "Epoch(11) - Fold 3 - Validation Accuracy : 0.5029\n",
      "Epoch(11) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 4 - Validation Loss : 0.6935\n",
      "Epoch(11) - Fold 4 - Validation Accuracy : 0.5018\n",
      "Epoch(11) - Fold 4 - Validation Utility score : 61.9785\n",
      "Epoch(11) - GLOBAL - Validation Loss: 0.6932\n",
      "Epoch(11) - GLOBAL - Validation Accuracy: 0.5040\n",
      "Epoch(11) - GLOBAL - Validation Utility score: 61.9785\n",
      "Saving model corresponding to last_utility_score == 61.97854906610233\n",
      "\n",
      "\n",
      "Epoch(12) - Training Loss: 0.6935\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(12) - Fold 0 - Validation Loss : 0.6932\n",
      "Epoch(12) - Fold 0 - Validation Accuracy : 0.5023\n",
      "Epoch(12) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(12) - Fold 1 - Validation Accuracy : 0.5080\n",
      "Epoch(12) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 2 - Validation Loss : 0.6934\n",
      "Epoch(12) - Fold 2 - Validation Accuracy : 0.5026\n",
      "Epoch(12) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 3 - Validation Loss : 0.6936\n",
      "Epoch(12) - Fold 3 - Validation Accuracy : 0.5023\n",
      "Epoch(12) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 4 - Validation Loss : 0.6935\n",
      "Epoch(12) - Fold 4 - Validation Accuracy : 0.5017\n",
      "Epoch(12) - Fold 4 - Validation Utility score : 76.0869\n",
      "Epoch(12) - GLOBAL - Validation Loss: 0.6933\n",
      "Epoch(12) - GLOBAL - Validation Accuracy: 0.5034\n",
      "Epoch(12) - GLOBAL - Validation Utility score: 76.0869\n",
      "Intermediate early stopping : vepoch_loss = 0.6933, the_last_loss=0.6932\n",
      "\n",
      "\n",
      "Epoch(13) - Training Loss: 0.6934\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(13) - Fold 0 - Validation Loss : 0.6929\n",
      "Epoch(13) - Fold 0 - Validation Accuracy : 0.5071\n",
      "Epoch(13) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(13) - Fold 1 - Validation Accuracy : 0.5120\n",
      "Epoch(13) - Fold 1 - Validation Utility score : 14.3364\n",
      "Epoch(13) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(13) - Fold 2 - Validation Accuracy : 0.5032\n",
      "Epoch(13) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(13) - Fold 3 - Validation Accuracy : 0.5042\n",
      "Epoch(13) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 4 - Validation Loss : 0.6933\n",
      "Epoch(13) - Fold 4 - Validation Accuracy : 0.5035\n",
      "Epoch(13) - Fold 4 - Validation Utility score : 128.8023\n",
      "Epoch(13) - GLOBAL - Validation Loss: 0.6931\n",
      "Epoch(13) - GLOBAL - Validation Accuracy: 0.5060\n",
      "Epoch(13) - GLOBAL - Validation Utility score: 143.1388\n",
      "Saving model corresponding to last_utility_score == 143.1387686824235\n",
      "\n",
      "\n",
      "Epoch(14) - Training Loss: 0.6934\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(14) - Fold 0 - Validation Loss : 0.6928\n",
      "Epoch(14) - Fold 0 - Validation Accuracy : 0.5085\n",
      "Epoch(14) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(14) - Fold 1 - Validation Accuracy : 0.5128\n",
      "Epoch(14) - Fold 1 - Validation Utility score : 28.7396\n",
      "Epoch(14) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(14) - Fold 2 - Validation Accuracy : 0.5040\n",
      "Epoch(14) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(14) - Fold 3 - Validation Accuracy : 0.5047\n",
      "Epoch(14) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 4 - Validation Loss : 0.6932\n",
      "Epoch(14) - Fold 4 - Validation Accuracy : 0.5039\n",
      "Epoch(14) - Fold 4 - Validation Utility score : 170.5603\n",
      "Epoch(14) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(14) - GLOBAL - Validation Accuracy: 0.5068\n",
      "Epoch(14) - GLOBAL - Validation Utility score: 199.2999\n",
      "Saving model corresponding to last_utility_score == 199.29989397439127\n",
      "\n",
      "\n",
      "Epoch(15) - Training Loss: 0.6933\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(15) - Fold 0 - Validation Loss : 0.6928\n",
      "Epoch(15) - Fold 0 - Validation Accuracy : 0.5097\n",
      "Epoch(15) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(15) - Fold 1 - Validation Accuracy : 0.5139\n",
      "Epoch(15) - Fold 1 - Validation Utility score : 66.5638\n",
      "Epoch(15) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(15) - Fold 2 - Validation Accuracy : 0.5044\n",
      "Epoch(15) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(15) - Fold 3 - Validation Accuracy : 0.5053\n",
      "Epoch(15) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 4 - Validation Loss : 0.6932\n",
      "Epoch(15) - Fold 4 - Validation Accuracy : 0.5047\n",
      "Epoch(15) - Fold 4 - Validation Utility score : 239.7587\n",
      "Epoch(15) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(15) - GLOBAL - Validation Accuracy: 0.5076\n",
      "Epoch(15) - GLOBAL - Validation Utility score: 306.3225\n",
      "Saving model corresponding to last_utility_score == 306.32246869803606\n",
      "\n",
      "\n",
      "Epoch(16) - Training Loss: 0.6933\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(16) - Fold 0 - Validation Loss : 0.6929\n",
      "Epoch(16) - Fold 0 - Validation Accuracy : 0.5073\n",
      "Epoch(16) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(16) - Fold 1 - Validation Accuracy : 0.5115\n",
      "Epoch(16) - Fold 1 - Validation Utility score : 4.2832\n",
      "Epoch(16) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(16) - Fold 2 - Validation Accuracy : 0.5031\n",
      "Epoch(16) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(16) - Fold 3 - Validation Accuracy : 0.5045\n",
      "Epoch(16) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 4 - Validation Loss : 0.6932\n",
      "Epoch(16) - Fold 4 - Validation Accuracy : 0.5035\n",
      "Epoch(16) - Fold 4 - Validation Utility score : 162.7026\n",
      "Epoch(16) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(16) - GLOBAL - Validation Accuracy: 0.5060\n",
      "Epoch(16) - GLOBAL - Validation Utility score: 166.9858\n",
      "Intermediate early stopping : vepoch_loss = 0.6930, the_last_loss=0.6930\n",
      "\n",
      "\n",
      "Epoch(17) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(17) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(17) - Fold 0 - Validation Accuracy : 0.5097\n",
      "Epoch(17) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(17) - Fold 1 - Validation Accuracy : 0.5141\n",
      "Epoch(17) - Fold 1 - Validation Utility score : 75.9688\n",
      "Epoch(17) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(17) - Fold 2 - Validation Accuracy : 0.5040\n",
      "Epoch(17) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(17) - Fold 3 - Validation Accuracy : 0.5051\n",
      "Epoch(17) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 4 - Validation Loss : 0.6931\n",
      "Epoch(17) - Fold 4 - Validation Accuracy : 0.5054\n",
      "Epoch(17) - Fold 4 - Validation Utility score : 312.2695\n",
      "Epoch(17) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(17) - GLOBAL - Validation Accuracy: 0.5076\n",
      "Epoch(17) - GLOBAL - Validation Utility score: 388.2383\n",
      "Saving model corresponding to last_utility_score == 388.2383471521514\n",
      "\n",
      "\n",
      "Epoch(18) - Training Loss: 0.6931\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(18) - Fold 0 - Validation Loss : 0.6928\n",
      "Epoch(18) - Fold 0 - Validation Accuracy : 0.5091\n",
      "Epoch(18) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(18) - Fold 1 - Validation Accuracy : 0.5133\n",
      "Epoch(18) - Fold 1 - Validation Utility score : 26.1605\n",
      "Epoch(18) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(18) - Fold 2 - Validation Accuracy : 0.5041\n",
      "Epoch(18) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(18) - Fold 3 - Validation Accuracy : 0.5053\n",
      "Epoch(18) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 4 - Validation Loss : 0.6931\n",
      "Epoch(18) - Fold 4 - Validation Accuracy : 0.5050\n",
      "Epoch(18) - Fold 4 - Validation Utility score : 220.6544\n",
      "Epoch(18) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(18) - GLOBAL - Validation Accuracy: 0.5074\n",
      "Epoch(18) - GLOBAL - Validation Utility score: 246.8149\n",
      "Intermediate early stopping : vepoch_loss = 0.6929, the_last_loss=0.6929\n",
      "\n",
      "\n",
      "Epoch(19) - Training Loss: 0.6931\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(19) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(19) - Fold 0 - Validation Accuracy : 0.5127\n",
      "Epoch(19) - Fold 0 - Validation Utility score : 2.9867\n",
      "Epoch(19) - Fold 1 - Validation Loss : 0.6923\n",
      "Epoch(19) - Fold 1 - Validation Accuracy : 0.5165\n",
      "Epoch(19) - Fold 1 - Validation Utility score : 186.3756\n",
      "Epoch(19) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(19) - Fold 2 - Validation Accuracy : 0.5057\n",
      "Epoch(19) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(19) - Fold 3 - Validation Accuracy : 0.5068\n",
      "Epoch(19) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 4 - Validation Loss : 0.6930\n",
      "Epoch(19) - Fold 4 - Validation Accuracy : 0.5068\n",
      "Epoch(19) - Fold 4 - Validation Utility score : 481.7727\n",
      "Epoch(19) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(19) - GLOBAL - Validation Accuracy: 0.5097\n",
      "Epoch(19) - GLOBAL - Validation Utility score: 671.1351\n",
      "Saving model corresponding to last_utility_score == 671.1351010311578\n",
      "\n",
      "\n",
      "Epoch(20) - Training Loss: 0.6930\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(20) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(20) - Fold 0 - Validation Accuracy : 0.5147\n",
      "Epoch(20) - Fold 0 - Validation Utility score : 5.3437\n",
      "Epoch(20) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(20) - Fold 1 - Validation Accuracy : 0.5196\n",
      "Epoch(20) - Fold 1 - Validation Utility score : 263.1562\n",
      "Epoch(20) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(20) - Fold 2 - Validation Accuracy : 0.5070\n",
      "Epoch(20) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(20) - Fold 3 - Validation Accuracy : 0.5072\n",
      "Epoch(20) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(20) - Fold 4 - Validation Accuracy : 0.5076\n",
      "Epoch(20) - Fold 4 - Validation Utility score : 580.6758\n",
      "Epoch(20) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(20) - GLOBAL - Validation Accuracy: 0.5112\n",
      "Epoch(20) - GLOBAL - Validation Utility score: 849.1757\n",
      "Saving model corresponding to last_utility_score == 849.1757235836808\n",
      "\n",
      "\n",
      "Epoch(21) - Training Loss: 0.6930\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(21) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(21) - Fold 0 - Validation Accuracy : 0.5116\n",
      "Epoch(21) - Fold 0 - Validation Utility score : 0.0263\n",
      "Epoch(21) - Fold 1 - Validation Loss : 0.6923\n",
      "Epoch(21) - Fold 1 - Validation Accuracy : 0.5158\n",
      "Epoch(21) - Fold 1 - Validation Utility score : 148.5602\n",
      "Epoch(21) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(21) - Fold 2 - Validation Accuracy : 0.5052\n",
      "Epoch(21) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(21) - Fold 3 - Validation Accuracy : 0.5067\n",
      "Epoch(21) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 4 - Validation Loss : 0.6930\n",
      "Epoch(21) - Fold 4 - Validation Accuracy : 0.5063\n",
      "Epoch(21) - Fold 4 - Validation Utility score : 475.4160\n",
      "Epoch(21) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(21) - GLOBAL - Validation Accuracy: 0.5091\n",
      "Epoch(21) - GLOBAL - Validation Utility score: 624.0025\n",
      "Intermediate early stopping : vepoch_loss = 0.6928, the_last_loss=0.6927\n",
      "\n",
      "\n",
      "Epoch(22) - Training Loss: 0.6929\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(22) - Fold 0 - Validation Loss : 0.6924\n",
      "Epoch(22) - Fold 0 - Validation Accuracy : 0.5169\n",
      "Epoch(22) - Fold 0 - Validation Utility score : 66.3734\n",
      "Epoch(22) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(22) - Fold 1 - Validation Accuracy : 0.5221\n",
      "Epoch(22) - Fold 1 - Validation Utility score : 390.4753\n",
      "Epoch(22) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(22) - Fold 2 - Validation Accuracy : 0.5075\n",
      "Epoch(22) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(22) - Fold 3 - Validation Accuracy : 0.5077\n",
      "Epoch(22) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(22) - Fold 4 - Validation Accuracy : 0.5090\n",
      "Epoch(22) - Fold 4 - Validation Utility score : 776.2124\n",
      "Epoch(22) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(22) - GLOBAL - Validation Accuracy: 0.5126\n",
      "Epoch(22) - GLOBAL - Validation Utility score: 1233.0612\n",
      "Saving model corresponding to last_utility_score == 1233.0611710557243\n",
      "\n",
      "\n",
      "Epoch(23) - Training Loss: 0.6929\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(23) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(23) - Fold 0 - Validation Accuracy : 0.5134\n",
      "Epoch(23) - Fold 0 - Validation Utility score : 2.6755\n",
      "Epoch(23) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(23) - Fold 1 - Validation Accuracy : 0.5183\n",
      "Epoch(23) - Fold 1 - Validation Utility score : 234.5026\n",
      "Epoch(23) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(23) - Fold 2 - Validation Accuracy : 0.5075\n",
      "Epoch(23) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(23) - Fold 3 - Validation Accuracy : 0.5076\n",
      "Epoch(23) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(23) - Fold 4 - Validation Accuracy : 0.5083\n",
      "Epoch(23) - Fold 4 - Validation Utility score : 526.5426\n",
      "Epoch(23) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(23) - GLOBAL - Validation Accuracy: 0.5110\n",
      "Epoch(23) - GLOBAL - Validation Utility score: 763.7207\n",
      "Intermediate early stopping : vepoch_loss = 0.6927, the_last_loss=0.6926\n",
      "\n",
      "\n",
      "Epoch(24) - Training Loss: 0.6929\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(24) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(24) - Fold 0 - Validation Accuracy : 0.5192\n",
      "Epoch(24) - Fold 0 - Validation Utility score : 117.6753\n",
      "Epoch(24) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(24) - Fold 1 - Validation Accuracy : 0.5242\n",
      "Epoch(24) - Fold 1 - Validation Utility score : 493.9100\n",
      "Epoch(24) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(24) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(24) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(24) - Fold 3 - Validation Accuracy : 0.5067\n",
      "Epoch(24) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(24) - Fold 4 - Validation Accuracy : 0.5103\n",
      "Epoch(24) - Fold 4 - Validation Utility score : 804.0873\n",
      "Epoch(24) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(24) - GLOBAL - Validation Accuracy: 0.5138\n",
      "Epoch(24) - GLOBAL - Validation Utility score: 1415.6726\n",
      "Saving model corresponding to last_utility_score == 1415.6726312919272\n",
      "\n",
      "\n",
      "Epoch(25) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(25) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(25) - Fold 0 - Validation Accuracy : 0.5168\n",
      "Epoch(25) - Fold 0 - Validation Utility score : 49.2003\n",
      "Epoch(25) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(25) - Fold 1 - Validation Accuracy : 0.5223\n",
      "Epoch(25) - Fold 1 - Validation Utility score : 427.5681\n",
      "Epoch(25) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(25) - Fold 2 - Validation Accuracy : 0.5080\n",
      "Epoch(25) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(25) - Fold 3 - Validation Accuracy : 0.5077\n",
      "Epoch(25) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(25) - Fold 4 - Validation Accuracy : 0.5099\n",
      "Epoch(25) - Fold 4 - Validation Utility score : 830.7227\n",
      "Epoch(25) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(25) - GLOBAL - Validation Accuracy: 0.5129\n",
      "Epoch(25) - GLOBAL - Validation Utility score: 1307.4911\n",
      "Intermediate early stopping : vepoch_loss = 0.6926, the_last_loss=0.6926\n",
      "\n",
      "\n",
      "Epoch(26) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(26) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(26) - Fold 0 - Validation Accuracy : 0.5187\n",
      "Epoch(26) - Fold 0 - Validation Utility score : 96.6629\n",
      "Epoch(26) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(26) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(26) - Fold 1 - Validation Utility score : 426.3880\n",
      "Epoch(26) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(26) - Fold 2 - Validation Accuracy : 0.5084\n",
      "Epoch(26) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(26) - Fold 3 - Validation Accuracy : 0.5068\n",
      "Epoch(26) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(26) - Fold 4 - Validation Accuracy : 0.5102\n",
      "Epoch(26) - Fold 4 - Validation Utility score : 793.7718\n",
      "Epoch(26) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(26) - GLOBAL - Validation Accuracy: 0.5135\n",
      "Epoch(26) - GLOBAL - Validation Utility score: 1316.8227\n",
      "Saving model corresponding to last_utility_score == 1316.82265300667\n",
      "\n",
      "\n",
      "Epoch(27) - Training Loss: 0.6927\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(27) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(27) - Fold 0 - Validation Accuracy : 0.5166\n",
      "Epoch(27) - Fold 0 - Validation Utility score : 35.8728\n",
      "Epoch(27) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(27) - Fold 1 - Validation Accuracy : 0.5217\n",
      "Epoch(27) - Fold 1 - Validation Utility score : 359.5222\n",
      "Epoch(27) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(27) - Fold 2 - Validation Accuracy : 0.5080\n",
      "Epoch(27) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(27) - Fold 3 - Validation Accuracy : 0.5073\n",
      "Epoch(27) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(27) - Fold 4 - Validation Accuracy : 0.5093\n",
      "Epoch(27) - Fold 4 - Validation Utility score : 693.3051\n",
      "Epoch(27) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(27) - GLOBAL - Validation Accuracy: 0.5126\n",
      "Epoch(27) - GLOBAL - Validation Utility score: 1088.7001\n",
      "Intermediate early stopping : vepoch_loss = 0.6926, the_last_loss=0.6925\n",
      "\n",
      "\n",
      "Epoch(28) - Training Loss: 0.6927\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(28) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(28) - Fold 0 - Validation Accuracy : 0.5202\n",
      "Epoch(28) - Fold 0 - Validation Utility score : 217.3077\n",
      "Epoch(28) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(28) - Fold 1 - Validation Accuracy : 0.5241\n",
      "Epoch(28) - Fold 1 - Validation Utility score : 539.8897\n",
      "Epoch(28) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(28) - Fold 2 - Validation Accuracy : 0.5084\n",
      "Epoch(28) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(28) - Fold 3 - Validation Accuracy : 0.5070\n",
      "Epoch(28) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(28) - Fold 4 - Validation Accuracy : 0.5119\n",
      "Epoch(28) - Fold 4 - Validation Utility score : 835.5177\n",
      "Epoch(28) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(28) - GLOBAL - Validation Accuracy: 0.5143\n",
      "Epoch(28) - GLOBAL - Validation Utility score: 1592.7151\n",
      "Saving model corresponding to last_utility_score == 1592.715139633522\n",
      "\n",
      "\n",
      "Epoch(29) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(29) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(29) - Fold 0 - Validation Accuracy : 0.5208\n",
      "Epoch(29) - Fold 0 - Validation Utility score : 288.4437\n",
      "Epoch(29) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(29) - Fold 1 - Validation Accuracy : 0.5238\n",
      "Epoch(29) - Fold 1 - Validation Utility score : 493.9096\n",
      "Epoch(29) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(29) - Fold 2 - Validation Accuracy : 0.5082\n",
      "Epoch(29) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(29) - Fold 3 - Validation Accuracy : 0.5068\n",
      "Epoch(29) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(29) - Fold 4 - Validation Accuracy : 0.5118\n",
      "Epoch(29) - Fold 4 - Validation Utility score : 780.9943\n",
      "Epoch(29) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(29) - GLOBAL - Validation Accuracy: 0.5143\n",
      "Epoch(29) - GLOBAL - Validation Utility score: 1563.3476\n",
      "Saving model corresponding to last_utility_score == 1563.3475852175052\n",
      "\n",
      "\n",
      "Epoch(30) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(30) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(30) - Fold 0 - Validation Accuracy : 0.5173\n",
      "Epoch(30) - Fold 0 - Validation Utility score : 54.5040\n",
      "Epoch(30) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(30) - Fold 1 - Validation Accuracy : 0.5212\n",
      "Epoch(30) - Fold 1 - Validation Utility score : 368.3968\n",
      "Epoch(30) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(30) - Fold 2 - Validation Accuracy : 0.5081\n",
      "Epoch(30) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(30) - Fold 3 - Validation Accuracy : 0.5073\n",
      "Epoch(30) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(30) - Fold 4 - Validation Accuracy : 0.5091\n",
      "Epoch(30) - Fold 4 - Validation Utility score : 615.5598\n",
      "Epoch(30) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(30) - GLOBAL - Validation Accuracy: 0.5126\n",
      "Epoch(30) - GLOBAL - Validation Utility score: 1038.4605\n",
      "Intermediate early stopping : vepoch_loss = 0.6925, the_last_loss=0.6924\n",
      "\n",
      "\n",
      "Epoch(31) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(31) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(31) - Fold 0 - Validation Accuracy : 0.5200\n",
      "Epoch(31) - Fold 0 - Validation Utility score : 221.9866\n",
      "Epoch(31) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(31) - Fold 1 - Validation Accuracy : 0.5236\n",
      "Epoch(31) - Fold 1 - Validation Utility score : 502.7847\n",
      "Epoch(31) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(31) - Fold 2 - Validation Accuracy : 0.5095\n",
      "Epoch(31) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(31) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(31) - Fold 3 - Validation Accuracy : 0.5063\n",
      "Epoch(31) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(31) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(31) - Fold 4 - Validation Accuracy : 0.5122\n",
      "Epoch(31) - Fold 4 - Validation Utility score : 840.7291\n",
      "Epoch(31) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(31) - GLOBAL - Validation Accuracy: 0.5143\n",
      "Epoch(31) - GLOBAL - Validation Utility score: 1565.5004\n",
      "Saving model corresponding to last_utility_score == 1565.5003637645318\n",
      "\n",
      "\n",
      "Epoch(32) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(32) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(32) - Fold 0 - Validation Accuracy : 0.5199\n",
      "Epoch(32) - Fold 0 - Validation Utility score : 201.3724\n",
      "Epoch(32) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(32) - Fold 1 - Validation Accuracy : 0.5227\n",
      "Epoch(32) - Fold 1 - Validation Utility score : 501.7371\n",
      "Epoch(32) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(32) - Fold 2 - Validation Accuracy : 0.5086\n",
      "Epoch(32) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(32) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(32) - Fold 3 - Validation Accuracy : 0.5077\n",
      "Epoch(32) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(32) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(32) - Fold 4 - Validation Accuracy : 0.5121\n",
      "Epoch(32) - Fold 4 - Validation Utility score : 900.0129\n",
      "Epoch(32) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(32) - GLOBAL - Validation Accuracy: 0.5142\n",
      "Epoch(32) - GLOBAL - Validation Utility score: 1603.1225\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6924\n",
      "\n",
      "\n",
      "Epoch(33) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(33) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(33) - Fold 0 - Validation Accuracy : 0.5205\n",
      "Epoch(33) - Fold 0 - Validation Utility score : 196.0035\n",
      "Epoch(33) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(33) - Fold 1 - Validation Accuracy : 0.5233\n",
      "Epoch(33) - Fold 1 - Validation Utility score : 470.8225\n",
      "Epoch(33) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(33) - Fold 2 - Validation Accuracy : 0.5092\n",
      "Epoch(33) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(33) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(33) - Fold 3 - Validation Accuracy : 0.5077\n",
      "Epoch(33) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(33) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(33) - Fold 4 - Validation Accuracy : 0.5117\n",
      "Epoch(33) - Fold 4 - Validation Utility score : 975.8209\n",
      "Epoch(33) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(33) - GLOBAL - Validation Accuracy: 0.5145\n",
      "Epoch(33) - GLOBAL - Validation Utility score: 1642.6469\n",
      "Saving model corresponding to last_utility_score == 1642.6468600794833\n",
      "\n",
      "\n",
      "Epoch(34) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(34) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(34) - Fold 0 - Validation Accuracy : 0.5192\n",
      "Epoch(34) - Fold 0 - Validation Utility score : 114.1956\n",
      "Epoch(34) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(34) - Fold 1 - Validation Accuracy : 0.5221\n",
      "Epoch(34) - Fold 1 - Validation Utility score : 451.5055\n",
      "Epoch(34) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(34) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(34) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(34) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(34) - Fold 3 - Validation Accuracy : 0.5071\n",
      "Epoch(34) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(34) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(34) - Fold 4 - Validation Accuracy : 0.5107\n",
      "Epoch(34) - Fold 4 - Validation Utility score : 828.9768\n",
      "Epoch(34) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(34) - GLOBAL - Validation Accuracy: 0.5136\n",
      "Epoch(34) - GLOBAL - Validation Utility score: 1394.6779\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6923\n",
      "\n",
      "\n",
      "Epoch(35) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(35) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(35) - Fold 0 - Validation Accuracy : 0.5222\n",
      "Epoch(35) - Fold 0 - Validation Utility score : 325.9382\n",
      "Epoch(35) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(35) - Fold 1 - Validation Accuracy : 0.5246\n",
      "Epoch(35) - Fold 1 - Validation Utility score : 577.7599\n",
      "Epoch(35) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(35) - Fold 2 - Validation Accuracy : 0.5093\n",
      "Epoch(35) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(35) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(35) - Fold 3 - Validation Accuracy : 0.5065\n",
      "Epoch(35) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(35) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(35) - Fold 4 - Validation Accuracy : 0.5126\n",
      "Epoch(35) - Fold 4 - Validation Utility score : 888.4841\n",
      "Epoch(35) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(35) - GLOBAL - Validation Accuracy: 0.5150\n",
      "Epoch(35) - GLOBAL - Validation Utility score: 1792.1822\n",
      "Saving model corresponding to last_utility_score == 1792.182226981061\n",
      "\n",
      "\n",
      "Epoch(36) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(36) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(36) - Fold 0 - Validation Accuracy : 0.5188\n",
      "Epoch(36) - Fold 0 - Validation Utility score : 94.2036\n",
      "Epoch(36) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(36) - Fold 1 - Validation Accuracy : 0.5222\n",
      "Epoch(36) - Fold 1 - Validation Utility score : 450.2364\n",
      "Epoch(36) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(36) - Fold 2 - Validation Accuracy : 0.5082\n",
      "Epoch(36) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(36) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(36) - Fold 3 - Validation Accuracy : 0.5072\n",
      "Epoch(36) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(36) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(36) - Fold 4 - Validation Accuracy : 0.5106\n",
      "Epoch(36) - Fold 4 - Validation Utility score : 827.3622\n",
      "Epoch(36) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(36) - GLOBAL - Validation Accuracy: 0.5134\n",
      "Epoch(36) - GLOBAL - Validation Utility score: 1371.8023\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(37) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(37) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(37) - Fold 0 - Validation Accuracy : 0.5234\n",
      "Epoch(37) - Fold 0 - Validation Utility score : 402.9033\n",
      "Epoch(37) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(37) - Fold 1 - Validation Accuracy : 0.5243\n",
      "Epoch(37) - Fold 1 - Validation Utility score : 600.1563\n",
      "Epoch(37) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(37) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(37) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(37) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(37) - Fold 3 - Validation Accuracy : 0.5066\n",
      "Epoch(37) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(37) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(37) - Fold 4 - Validation Accuracy : 0.5135\n",
      "Epoch(37) - Fold 4 - Validation Utility score : 888.4418\n",
      "Epoch(37) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(37) - GLOBAL - Validation Accuracy: 0.5152\n",
      "Epoch(37) - GLOBAL - Validation Utility score: 1891.5014\n",
      "Saving model corresponding to last_utility_score == 1891.5014220142216\n",
      "\n",
      "\n",
      "Epoch(38) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(38) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(38) - Fold 0 - Validation Accuracy : 0.5198\n",
      "Epoch(38) - Fold 0 - Validation Utility score : 133.9340\n",
      "Epoch(38) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(38) - Fold 1 - Validation Accuracy : 0.5228\n",
      "Epoch(38) - Fold 1 - Validation Utility score : 485.6812\n",
      "Epoch(38) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(38) - Fold 2 - Validation Accuracy : 0.5086\n",
      "Epoch(38) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(38) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(38) - Fold 3 - Validation Accuracy : 0.5070\n",
      "Epoch(38) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(38) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(38) - Fold 4 - Validation Accuracy : 0.5112\n",
      "Epoch(38) - Fold 4 - Validation Utility score : 890.4527\n",
      "Epoch(38) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(38) - GLOBAL - Validation Accuracy: 0.5139\n",
      "Epoch(38) - GLOBAL - Validation Utility score: 1510.0678\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(39) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(39) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(39) - Fold 0 - Validation Accuracy : 0.5224\n",
      "Epoch(39) - Fold 0 - Validation Utility score : 291.9573\n",
      "Epoch(39) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(39) - Fold 1 - Validation Accuracy : 0.5242\n",
      "Epoch(39) - Fold 1 - Validation Utility score : 575.1574\n",
      "Epoch(39) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(39) - Fold 2 - Validation Accuracy : 0.5090\n",
      "Epoch(39) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(39) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(39) - Fold 3 - Validation Accuracy : 0.5069\n",
      "Epoch(39) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(39) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(39) - Fold 4 - Validation Accuracy : 0.5130\n",
      "Epoch(39) - Fold 4 - Validation Utility score : 939.2802\n",
      "Epoch(39) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(39) - GLOBAL - Validation Accuracy: 0.5151\n",
      "Epoch(39) - GLOBAL - Validation Utility score: 1806.3949\n",
      "Intermediate early stopping : vepoch_loss = 0.6922, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(40) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(40) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(40) - Fold 0 - Validation Accuracy : 0.5229\n",
      "Epoch(40) - Fold 0 - Validation Utility score : 360.0581\n",
      "Epoch(40) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(40) - Fold 1 - Validation Accuracy : 0.5248\n",
      "Epoch(40) - Fold 1 - Validation Utility score : 600.8950\n",
      "Epoch(40) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(40) - Fold 2 - Validation Accuracy : 0.5090\n",
      "Epoch(40) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(40) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(40) - Fold 3 - Validation Accuracy : 0.5072\n",
      "Epoch(40) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(40) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(40) - Fold 4 - Validation Accuracy : 0.5134\n",
      "Epoch(40) - Fold 4 - Validation Utility score : 920.2451\n",
      "Epoch(40) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(40) - GLOBAL - Validation Accuracy: 0.5155\n",
      "Epoch(40) - GLOBAL - Validation Utility score: 1881.1981\n",
      "Saving model corresponding to last_utility_score == 1881.1981399729116\n",
      "\n",
      "\n",
      "Epoch(41) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(41) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(41) - Fold 0 - Validation Accuracy : 0.5212\n",
      "Epoch(41) - Fold 0 - Validation Utility score : 211.9649\n",
      "Epoch(41) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(41) - Fold 1 - Validation Accuracy : 0.5239\n",
      "Epoch(41) - Fold 1 - Validation Utility score : 577.3438\n",
      "Epoch(41) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(41) - Fold 2 - Validation Accuracy : 0.5091\n",
      "Epoch(41) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(41) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(41) - Fold 3 - Validation Accuracy : 0.5066\n",
      "Epoch(41) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(41) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(41) - Fold 4 - Validation Accuracy : 0.5128\n",
      "Epoch(41) - Fold 4 - Validation Utility score : 1020.1592\n",
      "Epoch(41) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(41) - GLOBAL - Validation Accuracy: 0.5147\n",
      "Epoch(41) - GLOBAL - Validation Utility score: 1809.4679\n",
      "Intermediate early stopping : vepoch_loss = 0.6922, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(42) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(42) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(42) - Fold 0 - Validation Accuracy : 0.5221\n",
      "Epoch(42) - Fold 0 - Validation Utility score : 236.7784\n",
      "Epoch(42) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(42) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(42) - Fold 1 - Validation Utility score : 557.7998\n",
      "Epoch(42) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(42) - Fold 2 - Validation Accuracy : 0.5090\n",
      "Epoch(42) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(42) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(42) - Fold 3 - Validation Accuracy : 0.5074\n",
      "Epoch(42) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(42) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(42) - Fold 4 - Validation Accuracy : 0.5128\n",
      "Epoch(42) - Fold 4 - Validation Utility score : 936.8843\n",
      "Epoch(42) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(42) - GLOBAL - Validation Accuracy: 0.5151\n",
      "Epoch(42) - GLOBAL - Validation Utility score: 1731.4624\n",
      "Intermediate early stopping : vepoch_loss = 0.6922, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(43) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(43) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(43) - Fold 0 - Validation Accuracy : 0.5186\n",
      "Epoch(43) - Fold 0 - Validation Utility score : 89.6061\n",
      "Epoch(43) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(43) - Fold 1 - Validation Accuracy : 0.5219\n",
      "Epoch(43) - Fold 1 - Validation Utility score : 372.0429\n",
      "Epoch(43) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(43) - Fold 2 - Validation Accuracy : 0.5079\n",
      "Epoch(43) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(43) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(43) - Fold 3 - Validation Accuracy : 0.5071\n",
      "Epoch(43) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(43) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(43) - Fold 4 - Validation Accuracy : 0.5110\n",
      "Epoch(43) - Fold 4 - Validation Utility score : 754.5285\n",
      "Epoch(43) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(43) - GLOBAL - Validation Accuracy: 0.5133\n",
      "Epoch(43) - GLOBAL - Validation Utility score: 1216.1774\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(44) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(44) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(44) - Fold 0 - Validation Accuracy : 0.5222\n",
      "Epoch(44) - Fold 0 - Validation Utility score : 281.2795\n",
      "Epoch(44) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(44) - Fold 1 - Validation Accuracy : 0.5247\n",
      "Epoch(44) - Fold 1 - Validation Utility score : 687.7309\n",
      "Epoch(44) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(44) - Fold 2 - Validation Accuracy : 0.5089\n",
      "Epoch(44) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(44) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(44) - Fold 3 - Validation Accuracy : 0.5088\n",
      "Epoch(44) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(44) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(44) - Fold 4 - Validation Accuracy : 0.5139\n",
      "Epoch(44) - Fold 4 - Validation Utility score : 879.5600\n",
      "Epoch(44) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(44) - GLOBAL - Validation Accuracy: 0.5157\n",
      "Epoch(44) - GLOBAL - Validation Utility score: 1848.5703\n",
      "Saving model corresponding to last_utility_score == 1848.5703062077716\n",
      "\n",
      "\n",
      "Epoch(45) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(45) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(45) - Fold 0 - Validation Accuracy : 0.5209\n",
      "Epoch(45) - Fold 0 - Validation Utility score : 183.5944\n",
      "Epoch(45) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(45) - Fold 1 - Validation Accuracy : 0.5229\n",
      "Epoch(45) - Fold 1 - Validation Utility score : 462.3772\n",
      "Epoch(45) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(45) - Fold 2 - Validation Accuracy : 0.5091\n",
      "Epoch(45) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(45) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(45) - Fold 3 - Validation Accuracy : 0.5074\n",
      "Epoch(45) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(45) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(45) - Fold 4 - Validation Accuracy : 0.5120\n",
      "Epoch(45) - Fold 4 - Validation Utility score : 890.6210\n",
      "Epoch(45) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(45) - GLOBAL - Validation Accuracy: 0.5145\n",
      "Epoch(45) - GLOBAL - Validation Utility score: 1536.5927\n",
      "Intermediate early stopping : vepoch_loss = 0.6922, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(46) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(46) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(46) - Fold 0 - Validation Accuracy : 0.5211\n",
      "Epoch(46) - Fold 0 - Validation Utility score : 180.3023\n",
      "Epoch(46) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(46) - Fold 1 - Validation Accuracy : 0.5231\n",
      "Epoch(46) - Fold 1 - Validation Utility score : 513.9047\n",
      "Epoch(46) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(46) - Fold 2 - Validation Accuracy : 0.5090\n",
      "Epoch(46) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(46) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(46) - Fold 3 - Validation Accuracy : 0.5077\n",
      "Epoch(46) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(46) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(46) - Fold 4 - Validation Accuracy : 0.5123\n",
      "Epoch(46) - Fold 4 - Validation Utility score : 962.1263\n",
      "Epoch(46) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(46) - GLOBAL - Validation Accuracy: 0.5146\n",
      "Epoch(46) - GLOBAL - Validation Utility score: 1656.3333\n",
      "Intermediate early stopping : vepoch_loss = 0.6922, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(47) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(47) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(47) - Fold 0 - Validation Accuracy : 0.5223\n",
      "Epoch(47) - Fold 0 - Validation Utility score : 222.0695\n",
      "Epoch(47) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(47) - Fold 1 - Validation Accuracy : 0.5251\n",
      "Epoch(47) - Fold 1 - Validation Utility score : 683.4313\n",
      "Epoch(47) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(47) - Fold 2 - Validation Accuracy : 0.5095\n",
      "Epoch(47) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(47) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(47) - Fold 3 - Validation Accuracy : 0.5085\n",
      "Epoch(47) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(47) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(47) - Fold 4 - Validation Accuracy : 0.5134\n",
      "Epoch(47) - Fold 4 - Validation Utility score : 841.9867\n",
      "Epoch(47) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(47) - GLOBAL - Validation Accuracy: 0.5158\n",
      "Epoch(47) - GLOBAL - Validation Utility score: 1747.4875\n",
      "Saving model corresponding to last_utility_score == 1747.4875133652931\n",
      "\n",
      "\n",
      "Epoch(48) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(48) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(48) - Fold 0 - Validation Accuracy : 0.5221\n",
      "Epoch(48) - Fold 0 - Validation Utility score : 195.2211\n",
      "Epoch(48) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(48) - Fold 1 - Validation Accuracy : 0.5243\n",
      "Epoch(48) - Fold 1 - Validation Utility score : 585.0275\n",
      "Epoch(48) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(48) - Fold 2 - Validation Accuracy : 0.5104\n",
      "Epoch(48) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(48) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(48) - Fold 3 - Validation Accuracy : 0.5078\n",
      "Epoch(48) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(48) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(48) - Fold 4 - Validation Accuracy : 0.5137\n",
      "Epoch(48) - Fold 4 - Validation Utility score : 823.5859\n",
      "Epoch(48) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(48) - GLOBAL - Validation Accuracy: 0.5157\n",
      "Epoch(48) - GLOBAL - Validation Utility score: 1603.8345\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(49) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(49) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(49) - Fold 0 - Validation Accuracy : 0.5226\n",
      "Epoch(49) - Fold 0 - Validation Utility score : 257.9452\n",
      "Epoch(49) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(49) - Fold 1 - Validation Accuracy : 0.5251\n",
      "Epoch(49) - Fold 1 - Validation Utility score : 694.6145\n",
      "Epoch(49) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(49) - Fold 2 - Validation Accuracy : 0.5100\n",
      "Epoch(49) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(49) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(49) - Fold 3 - Validation Accuracy : 0.5093\n",
      "Epoch(49) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(49) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(49) - Fold 4 - Validation Accuracy : 0.5150\n",
      "Epoch(49) - Fold 4 - Validation Utility score : 908.6991\n",
      "Epoch(49) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(49) - GLOBAL - Validation Accuracy: 0.5164\n",
      "Epoch(49) - GLOBAL - Validation Utility score: 1861.2587\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(50) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(50) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(50) - Fold 0 - Validation Accuracy : 0.5236\n",
      "Epoch(50) - Fold 0 - Validation Utility score : 332.5623\n",
      "Epoch(50) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(50) - Fold 1 - Validation Accuracy : 0.5254\n",
      "Epoch(50) - Fold 1 - Validation Utility score : 765.5854\n",
      "Epoch(50) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(50) - Fold 2 - Validation Accuracy : 0.5092\n",
      "Epoch(50) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(50) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(50) - Fold 3 - Validation Accuracy : 0.5091\n",
      "Epoch(50) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(50) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(50) - Fold 4 - Validation Accuracy : 0.5164\n",
      "Epoch(50) - Fold 4 - Validation Utility score : 1007.4621\n",
      "Epoch(50) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(50) - GLOBAL - Validation Accuracy: 0.5167\n",
      "Epoch(50) - GLOBAL - Validation Utility score: 2105.6098\n",
      "Saving model corresponding to last_utility_score == 2105.6098476774105\n",
      "\n",
      "\n",
      "Epoch(51) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(51) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(51) - Fold 0 - Validation Accuracy : 0.5230\n",
      "Epoch(51) - Fold 0 - Validation Utility score : 327.7708\n",
      "Epoch(51) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(51) - Fold 1 - Validation Accuracy : 0.5252\n",
      "Epoch(51) - Fold 1 - Validation Utility score : 747.8354\n",
      "Epoch(51) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(51) - Fold 2 - Validation Accuracy : 0.5098\n",
      "Epoch(51) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(51) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(51) - Fold 3 - Validation Accuracy : 0.5092\n",
      "Epoch(51) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(51) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(51) - Fold 4 - Validation Accuracy : 0.5162\n",
      "Epoch(51) - Fold 4 - Validation Utility score : 939.5013\n",
      "Epoch(51) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(51) - GLOBAL - Validation Accuracy: 0.5167\n",
      "Epoch(51) - GLOBAL - Validation Utility score: 2015.1076\n",
      "Saving model corresponding to last_utility_score == 2015.1076147809633\n",
      "\n",
      "\n",
      "Epoch(52) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(52) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(52) - Fold 0 - Validation Accuracy : 0.5223\n",
      "Epoch(52) - Fold 0 - Validation Utility score : 254.5708\n",
      "Epoch(52) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(52) - Fold 1 - Validation Accuracy : 0.5254\n",
      "Epoch(52) - Fold 1 - Validation Utility score : 655.0590\n",
      "Epoch(52) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(52) - Fold 2 - Validation Accuracy : 0.5097\n",
      "Epoch(52) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(52) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(52) - Fold 3 - Validation Accuracy : 0.5096\n",
      "Epoch(52) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(52) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(52) - Fold 4 - Validation Accuracy : 0.5156\n",
      "Epoch(52) - Fold 4 - Validation Utility score : 1013.7092\n",
      "Epoch(52) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(52) - GLOBAL - Validation Accuracy: 0.5165\n",
      "Epoch(52) - GLOBAL - Validation Utility score: 1923.3390\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(53) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(53) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(53) - Fold 0 - Validation Accuracy : 0.5223\n",
      "Epoch(53) - Fold 0 - Validation Utility score : 227.3534\n",
      "Epoch(53) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(53) - Fold 1 - Validation Accuracy : 0.5249\n",
      "Epoch(53) - Fold 1 - Validation Utility score : 684.2164\n",
      "Epoch(53) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(53) - Fold 2 - Validation Accuracy : 0.5101\n",
      "Epoch(53) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(53) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(53) - Fold 3 - Validation Accuracy : 0.5089\n",
      "Epoch(53) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(53) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(53) - Fold 4 - Validation Accuracy : 0.5156\n",
      "Epoch(53) - Fold 4 - Validation Utility score : 952.4746\n",
      "Epoch(53) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(53) - GLOBAL - Validation Accuracy: 0.5164\n",
      "Epoch(53) - GLOBAL - Validation Utility score: 1864.0444\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(54) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(54) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(54) - Fold 0 - Validation Accuracy : 0.5228\n",
      "Epoch(54) - Fold 0 - Validation Utility score : 266.5204\n",
      "Epoch(54) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(54) - Fold 1 - Validation Accuracy : 0.5249\n",
      "Epoch(54) - Fold 1 - Validation Utility score : 704.5204\n",
      "Epoch(54) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(54) - Fold 2 - Validation Accuracy : 0.5097\n",
      "Epoch(54) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(54) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(54) - Fold 3 - Validation Accuracy : 0.5095\n",
      "Epoch(54) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(54) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(54) - Fold 4 - Validation Accuracy : 0.5170\n",
      "Epoch(54) - Fold 4 - Validation Utility score : 1179.1584\n",
      "Epoch(54) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(54) - GLOBAL - Validation Accuracy: 0.5168\n",
      "Epoch(54) - GLOBAL - Validation Utility score: 2150.1992\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(55) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(55) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(55) - Fold 0 - Validation Accuracy : 0.5227\n",
      "Epoch(55) - Fold 0 - Validation Utility score : 281.1083\n",
      "Epoch(55) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(55) - Fold 1 - Validation Accuracy : 0.5244\n",
      "Epoch(55) - Fold 1 - Validation Utility score : 691.5677\n",
      "Epoch(55) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(55) - Fold 2 - Validation Accuracy : 0.5099\n",
      "Epoch(55) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(55) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(55) - Fold 3 - Validation Accuracy : 0.5094\n",
      "Epoch(55) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(55) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(55) - Fold 4 - Validation Accuracy : 0.5164\n",
      "Epoch(55) - Fold 4 - Validation Utility score : 1111.6556\n",
      "Epoch(55) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(55) - GLOBAL - Validation Accuracy: 0.5166\n",
      "Epoch(55) - GLOBAL - Validation Utility score: 2084.3316\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(56) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(56) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(56) - Fold 0 - Validation Accuracy : 0.5217\n",
      "Epoch(56) - Fold 0 - Validation Utility score : 194.8503\n",
      "Epoch(56) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(56) - Fold 1 - Validation Accuracy : 0.5230\n",
      "Epoch(56) - Fold 1 - Validation Utility score : 548.2824\n",
      "Epoch(56) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(56) - Fold 2 - Validation Accuracy : 0.5099\n",
      "Epoch(56) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(56) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(56) - Fold 3 - Validation Accuracy : 0.5085\n",
      "Epoch(56) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(56) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(56) - Fold 4 - Validation Accuracy : 0.5151\n",
      "Epoch(56) - Fold 4 - Validation Utility score : 919.3391\n",
      "Epoch(56) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(56) - GLOBAL - Validation Accuracy: 0.5157\n",
      "Epoch(56) - GLOBAL - Validation Utility score: 1662.4718\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6920\n",
      "Meet Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 498254<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_035206-hdxrf4l7/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_035206-hdxrf4l7/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>0.69178</td></tr><tr><td>Global valid/Loss</td><td>0.69208</td></tr><tr><td>Global valid/Accuracy</td><td>0.51566</td></tr><tr><td>Global valid/Utility</td><td>1662.4718</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>0.6918</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>0.52172</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>194.85026</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>0.69132</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>0.52303</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>548.28244</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>0.69284</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>0.50992</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>0.69282</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>0.50855</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>0.69164</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>0.51509</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>919.33909</td></tr><tr><td>Best accuracy</td><td>0.51668</td></tr><tr><td>Best utility</td><td>2015.10761</td></tr><tr><td>_runtime</td><td>2812</td></tr><tr><td>_timestamp</td><td>1613446738</td></tr><tr><td>_step</td><td>56</td></tr><tr><td>Final utility score</td><td>{'utility_score': 20...</td></tr><tr><td>Batch size</td><td>35620</td></tr><tr><td>Patience</td><td>5</td></tr><tr><td>Number of epochs</td><td>1000</td></tr><tr><td>Best epoch</td><td>51</td></tr><tr><td>Number of parameters per layer</td><td>[8384, 64, 2048, 32,...</td></tr><tr><td>Model architecture</td><td>MLP(<BR>  (AEncoder)...</td></tr><tr><td>comment</td><td>All folds MLP with a...</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>█▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Loss</td><td>█▄▃▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Accuracy</td><td>▁▁▂▂▂▂▂▃▃▂▄▄▄▄▆▅▆▇▆▆▇▆▇▇▇▇▇▇▇▇▇█▇███████</td></tr><tr><td>Global valid/Utility</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▂▂▄▃▅▆▅▅▆▄▆▆▆▇▇▆▇▇▅▇▆▇▆██▇█▆</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>█▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>▁▁▁▁▁▂▂▂▂▂▄▄▄▄▅▅▆▇▆▆▇▆▇▇▇██▇█▇▇█▇██████▇</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▂▂▅▂▅▄▃▇█▃▇▅▃▆▄▅▄▇▇▅▆▄</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>█▄▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>▁▁▁▁▂▂▂▂▂▂▄▄▄▄▆▅▇█▇▇█▇▇▇▇██▇█▇▇█▇██████▇</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>▁▁▁▁▁▁▁▁▁▁▁▂▂▁▃▂▅▆▅▄▆▄▆▅▅▆▆▅▆▆▄▇▅▇▆██▇▇▆</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>█▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>▂▁▃▃▃▃▄▄▄▃▄▅▄▄▆▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>█▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>▁▁▂▁▁▃▂▃▃▃▅▅▅▅▆▆▇▆▇▇▆▆▆▇▆▆▆▆▆▆▆█▇▇▇████▇</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>█▄▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>▂▁▂▂▂▂▂▃▃▃▄▄▄▄▅▄▅▆▆▅▆▅▆▆▆▇▇▆▇▇▆▇▆▇▇████▇</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▃▂▄▄▆▆▆▅▆▅▆▇▆▆▆▆▆▇▅▆▆▆▆▇▇▇█▆</td></tr><tr><td>Best accuracy</td><td>▁▁▂▂▂▂▂▂▃▃▄▄▄▄▅▆▆▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>Best utility</td><td>▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▄▅▆▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 286 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">fiery-sweep-1</strong>: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/hdxrf4l7\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/hdxrf4l7</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training summary:\n",
      "{'utility_score': 2015.1076147809633, 'utility_scores': [327.7708477465766, 747.8354423859281, -0.0, -0.0, 939.5013246484586], 'utility_score_std': 383.9850457264267, 'accuracy_scores': [0.5229833737296424, 0.5252228852228852, 0.5098282881682927, 0.5091943834768416, 0.5161853782222848]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7lc6i2hc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leakyrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 57181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.44954950011207173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0009316216809488974\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_autoenc: encoder-only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.00014586050890855241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">revived-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/7lc6i2hc\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/7lc6i2hc</a><br/>\n",
       "                Run data is saved locally in <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_043902-7lc6i2hc</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Run config :\n",
      "config: {'activation_function': 'leakyrelu', 'batch_size': 57181, 'dropout': 0.44954950011207173, 'learning_rate': 0.0009316216809488974, 'use_autoenc': 'encoder-only', 'weight_decay': 0.00014586050890855241, 'epochs': 1000}\n",
      "Epoch(0) - Training Loss: 0.9488\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(0) - Fold 0 - Validation Loss : 0.7186\n",
      "Epoch(0) - Fold 0 - Validation Accuracy : 0.5008\n",
      "Epoch(0) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 1 - Validation Loss : 0.7138\n",
      "Epoch(0) - Fold 1 - Validation Accuracy : 0.5056\n",
      "Epoch(0) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 2 - Validation Loss : 0.7140\n",
      "Epoch(0) - Fold 2 - Validation Accuracy : 0.5007\n",
      "Epoch(0) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 3 - Validation Loss : 0.7156\n",
      "Epoch(0) - Fold 3 - Validation Accuracy : 0.4999\n",
      "Epoch(0) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 4 - Validation Loss : 0.7160\n",
      "Epoch(0) - Fold 4 - Validation Accuracy : 0.4986\n",
      "Epoch(0) - Fold 4 - Validation Utility score : 32.8224\n",
      "Epoch(0) - GLOBAL - Validation Loss: 0.7156\n",
      "Epoch(0) - GLOBAL - Validation Accuracy: 0.5011\n",
      "Epoch(0) - GLOBAL - Validation Utility score: 32.8224\n",
      "Saving model corresponding to last_utility_score == 32.822444418069495\n",
      "\n",
      "\n",
      "Epoch(1) - Training Loss: 0.8572\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(1) - Fold 0 - Validation Loss : 0.6971\n",
      "Epoch(1) - Fold 0 - Validation Accuracy : 0.5048\n",
      "Epoch(1) - Fold 0 - Validation Utility score : 22.9734\n",
      "Epoch(1) - Fold 1 - Validation Loss : 0.6964\n",
      "Epoch(1) - Fold 1 - Validation Accuracy : 0.5020\n",
      "Epoch(1) - Fold 1 - Validation Utility score : 28.2540\n",
      "Epoch(1) - Fold 2 - Validation Loss : 0.6975\n",
      "Epoch(1) - Fold 2 - Validation Accuracy : 0.4969\n",
      "Epoch(1) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 3 - Validation Loss : 0.6968\n",
      "Epoch(1) - Fold 3 - Validation Accuracy : 0.5019\n",
      "Epoch(1) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 4 - Validation Loss : 0.6982\n",
      "Epoch(1) - Fold 4 - Validation Accuracy : 0.4928\n",
      "Epoch(1) - Fold 4 - Validation Utility score : -0.0000\n",
      "Epoch(1) - GLOBAL - Validation Loss: 0.6972\n",
      "Epoch(1) - GLOBAL - Validation Accuracy: 0.4997\n",
      "Epoch(1) - GLOBAL - Validation Utility score: 51.2274\n",
      "Saving model corresponding to last_utility_score == 51.227409945313084\n",
      "\n",
      "\n",
      "Epoch(2) - Training Loss: 0.7937\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(2) - Fold 0 - Validation Loss : 0.6963\n",
      "Epoch(2) - Fold 0 - Validation Accuracy : 0.5013\n",
      "Epoch(2) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 1 - Validation Loss : 0.6958\n",
      "Epoch(2) - Fold 1 - Validation Accuracy : 0.5061\n",
      "Epoch(2) - Fold 1 - Validation Utility score : 1.7355\n",
      "Epoch(2) - Fold 2 - Validation Loss : 0.6960\n",
      "Epoch(2) - Fold 2 - Validation Accuracy : 0.5008\n",
      "Epoch(2) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 3 - Validation Loss : 0.6965\n",
      "Epoch(2) - Fold 3 - Validation Accuracy : 0.5004\n",
      "Epoch(2) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 4 - Validation Loss : 0.6966\n",
      "Epoch(2) - Fold 4 - Validation Accuracy : 0.4986\n",
      "Epoch(2) - Fold 4 - Validation Utility score : 8.8512\n",
      "Epoch(2) - GLOBAL - Validation Loss: 0.6963\n",
      "Epoch(2) - GLOBAL - Validation Accuracy: 0.5014\n",
      "Epoch(2) - GLOBAL - Validation Utility score: 10.5867\n",
      "Saving model corresponding to last_utility_score == 10.586739862915495\n",
      "\n",
      "\n",
      "Epoch(3) - Training Loss: 0.7460\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(3) - Fold 0 - Validation Loss : 0.6967\n",
      "Epoch(3) - Fold 0 - Validation Accuracy : 0.5010\n",
      "Epoch(3) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 1 - Validation Loss : 0.6962\n",
      "Epoch(3) - Fold 1 - Validation Accuracy : 0.5062\n",
      "Epoch(3) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 2 - Validation Loss : 0.6966\n",
      "Epoch(3) - Fold 2 - Validation Accuracy : 0.5018\n",
      "Epoch(3) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 3 - Validation Loss : 0.6971\n",
      "Epoch(3) - Fold 3 - Validation Accuracy : 0.5003\n",
      "Epoch(3) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 4 - Validation Loss : 0.6969\n",
      "Epoch(3) - Fold 4 - Validation Accuracy : 0.4986\n",
      "Epoch(3) - Fold 4 - Validation Utility score : 15.1787\n",
      "Epoch(3) - GLOBAL - Validation Loss: 0.6967\n",
      "Epoch(3) - GLOBAL - Validation Accuracy: 0.5016\n",
      "Epoch(3) - GLOBAL - Validation Utility score: 15.1787\n",
      "Intermediate early stopping : vepoch_loss = 0.6967, the_last_loss=0.6963\n",
      "\n",
      "\n",
      "Epoch(4) - Training Loss: 0.7183\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(4) - Fold 0 - Validation Loss : 0.6949\n",
      "Epoch(4) - Fold 0 - Validation Accuracy : 0.5002\n",
      "Epoch(4) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 1 - Validation Loss : 0.6945\n",
      "Epoch(4) - Fold 1 - Validation Accuracy : 0.5059\n",
      "Epoch(4) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 2 - Validation Loss : 0.6946\n",
      "Epoch(4) - Fold 2 - Validation Accuracy : 0.5018\n",
      "Epoch(4) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 3 - Validation Loss : 0.6950\n",
      "Epoch(4) - Fold 3 - Validation Accuracy : 0.4997\n",
      "Epoch(4) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 4 - Validation Loss : 0.6949\n",
      "Epoch(4) - Fold 4 - Validation Accuracy : 0.4988\n",
      "Epoch(4) - Fold 4 - Validation Utility score : 19.4484\n",
      "Epoch(4) - GLOBAL - Validation Loss: 0.6948\n",
      "Epoch(4) - GLOBAL - Validation Accuracy: 0.5013\n",
      "Epoch(4) - GLOBAL - Validation Utility score: 19.4484\n",
      "Saving model corresponding to last_utility_score == 19.448395710341995\n",
      "\n",
      "\n",
      "Epoch(5) - Training Loss: 0.7039\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(5) - Fold 0 - Validation Loss : 0.6946\n",
      "Epoch(5) - Fold 0 - Validation Accuracy : 0.5002\n",
      "Epoch(5) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 1 - Validation Loss : 0.6939\n",
      "Epoch(5) - Fold 1 - Validation Accuracy : 0.5062\n",
      "Epoch(5) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 2 - Validation Loss : 0.6942\n",
      "Epoch(5) - Fold 2 - Validation Accuracy : 0.5019\n",
      "Epoch(5) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 3 - Validation Loss : 0.6944\n",
      "Epoch(5) - Fold 3 - Validation Accuracy : 0.4997\n",
      "Epoch(5) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 4 - Validation Loss : 0.6945\n",
      "Epoch(5) - Fold 4 - Validation Accuracy : 0.4988\n",
      "Epoch(5) - Fold 4 - Validation Utility score : 17.7288\n",
      "Epoch(5) - GLOBAL - Validation Loss: 0.6943\n",
      "Epoch(5) - GLOBAL - Validation Accuracy: 0.5014\n",
      "Epoch(5) - GLOBAL - Validation Utility score: 17.7288\n",
      "Saving model corresponding to last_utility_score == 17.72882584378327\n",
      "\n",
      "\n",
      "Epoch(6) - Training Loss: 0.6980\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(6) - Fold 0 - Validation Loss : 0.6942\n",
      "Epoch(6) - Fold 0 - Validation Accuracy : 0.5002\n",
      "Epoch(6) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 1 - Validation Loss : 0.6934\n",
      "Epoch(6) - Fold 1 - Validation Accuracy : 0.5063\n",
      "Epoch(6) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 2 - Validation Loss : 0.6939\n",
      "Epoch(6) - Fold 2 - Validation Accuracy : 0.5020\n",
      "Epoch(6) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 3 - Validation Loss : 0.6940\n",
      "Epoch(6) - Fold 3 - Validation Accuracy : 0.4997\n",
      "Epoch(6) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 4 - Validation Loss : 0.6942\n",
      "Epoch(6) - Fold 4 - Validation Accuracy : 0.4989\n",
      "Epoch(6) - Fold 4 - Validation Utility score : 17.5617\n",
      "Epoch(6) - GLOBAL - Validation Loss: 0.6939\n",
      "Epoch(6) - GLOBAL - Validation Accuracy: 0.5014\n",
      "Epoch(6) - GLOBAL - Validation Utility score: 17.5617\n",
      "Saving model corresponding to last_utility_score == 17.561672661497145\n",
      "\n",
      "\n",
      "Epoch(7) - Training Loss: 0.6958\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(7) - Fold 0 - Validation Loss : 0.6937\n",
      "Epoch(7) - Fold 0 - Validation Accuracy : 0.5002\n",
      "Epoch(7) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 1 - Validation Loss : 0.6931\n",
      "Epoch(7) - Fold 1 - Validation Accuracy : 0.5066\n",
      "Epoch(7) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 2 - Validation Loss : 0.6936\n",
      "Epoch(7) - Fold 2 - Validation Accuracy : 0.5025\n",
      "Epoch(7) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 3 - Validation Loss : 0.6937\n",
      "Epoch(7) - Fold 3 - Validation Accuracy : 0.5002\n",
      "Epoch(7) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 4 - Validation Loss : 0.6938\n",
      "Epoch(7) - Fold 4 - Validation Accuracy : 0.4994\n",
      "Epoch(7) - Fold 4 - Validation Utility score : 22.0121\n",
      "Epoch(7) - GLOBAL - Validation Loss: 0.6936\n",
      "Epoch(7) - GLOBAL - Validation Accuracy: 0.5018\n",
      "Epoch(7) - GLOBAL - Validation Utility score: 22.0121\n",
      "Saving model corresponding to last_utility_score == 22.012066370553175\n",
      "\n",
      "\n",
      "Epoch(8) - Training Loss: 0.6946\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(8) - Fold 0 - Validation Loss : 0.6935\n",
      "Epoch(8) - Fold 0 - Validation Accuracy : 0.5009\n",
      "Epoch(8) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 1 - Validation Loss : 0.6930\n",
      "Epoch(8) - Fold 1 - Validation Accuracy : 0.5069\n",
      "Epoch(8) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 2 - Validation Loss : 0.6935\n",
      "Epoch(8) - Fold 2 - Validation Accuracy : 0.5026\n",
      "Epoch(8) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 3 - Validation Loss : 0.6937\n",
      "Epoch(8) - Fold 3 - Validation Accuracy : 0.5003\n",
      "Epoch(8) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 4 - Validation Loss : 0.6938\n",
      "Epoch(8) - Fold 4 - Validation Accuracy : 0.4995\n",
      "Epoch(8) - Fold 4 - Validation Utility score : 23.4717\n",
      "Epoch(8) - GLOBAL - Validation Loss: 0.6935\n",
      "Epoch(8) - GLOBAL - Validation Accuracy: 0.5020\n",
      "Epoch(8) - GLOBAL - Validation Utility score: 23.4717\n",
      "Saving model corresponding to last_utility_score == 23.471690165973648\n",
      "\n",
      "\n",
      "Epoch(9) - Training Loss: 0.6941\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(9) - Fold 0 - Validation Loss : 0.6934\n",
      "Epoch(9) - Fold 0 - Validation Accuracy : 0.5015\n",
      "Epoch(9) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(9) - Fold 1 - Validation Accuracy : 0.5075\n",
      "Epoch(9) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 2 - Validation Loss : 0.6934\n",
      "Epoch(9) - Fold 2 - Validation Accuracy : 0.5029\n",
      "Epoch(9) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 3 - Validation Loss : 0.6936\n",
      "Epoch(9) - Fold 3 - Validation Accuracy : 0.5015\n",
      "Epoch(9) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 4 - Validation Loss : 0.6936\n",
      "Epoch(9) - Fold 4 - Validation Accuracy : 0.5002\n",
      "Epoch(9) - Fold 4 - Validation Utility score : 30.1986\n",
      "Epoch(9) - GLOBAL - Validation Loss: 0.6934\n",
      "Epoch(9) - GLOBAL - Validation Accuracy: 0.5027\n",
      "Epoch(9) - GLOBAL - Validation Utility score: 30.1986\n",
      "Saving model corresponding to last_utility_score == 30.19858712633475\n",
      "\n",
      "\n",
      "Epoch(10) - Training Loss: 0.6940\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(10) - Fold 0 - Validation Loss : 0.6932\n",
      "Epoch(10) - Fold 0 - Validation Accuracy : 0.5023\n",
      "Epoch(10) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(10) - Fold 1 - Validation Accuracy : 0.5083\n",
      "Epoch(10) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(10) - Fold 2 - Validation Accuracy : 0.5032\n",
      "Epoch(10) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 3 - Validation Loss : 0.6935\n",
      "Epoch(10) - Fold 3 - Validation Accuracy : 0.5020\n",
      "Epoch(10) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 4 - Validation Loss : 0.6935\n",
      "Epoch(10) - Fold 4 - Validation Accuracy : 0.5006\n",
      "Epoch(10) - Fold 4 - Validation Utility score : 32.5730\n",
      "Epoch(10) - GLOBAL - Validation Loss: 0.6933\n",
      "Epoch(10) - GLOBAL - Validation Accuracy: 0.5033\n",
      "Epoch(10) - GLOBAL - Validation Utility score: 32.5730\n",
      "Saving model corresponding to last_utility_score == 32.57299389327414\n",
      "\n",
      "\n",
      "Epoch(11) - Training Loss: 0.6937\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(11) - Fold 0 - Validation Loss : 0.6932\n",
      "Epoch(11) - Fold 0 - Validation Accuracy : 0.5022\n",
      "Epoch(11) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(11) - Fold 1 - Validation Accuracy : 0.5080\n",
      "Epoch(11) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(11) - Fold 2 - Validation Accuracy : 0.5029\n",
      "Epoch(11) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 3 - Validation Loss : 0.6935\n",
      "Epoch(11) - Fold 3 - Validation Accuracy : 0.5021\n",
      "Epoch(11) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 4 - Validation Loss : 0.6935\n",
      "Epoch(11) - Fold 4 - Validation Accuracy : 0.5007\n",
      "Epoch(11) - Fold 4 - Validation Utility score : 40.8687\n",
      "Epoch(11) - GLOBAL - Validation Loss: 0.6933\n",
      "Epoch(11) - GLOBAL - Validation Accuracy: 0.5032\n",
      "Epoch(11) - GLOBAL - Validation Utility score: 40.8687\n",
      "Intermediate early stopping : vepoch_loss = 0.6933, the_last_loss=0.6933\n",
      "\n",
      "\n",
      "Epoch(12) - Training Loss: 0.6936\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(12) - Fold 0 - Validation Loss : 0.6932\n",
      "Epoch(12) - Fold 0 - Validation Accuracy : 0.5024\n",
      "Epoch(12) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(12) - Fold 1 - Validation Accuracy : 0.5081\n",
      "Epoch(12) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(12) - Fold 2 - Validation Accuracy : 0.5026\n",
      "Epoch(12) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 3 - Validation Loss : 0.6935\n",
      "Epoch(12) - Fold 3 - Validation Accuracy : 0.5020\n",
      "Epoch(12) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 4 - Validation Loss : 0.6935\n",
      "Epoch(12) - Fold 4 - Validation Accuracy : 0.5008\n",
      "Epoch(12) - Fold 4 - Validation Utility score : 51.9880\n",
      "Epoch(12) - GLOBAL - Validation Loss: 0.6933\n",
      "Epoch(12) - GLOBAL - Validation Accuracy: 0.5032\n",
      "Epoch(12) - GLOBAL - Validation Utility score: 51.9880\n",
      "Saving model corresponding to last_utility_score == 51.98800179057412\n",
      "\n",
      "\n",
      "Epoch(13) - Training Loss: 0.6935\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(13) - Fold 0 - Validation Loss : 0.6931\n",
      "Epoch(13) - Fold 0 - Validation Accuracy : 0.5026\n",
      "Epoch(13) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(13) - Fold 1 - Validation Accuracy : 0.5081\n",
      "Epoch(13) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(13) - Fold 2 - Validation Accuracy : 0.5024\n",
      "Epoch(13) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 3 - Validation Loss : 0.6935\n",
      "Epoch(13) - Fold 3 - Validation Accuracy : 0.5022\n",
      "Epoch(13) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 4 - Validation Loss : 0.6935\n",
      "Epoch(13) - Fold 4 - Validation Accuracy : 0.5013\n",
      "Epoch(13) - Fold 4 - Validation Utility score : 71.5510\n",
      "Epoch(13) - GLOBAL - Validation Loss: 0.6932\n",
      "Epoch(13) - GLOBAL - Validation Accuracy: 0.5033\n",
      "Epoch(13) - GLOBAL - Validation Utility score: 71.5510\n",
      "Saving model corresponding to last_utility_score == 71.55096971329714\n",
      "\n",
      "\n",
      "Epoch(14) - Training Loss: 0.6934\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(14) - Fold 0 - Validation Loss : 0.6930\n",
      "Epoch(14) - Fold 0 - Validation Accuracy : 0.5041\n",
      "Epoch(14) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 1 - Validation Loss : 0.6926\n",
      "Epoch(14) - Fold 1 - Validation Accuracy : 0.5095\n",
      "Epoch(14) - Fold 1 - Validation Utility score : 1.6608\n",
      "Epoch(14) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(14) - Fold 2 - Validation Accuracy : 0.5024\n",
      "Epoch(14) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(14) - Fold 3 - Validation Accuracy : 0.5033\n",
      "Epoch(14) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 4 - Validation Loss : 0.6934\n",
      "Epoch(14) - Fold 4 - Validation Accuracy : 0.5017\n",
      "Epoch(14) - Fold 4 - Validation Utility score : 85.2260\n",
      "Epoch(14) - GLOBAL - Validation Loss: 0.6931\n",
      "Epoch(14) - GLOBAL - Validation Accuracy: 0.5042\n",
      "Epoch(14) - GLOBAL - Validation Utility score: 86.8868\n",
      "Saving model corresponding to last_utility_score == 86.88682084350994\n",
      "\n",
      "\n",
      "Epoch(15) - Training Loss: 0.6934\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(15) - Fold 0 - Validation Loss : 0.6930\n",
      "Epoch(15) - Fold 0 - Validation Accuracy : 0.5037\n",
      "Epoch(15) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 1 - Validation Loss : 0.6926\n",
      "Epoch(15) - Fold 1 - Validation Accuracy : 0.5093\n",
      "Epoch(15) - Fold 1 - Validation Utility score : 1.1425\n",
      "Epoch(15) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(15) - Fold 2 - Validation Accuracy : 0.5026\n",
      "Epoch(15) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(15) - Fold 3 - Validation Accuracy : 0.5033\n",
      "Epoch(15) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 4 - Validation Loss : 0.6934\n",
      "Epoch(15) - Fold 4 - Validation Accuracy : 0.5020\n",
      "Epoch(15) - Fold 4 - Validation Utility score : 104.1969\n",
      "Epoch(15) - GLOBAL - Validation Loss: 0.6931\n",
      "Epoch(15) - GLOBAL - Validation Accuracy: 0.5042\n",
      "Epoch(15) - GLOBAL - Validation Utility score: 105.3394\n",
      "Intermediate early stopping : vepoch_loss = 0.6931, the_last_loss=0.6931\n",
      "\n",
      "\n",
      "Epoch(16) - Training Loss: 0.6933\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(16) - Fold 0 - Validation Loss : 0.6928\n",
      "Epoch(16) - Fold 0 - Validation Accuracy : 0.5086\n",
      "Epoch(16) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(16) - Fold 1 - Validation Accuracy : 0.5127\n",
      "Epoch(16) - Fold 1 - Validation Utility score : 30.4540\n",
      "Epoch(16) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(16) - Fold 2 - Validation Accuracy : 0.5032\n",
      "Epoch(16) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(16) - Fold 3 - Validation Accuracy : 0.5044\n",
      "Epoch(16) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 4 - Validation Loss : 0.6932\n",
      "Epoch(16) - Fold 4 - Validation Accuracy : 0.5035\n",
      "Epoch(16) - Fold 4 - Validation Utility score : 186.8585\n",
      "Epoch(16) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(16) - GLOBAL - Validation Accuracy: 0.5065\n",
      "Epoch(16) - GLOBAL - Validation Utility score: 217.3125\n",
      "Saving model corresponding to last_utility_score == 217.31251897096354\n",
      "\n",
      "\n",
      "Epoch(17) - Training Loss: 0.6933\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(17) - Fold 0 - Validation Loss : 0.6929\n",
      "Epoch(17) - Fold 0 - Validation Accuracy : 0.5061\n",
      "Epoch(17) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 1 - Validation Loss : 0.6926\n",
      "Epoch(17) - Fold 1 - Validation Accuracy : 0.5108\n",
      "Epoch(17) - Fold 1 - Validation Utility score : 1.8903\n",
      "Epoch(17) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(17) - Fold 2 - Validation Accuracy : 0.5025\n",
      "Epoch(17) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(17) - Fold 3 - Validation Accuracy : 0.5040\n",
      "Epoch(17) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 4 - Validation Loss : 0.6933\n",
      "Epoch(17) - Fold 4 - Validation Accuracy : 0.5027\n",
      "Epoch(17) - Fold 4 - Validation Utility score : 154.1437\n",
      "Epoch(17) - GLOBAL - Validation Loss: 0.6931\n",
      "Epoch(17) - GLOBAL - Validation Accuracy: 0.5052\n",
      "Epoch(17) - GLOBAL - Validation Utility score: 156.0340\n",
      "Intermediate early stopping : vepoch_loss = 0.6931, the_last_loss=0.6930\n",
      "\n",
      "\n",
      "Epoch(18) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(18) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(18) - Fold 0 - Validation Accuracy : 0.5106\n",
      "Epoch(18) - Fold 0 - Validation Utility score : 1.9338\n",
      "Epoch(18) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(18) - Fold 1 - Validation Accuracy : 0.5144\n",
      "Epoch(18) - Fold 1 - Validation Utility score : 96.1674\n",
      "Epoch(18) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(18) - Fold 2 - Validation Accuracy : 0.5036\n",
      "Epoch(18) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(18) - Fold 3 - Validation Accuracy : 0.5054\n",
      "Epoch(18) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 4 - Validation Loss : 0.6931\n",
      "Epoch(18) - Fold 4 - Validation Accuracy : 0.5045\n",
      "Epoch(18) - Fold 4 - Validation Utility score : 313.5777\n",
      "Epoch(18) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(18) - GLOBAL - Validation Accuracy: 0.5077\n",
      "Epoch(18) - GLOBAL - Validation Utility score: 411.6788\n",
      "Saving model corresponding to last_utility_score == 411.67878751533067\n",
      "\n",
      "\n",
      "Epoch(19) - Training Loss: 0.6933\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(19) - Fold 0 - Validation Loss : 0.6929\n",
      "Epoch(19) - Fold 0 - Validation Accuracy : 0.5088\n",
      "Epoch(19) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(19) - Fold 1 - Validation Accuracy : 0.5122\n",
      "Epoch(19) - Fold 1 - Validation Utility score : 12.0775\n",
      "Epoch(19) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(19) - Fold 2 - Validation Accuracy : 0.5031\n",
      "Epoch(19) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(19) - Fold 3 - Validation Accuracy : 0.5044\n",
      "Epoch(19) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 4 - Validation Loss : 0.6932\n",
      "Epoch(19) - Fold 4 - Validation Accuracy : 0.5042\n",
      "Epoch(19) - Fold 4 - Validation Utility score : 217.6550\n",
      "Epoch(19) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(19) - GLOBAL - Validation Accuracy: 0.5065\n",
      "Epoch(19) - GLOBAL - Validation Utility score: 229.7325\n",
      "Intermediate early stopping : vepoch_loss = 0.6930, the_last_loss=0.6929\n",
      "\n",
      "\n",
      "Epoch(20) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(20) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(20) - Fold 0 - Validation Accuracy : 0.5119\n",
      "Epoch(20) - Fold 0 - Validation Utility score : 8.6167\n",
      "Epoch(20) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(20) - Fold 1 - Validation Accuracy : 0.5152\n",
      "Epoch(20) - Fold 1 - Validation Utility score : 101.7578\n",
      "Epoch(20) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(20) - Fold 2 - Validation Accuracy : 0.5046\n",
      "Epoch(20) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(20) - Fold 3 - Validation Accuracy : 0.5066\n",
      "Epoch(20) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 4 - Validation Loss : 0.6931\n",
      "Epoch(20) - Fold 4 - Validation Accuracy : 0.5050\n",
      "Epoch(20) - Fold 4 - Validation Utility score : 416.9483\n",
      "Epoch(20) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(20) - GLOBAL - Validation Accuracy: 0.5087\n",
      "Epoch(20) - GLOBAL - Validation Utility score: 527.3228\n",
      "Saving model corresponding to last_utility_score == 527.3227555172213\n",
      "\n",
      "\n",
      "Epoch(21) - Training Loss: 0.6931\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(21) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(21) - Fold 0 - Validation Accuracy : 0.5109\n",
      "Epoch(21) - Fold 0 - Validation Utility score : 0.0099\n",
      "Epoch(21) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(21) - Fold 1 - Validation Accuracy : 0.5141\n",
      "Epoch(21) - Fold 1 - Validation Utility score : 87.4626\n",
      "Epoch(21) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(21) - Fold 2 - Validation Accuracy : 0.5043\n",
      "Epoch(21) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(21) - Fold 3 - Validation Accuracy : 0.5059\n",
      "Epoch(21) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 4 - Validation Loss : 0.6931\n",
      "Epoch(21) - Fold 4 - Validation Accuracy : 0.5049\n",
      "Epoch(21) - Fold 4 - Validation Utility score : 369.6949\n",
      "Epoch(21) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(21) - GLOBAL - Validation Accuracy: 0.5080\n",
      "Epoch(21) - GLOBAL - Validation Utility score: 457.1674\n",
      "Intermediate early stopping : vepoch_loss = 0.6929, the_last_loss=0.6929\n",
      "\n",
      "\n",
      "Epoch(22) - Training Loss: 0.6931\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(22) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(22) - Fold 0 - Validation Accuracy : 0.5113\n",
      "Epoch(22) - Fold 0 - Validation Utility score : 2.3590\n",
      "Epoch(22) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(22) - Fold 1 - Validation Accuracy : 0.5151\n",
      "Epoch(22) - Fold 1 - Validation Utility score : 90.1506\n",
      "Epoch(22) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(22) - Fold 2 - Validation Accuracy : 0.5050\n",
      "Epoch(22) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(22) - Fold 3 - Validation Accuracy : 0.5064\n",
      "Epoch(22) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 4 - Validation Loss : 0.6930\n",
      "Epoch(22) - Fold 4 - Validation Accuracy : 0.5052\n",
      "Epoch(22) - Fold 4 - Validation Utility score : 404.1141\n",
      "Epoch(22) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(22) - GLOBAL - Validation Accuracy: 0.5086\n",
      "Epoch(22) - GLOBAL - Validation Utility score: 496.6237\n",
      "Saving model corresponding to last_utility_score == 496.62366413367096\n",
      "\n",
      "\n",
      "Epoch(23) - Training Loss: 0.6930\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(23) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(23) - Fold 0 - Validation Accuracy : 0.5147\n",
      "Epoch(23) - Fold 0 - Validation Utility score : 12.6143\n",
      "Epoch(23) - Fold 1 - Validation Loss : 0.6923\n",
      "Epoch(23) - Fold 1 - Validation Accuracy : 0.5184\n",
      "Epoch(23) - Fold 1 - Validation Utility score : 226.2823\n",
      "Epoch(23) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(23) - Fold 2 - Validation Accuracy : 0.5061\n",
      "Epoch(23) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(23) - Fold 3 - Validation Accuracy : 0.5079\n",
      "Epoch(23) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(23) - Fold 4 - Validation Accuracy : 0.5068\n",
      "Epoch(23) - Fold 4 - Validation Utility score : 572.4076\n",
      "Epoch(23) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(23) - GLOBAL - Validation Accuracy: 0.5108\n",
      "Epoch(23) - GLOBAL - Validation Utility score: 811.3042\n",
      "Saving model corresponding to last_utility_score == 811.3042227756789\n",
      "\n",
      "\n",
      "Epoch(24) - Training Loss: 0.6930\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(24) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(24) - Fold 0 - Validation Accuracy : 0.5154\n",
      "Epoch(24) - Fold 0 - Validation Utility score : 16.2546\n",
      "Epoch(24) - Fold 1 - Validation Loss : 0.6923\n",
      "Epoch(24) - Fold 1 - Validation Accuracy : 0.5195\n",
      "Epoch(24) - Fold 1 - Validation Utility score : 236.5226\n",
      "Epoch(24) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(24) - Fold 2 - Validation Accuracy : 0.5067\n",
      "Epoch(24) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(24) - Fold 3 - Validation Accuracy : 0.5078\n",
      "Epoch(24) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(24) - Fold 4 - Validation Accuracy : 0.5071\n",
      "Epoch(24) - Fold 4 - Validation Utility score : 580.9694\n",
      "Epoch(24) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(24) - GLOBAL - Validation Accuracy: 0.5113\n",
      "Epoch(24) - GLOBAL - Validation Utility score: 833.7466\n",
      "Saving model corresponding to last_utility_score == 833.7466203581602\n",
      "\n",
      "\n",
      "Epoch(25) - Training Loss: 0.6930\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(25) - Fold 0 - Validation Loss : 0.6924\n",
      "Epoch(25) - Fold 0 - Validation Accuracy : 0.5161\n",
      "Epoch(25) - Fold 0 - Validation Utility score : 22.9889\n",
      "Epoch(25) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(25) - Fold 1 - Validation Accuracy : 0.5211\n",
      "Epoch(25) - Fold 1 - Validation Utility score : 277.5851\n",
      "Epoch(25) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(25) - Fold 2 - Validation Accuracy : 0.5069\n",
      "Epoch(25) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(25) - Fold 3 - Validation Accuracy : 0.5079\n",
      "Epoch(25) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(25) - Fold 4 - Validation Accuracy : 0.5079\n",
      "Epoch(25) - Fold 4 - Validation Utility score : 623.7685\n",
      "Epoch(25) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(25) - GLOBAL - Validation Accuracy: 0.5120\n",
      "Epoch(25) - GLOBAL - Validation Utility score: 924.3425\n",
      "Saving model corresponding to last_utility_score == 924.3424584311443\n",
      "\n",
      "\n",
      "Epoch(26) - Training Loss: 0.6929\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(26) - Fold 0 - Validation Loss : 0.6924\n",
      "Epoch(26) - Fold 0 - Validation Accuracy : 0.5159\n",
      "Epoch(26) - Fold 0 - Validation Utility score : 12.3860\n",
      "Epoch(26) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(26) - Fold 1 - Validation Accuracy : 0.5210\n",
      "Epoch(26) - Fold 1 - Validation Utility score : 280.3803\n",
      "Epoch(26) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(26) - Fold 2 - Validation Accuracy : 0.5068\n",
      "Epoch(26) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(26) - Fold 3 - Validation Accuracy : 0.5084\n",
      "Epoch(26) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(26) - Fold 4 - Validation Accuracy : 0.5077\n",
      "Epoch(26) - Fold 4 - Validation Utility score : 576.5819\n",
      "Epoch(26) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(26) - GLOBAL - Validation Accuracy: 0.5120\n",
      "Epoch(26) - GLOBAL - Validation Utility score: 869.3482\n",
      "Saving model corresponding to last_utility_score == 869.3482126851356\n",
      "\n",
      "\n",
      "Epoch(27) - Training Loss: 0.6929\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(27) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(27) - Fold 0 - Validation Accuracy : 0.5171\n",
      "Epoch(27) - Fold 0 - Validation Utility score : 38.8059\n",
      "Epoch(27) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(27) - Fold 1 - Validation Accuracy : 0.5224\n",
      "Epoch(27) - Fold 1 - Validation Utility score : 353.4514\n",
      "Epoch(27) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(27) - Fold 2 - Validation Accuracy : 0.5074\n",
      "Epoch(27) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(27) - Fold 3 - Validation Accuracy : 0.5075\n",
      "Epoch(27) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(27) - Fold 4 - Validation Accuracy : 0.5093\n",
      "Epoch(27) - Fold 4 - Validation Utility score : 695.9855\n",
      "Epoch(27) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(27) - GLOBAL - Validation Accuracy: 0.5128\n",
      "Epoch(27) - GLOBAL - Validation Utility score: 1088.2428\n",
      "Saving model corresponding to last_utility_score == 1088.2428433888028\n",
      "\n",
      "\n",
      "Epoch(28) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(28) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(28) - Fold 0 - Validation Accuracy : 0.5186\n",
      "Epoch(28) - Fold 0 - Validation Utility score : 64.5416\n",
      "Epoch(28) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(28) - Fold 1 - Validation Accuracy : 0.5229\n",
      "Epoch(28) - Fold 1 - Validation Utility score : 382.0280\n",
      "Epoch(28) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(28) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(28) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(28) - Fold 3 - Validation Accuracy : 0.5068\n",
      "Epoch(28) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(28) - Fold 4 - Validation Accuracy : 0.5097\n",
      "Epoch(28) - Fold 4 - Validation Utility score : 792.3787\n",
      "Epoch(28) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(28) - GLOBAL - Validation Accuracy: 0.5133\n",
      "Epoch(28) - GLOBAL - Validation Utility score: 1238.9483\n",
      "Saving model corresponding to last_utility_score == 1238.9483459519247\n",
      "\n",
      "\n",
      "Epoch(29) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(29) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(29) - Fold 0 - Validation Accuracy : 0.5174\n",
      "Epoch(29) - Fold 0 - Validation Utility score : 37.5918\n",
      "Epoch(29) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(29) - Fold 1 - Validation Accuracy : 0.5220\n",
      "Epoch(29) - Fold 1 - Validation Utility score : 316.5019\n",
      "Epoch(29) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(29) - Fold 2 - Validation Accuracy : 0.5077\n",
      "Epoch(29) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(29) - Fold 3 - Validation Accuracy : 0.5071\n",
      "Epoch(29) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(29) - Fold 4 - Validation Accuracy : 0.5085\n",
      "Epoch(29) - Fold 4 - Validation Utility score : 591.3926\n",
      "Epoch(29) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(29) - GLOBAL - Validation Accuracy: 0.5125\n",
      "Epoch(29) - GLOBAL - Validation Utility score: 945.4863\n",
      "Intermediate early stopping : vepoch_loss = 0.6926, the_last_loss=0.6926\n",
      "\n",
      "\n",
      "Epoch(30) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(30) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(30) - Fold 0 - Validation Accuracy : 0.5190\n",
      "Epoch(30) - Fold 0 - Validation Utility score : 110.9199\n",
      "Epoch(30) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(30) - Fold 1 - Validation Accuracy : 0.5227\n",
      "Epoch(30) - Fold 1 - Validation Utility score : 379.2149\n",
      "Epoch(30) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(30) - Fold 2 - Validation Accuracy : 0.5082\n",
      "Epoch(30) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(30) - Fold 3 - Validation Accuracy : 0.5069\n",
      "Epoch(30) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(30) - Fold 4 - Validation Accuracy : 0.5103\n",
      "Epoch(30) - Fold 4 - Validation Utility score : 822.1686\n",
      "Epoch(30) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(30) - GLOBAL - Validation Accuracy: 0.5134\n",
      "Epoch(30) - GLOBAL - Validation Utility score: 1312.3034\n",
      "Saving model corresponding to last_utility_score == 1312.3034150485382\n",
      "\n",
      "\n",
      "Epoch(31) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(31) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(31) - Fold 0 - Validation Accuracy : 0.5215\n",
      "Epoch(31) - Fold 0 - Validation Utility score : 292.8759\n",
      "Epoch(31) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(31) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(31) - Fold 1 - Validation Utility score : 486.4415\n",
      "Epoch(31) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(31) - Fold 2 - Validation Accuracy : 0.5092\n",
      "Epoch(31) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(31) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(31) - Fold 3 - Validation Accuracy : 0.5062\n",
      "Epoch(31) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(31) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(31) - Fold 4 - Validation Accuracy : 0.5119\n",
      "Epoch(31) - Fold 4 - Validation Utility score : 856.2475\n",
      "Epoch(31) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(31) - GLOBAL - Validation Accuracy: 0.5144\n",
      "Epoch(31) - GLOBAL - Validation Utility score: 1635.5648\n",
      "Saving model corresponding to last_utility_score == 1635.564849836339\n",
      "\n",
      "\n",
      "Epoch(32) - Training Loss: 0.6927\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(32) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(32) - Fold 0 - Validation Accuracy : 0.5178\n",
      "Epoch(32) - Fold 0 - Validation Utility score : 56.7821\n",
      "Epoch(32) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(32) - Fold 1 - Validation Accuracy : 0.5218\n",
      "Epoch(32) - Fold 1 - Validation Utility score : 328.1854\n",
      "Epoch(32) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(32) - Fold 2 - Validation Accuracy : 0.5084\n",
      "Epoch(32) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(32) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(32) - Fold 3 - Validation Accuracy : 0.5071\n",
      "Epoch(32) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(32) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(32) - Fold 4 - Validation Accuracy : 0.5095\n",
      "Epoch(32) - Fold 4 - Validation Utility score : 699.0987\n",
      "Epoch(32) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(32) - GLOBAL - Validation Accuracy: 0.5129\n",
      "Epoch(32) - GLOBAL - Validation Utility score: 1084.0662\n",
      "Intermediate early stopping : vepoch_loss = 0.6925, the_last_loss=0.6924\n",
      "\n",
      "\n",
      "Epoch(33) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(33) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(33) - Fold 0 - Validation Accuracy : 0.5195\n",
      "Epoch(33) - Fold 0 - Validation Utility score : 137.2092\n",
      "Epoch(33) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(33) - Fold 1 - Validation Accuracy : 0.5225\n",
      "Epoch(33) - Fold 1 - Validation Utility score : 457.3533\n",
      "Epoch(33) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(33) - Fold 2 - Validation Accuracy : 0.5092\n",
      "Epoch(33) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(33) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(33) - Fold 3 - Validation Accuracy : 0.5069\n",
      "Epoch(33) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(33) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(33) - Fold 4 - Validation Accuracy : 0.5112\n",
      "Epoch(33) - Fold 4 - Validation Utility score : 919.1735\n",
      "Epoch(33) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(33) - GLOBAL - Validation Accuracy: 0.5139\n",
      "Epoch(33) - GLOBAL - Validation Utility score: 1513.7359\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6924\n",
      "\n",
      "\n",
      "Epoch(34) - Training Loss: 0.6927\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(34) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(34) - Fold 0 - Validation Accuracy : 0.5207\n",
      "Epoch(34) - Fold 0 - Validation Utility score : 233.1098\n",
      "Epoch(34) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(34) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(34) - Fold 1 - Validation Utility score : 539.1197\n",
      "Epoch(34) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(34) - Fold 2 - Validation Accuracy : 0.5095\n",
      "Epoch(34) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(34) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(34) - Fold 3 - Validation Accuracy : 0.5068\n",
      "Epoch(34) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(34) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(34) - Fold 4 - Validation Accuracy : 0.5114\n",
      "Epoch(34) - Fold 4 - Validation Utility score : 928.7796\n",
      "Epoch(34) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(34) - GLOBAL - Validation Accuracy: 0.5144\n",
      "Epoch(34) - GLOBAL - Validation Utility score: 1701.0091\n",
      "Saving model corresponding to last_utility_score == 1701.0091486716954\n",
      "\n",
      "\n",
      "Epoch(35) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(35) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(35) - Fold 0 - Validation Accuracy : 0.5194\n",
      "Epoch(35) - Fold 0 - Validation Utility score : 169.8165\n",
      "Epoch(35) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(35) - Fold 1 - Validation Accuracy : 0.5224\n",
      "Epoch(35) - Fold 1 - Validation Utility score : 459.9691\n",
      "Epoch(35) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(35) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(35) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(35) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(35) - Fold 3 - Validation Accuracy : 0.5072\n",
      "Epoch(35) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(35) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(35) - Fold 4 - Validation Accuracy : 0.5108\n",
      "Epoch(35) - Fold 4 - Validation Utility score : 819.8709\n",
      "Epoch(35) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(35) - GLOBAL - Validation Accuracy: 0.5137\n",
      "Epoch(35) - GLOBAL - Validation Utility score: 1449.6565\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6924\n",
      "\n",
      "\n",
      "Epoch(36) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(36) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(36) - Fold 0 - Validation Accuracy : 0.5184\n",
      "Epoch(36) - Fold 0 - Validation Utility score : 70.4701\n",
      "Epoch(36) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(36) - Fold 1 - Validation Accuracy : 0.5205\n",
      "Epoch(36) - Fold 1 - Validation Utility score : 299.3330\n",
      "Epoch(36) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(36) - Fold 2 - Validation Accuracy : 0.5085\n",
      "Epoch(36) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(36) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(36) - Fold 3 - Validation Accuracy : 0.5076\n",
      "Epoch(36) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(36) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(36) - Fold 4 - Validation Accuracy : 0.5098\n",
      "Epoch(36) - Fold 4 - Validation Utility score : 762.4676\n",
      "Epoch(36) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(36) - GLOBAL - Validation Accuracy: 0.5130\n",
      "Epoch(36) - GLOBAL - Validation Utility score: 1132.2707\n",
      "Intermediate early stopping : vepoch_loss = 0.6925, the_last_loss=0.6924\n",
      "\n",
      "\n",
      "Epoch(37) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(37) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(37) - Fold 0 - Validation Accuracy : 0.5198\n",
      "Epoch(37) - Fold 0 - Validation Utility score : 144.5254\n",
      "Epoch(37) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(37) - Fold 1 - Validation Accuracy : 0.5227\n",
      "Epoch(37) - Fold 1 - Validation Utility score : 476.9962\n",
      "Epoch(37) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(37) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(37) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(37) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(37) - Fold 3 - Validation Accuracy : 0.5073\n",
      "Epoch(37) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(37) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(37) - Fold 4 - Validation Accuracy : 0.5115\n",
      "Epoch(37) - Fold 4 - Validation Utility score : 800.6640\n",
      "Epoch(37) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(37) - GLOBAL - Validation Accuracy: 0.5139\n",
      "Epoch(37) - GLOBAL - Validation Utility score: 1422.1856\n",
      "Saving model corresponding to last_utility_score == 1422.185558891665\n",
      "\n",
      "\n",
      "Epoch(38) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(38) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(38) - Fold 0 - Validation Accuracy : 0.5196\n",
      "Epoch(38) - Fold 0 - Validation Utility score : 117.5328\n",
      "Epoch(38) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(38) - Fold 1 - Validation Accuracy : 0.5221\n",
      "Epoch(38) - Fold 1 - Validation Utility score : 486.3831\n",
      "Epoch(38) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(38) - Fold 2 - Validation Accuracy : 0.5085\n",
      "Epoch(38) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(38) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(38) - Fold 3 - Validation Accuracy : 0.5073\n",
      "Epoch(38) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(38) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(38) - Fold 4 - Validation Accuracy : 0.5113\n",
      "Epoch(38) - Fold 4 - Validation Utility score : 829.9683\n",
      "Epoch(38) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(38) - GLOBAL - Validation Accuracy: 0.5138\n",
      "Epoch(38) - GLOBAL - Validation Utility score: 1433.8841\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6923\n",
      "\n",
      "\n",
      "Epoch(39) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(39) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(39) - Fold 0 - Validation Accuracy : 0.5203\n",
      "Epoch(39) - Fold 0 - Validation Utility score : 164.8848\n",
      "Epoch(39) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(39) - Fold 1 - Validation Accuracy : 0.5227\n",
      "Epoch(39) - Fold 1 - Validation Utility score : 488.6547\n",
      "Epoch(39) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(39) - Fold 2 - Validation Accuracy : 0.5085\n",
      "Epoch(39) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(39) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(39) - Fold 3 - Validation Accuracy : 0.5073\n",
      "Epoch(39) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(39) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(39) - Fold 4 - Validation Accuracy : 0.5116\n",
      "Epoch(39) - Fold 4 - Validation Utility score : 834.3099\n",
      "Epoch(39) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(39) - GLOBAL - Validation Accuracy: 0.5141\n",
      "Epoch(39) - GLOBAL - Validation Utility score: 1487.8495\n",
      "Saving model corresponding to last_utility_score == 1487.8494616630612\n",
      "\n",
      "\n",
      "Epoch(40) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(40) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(40) - Fold 0 - Validation Accuracy : 0.5213\n",
      "Epoch(40) - Fold 0 - Validation Utility score : 195.2678\n",
      "Epoch(40) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(40) - Fold 1 - Validation Accuracy : 0.5232\n",
      "Epoch(40) - Fold 1 - Validation Utility score : 540.0758\n",
      "Epoch(40) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(40) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(40) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(40) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(40) - Fold 3 - Validation Accuracy : 0.5077\n",
      "Epoch(40) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(40) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(40) - Fold 4 - Validation Accuracy : 0.5115\n",
      "Epoch(40) - Fold 4 - Validation Utility score : 940.5591\n",
      "Epoch(40) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(40) - GLOBAL - Validation Accuracy: 0.5144\n",
      "Epoch(40) - GLOBAL - Validation Utility score: 1675.9027\n",
      "Saving model corresponding to last_utility_score == 1675.9027311557963\n",
      "\n",
      "\n",
      "Epoch(41) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(41) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(41) - Fold 0 - Validation Accuracy : 0.5213\n",
      "Epoch(41) - Fold 0 - Validation Utility score : 169.5210\n",
      "Epoch(41) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(41) - Fold 1 - Validation Accuracy : 0.5225\n",
      "Epoch(41) - Fold 1 - Validation Utility score : 435.7031\n",
      "Epoch(41) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(41) - Fold 2 - Validation Accuracy : 0.5088\n",
      "Epoch(41) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(41) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(41) - Fold 3 - Validation Accuracy : 0.5073\n",
      "Epoch(41) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(41) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(41) - Fold 4 - Validation Accuracy : 0.5113\n",
      "Epoch(41) - Fold 4 - Validation Utility score : 836.0100\n",
      "Epoch(41) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(41) - GLOBAL - Validation Accuracy: 0.5142\n",
      "Epoch(41) - GLOBAL - Validation Utility score: 1441.2342\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6923\n",
      "\n",
      "\n",
      "Epoch(42) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(42) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(42) - Fold 0 - Validation Accuracy : 0.5205\n",
      "Epoch(42) - Fold 0 - Validation Utility score : 152.4820\n",
      "Epoch(42) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(42) - Fold 1 - Validation Accuracy : 0.5228\n",
      "Epoch(42) - Fold 1 - Validation Utility score : 439.4966\n",
      "Epoch(42) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(42) - Fold 2 - Validation Accuracy : 0.5091\n",
      "Epoch(42) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(42) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(42) - Fold 3 - Validation Accuracy : 0.5073\n",
      "Epoch(42) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(42) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(42) - Fold 4 - Validation Accuracy : 0.5112\n",
      "Epoch(42) - Fold 4 - Validation Utility score : 897.3576\n",
      "Epoch(42) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(42) - GLOBAL - Validation Accuracy: 0.5142\n",
      "Epoch(42) - GLOBAL - Validation Utility score: 1489.3362\n",
      "Saving model corresponding to last_utility_score == 1489.3362001772475\n",
      "\n",
      "\n",
      "Epoch(43) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(43) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(43) - Fold 0 - Validation Accuracy : 0.5178\n",
      "Epoch(43) - Fold 0 - Validation Utility score : 68.1173\n",
      "Epoch(43) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(43) - Fold 1 - Validation Accuracy : 0.5211\n",
      "Epoch(43) - Fold 1 - Validation Utility score : 395.1295\n",
      "Epoch(43) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(43) - Fold 2 - Validation Accuracy : 0.5089\n",
      "Epoch(43) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(43) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(43) - Fold 3 - Validation Accuracy : 0.5064\n",
      "Epoch(43) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(43) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(43) - Fold 4 - Validation Accuracy : 0.5099\n",
      "Epoch(43) - Fold 4 - Validation Utility score : 726.8210\n",
      "Epoch(43) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(43) - GLOBAL - Validation Accuracy: 0.5128\n",
      "Epoch(43) - GLOBAL - Validation Utility score: 1190.0677\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(44) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(44) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(44) - Fold 0 - Validation Accuracy : 0.5206\n",
      "Epoch(44) - Fold 0 - Validation Utility score : 133.1885\n",
      "Epoch(44) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(44) - Fold 1 - Validation Accuracy : 0.5225\n",
      "Epoch(44) - Fold 1 - Validation Utility score : 455.1927\n",
      "Epoch(44) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(44) - Fold 2 - Validation Accuracy : 0.5091\n",
      "Epoch(44) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(44) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(44) - Fold 3 - Validation Accuracy : 0.5074\n",
      "Epoch(44) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(44) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(44) - Fold 4 - Validation Accuracy : 0.5109\n",
      "Epoch(44) - Fold 4 - Validation Utility score : 810.5910\n",
      "Epoch(44) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(44) - GLOBAL - Validation Accuracy: 0.5141\n",
      "Epoch(44) - GLOBAL - Validation Utility score: 1398.9721\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(45) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(45) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(45) - Fold 0 - Validation Accuracy : 0.5205\n",
      "Epoch(45) - Fold 0 - Validation Utility score : 144.2539\n",
      "Epoch(45) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(45) - Fold 1 - Validation Accuracy : 0.5223\n",
      "Epoch(45) - Fold 1 - Validation Utility score : 505.1861\n",
      "Epoch(45) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(45) - Fold 2 - Validation Accuracy : 0.5085\n",
      "Epoch(45) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(45) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(45) - Fold 3 - Validation Accuracy : 0.5068\n",
      "Epoch(45) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(45) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(45) - Fold 4 - Validation Accuracy : 0.5110\n",
      "Epoch(45) - Fold 4 - Validation Utility score : 905.9434\n",
      "Epoch(45) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(45) - GLOBAL - Validation Accuracy: 0.5138\n",
      "Epoch(45) - GLOBAL - Validation Utility score: 1555.3834\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(46) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(46) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(46) - Fold 0 - Validation Accuracy : 0.5219\n",
      "Epoch(46) - Fold 0 - Validation Utility score : 176.3840\n",
      "Epoch(46) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(46) - Fold 1 - Validation Accuracy : 0.5231\n",
      "Epoch(46) - Fold 1 - Validation Utility score : 488.8195\n",
      "Epoch(46) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(46) - Fold 2 - Validation Accuracy : 0.5096\n",
      "Epoch(46) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(46) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(46) - Fold 3 - Validation Accuracy : 0.5080\n",
      "Epoch(46) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(46) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(46) - Fold 4 - Validation Accuracy : 0.5113\n",
      "Epoch(46) - Fold 4 - Validation Utility score : 961.6821\n",
      "Epoch(46) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(46) - GLOBAL - Validation Accuracy: 0.5148\n",
      "Epoch(46) - GLOBAL - Validation Utility score: 1626.8857\n",
      "Saving model corresponding to last_utility_score == 1626.8856504700711\n",
      "\n",
      "\n",
      "Epoch(47) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(47) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(47) - Fold 0 - Validation Accuracy : 0.5241\n",
      "Epoch(47) - Fold 0 - Validation Utility score : 344.9456\n",
      "Epoch(47) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(47) - Fold 1 - Validation Accuracy : 0.5238\n",
      "Epoch(47) - Fold 1 - Validation Utility score : 609.8462\n",
      "Epoch(47) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(47) - Fold 2 - Validation Accuracy : 0.5088\n",
      "Epoch(47) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(47) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(47) - Fold 3 - Validation Accuracy : 0.5083\n",
      "Epoch(47) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(47) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(47) - Fold 4 - Validation Accuracy : 0.5128\n",
      "Epoch(47) - Fold 4 - Validation Utility score : 914.0413\n",
      "Epoch(47) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(47) - GLOBAL - Validation Accuracy: 0.5155\n",
      "Epoch(47) - GLOBAL - Validation Utility score: 1868.8331\n",
      "Saving model corresponding to last_utility_score == 1868.8330828178177\n",
      "\n",
      "\n",
      "Epoch(48) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(48) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(48) - Fold 0 - Validation Accuracy : 0.5224\n",
      "Epoch(48) - Fold 0 - Validation Utility score : 219.9970\n",
      "Epoch(48) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(48) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(48) - Fold 1 - Validation Utility score : 570.2310\n",
      "Epoch(48) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(48) - Fold 2 - Validation Accuracy : 0.5094\n",
      "Epoch(48) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(48) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(48) - Fold 3 - Validation Accuracy : 0.5078\n",
      "Epoch(48) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(48) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(48) - Fold 4 - Validation Accuracy : 0.5123\n",
      "Epoch(48) - Fold 4 - Validation Utility score : 839.5412\n",
      "Epoch(48) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(48) - GLOBAL - Validation Accuracy: 0.5152\n",
      "Epoch(48) - GLOBAL - Validation Utility score: 1629.7693\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(49) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(49) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(49) - Fold 0 - Validation Accuracy : 0.5211\n",
      "Epoch(49) - Fold 0 - Validation Utility score : 155.5330\n",
      "Epoch(49) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(49) - Fold 1 - Validation Accuracy : 0.5232\n",
      "Epoch(49) - Fold 1 - Validation Utility score : 520.8244\n",
      "Epoch(49) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(49) - Fold 2 - Validation Accuracy : 0.5086\n",
      "Epoch(49) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(49) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(49) - Fold 3 - Validation Accuracy : 0.5076\n",
      "Epoch(49) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(49) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(49) - Fold 4 - Validation Accuracy : 0.5114\n",
      "Epoch(49) - Fold 4 - Validation Utility score : 887.9539\n",
      "Epoch(49) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(49) - GLOBAL - Validation Accuracy: 0.5144\n",
      "Epoch(49) - GLOBAL - Validation Utility score: 1564.3113\n",
      "Intermediate early stopping : vepoch_loss = 0.6922, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(50) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(50) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(50) - Fold 0 - Validation Accuracy : 0.5232\n",
      "Epoch(50) - Fold 0 - Validation Utility score : 235.4617\n",
      "Epoch(50) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(50) - Fold 1 - Validation Accuracy : 0.5238\n",
      "Epoch(50) - Fold 1 - Validation Utility score : 547.1505\n",
      "Epoch(50) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(50) - Fold 2 - Validation Accuracy : 0.5090\n",
      "Epoch(50) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(50) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(50) - Fold 3 - Validation Accuracy : 0.5081\n",
      "Epoch(50) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(50) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(50) - Fold 4 - Validation Accuracy : 0.5126\n",
      "Epoch(50) - Fold 4 - Validation Utility score : 833.7929\n",
      "Epoch(50) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(50) - GLOBAL - Validation Accuracy: 0.5153\n",
      "Epoch(50) - GLOBAL - Validation Utility score: 1616.4051\n",
      "Saving model corresponding to last_utility_score == 1616.4051484711297\n",
      "\n",
      "\n",
      "Epoch(51) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(51) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(51) - Fold 0 - Validation Accuracy : 0.5230\n",
      "Epoch(51) - Fold 0 - Validation Utility score : 237.8087\n",
      "Epoch(51) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(51) - Fold 1 - Validation Accuracy : 0.5241\n",
      "Epoch(51) - Fold 1 - Validation Utility score : 659.2970\n",
      "Epoch(51) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(51) - Fold 2 - Validation Accuracy : 0.5094\n",
      "Epoch(51) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(51) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(51) - Fold 3 - Validation Accuracy : 0.5088\n",
      "Epoch(51) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(51) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(51) - Fold 4 - Validation Accuracy : 0.5128\n",
      "Epoch(51) - Fold 4 - Validation Utility score : 858.3478\n",
      "Epoch(51) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(51) - GLOBAL - Validation Accuracy: 0.5156\n",
      "Epoch(51) - GLOBAL - Validation Utility score: 1755.4535\n",
      "Saving model corresponding to last_utility_score == 1755.4534967815407\n",
      "\n",
      "\n",
      "Epoch(52) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(52) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(52) - Fold 0 - Validation Accuracy : 0.5245\n",
      "Epoch(52) - Fold 0 - Validation Utility score : 286.8821\n",
      "Epoch(52) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(52) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(52) - Fold 1 - Validation Utility score : 627.0565\n",
      "Epoch(52) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(52) - Fold 2 - Validation Accuracy : 0.5091\n",
      "Epoch(52) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(52) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(52) - Fold 3 - Validation Accuracy : 0.5085\n",
      "Epoch(52) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(52) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(52) - Fold 4 - Validation Accuracy : 0.5127\n",
      "Epoch(52) - Fold 4 - Validation Utility score : 1015.2505\n",
      "Epoch(52) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(52) - GLOBAL - Validation Accuracy: 0.5157\n",
      "Epoch(52) - GLOBAL - Validation Utility score: 1929.1892\n",
      "Saving model corresponding to last_utility_score == 1929.189152861359\n",
      "\n",
      "\n",
      "Epoch(53) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(53) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(53) - Fold 0 - Validation Accuracy : 0.5192\n",
      "Epoch(53) - Fold 0 - Validation Utility score : 125.4627\n",
      "Epoch(53) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(53) - Fold 1 - Validation Accuracy : 0.5220\n",
      "Epoch(53) - Fold 1 - Validation Utility score : 409.2298\n",
      "Epoch(53) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(53) - Fold 2 - Validation Accuracy : 0.5102\n",
      "Epoch(53) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(53) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(53) - Fold 3 - Validation Accuracy : 0.5074\n",
      "Epoch(53) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(53) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(53) - Fold 4 - Validation Accuracy : 0.5119\n",
      "Epoch(53) - Fold 4 - Validation Utility score : 879.9652\n",
      "Epoch(53) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(53) - GLOBAL - Validation Accuracy: 0.5142\n",
      "Epoch(53) - GLOBAL - Validation Utility score: 1414.6577\n",
      "Intermediate early stopping : vepoch_loss = 0.6922, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(54) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(54) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(54) - Fold 0 - Validation Accuracy : 0.5229\n",
      "Epoch(54) - Fold 0 - Validation Utility score : 258.6843\n",
      "Epoch(54) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(54) - Fold 1 - Validation Accuracy : 0.5231\n",
      "Epoch(54) - Fold 1 - Validation Utility score : 529.4657\n",
      "Epoch(54) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(54) - Fold 2 - Validation Accuracy : 0.5094\n",
      "Epoch(54) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(54) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(54) - Fold 3 - Validation Accuracy : 0.5089\n",
      "Epoch(54) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(54) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(54) - Fold 4 - Validation Accuracy : 0.5132\n",
      "Epoch(54) - Fold 4 - Validation Utility score : 897.0140\n",
      "Epoch(54) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(54) - GLOBAL - Validation Accuracy: 0.5155\n",
      "Epoch(54) - GLOBAL - Validation Utility score: 1685.1639\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(55) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(55) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(55) - Fold 0 - Validation Accuracy : 0.5240\n",
      "Epoch(55) - Fold 0 - Validation Utility score : 270.8330\n",
      "Epoch(55) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(55) - Fold 1 - Validation Accuracy : 0.5244\n",
      "Epoch(55) - Fold 1 - Validation Utility score : 705.8966\n",
      "Epoch(55) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(55) - Fold 2 - Validation Accuracy : 0.5094\n",
      "Epoch(55) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(55) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(55) - Fold 3 - Validation Accuracy : 0.5089\n",
      "Epoch(55) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(55) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(55) - Fold 4 - Validation Accuracy : 0.5136\n",
      "Epoch(55) - Fold 4 - Validation Utility score : 916.9672\n",
      "Epoch(55) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(55) - GLOBAL - Validation Accuracy: 0.5161\n",
      "Epoch(55) - GLOBAL - Validation Utility score: 1893.6968\n",
      "Saving model corresponding to last_utility_score == 1893.696768329321\n",
      "\n",
      "\n",
      "Epoch(56) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(56) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(56) - Fold 0 - Validation Accuracy : 0.5198\n",
      "Epoch(56) - Fold 0 - Validation Utility score : 118.6412\n",
      "Epoch(56) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(56) - Fold 1 - Validation Accuracy : 0.5210\n",
      "Epoch(56) - Fold 1 - Validation Utility score : 381.6030\n",
      "Epoch(56) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(56) - Fold 2 - Validation Accuracy : 0.5093\n",
      "Epoch(56) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(56) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(56) - Fold 3 - Validation Accuracy : 0.5078\n",
      "Epoch(56) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(56) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(56) - Fold 4 - Validation Accuracy : 0.5114\n",
      "Epoch(56) - Fold 4 - Validation Utility score : 791.4928\n",
      "Epoch(56) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(56) - GLOBAL - Validation Accuracy: 0.5138\n",
      "Epoch(56) - GLOBAL - Validation Utility score: 1291.7369\n",
      "Intermediate early stopping : vepoch_loss = 0.6922, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(57) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(57) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(57) - Fold 0 - Validation Accuracy : 0.5244\n",
      "Epoch(57) - Fold 0 - Validation Utility score : 389.7371\n",
      "Epoch(57) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(57) - Fold 1 - Validation Accuracy : 0.5248\n",
      "Epoch(57) - Fold 1 - Validation Utility score : 898.9493\n",
      "Epoch(57) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(57) - Fold 2 - Validation Accuracy : 0.5090\n",
      "Epoch(57) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(57) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(57) - Fold 3 - Validation Accuracy : 0.5097\n",
      "Epoch(57) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(57) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(57) - Fold 4 - Validation Accuracy : 0.5173\n",
      "Epoch(57) - Fold 4 - Validation Utility score : 1171.5522\n",
      "Epoch(57) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(57) - GLOBAL - Validation Accuracy: 0.5170\n",
      "Epoch(57) - GLOBAL - Validation Utility score: 2460.2386\n",
      "Saving model corresponding to last_utility_score == 2460.238566428713\n",
      "\n",
      "\n",
      "Epoch(58) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(58) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(58) - Fold 0 - Validation Accuracy : 0.5238\n",
      "Epoch(58) - Fold 0 - Validation Utility score : 314.1821\n",
      "Epoch(58) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(58) - Fold 1 - Validation Accuracy : 0.5253\n",
      "Epoch(58) - Fold 1 - Validation Utility score : 705.3748\n",
      "Epoch(58) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(58) - Fold 2 - Validation Accuracy : 0.5099\n",
      "Epoch(58) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(58) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(58) - Fold 3 - Validation Accuracy : 0.5090\n",
      "Epoch(58) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(58) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(58) - Fold 4 - Validation Accuracy : 0.5158\n",
      "Epoch(58) - Fold 4 - Validation Utility score : 1070.4675\n",
      "Epoch(58) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(58) - GLOBAL - Validation Accuracy: 0.5168\n",
      "Epoch(58) - GLOBAL - Validation Utility score: 2090.0244\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(59) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(59) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(59) - Fold 0 - Validation Accuracy : 0.5243\n",
      "Epoch(59) - Fold 0 - Validation Utility score : 345.3575\n",
      "Epoch(59) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(59) - Fold 1 - Validation Accuracy : 0.5245\n",
      "Epoch(59) - Fold 1 - Validation Utility score : 808.0063\n",
      "Epoch(59) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(59) - Fold 2 - Validation Accuracy : 0.5096\n",
      "Epoch(59) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(59) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(59) - Fold 3 - Validation Accuracy : 0.5111\n",
      "Epoch(59) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(59) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(59) - Fold 4 - Validation Accuracy : 0.5165\n",
      "Epoch(59) - Fold 4 - Validation Utility score : 1111.1353\n",
      "Epoch(59) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(59) - GLOBAL - Validation Accuracy: 0.5172\n",
      "Epoch(59) - GLOBAL - Validation Utility score: 2264.4991\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(60) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(60) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(60) - Fold 0 - Validation Accuracy : 0.5249\n",
      "Epoch(60) - Fold 0 - Validation Utility score : 447.0116\n",
      "Epoch(60) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(60) - Fold 1 - Validation Accuracy : 0.5236\n",
      "Epoch(60) - Fold 1 - Validation Utility score : 832.3493\n",
      "Epoch(60) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(60) - Fold 2 - Validation Accuracy : 0.5098\n",
      "Epoch(60) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(60) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(60) - Fold 3 - Validation Accuracy : 0.5093\n",
      "Epoch(60) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(60) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(60) - Fold 4 - Validation Accuracy : 0.5159\n",
      "Epoch(60) - Fold 4 - Validation Utility score : 1113.6634\n",
      "Epoch(60) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(60) - GLOBAL - Validation Accuracy: 0.5167\n",
      "Epoch(60) - GLOBAL - Validation Utility score: 2393.0243\n",
      "Saving model corresponding to last_utility_score == 2393.0242921099843\n",
      "\n",
      "\n",
      "Epoch(61) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(61) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(61) - Fold 0 - Validation Accuracy : 0.5224\n",
      "Epoch(61) - Fold 0 - Validation Utility score : 177.5597\n",
      "Epoch(61) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(61) - Fold 1 - Validation Accuracy : 0.5233\n",
      "Epoch(61) - Fold 1 - Validation Utility score : 581.2463\n",
      "Epoch(61) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(61) - Fold 2 - Validation Accuracy : 0.5103\n",
      "Epoch(61) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(61) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(61) - Fold 3 - Validation Accuracy : 0.5098\n",
      "Epoch(61) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(61) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(61) - Fold 4 - Validation Accuracy : 0.5158\n",
      "Epoch(61) - Fold 4 - Validation Utility score : 1065.3459\n",
      "Epoch(61) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(61) - GLOBAL - Validation Accuracy: 0.5163\n",
      "Epoch(61) - GLOBAL - Validation Utility score: 1824.1519\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(62) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(62) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(62) - Fold 0 - Validation Accuracy : 0.5235\n",
      "Epoch(62) - Fold 0 - Validation Utility score : 291.2636\n",
      "Epoch(62) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(62) - Fold 1 - Validation Accuracy : 0.5246\n",
      "Epoch(62) - Fold 1 - Validation Utility score : 714.4140\n",
      "Epoch(62) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(62) - Fold 2 - Validation Accuracy : 0.5108\n",
      "Epoch(62) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(62) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(62) - Fold 3 - Validation Accuracy : 0.5098\n",
      "Epoch(62) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(62) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(62) - Fold 4 - Validation Accuracy : 0.5160\n",
      "Epoch(62) - Fold 4 - Validation Utility score : 1010.0991\n",
      "Epoch(62) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(62) - GLOBAL - Validation Accuracy: 0.5169\n",
      "Epoch(62) - GLOBAL - Validation Utility score: 2015.7766\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(63) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(63) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(63) - Fold 0 - Validation Accuracy : 0.5244\n",
      "Epoch(63) - Fold 0 - Validation Utility score : 352.8087\n",
      "Epoch(63) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(63) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(63) - Fold 1 - Validation Utility score : 820.3947\n",
      "Epoch(63) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(63) - Fold 2 - Validation Accuracy : 0.5094\n",
      "Epoch(63) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(63) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(63) - Fold 3 - Validation Accuracy : 0.5099\n",
      "Epoch(63) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(63) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(63) - Fold 4 - Validation Accuracy : 0.5179\n",
      "Epoch(63) - Fold 4 - Validation Utility score : 1178.3509\n",
      "Epoch(63) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(63) - GLOBAL - Validation Accuracy: 0.5171\n",
      "Epoch(63) - GLOBAL - Validation Utility score: 2351.5543\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(64) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(64) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(64) - Fold 0 - Validation Accuracy : 0.5223\n",
      "Epoch(64) - Fold 0 - Validation Utility score : 229.8024\n",
      "Epoch(64) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(64) - Fold 1 - Validation Accuracy : 0.5242\n",
      "Epoch(64) - Fold 1 - Validation Utility score : 693.7844\n",
      "Epoch(64) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(64) - Fold 2 - Validation Accuracy : 0.5110\n",
      "Epoch(64) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(64) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(64) - Fold 3 - Validation Accuracy : 0.5100\n",
      "Epoch(64) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(64) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(64) - Fold 4 - Validation Accuracy : 0.5164\n",
      "Epoch(64) - Fold 4 - Validation Utility score : 1012.3874\n",
      "Epoch(64) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(64) - GLOBAL - Validation Accuracy: 0.5168\n",
      "Epoch(64) - GLOBAL - Validation Utility score: 1935.9742\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(65) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(65) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(65) - Fold 0 - Validation Accuracy : 0.5232\n",
      "Epoch(65) - Fold 0 - Validation Utility score : 218.3413\n",
      "Epoch(65) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(65) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(65) - Fold 1 - Validation Utility score : 673.9828\n",
      "Epoch(65) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(65) - Fold 2 - Validation Accuracy : 0.5099\n",
      "Epoch(65) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(65) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(65) - Fold 3 - Validation Accuracy : 0.5096\n",
      "Epoch(65) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(65) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(65) - Fold 4 - Validation Accuracy : 0.5142\n",
      "Epoch(65) - Fold 4 - Validation Utility score : 975.3495\n",
      "Epoch(65) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(65) - GLOBAL - Validation Accuracy: 0.5162\n",
      "Epoch(65) - GLOBAL - Validation Utility score: 1867.6735\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "Meet Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 502304<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_043902-7lc6i2hc/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_043902-7lc6i2hc/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>0.69166</td></tr><tr><td>Global valid/Loss</td><td>0.69199</td></tr><tr><td>Global valid/Accuracy</td><td>0.51619</td></tr><tr><td>Global valid/Utility</td><td>1867.67352</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>0.69153</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>0.52324</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>218.34126</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>0.69118</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>0.52402</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>673.98276</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>0.69286</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>0.50988</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>0.69281</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>0.50959</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>0.69156</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>0.51423</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>975.34951</td></tr><tr><td>Best accuracy</td><td>0.51671</td></tr><tr><td>Best utility</td><td>2393.02429</td></tr><tr><td>_runtime</td><td>3318</td></tr><tr><td>_timestamp</td><td>1613450060</td></tr><tr><td>_step</td><td>65</td></tr><tr><td>Final utility score</td><td>{'utility_score': 23...</td></tr><tr><td>Batch size</td><td>57181</td></tr><tr><td>Patience</td><td>5</td></tr><tr><td>Number of epochs</td><td>1000</td></tr><tr><td>Best epoch</td><td>60</td></tr><tr><td>Number of parameters per layer</td><td>[8384, 64, 2048, 32,...</td></tr><tr><td>Model architecture</td><td>MLP(<BR>  (AEncoder)...</td></tr><tr><td>comment</td><td>All folds MLP with a...</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>█▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Accuracy</td><td>▂▁▂▂▂▂▂▂▂▃▄▄▅▄▅▆▆▆▇▇▇▇▆▇▇▇▆▇▇▇▇▇▇█▇█████</td></tr><tr><td>Global valid/Utility</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▃▂▃▄▄▅▅▆▅▅▄▅▆▅▄▆▆▆▆▆▅▇▅▇█▆█▆</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>█▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>▁▂▁▁▁▁▂▂▂▂▃▄▄▄▅▆▅▆▆▇▆▆▆▇▇▇▆▇▇▇█▇▆█▇██▇██</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▆▃▄▂▃▄▄▂▃▄▄▅▅▃▅▃▆█▄▇▄</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>█▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>▂▁▂▂▂▂▃▃▃▃▄▅▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇█▇█▇▇██</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▄▄▅▅▅▄▅▆▅▄▅▅▆▆▇▄▇▄▇█▆█▇</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>▃▁▄▄▄▄▄▄▄▄▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇███▇█████</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>▁▃▁▁▁▁▃▃▃▃▄▅▆▅▇▇▇▆▆▅▆▆▆▆▆▆▆▆▇▇▇▇▆▇▇▇████</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>█▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>▃▁▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▆▇▆▇▇▇█▇</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>▁▁▁▁▁▁▁▁▁▂▂▃▃▃▄▅▄▆▆▆▆▆▆▆▇▆▅▆▇▆▆▆▆▆▆▇█▇█▇</td></tr><tr><td>Best accuracy</td><td>▂▁▂▂▂▂▂▂▂▂▂▂▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████</td></tr><tr><td>Best utility</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▄▃▄▅▅▆▆▅▅▆▅▆▆▆▆▆▆███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 331 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">revived-sweep-2</strong>: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/7lc6i2hc\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/7lc6i2hc</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training summary:\n",
      "{'utility_score': 2393.0242921099843, 'utility_scores': [447.0115815618938, 832.3493279899316, -0.0, -0.0, 1113.6633825581591], 'utility_score_std': 444.4227345626996, 'accuracy_scores': [0.524903970177602, 0.5236433836433837, 0.5097939595334052, 0.5093491473915246, 0.515861388928018]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7fl6blmv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leakyrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 26367\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.36161786215684677\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006964330441219877\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_autoenc: encoder\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 3.603274926466758e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">decent-sweep-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/7fl6blmv\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/7fl6blmv</a><br/>\n",
       "                Run data is saved locally in <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_053425-7fl6blmv</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Run config :\n",
      "config: {'activation_function': 'leakyrelu', 'batch_size': 26367, 'dropout': 0.36161786215684677, 'learning_rate': 0.0006964330441219877, 'use_autoenc': 'encoder', 'weight_decay': 3.603274926466758e-05, 'epochs': 1000}\n",
      "Epoch(0) - Training Loss: 0.7387\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(0) - Fold 0 - Validation Loss : 0.6933\n",
      "Epoch(0) - Fold 0 - Validation Accuracy : 0.5152\n",
      "Epoch(0) - Fold 0 - Validation Utility score : 77.0642\n",
      "Epoch(0) - Fold 1 - Validation Loss : 0.6930\n",
      "Epoch(0) - Fold 1 - Validation Accuracy : 0.5105\n",
      "Epoch(0) - Fold 1 - Validation Utility score : 444.6956\n",
      "Epoch(0) - Fold 2 - Validation Loss : 0.6947\n",
      "Epoch(0) - Fold 2 - Validation Accuracy : 0.5042\n",
      "Epoch(0) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 3 - Validation Loss : 0.6943\n",
      "Epoch(0) - Fold 3 - Validation Accuracy : 0.5025\n",
      "Epoch(0) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 4 - Validation Loss : 0.6937\n",
      "Epoch(0) - Fold 4 - Validation Accuracy : 0.5058\n",
      "Epoch(0) - Fold 4 - Validation Utility score : 253.3196\n",
      "Epoch(0) - GLOBAL - Validation Loss: 0.6938\n",
      "Epoch(0) - GLOBAL - Validation Accuracy: 0.5076\n",
      "Epoch(0) - GLOBAL - Validation Utility score: 775.0794\n",
      "Saving model corresponding to last_utility_score == 775.0794414659426\n",
      "\n",
      "\n",
      "Epoch(1) - Training Loss: 0.7056\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(1) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(1) - Fold 0 - Validation Accuracy : 0.5155\n",
      "Epoch(1) - Fold 0 - Validation Utility score : 120.8105\n",
      "Epoch(1) - Fold 1 - Validation Loss : 0.6923\n",
      "Epoch(1) - Fold 1 - Validation Accuracy : 0.5150\n",
      "Epoch(1) - Fold 1 - Validation Utility score : 972.6994\n",
      "Epoch(1) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(1) - Fold 2 - Validation Accuracy : 0.5053\n",
      "Epoch(1) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(1) - Fold 3 - Validation Accuracy : 0.5082\n",
      "Epoch(1) - Fold 3 - Validation Utility score : 54.1403\n",
      "Epoch(1) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(1) - Fold 4 - Validation Accuracy : 0.5147\n",
      "Epoch(1) - Fold 4 - Validation Utility score : 732.9105\n",
      "Epoch(1) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(1) - GLOBAL - Validation Accuracy: 0.5117\n",
      "Epoch(1) - GLOBAL - Validation Utility score: 1880.5607\n",
      "Saving model corresponding to last_utility_score == 1880.5607127316102\n",
      "\n",
      "\n",
      "Epoch(2) - Training Loss: 0.6957\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(2) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(2) - Fold 0 - Validation Accuracy : 0.5118\n",
      "Epoch(2) - Fold 0 - Validation Utility score : 119.1062\n",
      "Epoch(2) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(2) - Fold 1 - Validation Accuracy : 0.5066\n",
      "Epoch(2) - Fold 1 - Validation Utility score : 128.8670\n",
      "Epoch(2) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(2) - Fold 2 - Validation Accuracy : 0.5051\n",
      "Epoch(2) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(2) - Fold 3 - Validation Accuracy : 0.5047\n",
      "Epoch(2) - Fold 3 - Validation Utility score : 43.4533\n",
      "Epoch(2) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(2) - Fold 4 - Validation Accuracy : 0.5122\n",
      "Epoch(2) - Fold 4 - Validation Utility score : 544.4843\n",
      "Epoch(2) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(2) - GLOBAL - Validation Accuracy: 0.5081\n",
      "Epoch(2) - GLOBAL - Validation Utility score: 835.9108\n",
      "Intermediate early stopping : vepoch_loss = 0.6928, the_last_loss=0.6926\n",
      "\n",
      "\n",
      "Epoch(3) - Training Loss: 0.6936\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(3) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(3) - Fold 0 - Validation Accuracy : 0.5206\n",
      "Epoch(3) - Fold 0 - Validation Utility score : 408.2642\n",
      "Epoch(3) - Fold 1 - Validation Loss : 0.6926\n",
      "Epoch(3) - Fold 1 - Validation Accuracy : 0.5190\n",
      "Epoch(3) - Fold 1 - Validation Utility score : 582.8567\n",
      "Epoch(3) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(3) - Fold 2 - Validation Accuracy : 0.5070\n",
      "Epoch(3) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(3) - Fold 3 - Validation Accuracy : 0.5093\n",
      "Epoch(3) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(3) - Fold 4 - Validation Accuracy : 0.5187\n",
      "Epoch(3) - Fold 4 - Validation Utility score : 942.2332\n",
      "Epoch(3) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(3) - GLOBAL - Validation Accuracy: 0.5149\n",
      "Epoch(3) - GLOBAL - Validation Utility score: 1933.3540\n",
      "Saving model corresponding to last_utility_score == 1933.3540214812338\n",
      "\n",
      "\n",
      "Epoch(4) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(4) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(4) - Fold 0 - Validation Accuracy : 0.5220\n",
      "Epoch(4) - Fold 0 - Validation Utility score : 466.3359\n",
      "Epoch(4) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(4) - Fold 1 - Validation Accuracy : 0.5205\n",
      "Epoch(4) - Fold 1 - Validation Utility score : 856.0762\n",
      "Epoch(4) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(4) - Fold 2 - Validation Accuracy : 0.5062\n",
      "Epoch(4) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(4) - Fold 3 - Validation Accuracy : 0.5097\n",
      "Epoch(4) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(4) - Fold 4 - Validation Accuracy : 0.5189\n",
      "Epoch(4) - Fold 4 - Validation Utility score : 1251.9711\n",
      "Epoch(4) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(4) - GLOBAL - Validation Accuracy: 0.5154\n",
      "Epoch(4) - GLOBAL - Validation Utility score: 2574.3832\n",
      "Saving model corresponding to last_utility_score == 2574.3831955996284\n",
      "\n",
      "\n",
      "Epoch(5) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(5) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(5) - Fold 0 - Validation Accuracy : 0.5242\n",
      "Epoch(5) - Fold 0 - Validation Utility score : 555.6720\n",
      "Epoch(5) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(5) - Fold 1 - Validation Accuracy : 0.5219\n",
      "Epoch(5) - Fold 1 - Validation Utility score : 929.3971\n",
      "Epoch(5) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(5) - Fold 2 - Validation Accuracy : 0.5067\n",
      "Epoch(5) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(5) - Fold 3 - Validation Accuracy : 0.5122\n",
      "Epoch(5) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(5) - Fold 4 - Validation Accuracy : 0.5208\n",
      "Epoch(5) - Fold 4 - Validation Utility score : 1317.5673\n",
      "Epoch(5) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(5) - GLOBAL - Validation Accuracy: 0.5172\n",
      "Epoch(5) - GLOBAL - Validation Utility score: 2802.6364\n",
      "Saving model corresponding to last_utility_score == 2802.636403248916\n",
      "\n",
      "\n",
      "Epoch(6) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(6) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(6) - Fold 0 - Validation Accuracy : 0.5245\n",
      "Epoch(6) - Fold 0 - Validation Utility score : 670.5157\n",
      "Epoch(6) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(6) - Fold 1 - Validation Accuracy : 0.5221\n",
      "Epoch(6) - Fold 1 - Validation Utility score : 1051.3145\n",
      "Epoch(6) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(6) - Fold 2 - Validation Accuracy : 0.5066\n",
      "Epoch(6) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 3 - Validation Loss : 0.6926\n",
      "Epoch(6) - Fold 3 - Validation Accuracy : 0.5115\n",
      "Epoch(6) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(6) - Fold 4 - Validation Accuracy : 0.5227\n",
      "Epoch(6) - Fold 4 - Validation Utility score : 1329.8372\n",
      "Epoch(6) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(6) - GLOBAL - Validation Accuracy: 0.5175\n",
      "Epoch(6) - GLOBAL - Validation Utility score: 3051.6674\n",
      "Saving model corresponding to last_utility_score == 3051.6674394949605\n",
      "\n",
      "\n",
      "Epoch(7) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(7) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(7) - Fold 0 - Validation Accuracy : 0.5231\n",
      "Epoch(7) - Fold 0 - Validation Utility score : 475.7767\n",
      "Epoch(7) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(7) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(7) - Fold 1 - Validation Utility score : 985.8662\n",
      "Epoch(7) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(7) - Fold 2 - Validation Accuracy : 0.5079\n",
      "Epoch(7) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(7) - Fold 3 - Validation Accuracy : 0.5143\n",
      "Epoch(7) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(7) - Fold 4 - Validation Accuracy : 0.5222\n",
      "Epoch(7) - Fold 4 - Validation Utility score : 1241.8188\n",
      "Epoch(7) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(7) - GLOBAL - Validation Accuracy: 0.5182\n",
      "Epoch(7) - GLOBAL - Validation Utility score: 2703.4617\n",
      "Saving model corresponding to last_utility_score == 2703.4616521641638\n",
      "\n",
      "\n",
      "Epoch(8) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(8) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(8) - Fold 0 - Validation Accuracy : 0.5233\n",
      "Epoch(8) - Fold 0 - Validation Utility score : 477.0520\n",
      "Epoch(8) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(8) - Fold 1 - Validation Accuracy : 0.5236\n",
      "Epoch(8) - Fold 1 - Validation Utility score : 959.2817\n",
      "Epoch(8) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(8) - Fold 2 - Validation Accuracy : 0.5088\n",
      "Epoch(8) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(8) - Fold 3 - Validation Accuracy : 0.5141\n",
      "Epoch(8) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(8) - Fold 4 - Validation Accuracy : 0.5231\n",
      "Epoch(8) - Fold 4 - Validation Utility score : 1261.6889\n",
      "Epoch(8) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(8) - GLOBAL - Validation Accuracy: 0.5186\n",
      "Epoch(8) - GLOBAL - Validation Utility score: 2698.0226\n",
      "Saving model corresponding to last_utility_score == 2698.0225661822033\n",
      "\n",
      "\n",
      "Epoch(9) - Training Loss: 0.6914\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(9) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(9) - Fold 0 - Validation Accuracy : 0.5226\n",
      "Epoch(9) - Fold 0 - Validation Utility score : 418.0113\n",
      "Epoch(9) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(9) - Fold 1 - Validation Accuracy : 0.5239\n",
      "Epoch(9) - Fold 1 - Validation Utility score : 1169.1115\n",
      "Epoch(9) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(9) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(9) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(9) - Fold 3 - Validation Accuracy : 0.5126\n",
      "Epoch(9) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(9) - Fold 4 - Validation Accuracy : 0.5240\n",
      "Epoch(9) - Fold 4 - Validation Utility score : 1348.2847\n",
      "Epoch(9) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(9) - GLOBAL - Validation Accuracy: 0.5183\n",
      "Epoch(9) - GLOBAL - Validation Utility score: 2935.4074\n",
      "Saving model corresponding to last_utility_score == 2935.4074349870043\n",
      "\n",
      "\n",
      "Epoch(10) - Training Loss: 0.6912\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(10) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(10) - Fold 0 - Validation Accuracy : 0.5221\n",
      "Epoch(10) - Fold 0 - Validation Utility score : 388.0845\n",
      "Epoch(10) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(10) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(10) - Fold 1 - Validation Utility score : 1076.9566\n",
      "Epoch(10) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(10) - Fold 2 - Validation Accuracy : 0.5089\n",
      "Epoch(10) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(10) - Fold 3 - Validation Accuracy : 0.5137\n",
      "Epoch(10) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 4 - Validation Loss : 0.6912\n",
      "Epoch(10) - Fold 4 - Validation Accuracy : 0.5246\n",
      "Epoch(10) - Fold 4 - Validation Utility score : 1194.7339\n",
      "Epoch(10) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(10) - GLOBAL - Validation Accuracy: 0.5187\n",
      "Epoch(10) - GLOBAL - Validation Utility score: 2659.7750\n",
      "Saving model corresponding to last_utility_score == 2659.7749669239192\n",
      "\n",
      "\n",
      "Epoch(11) - Training Loss: 0.6910\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(11) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(11) - Fold 0 - Validation Accuracy : 0.5210\n",
      "Epoch(11) - Fold 0 - Validation Utility score : 320.0166\n",
      "Epoch(11) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(11) - Fold 1 - Validation Accuracy : 0.5224\n",
      "Epoch(11) - Fold 1 - Validation Utility score : 1088.4620\n",
      "Epoch(11) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(11) - Fold 2 - Validation Accuracy : 0.5089\n",
      "Epoch(11) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(11) - Fold 3 - Validation Accuracy : 0.5116\n",
      "Epoch(11) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 4 - Validation Loss : 0.6911\n",
      "Epoch(11) - Fold 4 - Validation Accuracy : 0.5237\n",
      "Epoch(11) - Fold 4 - Validation Utility score : 1257.6545\n",
      "Epoch(11) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(11) - GLOBAL - Validation Accuracy: 0.5175\n",
      "Epoch(11) - GLOBAL - Validation Utility score: 2666.1330\n",
      "Saving model corresponding to last_utility_score == 2666.1330216791084\n",
      "\n",
      "\n",
      "Epoch(12) - Training Loss: 0.6908\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(12) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(12) - Fold 0 - Validation Accuracy : 0.5205\n",
      "Epoch(12) - Fold 0 - Validation Utility score : 331.4974\n",
      "Epoch(12) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(12) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(12) - Fold 1 - Validation Utility score : 972.0556\n",
      "Epoch(12) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(12) - Fold 2 - Validation Accuracy : 0.5106\n",
      "Epoch(12) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(12) - Fold 3 - Validation Accuracy : 0.5135\n",
      "Epoch(12) - Fold 3 - Validation Utility score : 2.9681\n",
      "Epoch(12) - Fold 4 - Validation Loss : 0.6910\n",
      "Epoch(12) - Fold 4 - Validation Accuracy : 0.5252\n",
      "Epoch(12) - Fold 4 - Validation Utility score : 1327.9978\n",
      "Epoch(12) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(12) - GLOBAL - Validation Accuracy: 0.5187\n",
      "Epoch(12) - GLOBAL - Validation Utility score: 2634.5188\n",
      "Saving model corresponding to last_utility_score == 2634.518830431538\n",
      "\n",
      "\n",
      "Epoch(13) - Training Loss: 0.6907\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(13) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(13) - Fold 0 - Validation Accuracy : 0.5209\n",
      "Epoch(13) - Fold 0 - Validation Utility score : 295.5445\n",
      "Epoch(13) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(13) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(13) - Fold 1 - Validation Utility score : 964.8010\n",
      "Epoch(13) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(13) - Fold 2 - Validation Accuracy : 0.5094\n",
      "Epoch(13) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(13) - Fold 3 - Validation Accuracy : 0.5120\n",
      "Epoch(13) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 4 - Validation Loss : 0.6909\n",
      "Epoch(13) - Fold 4 - Validation Accuracy : 0.5252\n",
      "Epoch(13) - Fold 4 - Validation Utility score : 1284.9602\n",
      "Epoch(13) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(13) - GLOBAL - Validation Accuracy: 0.5182\n",
      "Epoch(13) - GLOBAL - Validation Utility score: 2545.3056\n",
      "Saving model corresponding to last_utility_score == 2545.305598837789\n",
      "\n",
      "\n",
      "Epoch(14) - Training Loss: 0.6906\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(14) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(14) - Fold 0 - Validation Accuracy : 0.5207\n",
      "Epoch(14) - Fold 0 - Validation Utility score : 274.2169\n",
      "Epoch(14) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(14) - Fold 1 - Validation Accuracy : 0.5230\n",
      "Epoch(14) - Fold 1 - Validation Utility score : 957.8719\n",
      "Epoch(14) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(14) - Fold 2 - Validation Accuracy : 0.5092\n",
      "Epoch(14) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(14) - Fold 3 - Validation Accuracy : 0.5113\n",
      "Epoch(14) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 4 - Validation Loss : 0.6908\n",
      "Epoch(14) - Fold 4 - Validation Accuracy : 0.5243\n",
      "Epoch(14) - Fold 4 - Validation Utility score : 1321.4450\n",
      "Epoch(14) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(14) - GLOBAL - Validation Accuracy: 0.5177\n",
      "Epoch(14) - GLOBAL - Validation Utility score: 2553.5339\n",
      "Saving model corresponding to last_utility_score == 2553.5338584377323\n",
      "\n",
      "\n",
      "Epoch(15) - Training Loss: 0.6903\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(15) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(15) - Fold 0 - Validation Accuracy : 0.5207\n",
      "Epoch(15) - Fold 0 - Validation Utility score : 249.5974\n",
      "Epoch(15) - Fold 1 - Validation Loss : 0.6909\n",
      "Epoch(15) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(15) - Fold 1 - Validation Utility score : 776.9390\n",
      "Epoch(15) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(15) - Fold 2 - Validation Accuracy : 0.5123\n",
      "Epoch(15) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(15) - Fold 3 - Validation Accuracy : 0.5121\n",
      "Epoch(15) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 4 - Validation Loss : 0.6908\n",
      "Epoch(15) - Fold 4 - Validation Accuracy : 0.5252\n",
      "Epoch(15) - Fold 4 - Validation Utility score : 1394.2189\n",
      "Epoch(15) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(15) - GLOBAL - Validation Accuracy: 0.5187\n",
      "Epoch(15) - GLOBAL - Validation Utility score: 2420.7553\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(16) - Training Loss: 0.6902\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(16) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(16) - Fold 0 - Validation Accuracy : 0.5200\n",
      "Epoch(16) - Fold 0 - Validation Utility score : 247.2909\n",
      "Epoch(16) - Fold 1 - Validation Loss : 0.6909\n",
      "Epoch(16) - Fold 1 - Validation Accuracy : 0.5217\n",
      "Epoch(16) - Fold 1 - Validation Utility score : 904.7595\n",
      "Epoch(16) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(16) - Fold 2 - Validation Accuracy : 0.5093\n",
      "Epoch(16) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(16) - Fold 3 - Validation Accuracy : 0.5096\n",
      "Epoch(16) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 4 - Validation Loss : 0.6906\n",
      "Epoch(16) - Fold 4 - Validation Accuracy : 0.5250\n",
      "Epoch(16) - Fold 4 - Validation Utility score : 1413.3079\n",
      "Epoch(16) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(16) - GLOBAL - Validation Accuracy: 0.5171\n",
      "Epoch(16) - GLOBAL - Validation Utility score: 2565.3583\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(17) - Training Loss: 0.6900\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(17) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(17) - Fold 0 - Validation Accuracy : 0.5207\n",
      "Epoch(17) - Fold 0 - Validation Utility score : 288.7527\n",
      "Epoch(17) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(17) - Fold 1 - Validation Accuracy : 0.5206\n",
      "Epoch(17) - Fold 1 - Validation Utility score : 866.7138\n",
      "Epoch(17) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(17) - Fold 2 - Validation Accuracy : 0.5092\n",
      "Epoch(17) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(17) - Fold 3 - Validation Accuracy : 0.5098\n",
      "Epoch(17) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 4 - Validation Loss : 0.6907\n",
      "Epoch(17) - Fold 4 - Validation Accuracy : 0.5252\n",
      "Epoch(17) - Fold 4 - Validation Utility score : 1332.3441\n",
      "Epoch(17) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(17) - GLOBAL - Validation Accuracy: 0.5171\n",
      "Epoch(17) - GLOBAL - Validation Utility score: 2487.8105\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(18) - Training Loss: 0.6897\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(18) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(18) - Fold 0 - Validation Accuracy : 0.5201\n",
      "Epoch(18) - Fold 0 - Validation Utility score : 262.7754\n",
      "Epoch(18) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(18) - Fold 1 - Validation Accuracy : 0.5210\n",
      "Epoch(18) - Fold 1 - Validation Utility score : 806.7586\n",
      "Epoch(18) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(18) - Fold 2 - Validation Accuracy : 0.5101\n",
      "Epoch(18) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 3 - Validation Loss : 0.6936\n",
      "Epoch(18) - Fold 3 - Validation Accuracy : 0.5097\n",
      "Epoch(18) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 4 - Validation Loss : 0.6906\n",
      "Epoch(18) - Fold 4 - Validation Accuracy : 0.5262\n",
      "Epoch(18) - Fold 4 - Validation Utility score : 1395.1407\n",
      "Epoch(18) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(18) - GLOBAL - Validation Accuracy: 0.5174\n",
      "Epoch(18) - GLOBAL - Validation Utility score: 2464.6747\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(19) - Training Loss: 0.6896\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(19) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(19) - Fold 0 - Validation Accuracy : 0.5197\n",
      "Epoch(19) - Fold 0 - Validation Utility score : 278.8722\n",
      "Epoch(19) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(19) - Fold 1 - Validation Accuracy : 0.5189\n",
      "Epoch(19) - Fold 1 - Validation Utility score : 774.7841\n",
      "Epoch(19) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(19) - Fold 2 - Validation Accuracy : 0.5089\n",
      "Epoch(19) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 3 - Validation Loss : 0.6937\n",
      "Epoch(19) - Fold 3 - Validation Accuracy : 0.5079\n",
      "Epoch(19) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 4 - Validation Loss : 0.6907\n",
      "Epoch(19) - Fold 4 - Validation Accuracy : 0.5244\n",
      "Epoch(19) - Fold 4 - Validation Utility score : 1240.3283\n",
      "Epoch(19) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(19) - GLOBAL - Validation Accuracy: 0.5160\n",
      "Epoch(19) - GLOBAL - Validation Utility score: 2293.9846\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6919\n",
      "Meet Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 507109<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_053425-7fl6blmv/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_053425-7fl6blmv/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>0.68957</td></tr><tr><td>Global valid/Loss</td><td>0.6921</td></tr><tr><td>Global valid/Accuracy</td><td>0.51598</td></tr><tr><td>Global valid/Utility</td><td>2293.98456</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>0.6918</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>0.51974</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>278.87222</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>0.69121</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>0.51893</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>774.78409</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>0.69305</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>0.50893</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>0.69373</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>0.50791</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>0.69069</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>0.52436</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>1240.32825</td></tr><tr><td>Best accuracy</td><td>0.51768</td></tr><tr><td>Best utility</td><td>2553.53386</td></tr><tr><td>_runtime</td><td>1104</td></tr><tr><td>_timestamp</td><td>1613451169</td></tr><tr><td>_step</td><td>19</td></tr><tr><td>Final utility score</td><td>{'utility_score': 25...</td></tr><tr><td>Batch size</td><td>26367</td></tr><tr><td>Patience</td><td>5</td></tr><tr><td>Number of epochs</td><td>1000</td></tr><tr><td>Best epoch</td><td>14</td></tr><tr><td>Number of parameters per layer</td><td>[8384, 64, 2048, 32,...</td></tr><tr><td>Model architecture</td><td>MLP(<BR>  (AEncoder)...</td></tr><tr><td>comment</td><td>All folds MLP with a...</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Loss</td><td>█▄▄▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▂▂</td></tr><tr><td>Global valid/Accuracy</td><td>▁▄▁▆▆▇▇████▇██▇█▇▇▇▆</td></tr><tr><td>Global valid/Utility</td><td>▁▄▁▅▇▇█▇▇█▇▇▇▆▆▆▇▆▆▆</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>█▅▅▅▄▃▂▂▁▁▁▁▁▁▂▂▂▂▃▃</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>▃▃▁▆▇██▇▇▇▇▆▆▆▆▆▆▆▆▅</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>▁▂▁▅▆▇█▆▆▅▅▄▄▄▃▃▃▃▃▃</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>█▆▇▇▆▅▄▄▃▃▂▂▂▂▁▁▁▂▂▂</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>▃▄▁▆▇▇▇████▇████▇▇▇▆</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>▃▇▁▄▆▆▇▇▇█▇▇▇▇▇▅▆▆▆▅</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>█▂▂▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▂</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>▁▂▂▃▃▃▃▄▅▅▅▅▇▆▅█▅▅▆▅</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>█▃▂▂▂▁▁▁▁▂▂▂▂▃▃▄▄▄▅▆</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>▁▄▂▅▅▇▆██▇█▆█▇▆▇▅▅▅▄</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>▁█▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>█▅▅▅▅▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>▁▄▃▅▆▆▇▇▇▇▇▇██▇████▇</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>▁▄▃▅▇▇▇▇▇█▇▇▇▇▇████▇</td></tr><tr><td>Best accuracy</td><td>▁▄▆▆▇▇████▇██▇▇</td></tr><tr><td>Best utility</td><td>▁▄▅▇▇█▇▇█▇▇▇▆▆▆</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▆▆▆▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▆▆▆▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 101 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">decent-sweep-3</strong>: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/7fl6blmv\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/7fl6blmv</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training summary:\n",
      "{'utility_score': 2553.5338584377323, 'utility_scores': [274.2169440084067, 957.8718904553774, -0.0, -0.0, 1321.445023973948], 'utility_score_std': 535.6908453676987, 'accuracy_scores': [0.5206588141911525, 0.522962442962443, 0.5091829098324077, 0.5113188699420339, 0.5242991970700098]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dl5rk074 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leakyrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 46919\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.396048378396177\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0015835521466513798\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_autoenc: encoder-only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 8.276252186079976e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">youthful-sweep-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/dl5rk074\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/dl5rk074</a><br/>\n",
       "                Run data is saved locally in <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_055255-dl5rk074</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Run config :\n",
      "config: {'activation_function': 'leakyrelu', 'batch_size': 46919, 'dropout': 0.396048378396177, 'learning_rate': 0.0015835521466513798, 'use_autoenc': 'encoder-only', 'weight_decay': 8.276252186079976e-05, 'epochs': 1000}\n",
      "Epoch(0) - Training Loss: 0.8664\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(0) - Fold 0 - Validation Loss : 0.6982\n",
      "Epoch(0) - Fold 0 - Validation Accuracy : 0.5060\n",
      "Epoch(0) - Fold 0 - Validation Utility score : 47.4982\n",
      "Epoch(0) - Fold 1 - Validation Loss : 0.6968\n",
      "Epoch(0) - Fold 1 - Validation Accuracy : 0.5010\n",
      "Epoch(0) - Fold 1 - Validation Utility score : 0.0685\n",
      "Epoch(0) - Fold 2 - Validation Loss : 0.6982\n",
      "Epoch(0) - Fold 2 - Validation Accuracy : 0.4964\n",
      "Epoch(0) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 3 - Validation Loss : 0.6970\n",
      "Epoch(0) - Fold 3 - Validation Accuracy : 0.5020\n",
      "Epoch(0) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 4 - Validation Loss : 0.6989\n",
      "Epoch(0) - Fold 4 - Validation Accuracy : 0.4920\n",
      "Epoch(0) - Fold 4 - Validation Utility score : -0.0000\n",
      "Epoch(0) - GLOBAL - Validation Loss: 0.6978\n",
      "Epoch(0) - GLOBAL - Validation Accuracy: 0.4995\n",
      "Epoch(0) - GLOBAL - Validation Utility score: 47.5668\n",
      "Saving model corresponding to last_utility_score == 47.56678453336018\n",
      "\n",
      "\n",
      "Epoch(1) - Training Loss: 0.7700\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(1) - Fold 0 - Validation Loss : 0.6957\n",
      "Epoch(1) - Fold 0 - Validation Accuracy : 0.5015\n",
      "Epoch(1) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 1 - Validation Loss : 0.6952\n",
      "Epoch(1) - Fold 1 - Validation Accuracy : 0.5057\n",
      "Epoch(1) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 2 - Validation Loss : 0.6954\n",
      "Epoch(1) - Fold 2 - Validation Accuracy : 0.5011\n",
      "Epoch(1) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 3 - Validation Loss : 0.6959\n",
      "Epoch(1) - Fold 3 - Validation Accuracy : 0.5001\n",
      "Epoch(1) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 4 - Validation Loss : 0.6957\n",
      "Epoch(1) - Fold 4 - Validation Accuracy : 0.4982\n",
      "Epoch(1) - Fold 4 - Validation Utility score : 16.0228\n",
      "Epoch(1) - GLOBAL - Validation Loss: 0.6956\n",
      "Epoch(1) - GLOBAL - Validation Accuracy: 0.5013\n",
      "Epoch(1) - GLOBAL - Validation Utility score: 16.0228\n",
      "Saving model corresponding to last_utility_score == 16.022810137325965\n",
      "\n",
      "\n",
      "Epoch(2) - Training Loss: 0.7189\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(2) - Fold 0 - Validation Loss : 0.6946\n",
      "Epoch(2) - Fold 0 - Validation Accuracy : 0.5003\n",
      "Epoch(2) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 1 - Validation Loss : 0.6943\n",
      "Epoch(2) - Fold 1 - Validation Accuracy : 0.5055\n",
      "Epoch(2) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 2 - Validation Loss : 0.6944\n",
      "Epoch(2) - Fold 2 - Validation Accuracy : 0.5016\n",
      "Epoch(2) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 3 - Validation Loss : 0.6947\n",
      "Epoch(2) - Fold 3 - Validation Accuracy : 0.5001\n",
      "Epoch(2) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 4 - Validation Loss : 0.6945\n",
      "Epoch(2) - Fold 4 - Validation Accuracy : 0.4987\n",
      "Epoch(2) - Fold 4 - Validation Utility score : 20.0824\n",
      "Epoch(2) - GLOBAL - Validation Loss: 0.6945\n",
      "Epoch(2) - GLOBAL - Validation Accuracy: 0.5012\n",
      "Epoch(2) - GLOBAL - Validation Utility score: 20.0824\n",
      "Saving model corresponding to last_utility_score == 20.082395297834697\n",
      "\n",
      "\n",
      "Epoch(3) - Training Loss: 0.6995\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(3) - Fold 0 - Validation Loss : 0.6945\n",
      "Epoch(3) - Fold 0 - Validation Accuracy : 0.5002\n",
      "Epoch(3) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 1 - Validation Loss : 0.6937\n",
      "Epoch(3) - Fold 1 - Validation Accuracy : 0.5062\n",
      "Epoch(3) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 2 - Validation Loss : 0.6941\n",
      "Epoch(3) - Fold 2 - Validation Accuracy : 0.5019\n",
      "Epoch(3) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 3 - Validation Loss : 0.6942\n",
      "Epoch(3) - Fold 3 - Validation Accuracy : 0.4998\n",
      "Epoch(3) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 4 - Validation Loss : 0.6943\n",
      "Epoch(3) - Fold 4 - Validation Accuracy : 0.4989\n",
      "Epoch(3) - Fold 4 - Validation Utility score : 17.7664\n",
      "Epoch(3) - GLOBAL - Validation Loss: 0.6942\n",
      "Epoch(3) - GLOBAL - Validation Accuracy: 0.5014\n",
      "Epoch(3) - GLOBAL - Validation Utility score: 17.7664\n",
      "Saving model corresponding to last_utility_score == 17.766392499036918\n",
      "\n",
      "\n",
      "Epoch(4) - Training Loss: 0.6950\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(4) - Fold 0 - Validation Loss : 0.6937\n",
      "Epoch(4) - Fold 0 - Validation Accuracy : 0.5004\n",
      "Epoch(4) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 1 - Validation Loss : 0.6931\n",
      "Epoch(4) - Fold 1 - Validation Accuracy : 0.5065\n",
      "Epoch(4) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 2 - Validation Loss : 0.6936\n",
      "Epoch(4) - Fold 2 - Validation Accuracy : 0.5025\n",
      "Epoch(4) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 3 - Validation Loss : 0.6937\n",
      "Epoch(4) - Fold 3 - Validation Accuracy : 0.5001\n",
      "Epoch(4) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 4 - Validation Loss : 0.6938\n",
      "Epoch(4) - Fold 4 - Validation Accuracy : 0.4995\n",
      "Epoch(4) - Fold 4 - Validation Utility score : 23.3402\n",
      "Epoch(4) - GLOBAL - Validation Loss: 0.6936\n",
      "Epoch(4) - GLOBAL - Validation Accuracy: 0.5018\n",
      "Epoch(4) - GLOBAL - Validation Utility score: 23.3402\n",
      "Saving model corresponding to last_utility_score == 23.340229430884804\n",
      "\n",
      "\n",
      "Epoch(5) - Training Loss: 0.6940\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(5) - Fold 0 - Validation Loss : 0.6932\n",
      "Epoch(5) - Fold 0 - Validation Accuracy : 0.5042\n",
      "Epoch(5) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(5) - Fold 1 - Validation Accuracy : 0.5110\n",
      "Epoch(5) - Fold 1 - Validation Utility score : 8.5585\n",
      "Epoch(5) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(5) - Fold 2 - Validation Accuracy : 0.5020\n",
      "Epoch(5) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(5) - Fold 3 - Validation Accuracy : 0.5030\n",
      "Epoch(5) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 4 - Validation Loss : 0.6934\n",
      "Epoch(5) - Fold 4 - Validation Accuracy : 0.5012\n",
      "Epoch(5) - Fold 4 - Validation Utility score : 77.3893\n",
      "Epoch(5) - GLOBAL - Validation Loss: 0.6932\n",
      "Epoch(5) - GLOBAL - Validation Accuracy: 0.5043\n",
      "Epoch(5) - GLOBAL - Validation Utility score: 85.9479\n",
      "Saving model corresponding to last_utility_score == 85.94786325151338\n",
      "\n",
      "\n",
      "Epoch(6) - Training Loss: 0.6935\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(6) - Fold 0 - Validation Loss : 0.6931\n",
      "Epoch(6) - Fold 0 - Validation Accuracy : 0.5036\n",
      "Epoch(6) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(6) - Fold 1 - Validation Accuracy : 0.5094\n",
      "Epoch(6) - Fold 1 - Validation Utility score : 0.1284\n",
      "Epoch(6) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(6) - Fold 2 - Validation Accuracy : 0.5022\n",
      "Epoch(6) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(6) - Fold 3 - Validation Accuracy : 0.5031\n",
      "Epoch(6) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 4 - Validation Loss : 0.6934\n",
      "Epoch(6) - Fold 4 - Validation Accuracy : 0.5011\n",
      "Epoch(6) - Fold 4 - Validation Utility score : 65.1476\n",
      "Epoch(6) - GLOBAL - Validation Loss: 0.6932\n",
      "Epoch(6) - GLOBAL - Validation Accuracy: 0.5039\n",
      "Epoch(6) - GLOBAL - Validation Utility score: 65.2760\n",
      "Saving model corresponding to last_utility_score == 65.27597956773914\n",
      "\n",
      "\n",
      "Epoch(7) - Training Loss: 0.6935\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(7) - Fold 0 - Validation Loss : 0.6928\n",
      "Epoch(7) - Fold 0 - Validation Accuracy : 0.5100\n",
      "Epoch(7) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(7) - Fold 1 - Validation Accuracy : 0.5160\n",
      "Epoch(7) - Fold 1 - Validation Utility score : 213.1035\n",
      "Epoch(7) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(7) - Fold 2 - Validation Accuracy : 0.5031\n",
      "Epoch(7) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(7) - Fold 3 - Validation Accuracy : 0.5045\n",
      "Epoch(7) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 4 - Validation Loss : 0.6932\n",
      "Epoch(7) - Fold 4 - Validation Accuracy : 0.5039\n",
      "Epoch(7) - Fold 4 - Validation Utility score : 311.4666\n",
      "Epoch(7) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(7) - GLOBAL - Validation Accuracy: 0.5075\n",
      "Epoch(7) - GLOBAL - Validation Utility score: 524.5701\n",
      "Saving model corresponding to last_utility_score == 524.5701063135516\n",
      "\n",
      "\n",
      "Epoch(8) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(8) - Fold 0 - Validation Loss : 0.6930\n",
      "Epoch(8) - Fold 0 - Validation Accuracy : 0.5056\n",
      "Epoch(8) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 1 - Validation Loss : 0.6926\n",
      "Epoch(8) - Fold 1 - Validation Accuracy : 0.5111\n",
      "Epoch(8) - Fold 1 - Validation Utility score : 2.6848\n",
      "Epoch(8) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(8) - Fold 2 - Validation Accuracy : 0.5023\n",
      "Epoch(8) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(8) - Fold 3 - Validation Accuracy : 0.5040\n",
      "Epoch(8) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 4 - Validation Loss : 0.6933\n",
      "Epoch(8) - Fold 4 - Validation Accuracy : 0.5022\n",
      "Epoch(8) - Fold 4 - Validation Utility score : 134.7371\n",
      "Epoch(8) - GLOBAL - Validation Loss: 0.6931\n",
      "Epoch(8) - GLOBAL - Validation Accuracy: 0.5050\n",
      "Epoch(8) - GLOBAL - Validation Utility score: 137.4219\n",
      "Intermediate early stopping : vepoch_loss = 0.6931, the_last_loss=0.6930\n",
      "\n",
      "\n",
      "Epoch(9) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(9) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(9) - Fold 0 - Validation Accuracy : 0.5098\n",
      "Epoch(9) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(9) - Fold 1 - Validation Accuracy : 0.5135\n",
      "Epoch(9) - Fold 1 - Validation Utility score : 61.6596\n",
      "Epoch(9) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(9) - Fold 2 - Validation Accuracy : 0.5031\n",
      "Epoch(9) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(9) - Fold 3 - Validation Accuracy : 0.5049\n",
      "Epoch(9) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 4 - Validation Loss : 0.6932\n",
      "Epoch(9) - Fold 4 - Validation Accuracy : 0.5041\n",
      "Epoch(9) - Fold 4 - Validation Utility score : 265.6018\n",
      "Epoch(9) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(9) - GLOBAL - Validation Accuracy: 0.5071\n",
      "Epoch(9) - GLOBAL - Validation Utility score: 327.2614\n",
      "Saving model corresponding to last_utility_score == 327.26139991969404\n",
      "\n",
      "\n",
      "Epoch(10) - Training Loss: 0.6931\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(10) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(10) - Fold 0 - Validation Accuracy : 0.5113\n",
      "Epoch(10) - Fold 0 - Validation Utility score : 5.0455\n",
      "Epoch(10) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(10) - Fold 1 - Validation Accuracy : 0.5152\n",
      "Epoch(10) - Fold 1 - Validation Utility score : 96.1905\n",
      "Epoch(10) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(10) - Fold 2 - Validation Accuracy : 0.5037\n",
      "Epoch(10) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(10) - Fold 3 - Validation Accuracy : 0.5063\n",
      "Epoch(10) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 4 - Validation Loss : 0.6931\n",
      "Epoch(10) - Fold 4 - Validation Accuracy : 0.5042\n",
      "Epoch(10) - Fold 4 - Validation Utility score : 409.6075\n",
      "Epoch(10) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(10) - GLOBAL - Validation Accuracy: 0.5082\n",
      "Epoch(10) - GLOBAL - Validation Utility score: 510.8436\n",
      "Saving model corresponding to last_utility_score == 510.8436054151026\n",
      "\n",
      "\n",
      "Epoch(11) - Training Loss: 0.6930\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(11) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(11) - Fold 0 - Validation Accuracy : 0.5139\n",
      "Epoch(11) - Fold 0 - Validation Utility score : 22.2084\n",
      "Epoch(11) - Fold 1 - Validation Loss : 0.6923\n",
      "Epoch(11) - Fold 1 - Validation Accuracy : 0.5172\n",
      "Epoch(11) - Fold 1 - Validation Utility score : 152.4586\n",
      "Epoch(11) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(11) - Fold 2 - Validation Accuracy : 0.5046\n",
      "Epoch(11) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(11) - Fold 3 - Validation Accuracy : 0.5075\n",
      "Epoch(11) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(11) - Fold 4 - Validation Accuracy : 0.5053\n",
      "Epoch(11) - Fold 4 - Validation Utility score : 539.1747\n",
      "Epoch(11) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(11) - GLOBAL - Validation Accuracy: 0.5097\n",
      "Epoch(11) - GLOBAL - Validation Utility score: 713.8416\n",
      "Saving model corresponding to last_utility_score == 713.8416274491778\n",
      "\n",
      "\n",
      "Epoch(12) - Training Loss: 0.6930\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(12) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(12) - Fold 0 - Validation Accuracy : 0.5103\n",
      "Epoch(12) - Fold 0 - Validation Utility score : 0.2916\n",
      "Epoch(12) - Fold 1 - Validation Loss : 0.6923\n",
      "Epoch(12) - Fold 1 - Validation Accuracy : 0.5141\n",
      "Epoch(12) - Fold 1 - Validation Utility score : 97.8263\n",
      "Epoch(12) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(12) - Fold 2 - Validation Accuracy : 0.5047\n",
      "Epoch(12) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(12) - Fold 3 - Validation Accuracy : 0.5069\n",
      "Epoch(12) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 4 - Validation Loss : 0.6930\n",
      "Epoch(12) - Fold 4 - Validation Accuracy : 0.5050\n",
      "Epoch(12) - Fold 4 - Validation Utility score : 413.7124\n",
      "Epoch(12) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(12) - GLOBAL - Validation Accuracy: 0.5082\n",
      "Epoch(12) - GLOBAL - Validation Utility score: 511.8303\n",
      "Intermediate early stopping : vepoch_loss = 0.6928, the_last_loss=0.6928\n",
      "\n",
      "\n",
      "Epoch(13) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(13) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(13) - Fold 0 - Validation Accuracy : 0.5157\n",
      "Epoch(13) - Fold 0 - Validation Utility score : 23.0535\n",
      "Epoch(13) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(13) - Fold 1 - Validation Accuracy : 0.5199\n",
      "Epoch(13) - Fold 1 - Validation Utility score : 335.8450\n",
      "Epoch(13) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(13) - Fold 2 - Validation Accuracy : 0.5062\n",
      "Epoch(13) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(13) - Fold 3 - Validation Accuracy : 0.5085\n",
      "Epoch(13) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(13) - Fold 4 - Validation Accuracy : 0.5074\n",
      "Epoch(13) - Fold 4 - Validation Utility score : 578.6984\n",
      "Epoch(13) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(13) - GLOBAL - Validation Accuracy: 0.5115\n",
      "Epoch(13) - GLOBAL - Validation Utility score: 937.5969\n",
      "Saving model corresponding to last_utility_score == 937.5968841582269\n",
      "\n",
      "\n",
      "Epoch(14) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(14) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(14) - Fold 0 - Validation Accuracy : 0.5161\n",
      "Epoch(14) - Fold 0 - Validation Utility score : 43.6989\n",
      "Epoch(14) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(14) - Fold 1 - Validation Accuracy : 0.5212\n",
      "Epoch(14) - Fold 1 - Validation Utility score : 298.3682\n",
      "Epoch(14) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(14) - Fold 2 - Validation Accuracy : 0.5064\n",
      "Epoch(14) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(14) - Fold 3 - Validation Accuracy : 0.5079\n",
      "Epoch(14) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(14) - Fold 4 - Validation Accuracy : 0.5085\n",
      "Epoch(14) - Fold 4 - Validation Utility score : 618.3572\n",
      "Epoch(14) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(14) - GLOBAL - Validation Accuracy: 0.5120\n",
      "Epoch(14) - GLOBAL - Validation Utility score: 960.4242\n",
      "Saving model corresponding to last_utility_score == 960.4242362365164\n",
      "\n",
      "\n",
      "Epoch(15) - Training Loss: 0.6927\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(15) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(15) - Fold 0 - Validation Accuracy : 0.5217\n",
      "Epoch(15) - Fold 0 - Validation Utility score : 365.4237\n",
      "Epoch(15) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(15) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(15) - Fold 1 - Validation Utility score : 490.9316\n",
      "Epoch(15) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(15) - Fold 2 - Validation Accuracy : 0.5084\n",
      "Epoch(15) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(15) - Fold 3 - Validation Accuracy : 0.5065\n",
      "Epoch(15) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(15) - Fold 4 - Validation Accuracy : 0.5122\n",
      "Epoch(15) - Fold 4 - Validation Utility score : 876.0641\n",
      "Epoch(15) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(15) - GLOBAL - Validation Accuracy: 0.5146\n",
      "Epoch(15) - GLOBAL - Validation Utility score: 1732.4194\n",
      "Saving model corresponding to last_utility_score == 1732.419390547764\n",
      "\n",
      "\n",
      "Epoch(16) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(16) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(16) - Fold 0 - Validation Accuracy : 0.5169\n",
      "Epoch(16) - Fold 0 - Validation Utility score : 57.4884\n",
      "Epoch(16) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(16) - Fold 1 - Validation Accuracy : 0.5225\n",
      "Epoch(16) - Fold 1 - Validation Utility score : 438.0343\n",
      "Epoch(16) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(16) - Fold 2 - Validation Accuracy : 0.5079\n",
      "Epoch(16) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(16) - Fold 3 - Validation Accuracy : 0.5068\n",
      "Epoch(16) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(16) - Fold 4 - Validation Accuracy : 0.5099\n",
      "Epoch(16) - Fold 4 - Validation Utility score : 747.6914\n",
      "Epoch(16) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(16) - GLOBAL - Validation Accuracy: 0.5128\n",
      "Epoch(16) - GLOBAL - Validation Utility score: 1243.2141\n",
      "Intermediate early stopping : vepoch_loss = 0.6925, the_last_loss=0.6924\n",
      "\n",
      "\n",
      "Epoch(17) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(17) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(17) - Fold 0 - Validation Accuracy : 0.5202\n",
      "Epoch(17) - Fold 0 - Validation Utility score : 187.9294\n",
      "Epoch(17) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(17) - Fold 1 - Validation Accuracy : 0.5230\n",
      "Epoch(17) - Fold 1 - Validation Utility score : 440.6573\n",
      "Epoch(17) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(17) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(17) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(17) - Fold 3 - Validation Accuracy : 0.5071\n",
      "Epoch(17) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(17) - Fold 4 - Validation Accuracy : 0.5120\n",
      "Epoch(17) - Fold 4 - Validation Utility score : 843.1657\n",
      "Epoch(17) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(17) - GLOBAL - Validation Accuracy: 0.5141\n",
      "Epoch(17) - GLOBAL - Validation Utility score: 1471.7524\n",
      "Saving model corresponding to last_utility_score == 1471.7523748669792\n",
      "\n",
      "\n",
      "Epoch(18) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(18) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(18) - Fold 0 - Validation Accuracy : 0.5183\n",
      "Epoch(18) - Fold 0 - Validation Utility score : 90.8371\n",
      "Epoch(18) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(18) - Fold 1 - Validation Accuracy : 0.5220\n",
      "Epoch(18) - Fold 1 - Validation Utility score : 416.1095\n",
      "Epoch(18) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(18) - Fold 2 - Validation Accuracy : 0.5088\n",
      "Epoch(18) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(18) - Fold 3 - Validation Accuracy : 0.5070\n",
      "Epoch(18) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(18) - Fold 4 - Validation Accuracy : 0.5111\n",
      "Epoch(18) - Fold 4 - Validation Utility score : 793.1639\n",
      "Epoch(18) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(18) - GLOBAL - Validation Accuracy: 0.5134\n",
      "Epoch(18) - GLOBAL - Validation Utility score: 1300.1105\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6924\n",
      "\n",
      "\n",
      "Epoch(19) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(19) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(19) - Fold 0 - Validation Accuracy : 0.5226\n",
      "Epoch(19) - Fold 0 - Validation Utility score : 315.4282\n",
      "Epoch(19) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(19) - Fold 1 - Validation Accuracy : 0.5241\n",
      "Epoch(19) - Fold 1 - Validation Utility score : 496.8940\n",
      "Epoch(19) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(19) - Fold 2 - Validation Accuracy : 0.5075\n",
      "Epoch(19) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(19) - Fold 3 - Validation Accuracy : 0.5068\n",
      "Epoch(19) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(19) - Fold 4 - Validation Accuracy : 0.5120\n",
      "Epoch(19) - Fold 4 - Validation Utility score : 987.0999\n",
      "Epoch(19) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(19) - GLOBAL - Validation Accuracy: 0.5146\n",
      "Epoch(19) - GLOBAL - Validation Utility score: 1799.4221\n",
      "Saving model corresponding to last_utility_score == 1799.4220625825824\n",
      "\n",
      "\n",
      "Epoch(20) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(20) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(20) - Fold 0 - Validation Accuracy : 0.5218\n",
      "Epoch(20) - Fold 0 - Validation Utility score : 227.4359\n",
      "Epoch(20) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(20) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(20) - Fold 1 - Validation Utility score : 513.0941\n",
      "Epoch(20) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(20) - Fold 2 - Validation Accuracy : 0.5085\n",
      "Epoch(20) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(20) - Fold 3 - Validation Accuracy : 0.5065\n",
      "Epoch(20) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(20) - Fold 4 - Validation Accuracy : 0.5121\n",
      "Epoch(20) - Fold 4 - Validation Utility score : 977.2136\n",
      "Epoch(20) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(20) - GLOBAL - Validation Accuracy: 0.5146\n",
      "Epoch(20) - GLOBAL - Validation Utility score: 1717.7436\n",
      "Saving model corresponding to last_utility_score == 1717.7435993353708\n",
      "\n",
      "\n",
      "Epoch(21) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(21) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(21) - Fold 0 - Validation Accuracy : 0.5208\n",
      "Epoch(21) - Fold 0 - Validation Utility score : 197.6367\n",
      "Epoch(21) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(21) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(21) - Fold 1 - Validation Utility score : 538.7965\n",
      "Epoch(21) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(21) - Fold 2 - Validation Accuracy : 0.5090\n",
      "Epoch(21) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(21) - Fold 3 - Validation Accuracy : 0.5074\n",
      "Epoch(21) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(21) - Fold 4 - Validation Accuracy : 0.5116\n",
      "Epoch(21) - Fold 4 - Validation Utility score : 872.8291\n",
      "Epoch(21) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(21) - GLOBAL - Validation Accuracy: 0.5145\n",
      "Epoch(21) - GLOBAL - Validation Utility score: 1609.2623\n",
      "Intermediate early stopping : vepoch_loss = 0.6922, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(22) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(22) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(22) - Fold 0 - Validation Accuracy : 0.5226\n",
      "Epoch(22) - Fold 0 - Validation Utility score : 303.4764\n",
      "Epoch(22) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(22) - Fold 1 - Validation Accuracy : 0.5251\n",
      "Epoch(22) - Fold 1 - Validation Utility score : 656.2497\n",
      "Epoch(22) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(22) - Fold 2 - Validation Accuracy : 0.5085\n",
      "Epoch(22) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(22) - Fold 3 - Validation Accuracy : 0.5071\n",
      "Epoch(22) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(22) - Fold 4 - Validation Accuracy : 0.5121\n",
      "Epoch(22) - Fold 4 - Validation Utility score : 871.9393\n",
      "Epoch(22) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(22) - GLOBAL - Validation Accuracy: 0.5151\n",
      "Epoch(22) - GLOBAL - Validation Utility score: 1831.6654\n",
      "Saving model corresponding to last_utility_score == 1831.6653858022557\n",
      "\n",
      "\n",
      "Epoch(23) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(23) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(23) - Fold 0 - Validation Accuracy : 0.5191\n",
      "Epoch(23) - Fold 0 - Validation Utility score : 118.7228\n",
      "Epoch(23) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(23) - Fold 1 - Validation Accuracy : 0.5219\n",
      "Epoch(23) - Fold 1 - Validation Utility score : 448.8332\n",
      "Epoch(23) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(23) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(23) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(23) - Fold 3 - Validation Accuracy : 0.5068\n",
      "Epoch(23) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(23) - Fold 4 - Validation Accuracy : 0.5108\n",
      "Epoch(23) - Fold 4 - Validation Utility score : 748.1140\n",
      "Epoch(23) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(23) - GLOBAL - Validation Accuracy: 0.5134\n",
      "Epoch(23) - GLOBAL - Validation Utility score: 1315.6700\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(24) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(24) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(24) - Fold 0 - Validation Accuracy : 0.5190\n",
      "Epoch(24) - Fold 0 - Validation Utility score : 123.1055\n",
      "Epoch(24) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(24) - Fold 1 - Validation Accuracy : 0.5222\n",
      "Epoch(24) - Fold 1 - Validation Utility score : 477.9476\n",
      "Epoch(24) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(24) - Fold 2 - Validation Accuracy : 0.5085\n",
      "Epoch(24) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(24) - Fold 3 - Validation Accuracy : 0.5068\n",
      "Epoch(24) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(24) - Fold 4 - Validation Accuracy : 0.5107\n",
      "Epoch(24) - Fold 4 - Validation Utility score : 817.6544\n",
      "Epoch(24) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(24) - GLOBAL - Validation Accuracy: 0.5134\n",
      "Epoch(24) - GLOBAL - Validation Utility score: 1418.7075\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(25) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(25) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(25) - Fold 0 - Validation Accuracy : 0.5160\n",
      "Epoch(25) - Fold 0 - Validation Utility score : 22.5666\n",
      "Epoch(25) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(25) - Fold 1 - Validation Accuracy : 0.5198\n",
      "Epoch(25) - Fold 1 - Validation Utility score : 162.8470\n",
      "Epoch(25) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(25) - Fold 2 - Validation Accuracy : 0.5084\n",
      "Epoch(25) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(25) - Fold 3 - Validation Accuracy : 0.5057\n",
      "Epoch(25) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(25) - Fold 4 - Validation Accuracy : 0.5101\n",
      "Epoch(25) - Fold 4 - Validation Utility score : 685.9550\n",
      "Epoch(25) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(25) - GLOBAL - Validation Accuracy: 0.5120\n",
      "Epoch(25) - GLOBAL - Validation Utility score: 871.3686\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(26) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(26) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(26) - Fold 0 - Validation Accuracy : 0.5216\n",
      "Epoch(26) - Fold 0 - Validation Utility score : 198.0790\n",
      "Epoch(26) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(26) - Fold 1 - Validation Accuracy : 0.5238\n",
      "Epoch(26) - Fold 1 - Validation Utility score : 582.8223\n",
      "Epoch(26) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(26) - Fold 2 - Validation Accuracy : 0.5084\n",
      "Epoch(26) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(26) - Fold 3 - Validation Accuracy : 0.5081\n",
      "Epoch(26) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(26) - Fold 4 - Validation Accuracy : 0.5119\n",
      "Epoch(26) - Fold 4 - Validation Utility score : 886.8163\n",
      "Epoch(26) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(26) - GLOBAL - Validation Accuracy: 0.5148\n",
      "Epoch(26) - GLOBAL - Validation Utility score: 1667.7176\n",
      "Saving model corresponding to last_utility_score == 1667.7175676284255\n",
      "\n",
      "\n",
      "Epoch(27) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(27) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(27) - Fold 0 - Validation Accuracy : 0.5180\n",
      "Epoch(27) - Fold 0 - Validation Utility score : 49.4373\n",
      "Epoch(27) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(27) - Fold 1 - Validation Accuracy : 0.5210\n",
      "Epoch(27) - Fold 1 - Validation Utility score : 267.0455\n",
      "Epoch(27) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(27) - Fold 2 - Validation Accuracy : 0.5079\n",
      "Epoch(27) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(27) - Fold 3 - Validation Accuracy : 0.5061\n",
      "Epoch(27) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(27) - Fold 4 - Validation Accuracy : 0.5102\n",
      "Epoch(27) - Fold 4 - Validation Utility score : 837.8573\n",
      "Epoch(27) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(27) - GLOBAL - Validation Accuracy: 0.5126\n",
      "Epoch(27) - GLOBAL - Validation Utility score: 1154.3401\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(28) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(28) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(28) - Fold 0 - Validation Accuracy : 0.5229\n",
      "Epoch(28) - Fold 0 - Validation Utility score : 231.0407\n",
      "Epoch(28) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(28) - Fold 1 - Validation Accuracy : 0.5241\n",
      "Epoch(28) - Fold 1 - Validation Utility score : 596.4830\n",
      "Epoch(28) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(28) - Fold 2 - Validation Accuracy : 0.5081\n",
      "Epoch(28) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(28) - Fold 3 - Validation Accuracy : 0.5081\n",
      "Epoch(28) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(28) - Fold 4 - Validation Accuracy : 0.5133\n",
      "Epoch(28) - Fold 4 - Validation Utility score : 863.4113\n",
      "Epoch(28) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(28) - GLOBAL - Validation Accuracy: 0.5153\n",
      "Epoch(28) - GLOBAL - Validation Utility score: 1690.9350\n",
      "Saving model corresponding to last_utility_score == 1690.9350241954276\n",
      "\n",
      "\n",
      "Epoch(29) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(29) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(29) - Fold 0 - Validation Accuracy : 0.5238\n",
      "Epoch(29) - Fold 0 - Validation Utility score : 398.1076\n",
      "Epoch(29) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(29) - Fold 1 - Validation Accuracy : 0.5239\n",
      "Epoch(29) - Fold 1 - Validation Utility score : 737.2730\n",
      "Epoch(29) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(29) - Fold 2 - Validation Accuracy : 0.5097\n",
      "Epoch(29) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(29) - Fold 3 - Validation Accuracy : 0.5080\n",
      "Epoch(29) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(29) - Fold 4 - Validation Accuracy : 0.5147\n",
      "Epoch(29) - Fold 4 - Validation Utility score : 1088.0677\n",
      "Epoch(29) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(29) - GLOBAL - Validation Accuracy: 0.5160\n",
      "Epoch(29) - GLOBAL - Validation Utility score: 2223.4483\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(30) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(30) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(30) - Fold 0 - Validation Accuracy : 0.5223\n",
      "Epoch(30) - Fold 0 - Validation Utility score : 220.1353\n",
      "Epoch(30) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(30) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(30) - Fold 1 - Validation Utility score : 589.0160\n",
      "Epoch(30) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(30) - Fold 2 - Validation Accuracy : 0.5092\n",
      "Epoch(30) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(30) - Fold 3 - Validation Accuracy : 0.5086\n",
      "Epoch(30) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(30) - Fold 4 - Validation Accuracy : 0.5144\n",
      "Epoch(30) - Fold 4 - Validation Utility score : 852.5264\n",
      "Epoch(30) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(30) - GLOBAL - Validation Accuracy: 0.5157\n",
      "Epoch(30) - GLOBAL - Validation Utility score: 1661.6777\n",
      "Saving model corresponding to last_utility_score == 1661.6776759544343\n",
      "\n",
      "\n",
      "Epoch(31) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(31) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(31) - Fold 0 - Validation Accuracy : 0.5229\n",
      "Epoch(31) - Fold 0 - Validation Utility score : 294.5678\n",
      "Epoch(31) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(31) - Fold 1 - Validation Accuracy : 0.5229\n",
      "Epoch(31) - Fold 1 - Validation Utility score : 818.4538\n",
      "Epoch(31) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(31) - Fold 2 - Validation Accuracy : 0.5098\n",
      "Epoch(31) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(31) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(31) - Fold 3 - Validation Accuracy : 0.5090\n",
      "Epoch(31) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(31) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(31) - Fold 4 - Validation Accuracy : 0.5173\n",
      "Epoch(31) - Fold 4 - Validation Utility score : 1112.7174\n",
      "Epoch(31) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(31) - GLOBAL - Validation Accuracy: 0.5164\n",
      "Epoch(31) - GLOBAL - Validation Utility score: 2225.7390\n",
      "Saving model corresponding to last_utility_score == 2225.7390247758385\n",
      "\n",
      "\n",
      "Epoch(32) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(32) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(32) - Fold 0 - Validation Accuracy : 0.5239\n",
      "Epoch(32) - Fold 0 - Validation Utility score : 423.9678\n",
      "Epoch(32) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(32) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(32) - Fold 1 - Validation Utility score : 688.6483\n",
      "Epoch(32) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(32) - Fold 2 - Validation Accuracy : 0.5096\n",
      "Epoch(32) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(32) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(32) - Fold 3 - Validation Accuracy : 0.5083\n",
      "Epoch(32) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(32) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(32) - Fold 4 - Validation Accuracy : 0.5164\n",
      "Epoch(32) - Fold 4 - Validation Utility score : 1020.7596\n",
      "Epoch(32) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(32) - GLOBAL - Validation Accuracy: 0.5163\n",
      "Epoch(32) - GLOBAL - Validation Utility score: 2133.3758\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(33) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(33) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(33) - Fold 0 - Validation Accuracy : 0.5224\n",
      "Epoch(33) - Fold 0 - Validation Utility score : 201.4630\n",
      "Epoch(33) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(33) - Fold 1 - Validation Accuracy : 0.5231\n",
      "Epoch(33) - Fold 1 - Validation Utility score : 524.7816\n",
      "Epoch(33) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(33) - Fold 2 - Validation Accuracy : 0.5092\n",
      "Epoch(33) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(33) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(33) - Fold 3 - Validation Accuracy : 0.5080\n",
      "Epoch(33) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(33) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(33) - Fold 4 - Validation Accuracy : 0.5146\n",
      "Epoch(33) - Fold 4 - Validation Utility score : 878.3904\n",
      "Epoch(33) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(33) - GLOBAL - Validation Accuracy: 0.5155\n",
      "Epoch(33) - GLOBAL - Validation Utility score: 1604.6350\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(34) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(34) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(34) - Fold 0 - Validation Accuracy : 0.5220\n",
      "Epoch(34) - Fold 0 - Validation Utility score : 158.6661\n",
      "Epoch(34) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(34) - Fold 1 - Validation Accuracy : 0.5236\n",
      "Epoch(34) - Fold 1 - Validation Utility score : 602.7199\n",
      "Epoch(34) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(34) - Fold 2 - Validation Accuracy : 0.5106\n",
      "Epoch(34) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(34) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(34) - Fold 3 - Validation Accuracy : 0.5087\n",
      "Epoch(34) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(34) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(34) - Fold 4 - Validation Accuracy : 0.5156\n",
      "Epoch(34) - Fold 4 - Validation Utility score : 829.5751\n",
      "Epoch(34) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(34) - GLOBAL - Validation Accuracy: 0.5161\n",
      "Epoch(34) - GLOBAL - Validation Utility score: 1590.9611\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(35) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(35) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(35) - Fold 0 - Validation Accuracy : 0.5237\n",
      "Epoch(35) - Fold 0 - Validation Utility score : 319.6947\n",
      "Epoch(35) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(35) - Fold 1 - Validation Accuracy : 0.5233\n",
      "Epoch(35) - Fold 1 - Validation Utility score : 714.8535\n",
      "Epoch(35) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(35) - Fold 2 - Validation Accuracy : 0.5093\n",
      "Epoch(35) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(35) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(35) - Fold 3 - Validation Accuracy : 0.5088\n",
      "Epoch(35) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(35) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(35) - Fold 4 - Validation Accuracy : 0.5165\n",
      "Epoch(35) - Fold 4 - Validation Utility score : 998.2656\n",
      "Epoch(35) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(35) - GLOBAL - Validation Accuracy: 0.5163\n",
      "Epoch(35) - GLOBAL - Validation Utility score: 2032.8138\n",
      "Saving model corresponding to last_utility_score == 2032.8138365276207\n",
      "\n",
      "\n",
      "Epoch(36) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(36) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(36) - Fold 0 - Validation Accuracy : 0.5247\n",
      "Epoch(36) - Fold 0 - Validation Utility score : 584.7748\n",
      "Epoch(36) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(36) - Fold 1 - Validation Accuracy : 0.5219\n",
      "Epoch(36) - Fold 1 - Validation Utility score : 705.8219\n",
      "Epoch(36) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(36) - Fold 2 - Validation Accuracy : 0.5092\n",
      "Epoch(36) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(36) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(36) - Fold 3 - Validation Accuracy : 0.5102\n",
      "Epoch(36) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(36) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(36) - Fold 4 - Validation Accuracy : 0.5205\n",
      "Epoch(36) - Fold 4 - Validation Utility score : 1324.6339\n",
      "Epoch(36) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(36) - GLOBAL - Validation Accuracy: 0.5173\n",
      "Epoch(36) - GLOBAL - Validation Utility score: 2615.2306\n",
      "Saving model corresponding to last_utility_score == 2615.230564996192\n",
      "\n",
      "\n",
      "Epoch(37) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(37) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(37) - Fold 0 - Validation Accuracy : 0.5238\n",
      "Epoch(37) - Fold 0 - Validation Utility score : 299.6386\n",
      "Epoch(37) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(37) - Fold 1 - Validation Accuracy : 0.5225\n",
      "Epoch(37) - Fold 1 - Validation Utility score : 701.7236\n",
      "Epoch(37) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(37) - Fold 2 - Validation Accuracy : 0.5103\n",
      "Epoch(37) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(37) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(37) - Fold 3 - Validation Accuracy : 0.5109\n",
      "Epoch(37) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(37) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(37) - Fold 4 - Validation Accuracy : 0.5183\n",
      "Epoch(37) - Fold 4 - Validation Utility score : 1223.9463\n",
      "Epoch(37) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(37) - GLOBAL - Validation Accuracy: 0.5172\n",
      "Epoch(37) - GLOBAL - Validation Utility score: 2225.3085\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(38) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(38) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(38) - Fold 0 - Validation Accuracy : 0.5214\n",
      "Epoch(38) - Fold 0 - Validation Utility score : 141.9420\n",
      "Epoch(38) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(38) - Fold 1 - Validation Accuracy : 0.5221\n",
      "Epoch(38) - Fold 1 - Validation Utility score : 474.1122\n",
      "Epoch(38) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(38) - Fold 2 - Validation Accuracy : 0.5119\n",
      "Epoch(38) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(38) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(38) - Fold 3 - Validation Accuracy : 0.5080\n",
      "Epoch(38) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(38) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(38) - Fold 4 - Validation Accuracy : 0.5163\n",
      "Epoch(38) - Fold 4 - Validation Utility score : 1049.1602\n",
      "Epoch(38) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(38) - GLOBAL - Validation Accuracy: 0.5160\n",
      "Epoch(38) - GLOBAL - Validation Utility score: 1665.2144\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(39) - Training Loss: 0.6915\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(39) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(39) - Fold 0 - Validation Accuracy : 0.5240\n",
      "Epoch(39) - Fold 0 - Validation Utility score : 270.6659\n",
      "Epoch(39) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(39) - Fold 1 - Validation Accuracy : 0.5228\n",
      "Epoch(39) - Fold 1 - Validation Utility score : 614.0345\n",
      "Epoch(39) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(39) - Fold 2 - Validation Accuracy : 0.5103\n",
      "Epoch(39) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(39) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(39) - Fold 3 - Validation Accuracy : 0.5094\n",
      "Epoch(39) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(39) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(39) - Fold 4 - Validation Accuracy : 0.5194\n",
      "Epoch(39) - Fold 4 - Validation Utility score : 1114.5230\n",
      "Epoch(39) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(39) - GLOBAL - Validation Accuracy: 0.5172\n",
      "Epoch(39) - GLOBAL - Validation Utility score: 1999.2233\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(40) - Training Loss: 0.6915\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(40) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(40) - Fold 0 - Validation Accuracy : 0.5217\n",
      "Epoch(40) - Fold 0 - Validation Utility score : 214.9297\n",
      "Epoch(40) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(40) - Fold 1 - Validation Accuracy : 0.5218\n",
      "Epoch(40) - Fold 1 - Validation Utility score : 512.0020\n",
      "Epoch(40) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(40) - Fold 2 - Validation Accuracy : 0.5109\n",
      "Epoch(40) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(40) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(40) - Fold 3 - Validation Accuracy : 0.5089\n",
      "Epoch(40) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(40) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(40) - Fold 4 - Validation Accuracy : 0.5169\n",
      "Epoch(40) - Fold 4 - Validation Utility score : 991.3544\n",
      "Epoch(40) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(40) - GLOBAL - Validation Accuracy: 0.5160\n",
      "Epoch(40) - GLOBAL - Validation Utility score: 1718.2862\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(41) - Training Loss: 0.6915\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(41) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(41) - Fold 0 - Validation Accuracy : 0.5225\n",
      "Epoch(41) - Fold 0 - Validation Utility score : 222.3490\n",
      "Epoch(41) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(41) - Fold 1 - Validation Accuracy : 0.5214\n",
      "Epoch(41) - Fold 1 - Validation Utility score : 499.4284\n",
      "Epoch(41) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(41) - Fold 2 - Validation Accuracy : 0.5114\n",
      "Epoch(41) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(41) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(41) - Fold 3 - Validation Accuracy : 0.5085\n",
      "Epoch(41) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(41) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(41) - Fold 4 - Validation Accuracy : 0.5178\n",
      "Epoch(41) - Fold 4 - Validation Utility score : 1014.1165\n",
      "Epoch(41) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(41) - GLOBAL - Validation Accuracy: 0.5163\n",
      "Epoch(41) - GLOBAL - Validation Utility score: 1735.8939\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "Meet Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 508741<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_055255-dl5rk074/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_055255-dl5rk074/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>0.69147</td></tr><tr><td>Global valid/Loss</td><td>0.69202</td></tr><tr><td>Global valid/Accuracy</td><td>0.51633</td></tr><tr><td>Global valid/Utility</td><td>1735.89388</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>0.6917</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>0.52249</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>222.34898</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>0.69132</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>0.52137</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>499.42836</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>0.69271</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>0.51141</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>0.69283</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>0.50851</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>0.69153</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>0.51785</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>1014.11654</td></tr><tr><td>Best accuracy</td><td>0.51732</td></tr><tr><td>Best utility</td><td>2615.23056</td></tr><tr><td>_runtime</td><td>2264</td></tr><tr><td>_timestamp</td><td>1613453439</td></tr><tr><td>_step</td><td>41</td></tr><tr><td>Final utility score</td><td>{'utility_score': 26...</td></tr><tr><td>Batch size</td><td>46919</td></tr><tr><td>Patience</td><td>5</td></tr><tr><td>Number of epochs</td><td>1000</td></tr><tr><td>Best epoch</td><td>36</td></tr><tr><td>Number of parameters per layer</td><td>[8384, 64, 2048, 32,...</td></tr><tr><td>Model architecture</td><td>MLP(<BR>  (AEncoder)...</td></tr><tr><td>comment</td><td>All folds MLP with a...</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Loss</td><td>█▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Accuracy</td><td>▁▂▂▂▂▃▃▄▃▄▄▅▄▆▆▇▆▇▆▇▇▇▆▆▆▇▆▇▇▇██▇████▇██</td></tr><tr><td>Global valid/Utility</td><td>▁▁▁▁▁▁▁▂▁▂▂▃▂▃▄▆▄▅▄▆▅▆▅▅▃▅▄▆▇▅▇▇▅▅▆█▇▅▆▆</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>█▅▄▄▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>▃▁▁▁▁▂▂▄▃▄▄▅▄▅▆▇▆▇▆▇▇▇▆▆▆▇▆▇█▇▇█▇▇███▇█▇</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▅▂▃▂▅▃▅▂▂▁▃▂▄▆▄▅▆▃▃▅█▅▃▄▄</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>█▆▅▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>▁▂▂▃▃▄▃▅▄▅▅▆▅▆▇█▇▇▇███▇▇▆█▇███▇▇▇█▇▇▇▇▇▇</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>▁▁▁▁▁▁▁▃▁▂▂▂▂▄▄▅▅▅▅▅▆▇▅▅▂▆▃▆▇▆█▇▅▆▇▇▇▅▆▅</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>█▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>▁▃▃▃▄▄▄▄▄▄▄▅▅▅▆▆▆▆▇▆▇▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇█</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>█▆▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>▂▁▁▁▁▃▃▄▄▄▅▆▅▆▆▅▅▆▆▅▆▆▅▅▅▆▅▆▆▇▇▆▆▇▇██▆▇▆</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>█▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>▁▃▃▃▃▃▃▄▄▄▄▄▄▅▅▆▅▆▆▆▆▆▆▆▅▆▅▆▇▇▇▇▇▇▇█▇▇█▇</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>▁▁▁▁▁▁▁▃▂▂▃▄▃▄▄▆▅▅▅▆▆▆▅▅▅▆▅▆▇▆▇▆▆▅▆█▇▇▇▆</td></tr><tr><td>Best accuracy</td><td>▁▂▂▂▂▃▃▄▄▄▅▆▆▇▇▇▇▇▇▇▇████</td></tr><tr><td>Best utility</td><td>▁▁▁▁▁▁▁▂▂▂▃▃▄▆▅▆▆▆▅▆▅▇▆██</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 211 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">youthful-sweep-4</strong>: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/dl5rk074\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/dl5rk074</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training summary:\n",
      "{'utility_score': 2615.230564996192, 'utility_scores': [584.7747666395074, 705.821897625919, -0.0, -0.0, 1324.6339007307656], 'utility_score_std': 495.36145756683317, 'accuracy_scores': [0.5247126192399825, 0.521944541944542, 0.5091829098324077, 0.5102495919860431, 0.5204958444851387]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dy23qx9k with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leakyrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64483\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3833652301206686\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0015275092015745464\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_autoenc: encoder\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 3.6084674193816716e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">sleek-sweep-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/dy23qx9k\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/dy23qx9k</a><br/>\n",
       "                Run data is saved locally in <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_063044-dy23qx9k</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Run config :\n",
      "config: {'activation_function': 'leakyrelu', 'batch_size': 64483, 'dropout': 0.3833652301206686, 'learning_rate': 0.0015275092015745464, 'use_autoenc': 'encoder', 'weight_decay': 3.6084674193816716e-05, 'epochs': 1000}\n",
      "Epoch(0) - Training Loss: 0.7521\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(0) - Fold 0 - Validation Loss : 0.6942\n",
      "Epoch(0) - Fold 0 - Validation Accuracy : 0.5115\n",
      "Epoch(0) - Fold 0 - Validation Utility score : 50.6577\n",
      "Epoch(0) - Fold 1 - Validation Loss : 0.6938\n",
      "Epoch(0) - Fold 1 - Validation Accuracy : 0.5058\n",
      "Epoch(0) - Fold 1 - Validation Utility score : 182.1006\n",
      "Epoch(0) - Fold 2 - Validation Loss : 0.6957\n",
      "Epoch(0) - Fold 2 - Validation Accuracy : 0.5002\n",
      "Epoch(0) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 3 - Validation Loss : 0.6952\n",
      "Epoch(0) - Fold 3 - Validation Accuracy : 0.5007\n",
      "Epoch(0) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 4 - Validation Loss : 0.6948\n",
      "Epoch(0) - Fold 4 - Validation Accuracy : 0.5003\n",
      "Epoch(0) - Fold 4 - Validation Utility score : 94.5546\n",
      "Epoch(0) - GLOBAL - Validation Loss: 0.6948\n",
      "Epoch(0) - GLOBAL - Validation Accuracy: 0.5037\n",
      "Epoch(0) - GLOBAL - Validation Utility score: 327.3130\n",
      "Saving model corresponding to last_utility_score == 327.3129633553403\n",
      "\n",
      "\n",
      "Epoch(1) - Training Loss: 0.7200\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(1) - Fold 0 - Validation Loss : 0.6932\n",
      "Epoch(1) - Fold 0 - Validation Accuracy : 0.5119\n",
      "Epoch(1) - Fold 0 - Validation Utility score : 15.0773\n",
      "Epoch(1) - Fold 1 - Validation Loss : 0.6932\n",
      "Epoch(1) - Fold 1 - Validation Accuracy : 0.5087\n",
      "Epoch(1) - Fold 1 - Validation Utility score : 502.5590\n",
      "Epoch(1) - Fold 2 - Validation Loss : 0.6943\n",
      "Epoch(1) - Fold 2 - Validation Accuracy : 0.5057\n",
      "Epoch(1) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 3 - Validation Loss : 0.6940\n",
      "Epoch(1) - Fold 3 - Validation Accuracy : 0.5027\n",
      "Epoch(1) - Fold 3 - Validation Utility score : 11.8324\n",
      "Epoch(1) - Fold 4 - Validation Loss : 0.6933\n",
      "Epoch(1) - Fold 4 - Validation Accuracy : 0.5076\n",
      "Epoch(1) - Fold 4 - Validation Utility score : 229.3775\n",
      "Epoch(1) - GLOBAL - Validation Loss: 0.6936\n",
      "Epoch(1) - GLOBAL - Validation Accuracy: 0.5073\n",
      "Epoch(1) - GLOBAL - Validation Utility score: 758.8462\n",
      "Saving model corresponding to last_utility_score == 758.8461709964324\n",
      "\n",
      "\n",
      "Epoch(2) - Training Loss: 0.7021\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(2) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(2) - Fold 0 - Validation Accuracy : 0.5122\n",
      "Epoch(2) - Fold 0 - Validation Utility score : 36.2160\n",
      "Epoch(2) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(2) - Fold 1 - Validation Accuracy : 0.5098\n",
      "Epoch(2) - Fold 1 - Validation Utility score : 636.0283\n",
      "Epoch(2) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(2) - Fold 2 - Validation Accuracy : 0.5060\n",
      "Epoch(2) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(2) - Fold 3 - Validation Accuracy : 0.5063\n",
      "Epoch(2) - Fold 3 - Validation Utility score : 48.9066\n",
      "Epoch(2) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(2) - Fold 4 - Validation Accuracy : 0.5121\n",
      "Epoch(2) - Fold 4 - Validation Utility score : 684.5078\n",
      "Epoch(2) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(2) - GLOBAL - Validation Accuracy: 0.5093\n",
      "Epoch(2) - GLOBAL - Validation Utility score: 1405.6587\n",
      "Saving model corresponding to last_utility_score == 1405.6586978606433\n",
      "\n",
      "\n",
      "Epoch(3) - Training Loss: 0.6963\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(3) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(3) - Fold 0 - Validation Accuracy : 0.5129\n",
      "Epoch(3) - Fold 0 - Validation Utility score : 134.4582\n",
      "Epoch(3) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(3) - Fold 1 - Validation Accuracy : 0.5106\n",
      "Epoch(3) - Fold 1 - Validation Utility score : 307.9631\n",
      "Epoch(3) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(3) - Fold 2 - Validation Accuracy : 0.5056\n",
      "Epoch(3) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(3) - Fold 3 - Validation Accuracy : 0.5065\n",
      "Epoch(3) - Fold 3 - Validation Utility score : 8.1880\n",
      "Epoch(3) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(3) - Fold 4 - Validation Accuracy : 0.5116\n",
      "Epoch(3) - Fold 4 - Validation Utility score : 475.5412\n",
      "Epoch(3) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(3) - GLOBAL - Validation Accuracy: 0.5094\n",
      "Epoch(3) - GLOBAL - Validation Utility score: 926.1504\n",
      "Saving model corresponding to last_utility_score == 926.150391028978\n",
      "\n",
      "\n",
      "Epoch(4) - Training Loss: 0.6939\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(4) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(4) - Fold 0 - Validation Accuracy : 0.5177\n",
      "Epoch(4) - Fold 0 - Validation Utility score : 492.8981\n",
      "Epoch(4) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(4) - Fold 1 - Validation Accuracy : 0.5115\n",
      "Epoch(4) - Fold 1 - Validation Utility score : 469.1901\n",
      "Epoch(4) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(4) - Fold 2 - Validation Accuracy : 0.5056\n",
      "Epoch(4) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(4) - Fold 3 - Validation Accuracy : 0.5047\n",
      "Epoch(4) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(4) - Fold 4 - Validation Accuracy : 0.5129\n",
      "Epoch(4) - Fold 4 - Validation Utility score : 847.0272\n",
      "Epoch(4) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(4) - GLOBAL - Validation Accuracy: 0.5105\n",
      "Epoch(4) - GLOBAL - Validation Utility score: 1809.1153\n",
      "Intermediate early stopping : vepoch_loss = 0.6927, the_last_loss=0.6927\n",
      "\n",
      "\n",
      "Epoch(5) - Training Loss: 0.6931\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(5) - Fold 0 - Validation Loss : 0.6924\n",
      "Epoch(5) - Fold 0 - Validation Accuracy : 0.5217\n",
      "Epoch(5) - Fold 0 - Validation Utility score : 536.7154\n",
      "Epoch(5) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(5) - Fold 1 - Validation Accuracy : 0.5150\n",
      "Epoch(5) - Fold 1 - Validation Utility score : 497.4324\n",
      "Epoch(5) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(5) - Fold 2 - Validation Accuracy : 0.5064\n",
      "Epoch(5) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(5) - Fold 3 - Validation Accuracy : 0.5051\n",
      "Epoch(5) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(5) - Fold 4 - Validation Accuracy : 0.5167\n",
      "Epoch(5) - Fold 4 - Validation Utility score : 1066.0738\n",
      "Epoch(5) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(5) - GLOBAL - Validation Accuracy: 0.5130\n",
      "Epoch(5) - GLOBAL - Validation Utility score: 2100.2215\n",
      "Saving model corresponding to last_utility_score == 2100.221536901743\n",
      "\n",
      "\n",
      "Epoch(6) - Training Loss: 0.6927\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(6) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(6) - Fold 0 - Validation Accuracy : 0.5220\n",
      "Epoch(6) - Fold 0 - Validation Utility score : 515.6878\n",
      "Epoch(6) - Fold 1 - Validation Loss : 0.6926\n",
      "Epoch(6) - Fold 1 - Validation Accuracy : 0.5179\n",
      "Epoch(6) - Fold 1 - Validation Utility score : 730.4349\n",
      "Epoch(6) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(6) - Fold 2 - Validation Accuracy : 0.5057\n",
      "Epoch(6) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(6) - Fold 3 - Validation Accuracy : 0.5083\n",
      "Epoch(6) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(6) - Fold 4 - Validation Accuracy : 0.5196\n",
      "Epoch(6) - Fold 4 - Validation Utility score : 1184.8748\n",
      "Epoch(6) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(6) - GLOBAL - Validation Accuracy: 0.5147\n",
      "Epoch(6) - GLOBAL - Validation Utility score: 2430.9976\n",
      "Saving model corresponding to last_utility_score == 2430.9975519048357\n",
      "\n",
      "\n",
      "Epoch(7) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(7) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(7) - Fold 0 - Validation Accuracy : 0.5233\n",
      "Epoch(7) - Fold 0 - Validation Utility score : 602.9056\n",
      "Epoch(7) - Fold 1 - Validation Loss : 0.6923\n",
      "Epoch(7) - Fold 1 - Validation Accuracy : 0.5207\n",
      "Epoch(7) - Fold 1 - Validation Utility score : 893.0388\n",
      "Epoch(7) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(7) - Fold 2 - Validation Accuracy : 0.5076\n",
      "Epoch(7) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(7) - Fold 3 - Validation Accuracy : 0.5113\n",
      "Epoch(7) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(7) - Fold 4 - Validation Accuracy : 0.5213\n",
      "Epoch(7) - Fold 4 - Validation Utility score : 1347.7601\n",
      "Epoch(7) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(7) - GLOBAL - Validation Accuracy: 0.5168\n",
      "Epoch(7) - GLOBAL - Validation Utility score: 2843.7045\n",
      "Saving model corresponding to last_utility_score == 2843.7044649107156\n",
      "\n",
      "\n",
      "Epoch(8) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(8) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(8) - Fold 0 - Validation Accuracy : 0.5245\n",
      "Epoch(8) - Fold 0 - Validation Utility score : 511.8517\n",
      "Epoch(8) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(8) - Fold 1 - Validation Accuracy : 0.5214\n",
      "Epoch(8) - Fold 1 - Validation Utility score : 908.2698\n",
      "Epoch(8) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(8) - Fold 2 - Validation Accuracy : 0.5076\n",
      "Epoch(8) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(8) - Fold 3 - Validation Accuracy : 0.5115\n",
      "Epoch(8) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(8) - Fold 4 - Validation Accuracy : 0.5215\n",
      "Epoch(8) - Fold 4 - Validation Utility score : 1479.5403\n",
      "Epoch(8) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(8) - GLOBAL - Validation Accuracy: 0.5173\n",
      "Epoch(8) - GLOBAL - Validation Utility score: 2899.6619\n",
      "Saving model corresponding to last_utility_score == 2899.661857339599\n",
      "\n",
      "\n",
      "Epoch(9) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(9) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(9) - Fold 0 - Validation Accuracy : 0.5239\n",
      "Epoch(9) - Fold 0 - Validation Utility score : 521.4088\n",
      "Epoch(9) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(9) - Fold 1 - Validation Accuracy : 0.5226\n",
      "Epoch(9) - Fold 1 - Validation Utility score : 1050.8404\n",
      "Epoch(9) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(9) - Fold 2 - Validation Accuracy : 0.5071\n",
      "Epoch(9) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(9) - Fold 3 - Validation Accuracy : 0.5113\n",
      "Epoch(9) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(9) - Fold 4 - Validation Accuracy : 0.5229\n",
      "Epoch(9) - Fold 4 - Validation Utility score : 1464.3943\n",
      "Epoch(9) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(9) - GLOBAL - Validation Accuracy: 0.5176\n",
      "Epoch(9) - GLOBAL - Validation Utility score: 3036.6435\n",
      "Saving model corresponding to last_utility_score == 3036.643525269974\n",
      "\n",
      "\n",
      "Epoch(10) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(10) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(10) - Fold 0 - Validation Accuracy : 0.5243\n",
      "Epoch(10) - Fold 0 - Validation Utility score : 534.4395\n",
      "Epoch(10) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(10) - Fold 1 - Validation Accuracy : 0.5226\n",
      "Epoch(10) - Fold 1 - Validation Utility score : 1100.8326\n",
      "Epoch(10) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(10) - Fold 2 - Validation Accuracy : 0.5073\n",
      "Epoch(10) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 3 - Validation Loss : 0.6926\n",
      "Epoch(10) - Fold 3 - Validation Accuracy : 0.5111\n",
      "Epoch(10) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(10) - Fold 4 - Validation Accuracy : 0.5228\n",
      "Epoch(10) - Fold 4 - Validation Utility score : 1373.1957\n",
      "Epoch(10) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(10) - GLOBAL - Validation Accuracy: 0.5176\n",
      "Epoch(10) - GLOBAL - Validation Utility score: 3008.4678\n",
      "Saving model corresponding to last_utility_score == 3008.467795059754\n",
      "\n",
      "\n",
      "Epoch(11) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(11) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(11) - Fold 0 - Validation Accuracy : 0.5240\n",
      "Epoch(11) - Fold 0 - Validation Utility score : 417.4469\n",
      "Epoch(11) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(11) - Fold 1 - Validation Accuracy : 0.5237\n",
      "Epoch(11) - Fold 1 - Validation Utility score : 1057.4585\n",
      "Epoch(11) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(11) - Fold 2 - Validation Accuracy : 0.5089\n",
      "Epoch(11) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 3 - Validation Loss : 0.6926\n",
      "Epoch(11) - Fold 3 - Validation Accuracy : 0.5138\n",
      "Epoch(11) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(11) - Fold 4 - Validation Accuracy : 0.5233\n",
      "Epoch(11) - Fold 4 - Validation Utility score : 1353.1125\n",
      "Epoch(11) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(11) - GLOBAL - Validation Accuracy: 0.5187\n",
      "Epoch(11) - GLOBAL - Validation Utility score: 2828.0179\n",
      "Saving model corresponding to last_utility_score == 2828.0179394524484\n",
      "\n",
      "\n",
      "Epoch(12) - Training Loss: 0.6915\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(12) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(12) - Fold 0 - Validation Accuracy : 0.5242\n",
      "Epoch(12) - Fold 0 - Validation Utility score : 472.9938\n",
      "Epoch(12) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(12) - Fold 1 - Validation Accuracy : 0.5226\n",
      "Epoch(12) - Fold 1 - Validation Utility score : 976.7765\n",
      "Epoch(12) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(12) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(12) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(12) - Fold 3 - Validation Accuracy : 0.5135\n",
      "Epoch(12) - Fold 3 - Validation Utility score : 3.2124\n",
      "Epoch(12) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(12) - Fold 4 - Validation Accuracy : 0.5240\n",
      "Epoch(12) - Fold 4 - Validation Utility score : 1310.4096\n",
      "Epoch(12) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(12) - GLOBAL - Validation Accuracy: 0.5185\n",
      "Epoch(12) - GLOBAL - Validation Utility score: 2763.3923\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(13) - Training Loss: 0.6913\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(13) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(13) - Fold 0 - Validation Accuracy : 0.5235\n",
      "Epoch(13) - Fold 0 - Validation Utility score : 393.3742\n",
      "Epoch(13) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(13) - Fold 1 - Validation Accuracy : 0.5226\n",
      "Epoch(13) - Fold 1 - Validation Utility score : 1057.8136\n",
      "Epoch(13) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(13) - Fold 2 - Validation Accuracy : 0.5074\n",
      "Epoch(13) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 3 - Validation Loss : 0.6926\n",
      "Epoch(13) - Fold 3 - Validation Accuracy : 0.5121\n",
      "Epoch(13) - Fold 3 - Validation Utility score : 0.0014\n",
      "Epoch(13) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(13) - Fold 4 - Validation Accuracy : 0.5246\n",
      "Epoch(13) - Fold 4 - Validation Utility score : 1275.8214\n",
      "Epoch(13) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(13) - GLOBAL - Validation Accuracy: 0.5180\n",
      "Epoch(13) - GLOBAL - Validation Utility score: 2727.0106\n",
      "Saving model corresponding to last_utility_score == 2727.0105701438906\n",
      "\n",
      "\n",
      "Epoch(14) - Training Loss: 0.6912\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(14) - Fold 0 - Validation Loss : 0.6912\n",
      "Epoch(14) - Fold 0 - Validation Accuracy : 0.5225\n",
      "Epoch(14) - Fold 0 - Validation Utility score : 398.7505\n",
      "Epoch(14) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(14) - Fold 1 - Validation Accuracy : 0.5227\n",
      "Epoch(14) - Fold 1 - Validation Utility score : 1062.3950\n",
      "Epoch(14) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(14) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(14) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 3 - Validation Loss : 0.6926\n",
      "Epoch(14) - Fold 3 - Validation Accuracy : 0.5131\n",
      "Epoch(14) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 4 - Validation Loss : 0.6912\n",
      "Epoch(14) - Fold 4 - Validation Accuracy : 0.5252\n",
      "Epoch(14) - Fold 4 - Validation Utility score : 1257.2555\n",
      "Epoch(14) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(14) - GLOBAL - Validation Accuracy: 0.5183\n",
      "Epoch(14) - GLOBAL - Validation Utility score: 2718.4010\n",
      "Saving model corresponding to last_utility_score == 2718.401045019632\n",
      "\n",
      "\n",
      "Epoch(15) - Training Loss: 0.6910\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(15) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(15) - Fold 0 - Validation Accuracy : 0.5218\n",
      "Epoch(15) - Fold 0 - Validation Utility score : 379.9577\n",
      "Epoch(15) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(15) - Fold 1 - Validation Accuracy : 0.5223\n",
      "Epoch(15) - Fold 1 - Validation Utility score : 1033.6668\n",
      "Epoch(15) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(15) - Fold 2 - Validation Accuracy : 0.5084\n",
      "Epoch(15) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(15) - Fold 3 - Validation Accuracy : 0.5123\n",
      "Epoch(15) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 4 - Validation Loss : 0.6911\n",
      "Epoch(15) - Fold 4 - Validation Accuracy : 0.5248\n",
      "Epoch(15) - Fold 4 - Validation Utility score : 1250.1735\n",
      "Epoch(15) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(15) - GLOBAL - Validation Accuracy: 0.5179\n",
      "Epoch(15) - GLOBAL - Validation Utility score: 2663.7981\n",
      "Saving model corresponding to last_utility_score == 2663.798052592544\n",
      "\n",
      "\n",
      "Epoch(16) - Training Loss: 0.6908\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(16) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(16) - Fold 0 - Validation Accuracy : 0.5207\n",
      "Epoch(16) - Fold 0 - Validation Utility score : 260.9877\n",
      "Epoch(16) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(16) - Fold 1 - Validation Accuracy : 0.5224\n",
      "Epoch(16) - Fold 1 - Validation Utility score : 1048.4522\n",
      "Epoch(16) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(16) - Fold 2 - Validation Accuracy : 0.5079\n",
      "Epoch(16) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(16) - Fold 3 - Validation Accuracy : 0.5116\n",
      "Epoch(16) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 4 - Validation Loss : 0.6910\n",
      "Epoch(16) - Fold 4 - Validation Accuracy : 0.5237\n",
      "Epoch(16) - Fold 4 - Validation Utility score : 1244.9685\n",
      "Epoch(16) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(16) - GLOBAL - Validation Accuracy: 0.5173\n",
      "Epoch(16) - GLOBAL - Validation Utility score: 2554.4084\n",
      "Saving model corresponding to last_utility_score == 2554.4083909909587\n",
      "\n",
      "\n",
      "Epoch(17) - Training Loss: 0.6908\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(17) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(17) - Fold 0 - Validation Accuracy : 0.5224\n",
      "Epoch(17) - Fold 0 - Validation Utility score : 355.9991\n",
      "Epoch(17) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(17) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(17) - Fold 1 - Validation Utility score : 1052.1754\n",
      "Epoch(17) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(17) - Fold 2 - Validation Accuracy : 0.5100\n",
      "Epoch(17) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(17) - Fold 3 - Validation Accuracy : 0.5136\n",
      "Epoch(17) - Fold 3 - Validation Utility score : 0.6947\n",
      "Epoch(17) - Fold 4 - Validation Loss : 0.6909\n",
      "Epoch(17) - Fold 4 - Validation Accuracy : 0.5242\n",
      "Epoch(17) - Fold 4 - Validation Utility score : 1368.8807\n",
      "Epoch(17) - GLOBAL - Validation Loss: 0.6918\n",
      "Epoch(17) - GLOBAL - Validation Accuracy: 0.5187\n",
      "Epoch(17) - GLOBAL - Validation Utility score: 2777.7498\n",
      "Saving model corresponding to last_utility_score == 2777.749835745154\n",
      "\n",
      "\n",
      "Epoch(18) - Training Loss: 0.6906\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(18) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(18) - Fold 0 - Validation Accuracy : 0.5220\n",
      "Epoch(18) - Fold 0 - Validation Utility score : 363.5052\n",
      "Epoch(18) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(18) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(18) - Fold 1 - Validation Utility score : 988.2418\n",
      "Epoch(18) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(18) - Fold 2 - Validation Accuracy : 0.5101\n",
      "Epoch(18) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(18) - Fold 3 - Validation Accuracy : 0.5118\n",
      "Epoch(18) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 4 - Validation Loss : 0.6908\n",
      "Epoch(18) - Fold 4 - Validation Accuracy : 0.5256\n",
      "Epoch(18) - Fold 4 - Validation Utility score : 1361.6227\n",
      "Epoch(18) - GLOBAL - Validation Loss: 0.6918\n",
      "Epoch(18) - GLOBAL - Validation Accuracy: 0.5186\n",
      "Epoch(18) - GLOBAL - Validation Utility score: 2713.3697\n",
      "Saving model corresponding to last_utility_score == 2713.369744219427\n",
      "\n",
      "\n",
      "Epoch(19) - Training Loss: 0.6905\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(19) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(19) - Fold 0 - Validation Accuracy : 0.5205\n",
      "Epoch(19) - Fold 0 - Validation Utility score : 250.7021\n",
      "Epoch(19) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(19) - Fold 1 - Validation Accuracy : 0.5218\n",
      "Epoch(19) - Fold 1 - Validation Utility score : 926.0852\n",
      "Epoch(19) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(19) - Fold 2 - Validation Accuracy : 0.5102\n",
      "Epoch(19) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(19) - Fold 3 - Validation Accuracy : 0.5099\n",
      "Epoch(19) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 4 - Validation Loss : 0.6908\n",
      "Epoch(19) - Fold 4 - Validation Accuracy : 0.5246\n",
      "Epoch(19) - Fold 4 - Validation Utility score : 1282.8409\n",
      "Epoch(19) - GLOBAL - Validation Loss: 0.6918\n",
      "Epoch(19) - GLOBAL - Validation Accuracy: 0.5174\n",
      "Epoch(19) - GLOBAL - Validation Utility score: 2459.6281\n",
      "Saving model corresponding to last_utility_score == 2459.6281194328785\n",
      "\n",
      "\n",
      "Epoch(20) - Training Loss: 0.6903\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(20) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(20) - Fold 0 - Validation Accuracy : 0.5203\n",
      "Epoch(20) - Fold 0 - Validation Utility score : 259.8672\n",
      "Epoch(20) - Fold 1 - Validation Loss : 0.6908\n",
      "Epoch(20) - Fold 1 - Validation Accuracy : 0.5218\n",
      "Epoch(20) - Fold 1 - Validation Utility score : 936.2349\n",
      "Epoch(20) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(20) - Fold 2 - Validation Accuracy : 0.5100\n",
      "Epoch(20) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(20) - Fold 3 - Validation Accuracy : 0.5111\n",
      "Epoch(20) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 4 - Validation Loss : 0.6907\n",
      "Epoch(20) - Fold 4 - Validation Accuracy : 0.5244\n",
      "Epoch(20) - Fold 4 - Validation Utility score : 1310.4680\n",
      "Epoch(20) - GLOBAL - Validation Loss: 0.6918\n",
      "Epoch(20) - GLOBAL - Validation Accuracy: 0.5175\n",
      "Epoch(20) - GLOBAL - Validation Utility score: 2506.5701\n",
      "Intermediate early stopping : vepoch_loss = 0.6918, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(21) - Training Loss: 0.6901\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(21) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(21) - Fold 0 - Validation Accuracy : 0.5216\n",
      "Epoch(21) - Fold 0 - Validation Utility score : 281.8406\n",
      "Epoch(21) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(21) - Fold 1 - Validation Accuracy : 0.5220\n",
      "Epoch(21) - Fold 1 - Validation Utility score : 901.4540\n",
      "Epoch(21) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(21) - Fold 2 - Validation Accuracy : 0.5093\n",
      "Epoch(21) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(21) - Fold 3 - Validation Accuracy : 0.5089\n",
      "Epoch(21) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 4 - Validation Loss : 0.6909\n",
      "Epoch(21) - Fold 4 - Validation Accuracy : 0.5246\n",
      "Epoch(21) - Fold 4 - Validation Utility score : 1299.0754\n",
      "Epoch(21) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(21) - GLOBAL - Validation Accuracy: 0.5173\n",
      "Epoch(21) - GLOBAL - Validation Utility score: 2482.3701\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(22) - Training Loss: 0.6900\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(22) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(22) - Fold 0 - Validation Accuracy : 0.5219\n",
      "Epoch(22) - Fold 0 - Validation Utility score : 302.5240\n",
      "Epoch(22) - Fold 1 - Validation Loss : 0.6908\n",
      "Epoch(22) - Fold 1 - Validation Accuracy : 0.5223\n",
      "Epoch(22) - Fold 1 - Validation Utility score : 927.0214\n",
      "Epoch(22) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(22) - Fold 2 - Validation Accuracy : 0.5094\n",
      "Epoch(22) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(22) - Fold 3 - Validation Accuracy : 0.5093\n",
      "Epoch(22) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 4 - Validation Loss : 0.6907\n",
      "Epoch(22) - Fold 4 - Validation Accuracy : 0.5250\n",
      "Epoch(22) - Fold 4 - Validation Utility score : 1299.0794\n",
      "Epoch(22) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(22) - GLOBAL - Validation Accuracy: 0.5176\n",
      "Epoch(22) - GLOBAL - Validation Utility score: 2528.6248\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(23) - Training Loss: 0.6898\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(23) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(23) - Fold 0 - Validation Accuracy : 0.5215\n",
      "Epoch(23) - Fold 0 - Validation Utility score : 205.0144\n",
      "Epoch(23) - Fold 1 - Validation Loss : 0.6909\n",
      "Epoch(23) - Fold 1 - Validation Accuracy : 0.5225\n",
      "Epoch(23) - Fold 1 - Validation Utility score : 881.7139\n",
      "Epoch(23) - Fold 2 - Validation Loss : 0.6934\n",
      "Epoch(23) - Fold 2 - Validation Accuracy : 0.5095\n",
      "Epoch(23) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(23) - Fold 3 - Validation Accuracy : 0.5080\n",
      "Epoch(23) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 4 - Validation Loss : 0.6906\n",
      "Epoch(23) - Fold 4 - Validation Accuracy : 0.5254\n",
      "Epoch(23) - Fold 4 - Validation Utility score : 1302.3201\n",
      "Epoch(23) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(23) - GLOBAL - Validation Accuracy: 0.5174\n",
      "Epoch(23) - GLOBAL - Validation Utility score: 2389.0484\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(24) - Training Loss: 0.6896\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(24) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(24) - Fold 0 - Validation Accuracy : 0.5221\n",
      "Epoch(24) - Fold 0 - Validation Utility score : 272.6826\n",
      "Epoch(24) - Fold 1 - Validation Loss : 0.6909\n",
      "Epoch(24) - Fold 1 - Validation Accuracy : 0.5209\n",
      "Epoch(24) - Fold 1 - Validation Utility score : 783.3366\n",
      "Epoch(24) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(24) - Fold 2 - Validation Accuracy : 0.5093\n",
      "Epoch(24) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(24) - Fold 3 - Validation Accuracy : 0.5075\n",
      "Epoch(24) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 4 - Validation Loss : 0.6906\n",
      "Epoch(24) - Fold 4 - Validation Accuracy : 0.5249\n",
      "Epoch(24) - Fold 4 - Validation Utility score : 1357.4778\n",
      "Epoch(24) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(24) - GLOBAL - Validation Accuracy: 0.5169\n",
      "Epoch(24) - GLOBAL - Validation Utility score: 2413.4970\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "Meet Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 512391<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_063044-dy23qx9k/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_063044-dy23qx9k/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>0.68962</td></tr><tr><td>Global valid/Loss</td><td>0.69191</td></tr><tr><td>Global valid/Accuracy</td><td>0.51694</td></tr><tr><td>Global valid/Utility</td><td>2413.49704</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>0.69138</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>0.52211</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>272.68259</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>0.69091</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>0.52093</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>783.33665</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>0.69332</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>0.50925</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>0.6934</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>0.50754</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>0.69058</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>0.52486</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>1357.4778</td></tr><tr><td>Best accuracy</td><td>0.51739</td></tr><tr><td>Best utility</td><td>2459.62812</td></tr><tr><td>_runtime</td><td>1320</td></tr><tr><td>_timestamp</td><td>1613454765</td></tr><tr><td>_step</td><td>24</td></tr><tr><td>Final utility score</td><td>{'utility_score': 24...</td></tr><tr><td>Batch size</td><td>64483</td></tr><tr><td>Patience</td><td>5</td></tr><tr><td>Number of epochs</td><td>1000</td></tr><tr><td>Best epoch</td><td>19</td></tr><tr><td>Number of parameters per layer</td><td>[8384, 64, 2048, 32,...</td></tr><tr><td>Model architecture</td><td>MLP(<BR>  (AEncoder)...</td></tr><tr><td>comment</td><td>All folds MLP with a...</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Loss</td><td>█▅▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Accuracy</td><td>▁▃▄▄▄▅▆▇▇▇▇█████▇██▇▇▇▇▇▇</td></tr><tr><td>Global valid/Utility</td><td>▁▂▄▃▅▆▆████▇▇▇▇▇▇▇▇▇▇▇▇▆▆</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>█▆▄▄▄▄▃▃▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>▁▁▁▂▄▇▇▇█████▇▇▇▆▇▇▆▆▆▇▆▇</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>▁▁▁▂▇▇▇█▇▇▇▆▆▆▆▅▄▅▅▄▄▄▄▃▄</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>█▇▅▅▅▅▅▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>▁▂▃▃▃▅▆▇▇██████▇███▇▇▇▇█▇</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>▁▃▄▂▃▃▅▆▇███▇██▇██▇▇▇▆▇▆▆</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>█▅▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>▁▅▅▅▅▅▅▆▆▆▆▇▇▆▇▇▆████▇▇█▇</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>█▅▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂▂▃▃</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>▁▂▄▄▃▃▅▇▇▇▇██▇█▇▇█▇▆▇▅▆▅▅</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>▁▃█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>█▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>▁▃▄▄▅▆▆▇▇▇▇▇████▇████████</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>▁▂▄▃▅▆▇▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Best accuracy</td><td>▁▃▄▄▅▆▇▇▇▇████▇██▇▇</td></tr><tr><td>Best utility</td><td>▁▂▄▃▆▆████▇▇▇▇▇▇▇▇▇</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 126 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">sleek-sweep-5</strong>: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/dy23qx9k\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/dy23qx9k</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training summary:\n",
      "{'utility_score': 2459.6281194328785, 'utility_scores': [250.702086496128, 926.085154820696, -0.0, -0.0, 1282.8408781160547], 'utility_score_std': 520.80934544944, 'accuracy_scores': [0.520509985684115, 0.5218252018252019, 0.5101784402441453, 0.5098837863695199, 0.5245668404000563]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f6c9bgls with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leakyrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 47168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.44106670768102824\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000669346022501448\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_autoenc: encoder-only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 9.531772863174668e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">stilted-sweep-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/f6c9bgls\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/f6c9bgls</a><br/>\n",
       "                Run data is saved locally in <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_065303-f6c9bgls</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Run config :\n",
      "config: {'activation_function': 'leakyrelu', 'batch_size': 47168, 'dropout': 0.44106670768102824, 'learning_rate': 0.000669346022501448, 'use_autoenc': 'encoder-only', 'weight_decay': 9.531772863174668e-05, 'epochs': 1000}\n",
      "Epoch(0) - Training Loss: 0.9516\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(0) - Fold 0 - Validation Loss : 0.7145\n",
      "Epoch(0) - Fold 0 - Validation Accuracy : 0.5001\n",
      "Epoch(0) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 1 - Validation Loss : 0.7103\n",
      "Epoch(0) - Fold 1 - Validation Accuracy : 0.5051\n",
      "Epoch(0) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 2 - Validation Loss : 0.7106\n",
      "Epoch(0) - Fold 2 - Validation Accuracy : 0.4997\n",
      "Epoch(0) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 3 - Validation Loss : 0.7120\n",
      "Epoch(0) - Fold 3 - Validation Accuracy : 0.4998\n",
      "Epoch(0) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 4 - Validation Loss : 0.7127\n",
      "Epoch(0) - Fold 4 - Validation Accuracy : 0.4985\n",
      "Epoch(0) - Fold 4 - Validation Utility score : 31.6098\n",
      "Epoch(0) - GLOBAL - Validation Loss: 0.7120\n",
      "Epoch(0) - GLOBAL - Validation Accuracy: 0.5006\n",
      "Epoch(0) - GLOBAL - Validation Utility score: 31.6098\n",
      "Saving model corresponding to last_utility_score == 31.609849665065006\n",
      "\n",
      "\n",
      "Epoch(1) - Training Loss: 0.8581\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(1) - Fold 0 - Validation Loss : 0.6976\n",
      "Epoch(1) - Fold 0 - Validation Accuracy : 0.5047\n",
      "Epoch(1) - Fold 0 - Validation Utility score : 3.6429\n",
      "Epoch(1) - Fold 1 - Validation Loss : 0.6968\n",
      "Epoch(1) - Fold 1 - Validation Accuracy : 0.5023\n",
      "Epoch(1) - Fold 1 - Validation Utility score : 27.8740\n",
      "Epoch(1) - Fold 2 - Validation Loss : 0.6979\n",
      "Epoch(1) - Fold 2 - Validation Accuracy : 0.4969\n",
      "Epoch(1) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 3 - Validation Loss : 0.6972\n",
      "Epoch(1) - Fold 3 - Validation Accuracy : 0.5013\n",
      "Epoch(1) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 4 - Validation Loss : 0.6988\n",
      "Epoch(1) - Fold 4 - Validation Accuracy : 0.4926\n",
      "Epoch(1) - Fold 4 - Validation Utility score : -0.0000\n",
      "Epoch(1) - GLOBAL - Validation Loss: 0.6977\n",
      "Epoch(1) - GLOBAL - Validation Accuracy: 0.4996\n",
      "Epoch(1) - GLOBAL - Validation Utility score: 31.5169\n",
      "Saving model corresponding to last_utility_score == 31.51687184452795\n",
      "\n",
      "\n",
      "Epoch(2) - Training Loss: 0.7987\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(2) - Fold 0 - Validation Loss : 0.6967\n",
      "Epoch(2) - Fold 0 - Validation Accuracy : 0.5007\n",
      "Epoch(2) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 1 - Validation Loss : 0.6962\n",
      "Epoch(2) - Fold 1 - Validation Accuracy : 0.5062\n",
      "Epoch(2) - Fold 1 - Validation Utility score : 8.9495\n",
      "Epoch(2) - Fold 2 - Validation Loss : 0.6966\n",
      "Epoch(2) - Fold 2 - Validation Accuracy : 0.5003\n",
      "Epoch(2) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 3 - Validation Loss : 0.6970\n",
      "Epoch(2) - Fold 3 - Validation Accuracy : 0.5007\n",
      "Epoch(2) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 4 - Validation Loss : 0.6973\n",
      "Epoch(2) - Fold 4 - Validation Accuracy : 0.4985\n",
      "Epoch(2) - Fold 4 - Validation Utility score : 14.1093\n",
      "Epoch(2) - GLOBAL - Validation Loss: 0.6968\n",
      "Epoch(2) - GLOBAL - Validation Accuracy: 0.5013\n",
      "Epoch(2) - GLOBAL - Validation Utility score: 23.0588\n",
      "Saving model corresponding to last_utility_score == 23.058783708634486\n",
      "\n",
      "\n",
      "Epoch(3) - Training Loss: 0.7524\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(3) - Fold 0 - Validation Loss : 0.6972\n",
      "Epoch(3) - Fold 0 - Validation Accuracy : 0.5010\n",
      "Epoch(3) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 1 - Validation Loss : 0.6967\n",
      "Epoch(3) - Fold 1 - Validation Accuracy : 0.5061\n",
      "Epoch(3) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 2 - Validation Loss : 0.6970\n",
      "Epoch(3) - Fold 2 - Validation Accuracy : 0.5016\n",
      "Epoch(3) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 3 - Validation Loss : 0.6976\n",
      "Epoch(3) - Fold 3 - Validation Accuracy : 0.5003\n",
      "Epoch(3) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 4 - Validation Loss : 0.6974\n",
      "Epoch(3) - Fold 4 - Validation Accuracy : 0.4985\n",
      "Epoch(3) - Fold 4 - Validation Utility score : 12.0663\n",
      "Epoch(3) - GLOBAL - Validation Loss: 0.6972\n",
      "Epoch(3) - GLOBAL - Validation Accuracy: 0.5015\n",
      "Epoch(3) - GLOBAL - Validation Utility score: 12.0663\n",
      "Intermediate early stopping : vepoch_loss = 0.6972, the_last_loss=0.6968\n",
      "\n",
      "\n",
      "Epoch(4) - Training Loss: 0.7216\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(4) - Fold 0 - Validation Loss : 0.6951\n",
      "Epoch(4) - Fold 0 - Validation Accuracy : 0.5004\n",
      "Epoch(4) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 1 - Validation Loss : 0.6947\n",
      "Epoch(4) - Fold 1 - Validation Accuracy : 0.5059\n",
      "Epoch(4) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 2 - Validation Loss : 0.6949\n",
      "Epoch(4) - Fold 2 - Validation Accuracy : 0.5018\n",
      "Epoch(4) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 3 - Validation Loss : 0.6953\n",
      "Epoch(4) - Fold 3 - Validation Accuracy : 0.4998\n",
      "Epoch(4) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 4 - Validation Loss : 0.6952\n",
      "Epoch(4) - Fold 4 - Validation Accuracy : 0.4986\n",
      "Epoch(4) - Fold 4 - Validation Utility score : 12.9386\n",
      "Epoch(4) - GLOBAL - Validation Loss: 0.6950\n",
      "Epoch(4) - GLOBAL - Validation Accuracy: 0.5013\n",
      "Epoch(4) - GLOBAL - Validation Utility score: 12.9386\n",
      "Saving model corresponding to last_utility_score == 12.93860206870729\n",
      "\n",
      "\n",
      "Epoch(5) - Training Loss: 0.7062\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(5) - Fold 0 - Validation Loss : 0.6945\n",
      "Epoch(5) - Fold 0 - Validation Accuracy : 0.5002\n",
      "Epoch(5) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 1 - Validation Loss : 0.6939\n",
      "Epoch(5) - Fold 1 - Validation Accuracy : 0.5061\n",
      "Epoch(5) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 2 - Validation Loss : 0.6941\n",
      "Epoch(5) - Fold 2 - Validation Accuracy : 0.5019\n",
      "Epoch(5) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 3 - Validation Loss : 0.6943\n",
      "Epoch(5) - Fold 3 - Validation Accuracy : 0.4996\n",
      "Epoch(5) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 4 - Validation Loss : 0.6944\n",
      "Epoch(5) - Fold 4 - Validation Accuracy : 0.4989\n",
      "Epoch(5) - Fold 4 - Validation Utility score : 18.1363\n",
      "Epoch(5) - GLOBAL - Validation Loss: 0.6942\n",
      "Epoch(5) - GLOBAL - Validation Accuracy: 0.5013\n",
      "Epoch(5) - GLOBAL - Validation Utility score: 18.1363\n",
      "Saving model corresponding to last_utility_score == 18.136284148592672\n",
      "\n",
      "\n",
      "Epoch(6) - Training Loss: 0.6989\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(6) - Fold 0 - Validation Loss : 0.6941\n",
      "Epoch(6) - Fold 0 - Validation Accuracy : 0.4999\n",
      "Epoch(6) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 1 - Validation Loss : 0.6933\n",
      "Epoch(6) - Fold 1 - Validation Accuracy : 0.5064\n",
      "Epoch(6) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 2 - Validation Loss : 0.6938\n",
      "Epoch(6) - Fold 2 - Validation Accuracy : 0.5020\n",
      "Epoch(6) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 3 - Validation Loss : 0.6939\n",
      "Epoch(6) - Fold 3 - Validation Accuracy : 0.4999\n",
      "Epoch(6) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 4 - Validation Loss : 0.6940\n",
      "Epoch(6) - Fold 4 - Validation Accuracy : 0.4990\n",
      "Epoch(6) - Fold 4 - Validation Utility score : 19.5286\n",
      "Epoch(6) - GLOBAL - Validation Loss: 0.6938\n",
      "Epoch(6) - GLOBAL - Validation Accuracy: 0.5014\n",
      "Epoch(6) - GLOBAL - Validation Utility score: 19.5286\n",
      "Saving model corresponding to last_utility_score == 19.528553055679186\n",
      "\n",
      "\n",
      "Epoch(7) - Training Loss: 0.6961\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(7) - Fold 0 - Validation Loss : 0.6936\n",
      "Epoch(7) - Fold 0 - Validation Accuracy : 0.5003\n",
      "Epoch(7) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 1 - Validation Loss : 0.6930\n",
      "Epoch(7) - Fold 1 - Validation Accuracy : 0.5073\n",
      "Epoch(7) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 2 - Validation Loss : 0.6935\n",
      "Epoch(7) - Fold 2 - Validation Accuracy : 0.5030\n",
      "Epoch(7) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 3 - Validation Loss : 0.6936\n",
      "Epoch(7) - Fold 3 - Validation Accuracy : 0.5007\n",
      "Epoch(7) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 4 - Validation Loss : 0.6937\n",
      "Epoch(7) - Fold 4 - Validation Accuracy : 0.4996\n",
      "Epoch(7) - Fold 4 - Validation Utility score : 24.1057\n",
      "Epoch(7) - GLOBAL - Validation Loss: 0.6935\n",
      "Epoch(7) - GLOBAL - Validation Accuracy: 0.5022\n",
      "Epoch(7) - GLOBAL - Validation Utility score: 24.1057\n",
      "Saving model corresponding to last_utility_score == 24.10565681071371\n",
      "\n",
      "\n",
      "Epoch(8) - Training Loss: 0.6949\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(8) - Fold 0 - Validation Loss : 0.6936\n",
      "Epoch(8) - Fold 0 - Validation Accuracy : 0.5008\n",
      "Epoch(8) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 1 - Validation Loss : 0.6930\n",
      "Epoch(8) - Fold 1 - Validation Accuracy : 0.5070\n",
      "Epoch(8) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 2 - Validation Loss : 0.6935\n",
      "Epoch(8) - Fold 2 - Validation Accuracy : 0.5028\n",
      "Epoch(8) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 3 - Validation Loss : 0.6937\n",
      "Epoch(8) - Fold 3 - Validation Accuracy : 0.5006\n",
      "Epoch(8) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 4 - Validation Loss : 0.6938\n",
      "Epoch(8) - Fold 4 - Validation Accuracy : 0.4995\n",
      "Epoch(8) - Fold 4 - Validation Utility score : 22.1124\n",
      "Epoch(8) - GLOBAL - Validation Loss: 0.6935\n",
      "Epoch(8) - GLOBAL - Validation Accuracy: 0.5021\n",
      "Epoch(8) - GLOBAL - Validation Utility score: 22.1124\n",
      "Intermediate early stopping : vepoch_loss = 0.6935, the_last_loss=0.6935\n",
      "\n",
      "\n",
      "Epoch(9) - Training Loss: 0.6943\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(9) - Fold 0 - Validation Loss : 0.6934\n",
      "Epoch(9) - Fold 0 - Validation Accuracy : 0.5013\n",
      "Epoch(9) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 1 - Validation Loss : 0.6929\n",
      "Epoch(9) - Fold 1 - Validation Accuracy : 0.5074\n",
      "Epoch(9) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 2 - Validation Loss : 0.6934\n",
      "Epoch(9) - Fold 2 - Validation Accuracy : 0.5031\n",
      "Epoch(9) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 3 - Validation Loss : 0.6936\n",
      "Epoch(9) - Fold 3 - Validation Accuracy : 0.5010\n",
      "Epoch(9) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 4 - Validation Loss : 0.6937\n",
      "Epoch(9) - Fold 4 - Validation Accuracy : 0.4999\n",
      "Epoch(9) - Fold 4 - Validation Utility score : 26.4445\n",
      "Epoch(9) - GLOBAL - Validation Loss: 0.6934\n",
      "Epoch(9) - GLOBAL - Validation Accuracy: 0.5025\n",
      "Epoch(9) - GLOBAL - Validation Utility score: 26.4445\n",
      "Saving model corresponding to last_utility_score == 26.444526182080253\n",
      "\n",
      "\n",
      "Epoch(10) - Training Loss: 0.6939\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(10) - Fold 0 - Validation Loss : 0.6932\n",
      "Epoch(10) - Fold 0 - Validation Accuracy : 0.5025\n",
      "Epoch(10) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(10) - Fold 1 - Validation Accuracy : 0.5091\n",
      "Epoch(10) - Fold 1 - Validation Utility score : 0.1310\n",
      "Epoch(10) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(10) - Fold 2 - Validation Accuracy : 0.5036\n",
      "Epoch(10) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 3 - Validation Loss : 0.6935\n",
      "Epoch(10) - Fold 3 - Validation Accuracy : 0.5023\n",
      "Epoch(10) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 4 - Validation Loss : 0.6935\n",
      "Epoch(10) - Fold 4 - Validation Accuracy : 0.5006\n",
      "Epoch(10) - Fold 4 - Validation Utility score : 31.1546\n",
      "Epoch(10) - GLOBAL - Validation Loss: 0.6933\n",
      "Epoch(10) - GLOBAL - Validation Accuracy: 0.5036\n",
      "Epoch(10) - GLOBAL - Validation Utility score: 31.2856\n",
      "Saving model corresponding to last_utility_score == 31.285581903288048\n",
      "\n",
      "\n",
      "Epoch(11) - Training Loss: 0.6937\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(11) - Fold 0 - Validation Loss : 0.6933\n",
      "Epoch(11) - Fold 0 - Validation Accuracy : 0.5022\n",
      "Epoch(11) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(11) - Fold 1 - Validation Accuracy : 0.5078\n",
      "Epoch(11) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 2 - Validation Loss : 0.6934\n",
      "Epoch(11) - Fold 2 - Validation Accuracy : 0.5028\n",
      "Epoch(11) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 3 - Validation Loss : 0.6935\n",
      "Epoch(11) - Fold 3 - Validation Accuracy : 0.5019\n",
      "Epoch(11) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 4 - Validation Loss : 0.6936\n",
      "Epoch(11) - Fold 4 - Validation Accuracy : 0.5005\n",
      "Epoch(11) - Fold 4 - Validation Utility score : 34.2032\n",
      "Epoch(11) - GLOBAL - Validation Loss: 0.6933\n",
      "Epoch(11) - GLOBAL - Validation Accuracy: 0.5030\n",
      "Epoch(11) - GLOBAL - Validation Utility score: 34.2032\n",
      "Intermediate early stopping : vepoch_loss = 0.6933, the_last_loss=0.6933\n",
      "\n",
      "\n",
      "Epoch(12) - Training Loss: 0.6937\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(12) - Fold 0 - Validation Loss : 0.6933\n",
      "Epoch(12) - Fold 0 - Validation Accuracy : 0.5019\n",
      "Epoch(12) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(12) - Fold 1 - Validation Accuracy : 0.5075\n",
      "Epoch(12) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 2 - Validation Loss : 0.6934\n",
      "Epoch(12) - Fold 2 - Validation Accuracy : 0.5026\n",
      "Epoch(12) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 3 - Validation Loss : 0.6936\n",
      "Epoch(12) - Fold 3 - Validation Accuracy : 0.5015\n",
      "Epoch(12) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 4 - Validation Loss : 0.6936\n",
      "Epoch(12) - Fold 4 - Validation Accuracy : 0.5006\n",
      "Epoch(12) - Fold 4 - Validation Utility score : 44.7966\n",
      "Epoch(12) - GLOBAL - Validation Loss: 0.6933\n",
      "Epoch(12) - GLOBAL - Validation Accuracy: 0.5028\n",
      "Epoch(12) - GLOBAL - Validation Utility score: 44.7966\n",
      "Intermediate early stopping : vepoch_loss = 0.6933, the_last_loss=0.6933\n",
      "\n",
      "\n",
      "Epoch(13) - Training Loss: 0.6936\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(13) - Fold 0 - Validation Loss : 0.6932\n",
      "Epoch(13) - Fold 0 - Validation Accuracy : 0.5029\n",
      "Epoch(13) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(13) - Fold 1 - Validation Accuracy : 0.5084\n",
      "Epoch(13) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(13) - Fold 2 - Validation Accuracy : 0.5029\n",
      "Epoch(13) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 3 - Validation Loss : 0.6935\n",
      "Epoch(13) - Fold 3 - Validation Accuracy : 0.5020\n",
      "Epoch(13) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 4 - Validation Loss : 0.6935\n",
      "Epoch(13) - Fold 4 - Validation Accuracy : 0.5011\n",
      "Epoch(13) - Fold 4 - Validation Utility score : 55.8106\n",
      "Epoch(13) - GLOBAL - Validation Loss: 0.6933\n",
      "Epoch(13) - GLOBAL - Validation Accuracy: 0.5034\n",
      "Epoch(13) - GLOBAL - Validation Utility score: 55.8106\n",
      "Saving model corresponding to last_utility_score == 55.81055367760692\n",
      "\n",
      "\n",
      "Epoch(14) - Training Loss: 0.6935\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(14) - Fold 0 - Validation Loss : 0.6931\n",
      "Epoch(14) - Fold 0 - Validation Accuracy : 0.5030\n",
      "Epoch(14) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(14) - Fold 1 - Validation Accuracy : 0.5086\n",
      "Epoch(14) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(14) - Fold 2 - Validation Accuracy : 0.5026\n",
      "Epoch(14) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 3 - Validation Loss : 0.6935\n",
      "Epoch(14) - Fold 3 - Validation Accuracy : 0.5020\n",
      "Epoch(14) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 4 - Validation Loss : 0.6935\n",
      "Epoch(14) - Fold 4 - Validation Accuracy : 0.5014\n",
      "Epoch(14) - Fold 4 - Validation Utility score : 65.8343\n",
      "Epoch(14) - GLOBAL - Validation Loss: 0.6932\n",
      "Epoch(14) - GLOBAL - Validation Accuracy: 0.5035\n",
      "Epoch(14) - GLOBAL - Validation Utility score: 65.8343\n",
      "Saving model corresponding to last_utility_score == 65.83430251548754\n",
      "\n",
      "\n",
      "Epoch(15) - Training Loss: 0.6934\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(15) - Fold 0 - Validation Loss : 0.6930\n",
      "Epoch(15) - Fold 0 - Validation Accuracy : 0.5048\n",
      "Epoch(15) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 1 - Validation Loss : 0.6926\n",
      "Epoch(15) - Fold 1 - Validation Accuracy : 0.5101\n",
      "Epoch(15) - Fold 1 - Validation Utility score : 0.8879\n",
      "Epoch(15) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(15) - Fold 2 - Validation Accuracy : 0.5022\n",
      "Epoch(15) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(15) - Fold 3 - Validation Accuracy : 0.5037\n",
      "Epoch(15) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 4 - Validation Loss : 0.6933\n",
      "Epoch(15) - Fold 4 - Validation Accuracy : 0.5020\n",
      "Epoch(15) - Fold 4 - Validation Utility score : 76.3845\n",
      "Epoch(15) - GLOBAL - Validation Loss: 0.6931\n",
      "Epoch(15) - GLOBAL - Validation Accuracy: 0.5046\n",
      "Epoch(15) - GLOBAL - Validation Utility score: 77.2724\n",
      "Saving model corresponding to last_utility_score == 77.27243487177634\n",
      "\n",
      "\n",
      "Epoch(16) - Training Loss: 0.6934\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(16) - Fold 0 - Validation Loss : 0.6929\n",
      "Epoch(16) - Fold 0 - Validation Accuracy : 0.5058\n",
      "Epoch(16) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(16) - Fold 1 - Validation Accuracy : 0.5107\n",
      "Epoch(16) - Fold 1 - Validation Utility score : 3.5929\n",
      "Epoch(16) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(16) - Fold 2 - Validation Accuracy : 0.5025\n",
      "Epoch(16) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(16) - Fold 3 - Validation Accuracy : 0.5040\n",
      "Epoch(16) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 4 - Validation Loss : 0.6933\n",
      "Epoch(16) - Fold 4 - Validation Accuracy : 0.5025\n",
      "Epoch(16) - Fold 4 - Validation Utility score : 121.7107\n",
      "Epoch(16) - GLOBAL - Validation Loss: 0.6931\n",
      "Epoch(16) - GLOBAL - Validation Accuracy: 0.5051\n",
      "Epoch(16) - GLOBAL - Validation Utility score: 125.3036\n",
      "Saving model corresponding to last_utility_score == 125.30356970729879\n",
      "\n",
      "\n",
      "Epoch(17) - Training Loss: 0.6933\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(17) - Fold 0 - Validation Loss : 0.6929\n",
      "Epoch(17) - Fold 0 - Validation Accuracy : 0.5060\n",
      "Epoch(17) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(17) - Fold 1 - Validation Accuracy : 0.5109\n",
      "Epoch(17) - Fold 1 - Validation Utility score : 5.8496\n",
      "Epoch(17) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(17) - Fold 2 - Validation Accuracy : 0.5028\n",
      "Epoch(17) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(17) - Fold 3 - Validation Accuracy : 0.5042\n",
      "Epoch(17) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 4 - Validation Loss : 0.6932\n",
      "Epoch(17) - Fold 4 - Validation Accuracy : 0.5028\n",
      "Epoch(17) - Fold 4 - Validation Utility score : 133.1003\n",
      "Epoch(17) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(17) - GLOBAL - Validation Accuracy: 0.5053\n",
      "Epoch(17) - GLOBAL - Validation Utility score: 138.9499\n",
      "Saving model corresponding to last_utility_score == 138.94991847801617\n",
      "\n",
      "\n",
      "Epoch(18) - Training Loss: 0.6933\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(18) - Fold 0 - Validation Loss : 0.6929\n",
      "Epoch(18) - Fold 0 - Validation Accuracy : 0.5067\n",
      "Epoch(18) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(18) - Fold 1 - Validation Accuracy : 0.5113\n",
      "Epoch(18) - Fold 1 - Validation Utility score : 10.5429\n",
      "Epoch(18) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(18) - Fold 2 - Validation Accuracy : 0.5028\n",
      "Epoch(18) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(18) - Fold 3 - Validation Accuracy : 0.5042\n",
      "Epoch(18) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 4 - Validation Loss : 0.6932\n",
      "Epoch(18) - Fold 4 - Validation Accuracy : 0.5035\n",
      "Epoch(18) - Fold 4 - Validation Utility score : 153.8962\n",
      "Epoch(18) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(18) - GLOBAL - Validation Accuracy: 0.5057\n",
      "Epoch(18) - GLOBAL - Validation Utility score: 164.4391\n",
      "Saving model corresponding to last_utility_score == 164.43913715160656\n",
      "\n",
      "\n",
      "Epoch(19) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(19) - Fold 0 - Validation Loss : 0.6929\n",
      "Epoch(19) - Fold 0 - Validation Accuracy : 0.5061\n",
      "Epoch(19) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(19) - Fold 1 - Validation Accuracy : 0.5105\n",
      "Epoch(19) - Fold 1 - Validation Utility score : 2.9378\n",
      "Epoch(19) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(19) - Fold 2 - Validation Accuracy : 0.5027\n",
      "Epoch(19) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(19) - Fold 3 - Validation Accuracy : 0.5042\n",
      "Epoch(19) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 4 - Validation Loss : 0.6932\n",
      "Epoch(19) - Fold 4 - Validation Accuracy : 0.5038\n",
      "Epoch(19) - Fold 4 - Validation Utility score : 191.7132\n",
      "Epoch(19) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(19) - GLOBAL - Validation Accuracy: 0.5054\n",
      "Epoch(19) - GLOBAL - Validation Utility score: 194.6509\n",
      "Intermediate early stopping : vepoch_loss = 0.6930, the_last_loss=0.6930\n",
      "\n",
      "\n",
      "Epoch(20) - Training Loss: 0.6933\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(20) - Fold 0 - Validation Loss : 0.6929\n",
      "Epoch(20) - Fold 0 - Validation Accuracy : 0.5068\n",
      "Epoch(20) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(20) - Fold 1 - Validation Accuracy : 0.5114\n",
      "Epoch(20) - Fold 1 - Validation Utility score : 6.3353\n",
      "Epoch(20) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(20) - Fold 2 - Validation Accuracy : 0.5030\n",
      "Epoch(20) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(20) - Fold 3 - Validation Accuracy : 0.5049\n",
      "Epoch(20) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 4 - Validation Loss : 0.6932\n",
      "Epoch(20) - Fold 4 - Validation Accuracy : 0.5039\n",
      "Epoch(20) - Fold 4 - Validation Utility score : 178.6142\n",
      "Epoch(20) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(20) - GLOBAL - Validation Accuracy: 0.5060\n",
      "Epoch(20) - GLOBAL - Validation Utility score: 184.9495\n",
      "Saving model corresponding to last_utility_score == 184.94951286623925\n",
      "\n",
      "\n",
      "Epoch(21) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(21) - Fold 0 - Validation Loss : 0.6929\n",
      "Epoch(21) - Fold 0 - Validation Accuracy : 0.5065\n",
      "Epoch(21) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(21) - Fold 1 - Validation Accuracy : 0.5108\n",
      "Epoch(21) - Fold 1 - Validation Utility score : 1.5202\n",
      "Epoch(21) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(21) - Fold 2 - Validation Accuracy : 0.5031\n",
      "Epoch(21) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(21) - Fold 3 - Validation Accuracy : 0.5045\n",
      "Epoch(21) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 4 - Validation Loss : 0.6932\n",
      "Epoch(21) - Fold 4 - Validation Accuracy : 0.5037\n",
      "Epoch(21) - Fold 4 - Validation Utility score : 187.2784\n",
      "Epoch(21) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(21) - GLOBAL - Validation Accuracy: 0.5057\n",
      "Epoch(21) - GLOBAL - Validation Utility score: 188.7987\n",
      "Intermediate early stopping : vepoch_loss = 0.6930, the_last_loss=0.6930\n",
      "\n",
      "\n",
      "Epoch(22) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(22) - Fold 0 - Validation Loss : 0.6928\n",
      "Epoch(22) - Fold 0 - Validation Accuracy : 0.5096\n",
      "Epoch(22) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(22) - Fold 1 - Validation Accuracy : 0.5133\n",
      "Epoch(22) - Fold 1 - Validation Utility score : 35.2922\n",
      "Epoch(22) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(22) - Fold 2 - Validation Accuracy : 0.5042\n",
      "Epoch(22) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(22) - Fold 3 - Validation Accuracy : 0.5059\n",
      "Epoch(22) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 4 - Validation Loss : 0.6931\n",
      "Epoch(22) - Fold 4 - Validation Accuracy : 0.5050\n",
      "Epoch(22) - Fold 4 - Validation Utility score : 296.8297\n",
      "Epoch(22) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(22) - GLOBAL - Validation Accuracy: 0.5076\n",
      "Epoch(22) - GLOBAL - Validation Utility score: 332.1219\n",
      "Saving model corresponding to last_utility_score == 332.12188903792025\n",
      "\n",
      "\n",
      "Epoch(23) - Training Loss: 0.6931\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(23) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(23) - Fold 0 - Validation Accuracy : 0.5128\n",
      "Epoch(23) - Fold 0 - Validation Utility score : 6.1453\n",
      "Epoch(23) - Fold 1 - Validation Loss : 0.6923\n",
      "Epoch(23) - Fold 1 - Validation Accuracy : 0.5163\n",
      "Epoch(23) - Fold 1 - Validation Utility score : 183.5806\n",
      "Epoch(23) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(23) - Fold 2 - Validation Accuracy : 0.5058\n",
      "Epoch(23) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(23) - Fold 3 - Validation Accuracy : 0.5074\n",
      "Epoch(23) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(23) - Fold 4 - Validation Accuracy : 0.5064\n",
      "Epoch(23) - Fold 4 - Validation Utility score : 529.9037\n",
      "Epoch(23) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(23) - GLOBAL - Validation Accuracy: 0.5098\n",
      "Epoch(23) - GLOBAL - Validation Utility score: 719.6295\n",
      "Saving model corresponding to last_utility_score == 719.6295155412938\n",
      "\n",
      "\n",
      "Epoch(24) - Training Loss: 0.6931\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(24) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(24) - Fold 0 - Validation Accuracy : 0.5125\n",
      "Epoch(24) - Fold 0 - Validation Utility score : 1.1607\n",
      "Epoch(24) - Fold 1 - Validation Loss : 0.6923\n",
      "Epoch(24) - Fold 1 - Validation Accuracy : 0.5163\n",
      "Epoch(24) - Fold 1 - Validation Utility score : 183.9457\n",
      "Epoch(24) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(24) - Fold 2 - Validation Accuracy : 0.5059\n",
      "Epoch(24) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(24) - Fold 3 - Validation Accuracy : 0.5076\n",
      "Epoch(24) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(24) - Fold 4 - Validation Accuracy : 0.5066\n",
      "Epoch(24) - Fold 4 - Validation Utility score : 520.8216\n",
      "Epoch(24) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(24) - GLOBAL - Validation Accuracy: 0.5098\n",
      "Epoch(24) - GLOBAL - Validation Utility score: 705.9280\n",
      "Saving model corresponding to last_utility_score == 705.9280288515433\n",
      "\n",
      "\n",
      "Epoch(25) - Training Loss: 0.6930\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(25) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(25) - Fold 0 - Validation Accuracy : 0.5139\n",
      "Epoch(25) - Fold 0 - Validation Utility score : 2.9786\n",
      "Epoch(25) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(25) - Fold 1 - Validation Accuracy : 0.5179\n",
      "Epoch(25) - Fold 1 - Validation Utility score : 237.8059\n",
      "Epoch(25) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(25) - Fold 2 - Validation Accuracy : 0.5061\n",
      "Epoch(25) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(25) - Fold 3 - Validation Accuracy : 0.5081\n",
      "Epoch(25) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(25) - Fold 4 - Validation Accuracy : 0.5071\n",
      "Epoch(25) - Fold 4 - Validation Utility score : 540.2497\n",
      "Epoch(25) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(25) - GLOBAL - Validation Accuracy: 0.5106\n",
      "Epoch(25) - GLOBAL - Validation Utility score: 781.0342\n",
      "Saving model corresponding to last_utility_score == 781.034206240385\n",
      "\n",
      "\n",
      "Epoch(26) - Training Loss: 0.6930\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(26) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(26) - Fold 0 - Validation Accuracy : 0.5149\n",
      "Epoch(26) - Fold 0 - Validation Utility score : 7.5679\n",
      "Epoch(26) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(26) - Fold 1 - Validation Accuracy : 0.5197\n",
      "Epoch(26) - Fold 1 - Validation Utility score : 298.9999\n",
      "Epoch(26) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(26) - Fold 2 - Validation Accuracy : 0.5074\n",
      "Epoch(26) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(26) - Fold 3 - Validation Accuracy : 0.5079\n",
      "Epoch(26) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(26) - Fold 4 - Validation Accuracy : 0.5074\n",
      "Epoch(26) - Fold 4 - Validation Utility score : 613.3355\n",
      "Epoch(26) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(26) - GLOBAL - Validation Accuracy: 0.5115\n",
      "Epoch(26) - GLOBAL - Validation Utility score: 919.9034\n",
      "Saving model corresponding to last_utility_score == 919.9033984979071\n",
      "\n",
      "\n",
      "Epoch(27) - Training Loss: 0.6929\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(27) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(27) - Fold 0 - Validation Accuracy : 0.5144\n",
      "Epoch(27) - Fold 0 - Validation Utility score : 4.1499\n",
      "Epoch(27) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(27) - Fold 1 - Validation Accuracy : 0.5191\n",
      "Epoch(27) - Fold 1 - Validation Utility score : 288.5159\n",
      "Epoch(27) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(27) - Fold 2 - Validation Accuracy : 0.5074\n",
      "Epoch(27) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(27) - Fold 3 - Validation Accuracy : 0.5075\n",
      "Epoch(27) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(27) - Fold 4 - Validation Accuracy : 0.5075\n",
      "Epoch(27) - Fold 4 - Validation Utility score : 529.1220\n",
      "Epoch(27) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(27) - GLOBAL - Validation Accuracy: 0.5112\n",
      "Epoch(27) - GLOBAL - Validation Utility score: 821.7877\n",
      "Intermediate early stopping : vepoch_loss = 0.6927, the_last_loss=0.6927\n",
      "\n",
      "\n",
      "Epoch(28) - Training Loss: 0.6929\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(28) - Fold 0 - Validation Loss : 0.6924\n",
      "Epoch(28) - Fold 0 - Validation Accuracy : 0.5158\n",
      "Epoch(28) - Fold 0 - Validation Utility score : 12.8951\n",
      "Epoch(28) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(28) - Fold 1 - Validation Accuracy : 0.5201\n",
      "Epoch(28) - Fold 1 - Validation Utility score : 294.0171\n",
      "Epoch(28) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(28) - Fold 2 - Validation Accuracy : 0.5077\n",
      "Epoch(28) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(28) - Fold 3 - Validation Accuracy : 0.5077\n",
      "Epoch(28) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(28) - Fold 4 - Validation Accuracy : 0.5080\n",
      "Epoch(28) - Fold 4 - Validation Utility score : 629.7099\n",
      "Epoch(28) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(28) - GLOBAL - Validation Accuracy: 0.5118\n",
      "Epoch(28) - GLOBAL - Validation Utility score: 936.6221\n",
      "Saving model corresponding to last_utility_score == 936.6220722356451\n",
      "\n",
      "\n",
      "Epoch(29) - Training Loss: 0.6929\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(29) - Fold 0 - Validation Loss : 0.6924\n",
      "Epoch(29) - Fold 0 - Validation Accuracy : 0.5157\n",
      "Epoch(29) - Fold 0 - Validation Utility score : 25.1540\n",
      "Epoch(29) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(29) - Fold 1 - Validation Accuracy : 0.5207\n",
      "Epoch(29) - Fold 1 - Validation Utility score : 347.0470\n",
      "Epoch(29) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(29) - Fold 2 - Validation Accuracy : 0.5081\n",
      "Epoch(29) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(29) - Fold 3 - Validation Accuracy : 0.5080\n",
      "Epoch(29) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(29) - Fold 4 - Validation Accuracy : 0.5082\n",
      "Epoch(29) - Fold 4 - Validation Utility score : 680.1350\n",
      "Epoch(29) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(29) - GLOBAL - Validation Accuracy: 0.5121\n",
      "Epoch(29) - GLOBAL - Validation Utility score: 1052.3360\n",
      "Saving model corresponding to last_utility_score == 1052.3360374775193\n",
      "\n",
      "\n",
      "Epoch(30) - Training Loss: 0.6929\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(30) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(30) - Fold 0 - Validation Accuracy : 0.5148\n",
      "Epoch(30) - Fold 0 - Validation Utility score : 6.0341\n",
      "Epoch(30) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(30) - Fold 1 - Validation Accuracy : 0.5194\n",
      "Epoch(30) - Fold 1 - Validation Utility score : 285.7755\n",
      "Epoch(30) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(30) - Fold 2 - Validation Accuracy : 0.5073\n",
      "Epoch(30) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(30) - Fold 3 - Validation Accuracy : 0.5071\n",
      "Epoch(30) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(30) - Fold 4 - Validation Accuracy : 0.5077\n",
      "Epoch(30) - Fold 4 - Validation Utility score : 583.8162\n",
      "Epoch(30) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(30) - GLOBAL - Validation Accuracy: 0.5113\n",
      "Epoch(30) - GLOBAL - Validation Utility score: 875.6259\n",
      "Intermediate early stopping : vepoch_loss = 0.6927, the_last_loss=0.6926\n",
      "\n",
      "\n",
      "Epoch(31) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(31) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(31) - Fold 0 - Validation Accuracy : 0.5193\n",
      "Epoch(31) - Fold 0 - Validation Utility score : 109.3701\n",
      "Epoch(31) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(31) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(31) - Fold 1 - Validation Utility score : 413.3368\n",
      "Epoch(31) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(31) - Fold 2 - Validation Accuracy : 0.5079\n",
      "Epoch(31) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(31) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(31) - Fold 3 - Validation Accuracy : 0.5065\n",
      "Epoch(31) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(31) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(31) - Fold 4 - Validation Accuracy : 0.5100\n",
      "Epoch(31) - Fold 4 - Validation Utility score : 822.5753\n",
      "Epoch(31) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(31) - GLOBAL - Validation Accuracy: 0.5134\n",
      "Epoch(31) - GLOBAL - Validation Utility score: 1345.2823\n",
      "Saving model corresponding to last_utility_score == 1345.2822719060516\n",
      "\n",
      "\n",
      "Epoch(32) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(32) - Fold 0 - Validation Loss : 0.6924\n",
      "Epoch(32) - Fold 0 - Validation Accuracy : 0.5157\n",
      "Epoch(32) - Fold 0 - Validation Utility score : 17.2444\n",
      "Epoch(32) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(32) - Fold 1 - Validation Accuracy : 0.5199\n",
      "Epoch(32) - Fold 1 - Validation Utility score : 277.5413\n",
      "Epoch(32) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(32) - Fold 2 - Validation Accuracy : 0.5070\n",
      "Epoch(32) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(32) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(32) - Fold 3 - Validation Accuracy : 0.5070\n",
      "Epoch(32) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(32) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(32) - Fold 4 - Validation Accuracy : 0.5077\n",
      "Epoch(32) - Fold 4 - Validation Utility score : 576.9757\n",
      "Epoch(32) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(32) - GLOBAL - Validation Accuracy: 0.5115\n",
      "Epoch(32) - GLOBAL - Validation Utility score: 871.7615\n",
      "Intermediate early stopping : vepoch_loss = 0.6926, the_last_loss=0.6925\n",
      "\n",
      "\n",
      "Epoch(33) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(33) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(33) - Fold 0 - Validation Accuracy : 0.5176\n",
      "Epoch(33) - Fold 0 - Validation Utility score : 46.7817\n",
      "Epoch(33) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(33) - Fold 1 - Validation Accuracy : 0.5215\n",
      "Epoch(33) - Fold 1 - Validation Utility score : 356.7570\n",
      "Epoch(33) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(33) - Fold 2 - Validation Accuracy : 0.5077\n",
      "Epoch(33) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(33) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(33) - Fold 3 - Validation Accuracy : 0.5071\n",
      "Epoch(33) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(33) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(33) - Fold 4 - Validation Accuracy : 0.5096\n",
      "Epoch(33) - Fold 4 - Validation Utility score : 684.0825\n",
      "Epoch(33) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(33) - GLOBAL - Validation Accuracy: 0.5127\n",
      "Epoch(33) - GLOBAL - Validation Utility score: 1087.6212\n",
      "Intermediate early stopping : vepoch_loss = 0.6926, the_last_loss=0.6925\n",
      "\n",
      "\n",
      "Epoch(34) - Training Loss: 0.6927\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(34) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(34) - Fold 0 - Validation Accuracy : 0.5198\n",
      "Epoch(34) - Fold 0 - Validation Utility score : 168.3080\n",
      "Epoch(34) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(34) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(34) - Fold 1 - Validation Utility score : 476.8292\n",
      "Epoch(34) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(34) - Fold 2 - Validation Accuracy : 0.5084\n",
      "Epoch(34) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(34) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(34) - Fold 3 - Validation Accuracy : 0.5069\n",
      "Epoch(34) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(34) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(34) - Fold 4 - Validation Accuracy : 0.5116\n",
      "Epoch(34) - Fold 4 - Validation Utility score : 910.9541\n",
      "Epoch(34) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(34) - GLOBAL - Validation Accuracy: 0.5140\n",
      "Epoch(34) - GLOBAL - Validation Utility score: 1556.0913\n",
      "Saving model corresponding to last_utility_score == 1556.0912986866165\n",
      "\n",
      "\n",
      "Epoch(35) - Training Loss: 0.6927\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(35) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(35) - Fold 0 - Validation Accuracy : 0.5198\n",
      "Epoch(35) - Fold 0 - Validation Utility score : 126.7138\n",
      "Epoch(35) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(35) - Fold 1 - Validation Accuracy : 0.5225\n",
      "Epoch(35) - Fold 1 - Validation Utility score : 393.7340\n",
      "Epoch(35) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(35) - Fold 2 - Validation Accuracy : 0.5081\n",
      "Epoch(35) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(35) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(35) - Fold 3 - Validation Accuracy : 0.5073\n",
      "Epoch(35) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(35) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(35) - Fold 4 - Validation Accuracy : 0.5107\n",
      "Epoch(35) - Fold 4 - Validation Utility score : 848.7795\n",
      "Epoch(35) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(35) - GLOBAL - Validation Accuracy: 0.5137\n",
      "Epoch(35) - GLOBAL - Validation Utility score: 1369.2272\n",
      "Intermediate early stopping : vepoch_loss = 0.6925, the_last_loss=0.6925\n",
      "\n",
      "\n",
      "Epoch(36) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(36) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(36) - Fold 0 - Validation Accuracy : 0.5193\n",
      "Epoch(36) - Fold 0 - Validation Utility score : 103.1533\n",
      "Epoch(36) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(36) - Fold 1 - Validation Accuracy : 0.5228\n",
      "Epoch(36) - Fold 1 - Validation Utility score : 442.6369\n",
      "Epoch(36) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(36) - Fold 2 - Validation Accuracy : 0.5089\n",
      "Epoch(36) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(36) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(36) - Fold 3 - Validation Accuracy : 0.5068\n",
      "Epoch(36) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(36) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(36) - Fold 4 - Validation Accuracy : 0.5113\n",
      "Epoch(36) - Fold 4 - Validation Utility score : 926.4964\n",
      "Epoch(36) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(36) - GLOBAL - Validation Accuracy: 0.5138\n",
      "Epoch(36) - GLOBAL - Validation Utility score: 1472.2867\n",
      "Saving model corresponding to last_utility_score == 1472.286710956727\n",
      "\n",
      "\n",
      "Epoch(37) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(37) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(37) - Fold 0 - Validation Accuracy : 0.5195\n",
      "Epoch(37) - Fold 0 - Validation Utility score : 129.9369\n",
      "Epoch(37) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(37) - Fold 1 - Validation Accuracy : 0.5227\n",
      "Epoch(37) - Fold 1 - Validation Utility score : 429.1298\n",
      "Epoch(37) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(37) - Fold 2 - Validation Accuracy : 0.5081\n",
      "Epoch(37) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(37) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(37) - Fold 3 - Validation Accuracy : 0.5069\n",
      "Epoch(37) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(37) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(37) - Fold 4 - Validation Accuracy : 0.5114\n",
      "Epoch(37) - Fold 4 - Validation Utility score : 868.3991\n",
      "Epoch(37) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(37) - GLOBAL - Validation Accuracy: 0.5137\n",
      "Epoch(37) - GLOBAL - Validation Utility score: 1427.4658\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6924\n",
      "\n",
      "\n",
      "Epoch(38) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(38) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(38) - Fold 0 - Validation Accuracy : 0.5194\n",
      "Epoch(38) - Fold 0 - Validation Utility score : 98.0405\n",
      "Epoch(38) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(38) - Fold 1 - Validation Accuracy : 0.5218\n",
      "Epoch(38) - Fold 1 - Validation Utility score : 368.1392\n",
      "Epoch(38) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(38) - Fold 2 - Validation Accuracy : 0.5084\n",
      "Epoch(38) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(38) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(38) - Fold 3 - Validation Accuracy : 0.5069\n",
      "Epoch(38) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(38) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(38) - Fold 4 - Validation Accuracy : 0.5106\n",
      "Epoch(38) - Fold 4 - Validation Utility score : 754.5371\n",
      "Epoch(38) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(38) - GLOBAL - Validation Accuracy: 0.5134\n",
      "Epoch(38) - GLOBAL - Validation Utility score: 1220.7168\n",
      "Intermediate early stopping : vepoch_loss = 0.6925, the_last_loss=0.6924\n",
      "\n",
      "\n",
      "Epoch(39) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(39) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(39) - Fold 0 - Validation Accuracy : 0.5206\n",
      "Epoch(39) - Fold 0 - Validation Utility score : 137.5029\n",
      "Epoch(39) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(39) - Fold 1 - Validation Accuracy : 0.5224\n",
      "Epoch(39) - Fold 1 - Validation Utility score : 436.6525\n",
      "Epoch(39) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(39) - Fold 2 - Validation Accuracy : 0.5084\n",
      "Epoch(39) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(39) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(39) - Fold 3 - Validation Accuracy : 0.5076\n",
      "Epoch(39) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(39) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(39) - Fold 4 - Validation Accuracy : 0.5116\n",
      "Epoch(39) - Fold 4 - Validation Utility score : 942.4272\n",
      "Epoch(39) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(39) - GLOBAL - Validation Accuracy: 0.5141\n",
      "Epoch(39) - GLOBAL - Validation Utility score: 1516.5827\n",
      "Saving model corresponding to last_utility_score == 1516.5826537196504\n",
      "\n",
      "\n",
      "Epoch(40) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(40) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(40) - Fold 0 - Validation Accuracy : 0.5202\n",
      "Epoch(40) - Fold 0 - Validation Utility score : 128.4894\n",
      "Epoch(40) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(40) - Fold 1 - Validation Accuracy : 0.5221\n",
      "Epoch(40) - Fold 1 - Validation Utility score : 393.7304\n",
      "Epoch(40) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(40) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(40) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(40) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(40) - Fold 3 - Validation Accuracy : 0.5073\n",
      "Epoch(40) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(40) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(40) - Fold 4 - Validation Accuracy : 0.5114\n",
      "Epoch(40) - Fold 4 - Validation Utility score : 843.8849\n",
      "Epoch(40) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(40) - GLOBAL - Validation Accuracy: 0.5139\n",
      "Epoch(40) - GLOBAL - Validation Utility score: 1366.1047\n",
      "Saving model corresponding to last_utility_score == 1366.1047191570833\n",
      "\n",
      "\n",
      "Epoch(41) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(41) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(41) - Fold 0 - Validation Accuracy : 0.5206\n",
      "Epoch(41) - Fold 0 - Validation Utility score : 142.2419\n",
      "Epoch(41) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(41) - Fold 1 - Validation Accuracy : 0.5231\n",
      "Epoch(41) - Fold 1 - Validation Utility score : 467.4890\n",
      "Epoch(41) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(41) - Fold 2 - Validation Accuracy : 0.5080\n",
      "Epoch(41) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(41) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(41) - Fold 3 - Validation Accuracy : 0.5078\n",
      "Epoch(41) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(41) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(41) - Fold 4 - Validation Accuracy : 0.5120\n",
      "Epoch(41) - Fold 4 - Validation Utility score : 951.7043\n",
      "Epoch(41) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(41) - GLOBAL - Validation Accuracy: 0.5143\n",
      "Epoch(41) - GLOBAL - Validation Utility score: 1561.4351\n",
      "Saving model corresponding to last_utility_score == 1561.4351279020966\n",
      "\n",
      "\n",
      "Epoch(42) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(42) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(42) - Fold 0 - Validation Accuracy : 0.5206\n",
      "Epoch(42) - Fold 0 - Validation Utility score : 148.1714\n",
      "Epoch(42) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(42) - Fold 1 - Validation Accuracy : 0.5229\n",
      "Epoch(42) - Fold 1 - Validation Utility score : 402.5261\n",
      "Epoch(42) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(42) - Fold 2 - Validation Accuracy : 0.5086\n",
      "Epoch(42) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(42) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(42) - Fold 3 - Validation Accuracy : 0.5077\n",
      "Epoch(42) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(42) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(42) - Fold 4 - Validation Accuracy : 0.5121\n",
      "Epoch(42) - Fold 4 - Validation Utility score : 970.3794\n",
      "Epoch(42) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(42) - GLOBAL - Validation Accuracy: 0.5144\n",
      "Epoch(42) - GLOBAL - Validation Utility score: 1521.0769\n",
      "Saving model corresponding to last_utility_score == 1521.0768761904187\n",
      "\n",
      "\n",
      "Epoch(43) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(43) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(43) - Fold 0 - Validation Accuracy : 0.5186\n",
      "Epoch(43) - Fold 0 - Validation Utility score : 81.5710\n",
      "Epoch(43) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(43) - Fold 1 - Validation Accuracy : 0.5219\n",
      "Epoch(43) - Fold 1 - Validation Utility score : 384.7437\n",
      "Epoch(43) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(43) - Fold 2 - Validation Accuracy : 0.5082\n",
      "Epoch(43) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(43) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(43) - Fold 3 - Validation Accuracy : 0.5074\n",
      "Epoch(43) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(43) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(43) - Fold 4 - Validation Accuracy : 0.5110\n",
      "Epoch(43) - Fold 4 - Validation Utility score : 720.3394\n",
      "Epoch(43) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(43) - GLOBAL - Validation Accuracy: 0.5134\n",
      "Epoch(43) - GLOBAL - Validation Utility score: 1186.6541\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6923\n",
      "\n",
      "\n",
      "Epoch(44) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(44) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(44) - Fold 0 - Validation Accuracy : 0.5209\n",
      "Epoch(44) - Fold 0 - Validation Utility score : 185.7705\n",
      "Epoch(44) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(44) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(44) - Fold 1 - Validation Utility score : 553.0604\n",
      "Epoch(44) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(44) - Fold 2 - Validation Accuracy : 0.5082\n",
      "Epoch(44) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(44) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(44) - Fold 3 - Validation Accuracy : 0.5066\n",
      "Epoch(44) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(44) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(44) - Fold 4 - Validation Accuracy : 0.5123\n",
      "Epoch(44) - Fold 4 - Validation Utility score : 928.6868\n",
      "Epoch(44) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(44) - GLOBAL - Validation Accuracy: 0.5143\n",
      "Epoch(44) - GLOBAL - Validation Utility score: 1667.5177\n",
      "Saving model corresponding to last_utility_score == 1667.5176852838295\n",
      "\n",
      "\n",
      "Epoch(45) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(45) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(45) - Fold 0 - Validation Accuracy : 0.5218\n",
      "Epoch(45) - Fold 0 - Validation Utility score : 177.7951\n",
      "Epoch(45) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(45) - Fold 1 - Validation Accuracy : 0.5226\n",
      "Epoch(45) - Fold 1 - Validation Utility score : 427.2776\n",
      "Epoch(45) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(45) - Fold 2 - Validation Accuracy : 0.5070\n",
      "Epoch(45) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(45) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(45) - Fold 3 - Validation Accuracy : 0.5072\n",
      "Epoch(45) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(45) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(45) - Fold 4 - Validation Accuracy : 0.5122\n",
      "Epoch(45) - Fold 4 - Validation Utility score : 896.6188\n",
      "Epoch(45) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(45) - GLOBAL - Validation Accuracy: 0.5142\n",
      "Epoch(45) - GLOBAL - Validation Utility score: 1501.6916\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(46) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(46) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(46) - Fold 0 - Validation Accuracy : 0.5219\n",
      "Epoch(46) - Fold 0 - Validation Utility score : 184.8183\n",
      "Epoch(46) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(46) - Fold 1 - Validation Accuracy : 0.5229\n",
      "Epoch(46) - Fold 1 - Validation Utility score : 526.7957\n",
      "Epoch(46) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(46) - Fold 2 - Validation Accuracy : 0.5080\n",
      "Epoch(46) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(46) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(46) - Fold 3 - Validation Accuracy : 0.5079\n",
      "Epoch(46) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(46) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(46) - Fold 4 - Validation Accuracy : 0.5118\n",
      "Epoch(46) - Fold 4 - Validation Utility score : 925.9086\n",
      "Epoch(46) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(46) - GLOBAL - Validation Accuracy: 0.5145\n",
      "Epoch(46) - GLOBAL - Validation Utility score: 1637.5227\n",
      "Intermediate early stopping : vepoch_loss = 0.6922, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(47) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(47) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(47) - Fold 0 - Validation Accuracy : 0.5228\n",
      "Epoch(47) - Fold 0 - Validation Utility score : 235.8325\n",
      "Epoch(47) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(47) - Fold 1 - Validation Accuracy : 0.5239\n",
      "Epoch(47) - Fold 1 - Validation Utility score : 594.6613\n",
      "Epoch(47) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(47) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(47) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(47) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(47) - Fold 3 - Validation Accuracy : 0.5070\n",
      "Epoch(47) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(47) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(47) - Fold 4 - Validation Accuracy : 0.5120\n",
      "Epoch(47) - Fold 4 - Validation Utility score : 865.1721\n",
      "Epoch(47) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(47) - GLOBAL - Validation Accuracy: 0.5148\n",
      "Epoch(47) - GLOBAL - Validation Utility score: 1695.6659\n",
      "Saving model corresponding to last_utility_score == 1695.6659288970482\n",
      "\n",
      "\n",
      "Epoch(48) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(48) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(48) - Fold 0 - Validation Accuracy : 0.5221\n",
      "Epoch(48) - Fold 0 - Validation Utility score : 202.9985\n",
      "Epoch(48) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(48) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(48) - Fold 1 - Validation Utility score : 580.9217\n",
      "Epoch(48) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(48) - Fold 2 - Validation Accuracy : 0.5075\n",
      "Epoch(48) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(48) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(48) - Fold 3 - Validation Accuracy : 0.5073\n",
      "Epoch(48) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(48) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(48) - Fold 4 - Validation Accuracy : 0.5116\n",
      "Epoch(48) - Fold 4 - Validation Utility score : 840.2644\n",
      "Epoch(48) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(48) - GLOBAL - Validation Accuracy: 0.5145\n",
      "Epoch(48) - GLOBAL - Validation Utility score: 1624.1846\n",
      "Saving model corresponding to last_utility_score == 1624.1846198653182\n",
      "\n",
      "\n",
      "Epoch(49) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(49) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(49) - Fold 0 - Validation Accuracy : 0.5233\n",
      "Epoch(49) - Fold 0 - Validation Utility score : 250.2087\n",
      "Epoch(49) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(49) - Fold 1 - Validation Accuracy : 0.5232\n",
      "Epoch(49) - Fold 1 - Validation Utility score : 578.8003\n",
      "Epoch(49) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(49) - Fold 2 - Validation Accuracy : 0.5073\n",
      "Epoch(49) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(49) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(49) - Fold 3 - Validation Accuracy : 0.5076\n",
      "Epoch(49) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(49) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(49) - Fold 4 - Validation Accuracy : 0.5123\n",
      "Epoch(49) - Fold 4 - Validation Utility score : 857.5268\n",
      "Epoch(49) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(49) - GLOBAL - Validation Accuracy: 0.5148\n",
      "Epoch(49) - GLOBAL - Validation Utility score: 1686.5358\n",
      "Saving model corresponding to last_utility_score == 1686.535830212276\n",
      "\n",
      "\n",
      "Epoch(50) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(50) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(50) - Fold 0 - Validation Accuracy : 0.5235\n",
      "Epoch(50) - Fold 0 - Validation Utility score : 259.0820\n",
      "Epoch(50) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(50) - Fold 1 - Validation Accuracy : 0.5239\n",
      "Epoch(50) - Fold 1 - Validation Utility score : 625.4177\n",
      "Epoch(50) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(50) - Fold 2 - Validation Accuracy : 0.5079\n",
      "Epoch(50) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(50) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(50) - Fold 3 - Validation Accuracy : 0.5083\n",
      "Epoch(50) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(50) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(50) - Fold 4 - Validation Accuracy : 0.5120\n",
      "Epoch(50) - Fold 4 - Validation Utility score : 797.9258\n",
      "Epoch(50) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(50) - GLOBAL - Validation Accuracy: 0.5151\n",
      "Epoch(50) - GLOBAL - Validation Utility score: 1682.4255\n",
      "Saving model corresponding to last_utility_score == 1682.4254800266272\n",
      "\n",
      "\n",
      "Epoch(51) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(51) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(51) - Fold 0 - Validation Accuracy : 0.5232\n",
      "Epoch(51) - Fold 0 - Validation Utility score : 204.9354\n",
      "Epoch(51) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(51) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(51) - Fold 1 - Validation Utility score : 595.7001\n",
      "Epoch(51) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(51) - Fold 2 - Validation Accuracy : 0.5076\n",
      "Epoch(51) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(51) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(51) - Fold 3 - Validation Accuracy : 0.5089\n",
      "Epoch(51) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(51) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(51) - Fold 4 - Validation Accuracy : 0.5124\n",
      "Epoch(51) - Fold 4 - Validation Utility score : 780.4897\n",
      "Epoch(51) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(51) - GLOBAL - Validation Accuracy: 0.5151\n",
      "Epoch(51) - GLOBAL - Validation Utility score: 1581.1252\n",
      "Saving model corresponding to last_utility_score == 1581.1251924928144\n",
      "\n",
      "\n",
      "Epoch(52) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(52) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(52) - Fold 0 - Validation Accuracy : 0.5237\n",
      "Epoch(52) - Fold 0 - Validation Utility score : 291.1144\n",
      "Epoch(52) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(52) - Fold 1 - Validation Accuracy : 0.5243\n",
      "Epoch(52) - Fold 1 - Validation Utility score : 712.1030\n",
      "Epoch(52) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(52) - Fold 2 - Validation Accuracy : 0.5082\n",
      "Epoch(52) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(52) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(52) - Fold 3 - Validation Accuracy : 0.5083\n",
      "Epoch(52) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(52) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(52) - Fold 4 - Validation Accuracy : 0.5128\n",
      "Epoch(52) - Fold 4 - Validation Utility score : 882.5263\n",
      "Epoch(52) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(52) - GLOBAL - Validation Accuracy: 0.5154\n",
      "Epoch(52) - GLOBAL - Validation Utility score: 1885.7437\n",
      "Saving model corresponding to last_utility_score == 1885.7436841628219\n",
      "\n",
      "\n",
      "Epoch(53) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(53) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(53) - Fold 0 - Validation Accuracy : 0.5227\n",
      "Epoch(53) - Fold 0 - Validation Utility score : 205.6967\n",
      "Epoch(53) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(53) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(53) - Fold 1 - Validation Utility score : 574.9168\n",
      "Epoch(53) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(53) - Fold 2 - Validation Accuracy : 0.5078\n",
      "Epoch(53) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(53) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(53) - Fold 3 - Validation Accuracy : 0.5089\n",
      "Epoch(53) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(53) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(53) - Fold 4 - Validation Accuracy : 0.5123\n",
      "Epoch(53) - Fold 4 - Validation Utility score : 877.8341\n",
      "Epoch(53) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(53) - GLOBAL - Validation Accuracy: 0.5150\n",
      "Epoch(53) - GLOBAL - Validation Utility score: 1658.4475\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(54) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(54) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(54) - Fold 0 - Validation Accuracy : 0.5234\n",
      "Epoch(54) - Fold 0 - Validation Utility score : 227.0964\n",
      "Epoch(54) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(54) - Fold 1 - Validation Accuracy : 0.5248\n",
      "Epoch(54) - Fold 1 - Validation Utility score : 644.3679\n",
      "Epoch(54) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(54) - Fold 2 - Validation Accuracy : 0.5078\n",
      "Epoch(54) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(54) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(54) - Fold 3 - Validation Accuracy : 0.5082\n",
      "Epoch(54) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(54) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(54) - Fold 4 - Validation Accuracy : 0.5144\n",
      "Epoch(54) - Fold 4 - Validation Utility score : 933.9891\n",
      "Epoch(54) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(54) - GLOBAL - Validation Accuracy: 0.5157\n",
      "Epoch(54) - GLOBAL - Validation Utility score: 1805.4534\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(55) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(55) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(55) - Fold 0 - Validation Accuracy : 0.5234\n",
      "Epoch(55) - Fold 0 - Validation Utility score : 264.2004\n",
      "Epoch(55) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(55) - Fold 1 - Validation Accuracy : 0.5245\n",
      "Epoch(55) - Fold 1 - Validation Utility score : 701.6791\n",
      "Epoch(55) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(55) - Fold 2 - Validation Accuracy : 0.5081\n",
      "Epoch(55) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(55) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(55) - Fold 3 - Validation Accuracy : 0.5098\n",
      "Epoch(55) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(55) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(55) - Fold 4 - Validation Accuracy : 0.5147\n",
      "Epoch(55) - Fold 4 - Validation Utility score : 933.5944\n",
      "Epoch(55) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(55) - GLOBAL - Validation Accuracy: 0.5161\n",
      "Epoch(55) - GLOBAL - Validation Utility score: 1899.4739\n",
      "Saving model corresponding to last_utility_score == 1899.4739390643695\n",
      "\n",
      "\n",
      "Epoch(56) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(56) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(56) - Fold 0 - Validation Accuracy : 0.5198\n",
      "Epoch(56) - Fold 0 - Validation Utility score : 107.5969\n",
      "Epoch(56) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(56) - Fold 1 - Validation Accuracy : 0.5224\n",
      "Epoch(56) - Fold 1 - Validation Utility score : 467.0604\n",
      "Epoch(56) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(56) - Fold 2 - Validation Accuracy : 0.5078\n",
      "Epoch(56) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(56) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(56) - Fold 3 - Validation Accuracy : 0.5073\n",
      "Epoch(56) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(56) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(56) - Fold 4 - Validation Accuracy : 0.5110\n",
      "Epoch(56) - Fold 4 - Validation Utility score : 826.3148\n",
      "Epoch(56) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(56) - GLOBAL - Validation Accuracy: 0.5136\n",
      "Epoch(56) - GLOBAL - Validation Utility score: 1400.9721\n",
      "Intermediate early stopping : vepoch_loss = 0.6922, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(57) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(57) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(57) - Fold 0 - Validation Accuracy : 0.5242\n",
      "Epoch(57) - Fold 0 - Validation Utility score : 317.9473\n",
      "Epoch(57) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(57) - Fold 1 - Validation Accuracy : 0.5251\n",
      "Epoch(57) - Fold 1 - Validation Utility score : 834.3077\n",
      "Epoch(57) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(57) - Fold 2 - Validation Accuracy : 0.5080\n",
      "Epoch(57) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(57) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(57) - Fold 3 - Validation Accuracy : 0.5088\n",
      "Epoch(57) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(57) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(57) - Fold 4 - Validation Accuracy : 0.5158\n",
      "Epoch(57) - Fold 4 - Validation Utility score : 930.7564\n",
      "Epoch(57) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(57) - GLOBAL - Validation Accuracy: 0.5164\n",
      "Epoch(57) - GLOBAL - Validation Utility score: 2083.0114\n",
      "Saving model corresponding to last_utility_score == 2083.0114408787067\n",
      "\n",
      "\n",
      "Epoch(58) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(58) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(58) - Fold 0 - Validation Accuracy : 0.5240\n",
      "Epoch(58) - Fold 0 - Validation Utility score : 328.6821\n",
      "Epoch(58) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(58) - Fold 1 - Validation Accuracy : 0.5247\n",
      "Epoch(58) - Fold 1 - Validation Utility score : 767.2404\n",
      "Epoch(58) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(58) - Fold 2 - Validation Accuracy : 0.5079\n",
      "Epoch(58) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(58) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(58) - Fold 3 - Validation Accuracy : 0.5088\n",
      "Epoch(58) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(58) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(58) - Fold 4 - Validation Accuracy : 0.5157\n",
      "Epoch(58) - Fold 4 - Validation Utility score : 988.0585\n",
      "Epoch(58) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(58) - GLOBAL - Validation Accuracy: 0.5162\n",
      "Epoch(58) - GLOBAL - Validation Utility score: 2083.9810\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(59) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(59) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(59) - Fold 0 - Validation Accuracy : 0.5235\n",
      "Epoch(59) - Fold 0 - Validation Utility score : 238.0548\n",
      "Epoch(59) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(59) - Fold 1 - Validation Accuracy : 0.5236\n",
      "Epoch(59) - Fold 1 - Validation Utility score : 532.5309\n",
      "Epoch(59) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(59) - Fold 2 - Validation Accuracy : 0.5080\n",
      "Epoch(59) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(59) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(59) - Fold 3 - Validation Accuracy : 0.5086\n",
      "Epoch(59) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(59) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(59) - Fold 4 - Validation Accuracy : 0.5138\n",
      "Epoch(59) - Fold 4 - Validation Utility score : 1017.2689\n",
      "Epoch(59) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(59) - GLOBAL - Validation Accuracy: 0.5155\n",
      "Epoch(59) - GLOBAL - Validation Utility score: 1787.8546\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(60) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(60) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(60) - Fold 0 - Validation Accuracy : 0.5237\n",
      "Epoch(60) - Fold 0 - Validation Utility score : 245.7532\n",
      "Epoch(60) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(60) - Fold 1 - Validation Accuracy : 0.5246\n",
      "Epoch(60) - Fold 1 - Validation Utility score : 730.6072\n",
      "Epoch(60) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(60) - Fold 2 - Validation Accuracy : 0.5084\n",
      "Epoch(60) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(60) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(60) - Fold 3 - Validation Accuracy : 0.5086\n",
      "Epoch(60) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(60) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(60) - Fold 4 - Validation Accuracy : 0.5149\n",
      "Epoch(60) - Fold 4 - Validation Utility score : 935.6618\n",
      "Epoch(60) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(60) - GLOBAL - Validation Accuracy: 0.5160\n",
      "Epoch(60) - GLOBAL - Validation Utility score: 1912.0223\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(61) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(61) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(61) - Fold 0 - Validation Accuracy : 0.5226\n",
      "Epoch(61) - Fold 0 - Validation Utility score : 270.5037\n",
      "Epoch(61) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(61) - Fold 1 - Validation Accuracy : 0.5239\n",
      "Epoch(61) - Fold 1 - Validation Utility score : 766.0850\n",
      "Epoch(61) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(61) - Fold 2 - Validation Accuracy : 0.5082\n",
      "Epoch(61) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(61) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(61) - Fold 3 - Validation Accuracy : 0.5093\n",
      "Epoch(61) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(61) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(61) - Fold 4 - Validation Accuracy : 0.5157\n",
      "Epoch(61) - Fold 4 - Validation Utility score : 932.4458\n",
      "Epoch(61) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(61) - GLOBAL - Validation Accuracy: 0.5159\n",
      "Epoch(61) - GLOBAL - Validation Utility score: 1969.0345\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(62) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(62) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(62) - Fold 0 - Validation Accuracy : 0.5238\n",
      "Epoch(62) - Fold 0 - Validation Utility score : 305.9983\n",
      "Epoch(62) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(62) - Fold 1 - Validation Accuracy : 0.5255\n",
      "Epoch(62) - Fold 1 - Validation Utility score : 781.5477\n",
      "Epoch(62) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(62) - Fold 2 - Validation Accuracy : 0.5091\n",
      "Epoch(62) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(62) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(62) - Fold 3 - Validation Accuracy : 0.5089\n",
      "Epoch(62) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(62) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(62) - Fold 4 - Validation Accuracy : 0.5170\n",
      "Epoch(62) - Fold 4 - Validation Utility score : 1100.0968\n",
      "Epoch(62) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(62) - GLOBAL - Validation Accuracy: 0.5169\n",
      "Epoch(62) - GLOBAL - Validation Utility score: 2187.6428\n",
      "Saving model corresponding to last_utility_score == 2187.64282272498\n",
      "\n",
      "\n",
      "Epoch(63) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(63) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(63) - Fold 0 - Validation Accuracy : 0.5235\n",
      "Epoch(63) - Fold 0 - Validation Utility score : 297.0906\n",
      "Epoch(63) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(63) - Fold 1 - Validation Accuracy : 0.5244\n",
      "Epoch(63) - Fold 1 - Validation Utility score : 768.6015\n",
      "Epoch(63) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(63) - Fold 2 - Validation Accuracy : 0.5082\n",
      "Epoch(63) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(63) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(63) - Fold 3 - Validation Accuracy : 0.5087\n",
      "Epoch(63) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(63) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(63) - Fold 4 - Validation Accuracy : 0.5157\n",
      "Epoch(63) - Fold 4 - Validation Utility score : 1113.5855\n",
      "Epoch(63) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(63) - GLOBAL - Validation Accuracy: 0.5161\n",
      "Epoch(63) - GLOBAL - Validation Utility score: 2179.2776\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(64) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(64) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(64) - Fold 0 - Validation Accuracy : 0.5228\n",
      "Epoch(64) - Fold 0 - Validation Utility score : 249.9903\n",
      "Epoch(64) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(64) - Fold 1 - Validation Accuracy : 0.5239\n",
      "Epoch(64) - Fold 1 - Validation Utility score : 684.8650\n",
      "Epoch(64) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(64) - Fold 2 - Validation Accuracy : 0.5085\n",
      "Epoch(64) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(64) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(64) - Fold 3 - Validation Accuracy : 0.5091\n",
      "Epoch(64) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(64) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(64) - Fold 4 - Validation Accuracy : 0.5155\n",
      "Epoch(64) - Fold 4 - Validation Utility score : 1064.5913\n",
      "Epoch(64) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(64) - GLOBAL - Validation Accuracy: 0.5160\n",
      "Epoch(64) - GLOBAL - Validation Utility score: 1999.4466\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(65) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(65) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(65) - Fold 0 - Validation Accuracy : 0.5240\n",
      "Epoch(65) - Fold 0 - Validation Utility score : 382.9258\n",
      "Epoch(65) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(65) - Fold 1 - Validation Accuracy : 0.5244\n",
      "Epoch(65) - Fold 1 - Validation Utility score : 785.3330\n",
      "Epoch(65) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(65) - Fold 2 - Validation Accuracy : 0.5074\n",
      "Epoch(65) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(65) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(65) - Fold 3 - Validation Accuracy : 0.5095\n",
      "Epoch(65) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(65) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(65) - Fold 4 - Validation Accuracy : 0.5156\n",
      "Epoch(65) - Fold 4 - Validation Utility score : 1020.1166\n",
      "Epoch(65) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(65) - GLOBAL - Validation Accuracy: 0.5162\n",
      "Epoch(65) - GLOBAL - Validation Utility score: 2188.3754\n",
      "Saving model corresponding to last_utility_score == 2188.3754287562106\n",
      "\n",
      "\n",
      "Epoch(66) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(66) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(66) - Fold 0 - Validation Accuracy : 0.5230\n",
      "Epoch(66) - Fold 0 - Validation Utility score : 274.0078\n",
      "Epoch(66) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(66) - Fold 1 - Validation Accuracy : 0.5237\n",
      "Epoch(66) - Fold 1 - Validation Utility score : 718.2549\n",
      "Epoch(66) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(66) - Fold 2 - Validation Accuracy : 0.5090\n",
      "Epoch(66) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(66) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(66) - Fold 3 - Validation Accuracy : 0.5093\n",
      "Epoch(66) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(66) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(66) - Fold 4 - Validation Accuracy : 0.5175\n",
      "Epoch(66) - Fold 4 - Validation Utility score : 1198.5271\n",
      "Epoch(66) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(66) - GLOBAL - Validation Accuracy: 0.5165\n",
      "Epoch(66) - GLOBAL - Validation Utility score: 2190.7898\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(67) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(67) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(67) - Fold 0 - Validation Accuracy : 0.5238\n",
      "Epoch(67) - Fold 0 - Validation Utility score : 338.7306\n",
      "Epoch(67) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(67) - Fold 1 - Validation Accuracy : 0.5241\n",
      "Epoch(67) - Fold 1 - Validation Utility score : 784.2317\n",
      "Epoch(67) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(67) - Fold 2 - Validation Accuracy : 0.5096\n",
      "Epoch(67) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(67) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(67) - Fold 3 - Validation Accuracy : 0.5090\n",
      "Epoch(67) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(67) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(67) - Fold 4 - Validation Accuracy : 0.5173\n",
      "Epoch(67) - Fold 4 - Validation Utility score : 1182.6866\n",
      "Epoch(67) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(67) - GLOBAL - Validation Accuracy: 0.5168\n",
      "Epoch(67) - GLOBAL - Validation Utility score: 2305.6489\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(68) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(68) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(68) - Fold 0 - Validation Accuracy : 0.5229\n",
      "Epoch(68) - Fold 0 - Validation Utility score : 296.2016\n",
      "Epoch(68) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(68) - Fold 1 - Validation Accuracy : 0.5233\n",
      "Epoch(68) - Fold 1 - Validation Utility score : 729.1149\n",
      "Epoch(68) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(68) - Fold 2 - Validation Accuracy : 0.5098\n",
      "Epoch(68) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(68) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(68) - Fold 3 - Validation Accuracy : 0.5098\n",
      "Epoch(68) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(68) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(68) - Fold 4 - Validation Accuracy : 0.5179\n",
      "Epoch(68) - Fold 4 - Validation Utility score : 1129.2802\n",
      "Epoch(68) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(68) - GLOBAL - Validation Accuracy: 0.5167\n",
      "Epoch(68) - GLOBAL - Validation Utility score: 2154.5967\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(69) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(69) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(69) - Fold 0 - Validation Accuracy : 0.5238\n",
      "Epoch(69) - Fold 0 - Validation Utility score : 394.0027\n",
      "Epoch(69) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(69) - Fold 1 - Validation Accuracy : 0.5245\n",
      "Epoch(69) - Fold 1 - Validation Utility score : 807.4407\n",
      "Epoch(69) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(69) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(69) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(69) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(69) - Fold 3 - Validation Accuracy : 0.5101\n",
      "Epoch(69) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(69) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(69) - Fold 4 - Validation Accuracy : 0.5190\n",
      "Epoch(69) - Fold 4 - Validation Utility score : 1208.9670\n",
      "Epoch(69) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(69) - GLOBAL - Validation Accuracy: 0.5171\n",
      "Epoch(69) - GLOBAL - Validation Utility score: 2410.4104\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(70) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(70) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(70) - Fold 0 - Validation Accuracy : 0.5243\n",
      "Epoch(70) - Fold 0 - Validation Utility score : 442.4899\n",
      "Epoch(70) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(70) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(70) - Fold 1 - Validation Utility score : 792.2806\n",
      "Epoch(70) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(70) - Fold 2 - Validation Accuracy : 0.5088\n",
      "Epoch(70) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(70) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(70) - Fold 3 - Validation Accuracy : 0.5092\n",
      "Epoch(70) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(70) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(70) - Fold 4 - Validation Accuracy : 0.5176\n",
      "Epoch(70) - Fold 4 - Validation Utility score : 1087.2264\n",
      "Epoch(70) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(70) - GLOBAL - Validation Accuracy: 0.5167\n",
      "Epoch(70) - GLOBAL - Validation Utility score: 2321.9970\n",
      "Saving model corresponding to last_utility_score == 2321.996970965809\n",
      "\n",
      "\n",
      "Epoch(71) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(71) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(71) - Fold 0 - Validation Accuracy : 0.5230\n",
      "Epoch(71) - Fold 0 - Validation Utility score : 317.4437\n",
      "Epoch(71) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(71) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(71) - Fold 1 - Validation Utility score : 675.6623\n",
      "Epoch(71) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(71) - Fold 2 - Validation Accuracy : 0.5095\n",
      "Epoch(71) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(71) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(71) - Fold 3 - Validation Accuracy : 0.5092\n",
      "Epoch(71) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(71) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(71) - Fold 4 - Validation Accuracy : 0.5175\n",
      "Epoch(71) - Fold 4 - Validation Utility score : 1102.4515\n",
      "Epoch(71) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(71) - GLOBAL - Validation Accuracy: 0.5165\n",
      "Epoch(71) - GLOBAL - Validation Utility score: 2095.5575\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(72) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(72) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(72) - Fold 0 - Validation Accuracy : 0.5230\n",
      "Epoch(72) - Fold 0 - Validation Utility score : 282.7272\n",
      "Epoch(72) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(72) - Fold 1 - Validation Accuracy : 0.5242\n",
      "Epoch(72) - Fold 1 - Validation Utility score : 849.4446\n",
      "Epoch(72) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(72) - Fold 2 - Validation Accuracy : 0.5101\n",
      "Epoch(72) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(72) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(72) - Fold 3 - Validation Accuracy : 0.5102\n",
      "Epoch(72) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(72) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(72) - Fold 4 - Validation Accuracy : 0.5202\n",
      "Epoch(72) - Fold 4 - Validation Utility score : 1244.3641\n",
      "Epoch(72) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(72) - GLOBAL - Validation Accuracy: 0.5175\n",
      "Epoch(72) - GLOBAL - Validation Utility score: 2376.5360\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(73) - Training Loss: 0.6915\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(73) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(73) - Fold 0 - Validation Accuracy : 0.5232\n",
      "Epoch(73) - Fold 0 - Validation Utility score : 261.3130\n",
      "Epoch(73) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(73) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(73) - Fold 1 - Validation Utility score : 712.7406\n",
      "Epoch(73) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(73) - Fold 2 - Validation Accuracy : 0.5096\n",
      "Epoch(73) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(73) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(73) - Fold 3 - Validation Accuracy : 0.5100\n",
      "Epoch(73) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(73) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(73) - Fold 4 - Validation Accuracy : 0.5182\n",
      "Epoch(73) - Fold 4 - Validation Utility score : 1127.8873\n",
      "Epoch(73) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(73) - GLOBAL - Validation Accuracy: 0.5169\n",
      "Epoch(73) - GLOBAL - Validation Utility score: 2101.9408\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(74) - Training Loss: 0.6915\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(74) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(74) - Fold 0 - Validation Accuracy : 0.5220\n",
      "Epoch(74) - Fold 0 - Validation Utility score : 197.1759\n",
      "Epoch(74) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(74) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(74) - Fold 1 - Validation Utility score : 478.8072\n",
      "Epoch(74) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(74) - Fold 2 - Validation Accuracy : 0.5106\n",
      "Epoch(74) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(74) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(74) - Fold 3 - Validation Accuracy : 0.5090\n",
      "Epoch(74) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(74) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(74) - Fold 4 - Validation Accuracy : 0.5164\n",
      "Epoch(74) - Fold 4 - Validation Utility score : 972.9322\n",
      "Epoch(74) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(74) - GLOBAL - Validation Accuracy: 0.5163\n",
      "Epoch(74) - GLOBAL - Validation Utility score: 1648.9152\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(75) - Training Loss: 0.6915\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(75) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(75) - Fold 0 - Validation Accuracy : 0.5239\n",
      "Epoch(75) - Fold 0 - Validation Utility score : 294.9533\n",
      "Epoch(75) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(75) - Fold 1 - Validation Accuracy : 0.5243\n",
      "Epoch(75) - Fold 1 - Validation Utility score : 818.3173\n",
      "Epoch(75) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(75) - Fold 2 - Validation Accuracy : 0.5103\n",
      "Epoch(75) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(75) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(75) - Fold 3 - Validation Accuracy : 0.5102\n",
      "Epoch(75) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(75) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(75) - Fold 4 - Validation Accuracy : 0.5207\n",
      "Epoch(75) - Fold 4 - Validation Utility score : 1202.5090\n",
      "Epoch(75) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(75) - GLOBAL - Validation Accuracy: 0.5179\n",
      "Epoch(75) - GLOBAL - Validation Utility score: 2315.7796\n",
      "Saving model corresponding to last_utility_score == 2315.7796392537093\n",
      "\n",
      "\n",
      "Epoch(76) - Training Loss: 0.6915\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(76) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(76) - Fold 0 - Validation Accuracy : 0.5233\n",
      "Epoch(76) - Fold 0 - Validation Utility score : 239.0323\n",
      "Epoch(76) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(76) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(76) - Fold 1 - Validation Utility score : 609.4483\n",
      "Epoch(76) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(76) - Fold 2 - Validation Accuracy : 0.5098\n",
      "Epoch(76) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(76) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(76) - Fold 3 - Validation Accuracy : 0.5089\n",
      "Epoch(76) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(76) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(76) - Fold 4 - Validation Accuracy : 0.5182\n",
      "Epoch(76) - Fold 4 - Validation Utility score : 1142.8863\n",
      "Epoch(76) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(76) - GLOBAL - Validation Accuracy: 0.5167\n",
      "Epoch(76) - GLOBAL - Validation Utility score: 1991.3668\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(77) - Training Loss: 0.6915\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(77) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(77) - Fold 0 - Validation Accuracy : 0.5243\n",
      "Epoch(77) - Fold 0 - Validation Utility score : 339.4335\n",
      "Epoch(77) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(77) - Fold 1 - Validation Accuracy : 0.5237\n",
      "Epoch(77) - Fold 1 - Validation Utility score : 739.3844\n",
      "Epoch(77) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(77) - Fold 2 - Validation Accuracy : 0.5095\n",
      "Epoch(77) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(77) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(77) - Fold 3 - Validation Accuracy : 0.5100\n",
      "Epoch(77) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(77) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(77) - Fold 4 - Validation Accuracy : 0.5191\n",
      "Epoch(77) - Fold 4 - Validation Utility score : 1216.9649\n",
      "Epoch(77) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(77) - GLOBAL - Validation Accuracy: 0.5173\n",
      "Epoch(77) - GLOBAL - Validation Utility score: 2295.7829\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(78) - Training Loss: 0.6915\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(78) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(78) - Fold 0 - Validation Accuracy : 0.5244\n",
      "Epoch(78) - Fold 0 - Validation Utility score : 346.0169\n",
      "Epoch(78) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(78) - Fold 1 - Validation Accuracy : 0.5246\n",
      "Epoch(78) - Fold 1 - Validation Utility score : 749.8628\n",
      "Epoch(78) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(78) - Fold 2 - Validation Accuracy : 0.5091\n",
      "Epoch(78) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(78) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(78) - Fold 3 - Validation Accuracy : 0.5104\n",
      "Epoch(78) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(78) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(78) - Fold 4 - Validation Accuracy : 0.5199\n",
      "Epoch(78) - Fold 4 - Validation Utility score : 1211.4109\n",
      "Epoch(78) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(78) - GLOBAL - Validation Accuracy: 0.5177\n",
      "Epoch(78) - GLOBAL - Validation Utility score: 2307.2906\n",
      "Saving model corresponding to last_utility_score == 2307.2906353344806\n",
      "\n",
      "\n",
      "Epoch(79) - Training Loss: 0.6914\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(79) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(79) - Fold 0 - Validation Accuracy : 0.5238\n",
      "Epoch(79) - Fold 0 - Validation Utility score : 346.6385\n",
      "Epoch(79) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(79) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(79) - Fold 1 - Validation Utility score : 719.3190\n",
      "Epoch(79) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(79) - Fold 2 - Validation Accuracy : 0.5096\n",
      "Epoch(79) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(79) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(79) - Fold 3 - Validation Accuracy : 0.5100\n",
      "Epoch(79) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(79) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(79) - Fold 4 - Validation Accuracy : 0.5200\n",
      "Epoch(79) - Fold 4 - Validation Utility score : 1274.3771\n",
      "Epoch(79) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(79) - GLOBAL - Validation Accuracy: 0.5175\n",
      "Epoch(79) - GLOBAL - Validation Utility score: 2340.3346\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(80) - Training Loss: 0.6915\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(80) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(80) - Fold 0 - Validation Accuracy : 0.5236\n",
      "Epoch(80) - Fold 0 - Validation Utility score : 361.3651\n",
      "Epoch(80) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(80) - Fold 1 - Validation Accuracy : 0.5237\n",
      "Epoch(80) - Fold 1 - Validation Utility score : 619.7368\n",
      "Epoch(80) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(80) - Fold 2 - Validation Accuracy : 0.5099\n",
      "Epoch(80) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(80) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(80) - Fold 3 - Validation Accuracy : 0.5088\n",
      "Epoch(80) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(80) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(80) - Fold 4 - Validation Accuracy : 0.5200\n",
      "Epoch(80) - Fold 4 - Validation Utility score : 1214.0538\n",
      "Epoch(80) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(80) - GLOBAL - Validation Accuracy: 0.5172\n",
      "Epoch(80) - GLOBAL - Validation Utility score: 2195.1557\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(81) - Training Loss: 0.6914\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(81) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(81) - Fold 0 - Validation Accuracy : 0.5243\n",
      "Epoch(81) - Fold 0 - Validation Utility score : 404.2042\n",
      "Epoch(81) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(81) - Fold 1 - Validation Accuracy : 0.5241\n",
      "Epoch(81) - Fold 1 - Validation Utility score : 758.2329\n",
      "Epoch(81) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(81) - Fold 2 - Validation Accuracy : 0.5103\n",
      "Epoch(81) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(81) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(81) - Fold 3 - Validation Accuracy : 0.5097\n",
      "Epoch(81) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(81) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(81) - Fold 4 - Validation Accuracy : 0.5188\n",
      "Epoch(81) - Fold 4 - Validation Utility score : 1099.6449\n",
      "Epoch(81) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(81) - GLOBAL - Validation Accuracy: 0.5174\n",
      "Epoch(81) - GLOBAL - Validation Utility score: 2262.0820\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(82) - Training Loss: 0.6914\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(82) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(82) - Fold 0 - Validation Accuracy : 0.5234\n",
      "Epoch(82) - Fold 0 - Validation Utility score : 289.8212\n",
      "Epoch(82) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(82) - Fold 1 - Validation Accuracy : 0.5245\n",
      "Epoch(82) - Fold 1 - Validation Utility score : 837.4455\n",
      "Epoch(82) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(82) - Fold 2 - Validation Accuracy : 0.5094\n",
      "Epoch(82) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(82) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(82) - Fold 3 - Validation Accuracy : 0.5113\n",
      "Epoch(82) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(82) - Fold 4 - Validation Loss : 0.6912\n",
      "Epoch(82) - Fold 4 - Validation Accuracy : 0.5210\n",
      "Epoch(82) - Fold 4 - Validation Utility score : 1208.4989\n",
      "Epoch(82) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(82) - GLOBAL - Validation Accuracy: 0.5179\n",
      "Epoch(82) - GLOBAL - Validation Utility score: 2335.7657\n",
      "Saving model corresponding to last_utility_score == 2335.7656505704426\n",
      "\n",
      "\n",
      "Epoch(83) - Training Loss: 0.6914\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(83) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(83) - Fold 0 - Validation Accuracy : 0.5235\n",
      "Epoch(83) - Fold 0 - Validation Utility score : 375.4501\n",
      "Epoch(83) - Fold 1 - Validation Loss : 0.6909\n",
      "Epoch(83) - Fold 1 - Validation Accuracy : 0.5249\n",
      "Epoch(83) - Fold 1 - Validation Utility score : 826.8435\n",
      "Epoch(83) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(83) - Fold 2 - Validation Accuracy : 0.5100\n",
      "Epoch(83) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(83) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(83) - Fold 3 - Validation Accuracy : 0.5110\n",
      "Epoch(83) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(83) - Fold 4 - Validation Loss : 0.6912\n",
      "Epoch(83) - Fold 4 - Validation Accuracy : 0.5218\n",
      "Epoch(83) - Fold 4 - Validation Utility score : 1130.7225\n",
      "Epoch(83) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(83) - GLOBAL - Validation Accuracy: 0.5182\n",
      "Epoch(83) - GLOBAL - Validation Utility score: 2333.0162\n",
      "Saving model corresponding to last_utility_score == 2333.0161721868444\n",
      "\n",
      "\n",
      "Epoch(84) - Training Loss: 0.6913\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(84) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(84) - Fold 0 - Validation Accuracy : 0.5248\n",
      "Epoch(84) - Fold 0 - Validation Utility score : 349.0884\n",
      "Epoch(84) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(84) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(84) - Fold 1 - Validation Utility score : 795.8586\n",
      "Epoch(84) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(84) - Fold 2 - Validation Accuracy : 0.5102\n",
      "Epoch(84) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(84) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(84) - Fold 3 - Validation Accuracy : 0.5106\n",
      "Epoch(84) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(84) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(84) - Fold 4 - Validation Accuracy : 0.5198\n",
      "Epoch(84) - Fold 4 - Validation Utility score : 1045.8757\n",
      "Epoch(84) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(84) - GLOBAL - Validation Accuracy: 0.5177\n",
      "Epoch(84) - GLOBAL - Validation Utility score: 2190.8226\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(85) - Training Loss: 0.6914\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(85) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(85) - Fold 0 - Validation Accuracy : 0.5229\n",
      "Epoch(85) - Fold 0 - Validation Utility score : 317.3233\n",
      "Epoch(85) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(85) - Fold 1 - Validation Accuracy : 0.5248\n",
      "Epoch(85) - Fold 1 - Validation Utility score : 864.3357\n",
      "Epoch(85) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(85) - Fold 2 - Validation Accuracy : 0.5106\n",
      "Epoch(85) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(85) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(85) - Fold 3 - Validation Accuracy : 0.5104\n",
      "Epoch(85) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(85) - Fold 4 - Validation Loss : 0.6912\n",
      "Epoch(85) - Fold 4 - Validation Accuracy : 0.5224\n",
      "Epoch(85) - Fold 4 - Validation Utility score : 1285.7736\n",
      "Epoch(85) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(85) - GLOBAL - Validation Accuracy: 0.5182\n",
      "Epoch(85) - GLOBAL - Validation Utility score: 2467.4325\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(86) - Training Loss: 0.6914\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(86) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(86) - Fold 0 - Validation Accuracy : 0.5233\n",
      "Epoch(86) - Fold 0 - Validation Utility score : 268.0307\n",
      "Epoch(86) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(86) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(86) - Fold 1 - Validation Utility score : 687.7732\n",
      "Epoch(86) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(86) - Fold 2 - Validation Accuracy : 0.5110\n",
      "Epoch(86) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(86) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(86) - Fold 3 - Validation Accuracy : 0.5102\n",
      "Epoch(86) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(86) - Fold 4 - Validation Loss : 0.6912\n",
      "Epoch(86) - Fold 4 - Validation Accuracy : 0.5202\n",
      "Epoch(86) - Fold 4 - Validation Utility score : 1308.1439\n",
      "Epoch(86) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(86) - GLOBAL - Validation Accuracy: 0.5176\n",
      "Epoch(86) - GLOBAL - Validation Utility score: 2263.9479\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(87) - Training Loss: 0.6913\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(87) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(87) - Fold 0 - Validation Accuracy : 0.5241\n",
      "Epoch(87) - Fold 0 - Validation Utility score : 308.0719\n",
      "Epoch(87) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(87) - Fold 1 - Validation Accuracy : 0.5247\n",
      "Epoch(87) - Fold 1 - Validation Utility score : 824.9930\n",
      "Epoch(87) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(87) - Fold 2 - Validation Accuracy : 0.5096\n",
      "Epoch(87) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(87) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(87) - Fold 3 - Validation Accuracy : 0.5117\n",
      "Epoch(87) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(87) - Fold 4 - Validation Loss : 0.6911\n",
      "Epoch(87) - Fold 4 - Validation Accuracy : 0.5223\n",
      "Epoch(87) - Fold 4 - Validation Utility score : 1319.3173\n",
      "Epoch(87) - GLOBAL - Validation Loss: 0.6918\n",
      "Epoch(87) - GLOBAL - Validation Accuracy: 0.5185\n",
      "Epoch(87) - GLOBAL - Validation Utility score: 2452.3822\n",
      "Saving model corresponding to last_utility_score == 2452.3822098664223\n",
      "\n",
      "\n",
      "Epoch(88) - Training Loss: 0.6913\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(88) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(88) - Fold 0 - Validation Accuracy : 0.5231\n",
      "Epoch(88) - Fold 0 - Validation Utility score : 334.1190\n",
      "Epoch(88) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(88) - Fold 1 - Validation Accuracy : 0.5241\n",
      "Epoch(88) - Fold 1 - Validation Utility score : 965.4987\n",
      "Epoch(88) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(88) - Fold 2 - Validation Accuracy : 0.5110\n",
      "Epoch(88) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(88) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(88) - Fold 3 - Validation Accuracy : 0.5118\n",
      "Epoch(88) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(88) - Fold 4 - Validation Loss : 0.6911\n",
      "Epoch(88) - Fold 4 - Validation Accuracy : 0.5221\n",
      "Epoch(88) - Fold 4 - Validation Utility score : 1361.7795\n",
      "Epoch(88) - GLOBAL - Validation Loss: 0.6918\n",
      "Epoch(88) - GLOBAL - Validation Accuracy: 0.5184\n",
      "Epoch(88) - GLOBAL - Validation Utility score: 2661.3972\n",
      "Saving model corresponding to last_utility_score == 2661.397193334107\n",
      "\n",
      "\n",
      "Epoch(89) - Training Loss: 0.6913\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(89) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(89) - Fold 0 - Validation Accuracy : 0.5244\n",
      "Epoch(89) - Fold 0 - Validation Utility score : 342.7289\n",
      "Epoch(89) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(89) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(89) - Fold 1 - Validation Utility score : 713.3629\n",
      "Epoch(89) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(89) - Fold 2 - Validation Accuracy : 0.5107\n",
      "Epoch(89) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(89) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(89) - Fold 3 - Validation Accuracy : 0.5108\n",
      "Epoch(89) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(89) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(89) - Fold 4 - Validation Accuracy : 0.5201\n",
      "Epoch(89) - Fold 4 - Validation Utility score : 1152.9646\n",
      "Epoch(89) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(89) - GLOBAL - Validation Accuracy: 0.5180\n",
      "Epoch(89) - GLOBAL - Validation Utility score: 2209.0563\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(90) - Training Loss: 0.6913\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(90) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(90) - Fold 0 - Validation Accuracy : 0.5229\n",
      "Epoch(90) - Fold 0 - Validation Utility score : 293.3196\n",
      "Epoch(90) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(90) - Fold 1 - Validation Accuracy : 0.5247\n",
      "Epoch(90) - Fold 1 - Validation Utility score : 694.5301\n",
      "Epoch(90) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(90) - Fold 2 - Validation Accuracy : 0.5110\n",
      "Epoch(90) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(90) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(90) - Fold 3 - Validation Accuracy : 0.5097\n",
      "Epoch(90) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(90) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(90) - Fold 4 - Validation Accuracy : 0.5208\n",
      "Epoch(90) - Fold 4 - Validation Utility score : 1046.8726\n",
      "Epoch(90) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(90) - GLOBAL - Validation Accuracy: 0.5178\n",
      "Epoch(90) - GLOBAL - Validation Utility score: 2034.7223\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(91) - Training Loss: 0.6912\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(91) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(91) - Fold 0 - Validation Accuracy : 0.5239\n",
      "Epoch(91) - Fold 0 - Validation Utility score : 255.7172\n",
      "Epoch(91) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(91) - Fold 1 - Validation Accuracy : 0.5242\n",
      "Epoch(91) - Fold 1 - Validation Utility score : 705.4773\n",
      "Epoch(91) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(91) - Fold 2 - Validation Accuracy : 0.5113\n",
      "Epoch(91) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(91) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(91) - Fold 3 - Validation Accuracy : 0.5098\n",
      "Epoch(91) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(91) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(91) - Fold 4 - Validation Accuracy : 0.5188\n",
      "Epoch(91) - Fold 4 - Validation Utility score : 1223.6782\n",
      "Epoch(91) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(91) - GLOBAL - Validation Accuracy: 0.5176\n",
      "Epoch(91) - GLOBAL - Validation Utility score: 2184.8728\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(92) - Training Loss: 0.6912\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(92) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(92) - Fold 0 - Validation Accuracy : 0.5235\n",
      "Epoch(92) - Fold 0 - Validation Utility score : 298.2738\n",
      "Epoch(92) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(92) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(92) - Fold 1 - Validation Utility score : 682.0349\n",
      "Epoch(92) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(92) - Fold 2 - Validation Accuracy : 0.5114\n",
      "Epoch(92) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(92) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(92) - Fold 3 - Validation Accuracy : 0.5101\n",
      "Epoch(92) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(92) - Fold 4 - Validation Loss : 0.6912\n",
      "Epoch(92) - Fold 4 - Validation Accuracy : 0.5206\n",
      "Epoch(92) - Fold 4 - Validation Utility score : 1313.4019\n",
      "Epoch(92) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(92) - GLOBAL - Validation Accuracy: 0.5178\n",
      "Epoch(92) - GLOBAL - Validation Utility score: 2293.7106\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(93) - Training Loss: 0.6912\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(93) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(93) - Fold 0 - Validation Accuracy : 0.5236\n",
      "Epoch(93) - Fold 0 - Validation Utility score : 315.0869\n",
      "Epoch(93) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(93) - Fold 1 - Validation Accuracy : 0.5233\n",
      "Epoch(93) - Fold 1 - Validation Utility score : 608.8472\n",
      "Epoch(93) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(93) - Fold 2 - Validation Accuracy : 0.5110\n",
      "Epoch(93) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(93) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(93) - Fold 3 - Validation Accuracy : 0.5092\n",
      "Epoch(93) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(93) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(93) - Fold 4 - Validation Accuracy : 0.5196\n",
      "Epoch(93) - Fold 4 - Validation Utility score : 1224.1463\n",
      "Epoch(93) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(93) - GLOBAL - Validation Accuracy: 0.5173\n",
      "Epoch(93) - GLOBAL - Validation Utility score: 2148.0803\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6918\n",
      "Meet Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 514379<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_065303-f6c9bgls/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_065303-f6c9bgls/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>0.69125</td></tr><tr><td>Global valid/Loss</td><td>0.692</td></tr><tr><td>Global valid/Accuracy</td><td>0.51735</td></tr><tr><td>Global valid/Utility</td><td>2148.08033</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>0.69161</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>0.52361</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>315.08688</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>0.69124</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>0.52333</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>608.84716</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>0.6929</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>0.51102</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>0.6928</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>0.50922</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>0.69145</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>0.51956</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>1224.14629</td></tr><tr><td>Best accuracy</td><td>0.51843</td></tr><tr><td>Best utility</td><td>2661.39719</td></tr><tr><td>_runtime</td><td>5732</td></tr><tr><td>_timestamp</td><td>1613460515</td></tr><tr><td>_step</td><td>93</td></tr><tr><td>Final utility score</td><td>{'utility_score': 26...</td></tr><tr><td>Batch size</td><td>47168</td></tr><tr><td>Patience</td><td>5</td></tr><tr><td>Number of epochs</td><td>1000</td></tr><tr><td>Best epoch</td><td>88</td></tr><tr><td>Number of parameters per layer</td><td>[8384, 64, 2048, 32,...</td></tr><tr><td>Model architecture</td><td>MLP(<BR>  (AEncoder)...</td></tr><tr><td>comment</td><td>All folds MLP with a...</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Accuracy</td><td>▁▁▁▂▂▂▂▃▃▃▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>Global valid/Utility</td><td>▁▁▁▁▁▁▁▁▁▁▃▃▃▅▄▅▄▅▅▅▅▅▆▆▆▆▇▆▇▇▇▇▆▇▇▇▇█▆▇</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>█▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>▁▁▁▁▁▂▂▃▃▃▅▅▆▇▆▇▇▇▇▇████████████████████</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▃▂▃▃▃▄▄▅▅▆▅▇▅▆▅▆█▆▆▅▇██▆▇▆▆</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>█▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>▁▁▁▂▂▂▂▃▃▃▅▆▆▇▇▇▇▇▇▇▇▇███▇█▇▇█▇▇▇█▇████▇</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>▁▁▁▁▁▁▁▁▁▁▂▃▃▄▄▄▄▄▄▄▅▆▆▆▇▅▇▆▆▇▆▆▅▆▆▇▇█▆▅</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>▁▁▂▃▃▃▃▃▃▃▅▆▆▆▆▆▆▇▇▆▆▆▆▆▆▆▇▆▇▆▇▇▇▇█▇████</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>▁▂▁▂▂▂▂▃▄▄▅▆▆▅▅▅▅▅▆▅▅▆▆▆▆▆▆▆▇▇▆▇▆▇▇█▇█▇▆</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>█▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>▁▁▁▁▁▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▅▆▆▇▇▇▇▇▇▇████▇</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>▁▁▁▁▁▁▁▂▂▂▄▄▄▅▄▅▅▅▆▆▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇██▆▇</td></tr><tr><td>Best accuracy</td><td>▁▁▂▂▂▂▂▃▂▃▃▃▃▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>Best utility</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▃▄▅▅▅▅▅▅▅▅▅▅▅▆▆▇▇▇▇▇▇▇█</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 471 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">stilted-sweep-6</strong>: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/f6c9bgls\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/f6c9bgls</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training summary:\n",
      "{'utility_score': 2661.397193334107, 'utility_scores': [334.11901676276307, 965.4987172394525, -0.0, -0.0, 1361.7794593318915], 'utility_score_std': 544.3637721366972, 'accuracy_scores': [0.5230755056625703, 0.5241488241488241, 0.5109885960274904, 0.5118253700264506, 0.5220946612198901]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9a6ez55a with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leakyrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 54819\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4331434039411769\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0017668311378490752\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_autoenc: encoder-only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.2922198786496859e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">restful-sweep-7</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/9a6ez55a\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/9a6ez55a</a><br/>\n",
       "                Run data is saved locally in <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_082840-9a6ez55a</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Run config :\n",
      "config: {'activation_function': 'leakyrelu', 'batch_size': 54819, 'dropout': 0.4331434039411769, 'learning_rate': 0.0017668311378490752, 'use_autoenc': 'encoder-only', 'weight_decay': 1.2922198786496859e-05, 'epochs': 1000}\n",
      "Epoch(0) - Training Loss: 0.8936\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(0) - Fold 0 - Validation Loss : 0.6985\n",
      "Epoch(0) - Fold 0 - Validation Accuracy : 0.5048\n",
      "Epoch(0) - Fold 0 - Validation Utility score : 33.7420\n",
      "Epoch(0) - Fold 1 - Validation Loss : 0.6970\n",
      "Epoch(0) - Fold 1 - Validation Accuracy : 0.5026\n",
      "Epoch(0) - Fold 1 - Validation Utility score : 28.8405\n",
      "Epoch(0) - Fold 2 - Validation Loss : 0.6984\n",
      "Epoch(0) - Fold 2 - Validation Accuracy : 0.4960\n",
      "Epoch(0) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 3 - Validation Loss : 0.6973\n",
      "Epoch(0) - Fold 3 - Validation Accuracy : 0.5018\n",
      "Epoch(0) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 4 - Validation Loss : 0.6993\n",
      "Epoch(0) - Fold 4 - Validation Accuracy : 0.4913\n",
      "Epoch(0) - Fold 4 - Validation Utility score : -0.0000\n",
      "Epoch(0) - GLOBAL - Validation Loss: 0.6981\n",
      "Epoch(0) - GLOBAL - Validation Accuracy: 0.4993\n",
      "Epoch(0) - GLOBAL - Validation Utility score: 62.5825\n",
      "Saving model corresponding to last_utility_score == 62.5825022635848\n",
      "\n",
      "\n",
      "Epoch(1) - Training Loss: 0.7896\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(1) - Fold 0 - Validation Loss : 0.6954\n",
      "Epoch(1) - Fold 0 - Validation Accuracy : 0.5018\n",
      "Epoch(1) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 1 - Validation Loss : 0.6951\n",
      "Epoch(1) - Fold 1 - Validation Accuracy : 0.5053\n",
      "Epoch(1) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 2 - Validation Loss : 0.6953\n",
      "Epoch(1) - Fold 2 - Validation Accuracy : 0.5006\n",
      "Epoch(1) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 3 - Validation Loss : 0.6957\n",
      "Epoch(1) - Fold 3 - Validation Accuracy : 0.5008\n",
      "Epoch(1) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 4 - Validation Loss : 0.6956\n",
      "Epoch(1) - Fold 4 - Validation Accuracy : 0.4982\n",
      "Epoch(1) - Fold 4 - Validation Utility score : 7.5043\n",
      "Epoch(1) - GLOBAL - Validation Loss: 0.6954\n",
      "Epoch(1) - GLOBAL - Validation Accuracy: 0.5014\n",
      "Epoch(1) - GLOBAL - Validation Utility score: 7.5043\n",
      "Saving model corresponding to last_utility_score == 7.504280177806259\n",
      "\n",
      "\n",
      "Epoch(2) - Training Loss: 0.7277\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(2) - Fold 0 - Validation Loss : 0.6948\n",
      "Epoch(2) - Fold 0 - Validation Accuracy : 0.5001\n",
      "Epoch(2) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 1 - Validation Loss : 0.6946\n",
      "Epoch(2) - Fold 1 - Validation Accuracy : 0.5056\n",
      "Epoch(2) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 2 - Validation Loss : 0.6946\n",
      "Epoch(2) - Fold 2 - Validation Accuracy : 0.5019\n",
      "Epoch(2) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 3 - Validation Loss : 0.6950\n",
      "Epoch(2) - Fold 3 - Validation Accuracy : 0.5000\n",
      "Epoch(2) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 4 - Validation Loss : 0.6949\n",
      "Epoch(2) - Fold 4 - Validation Accuracy : 0.4986\n",
      "Epoch(2) - Fold 4 - Validation Utility score : 20.0155\n",
      "Epoch(2) - GLOBAL - Validation Loss: 0.6948\n",
      "Epoch(2) - GLOBAL - Validation Accuracy: 0.5012\n",
      "Epoch(2) - GLOBAL - Validation Utility score: 20.0155\n",
      "Saving model corresponding to last_utility_score == 20.0155447451204\n",
      "\n",
      "\n",
      "Epoch(3) - Training Loss: 0.7027\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(3) - Fold 0 - Validation Loss : 0.6947\n",
      "Epoch(3) - Fold 0 - Validation Accuracy : 0.5001\n",
      "Epoch(3) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 1 - Validation Loss : 0.6939\n",
      "Epoch(3) - Fold 1 - Validation Accuracy : 0.5062\n",
      "Epoch(3) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 2 - Validation Loss : 0.6942\n",
      "Epoch(3) - Fold 2 - Validation Accuracy : 0.5019\n",
      "Epoch(3) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 3 - Validation Loss : 0.6944\n",
      "Epoch(3) - Fold 3 - Validation Accuracy : 0.4998\n",
      "Epoch(3) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 4 - Validation Loss : 0.6945\n",
      "Epoch(3) - Fold 4 - Validation Accuracy : 0.4989\n",
      "Epoch(3) - Fold 4 - Validation Utility score : 17.6810\n",
      "Epoch(3) - GLOBAL - Validation Loss: 0.6944\n",
      "Epoch(3) - GLOBAL - Validation Accuracy: 0.5014\n",
      "Epoch(3) - GLOBAL - Validation Utility score: 17.6810\n",
      "Saving model corresponding to last_utility_score == 17.68095136672336\n",
      "\n",
      "\n",
      "Epoch(4) - Training Loss: 0.6959\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(4) - Fold 0 - Validation Loss : 0.6939\n",
      "Epoch(4) - Fold 0 - Validation Accuracy : 0.5002\n",
      "Epoch(4) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 1 - Validation Loss : 0.6933\n",
      "Epoch(4) - Fold 1 - Validation Accuracy : 0.5062\n",
      "Epoch(4) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 2 - Validation Loss : 0.6938\n",
      "Epoch(4) - Fold 2 - Validation Accuracy : 0.5020\n",
      "Epoch(4) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 3 - Validation Loss : 0.6939\n",
      "Epoch(4) - Fold 3 - Validation Accuracy : 0.4997\n",
      "Epoch(4) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 4 - Validation Loss : 0.6940\n",
      "Epoch(4) - Fold 4 - Validation Accuracy : 0.4988\n",
      "Epoch(4) - Fold 4 - Validation Utility score : 17.0741\n",
      "Epoch(4) - GLOBAL - Validation Loss: 0.6938\n",
      "Epoch(4) - GLOBAL - Validation Accuracy: 0.5014\n",
      "Epoch(4) - GLOBAL - Validation Utility score: 17.0741\n",
      "Saving model corresponding to last_utility_score == 17.074097798565663\n",
      "\n",
      "\n",
      "Epoch(5) - Training Loss: 0.6944\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(5) - Fold 0 - Validation Loss : 0.6934\n",
      "Epoch(5) - Fold 0 - Validation Accuracy : 0.5010\n",
      "Epoch(5) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 1 - Validation Loss : 0.6929\n",
      "Epoch(5) - Fold 1 - Validation Accuracy : 0.5079\n",
      "Epoch(5) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 2 - Validation Loss : 0.6934\n",
      "Epoch(5) - Fold 2 - Validation Accuracy : 0.5027\n",
      "Epoch(5) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 3 - Validation Loss : 0.6935\n",
      "Epoch(5) - Fold 3 - Validation Accuracy : 0.5014\n",
      "Epoch(5) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 4 - Validation Loss : 0.6936\n",
      "Epoch(5) - Fold 4 - Validation Accuracy : 0.4998\n",
      "Epoch(5) - Fold 4 - Validation Utility score : 28.6315\n",
      "Epoch(5) - GLOBAL - Validation Loss: 0.6933\n",
      "Epoch(5) - GLOBAL - Validation Accuracy: 0.5026\n",
      "Epoch(5) - GLOBAL - Validation Utility score: 28.6315\n",
      "Saving model corresponding to last_utility_score == 28.63151494044382\n",
      "\n",
      "\n",
      "Epoch(6) - Training Loss: 0.6939\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(6) - Fold 0 - Validation Loss : 0.6932\n",
      "Epoch(6) - Fold 0 - Validation Accuracy : 0.5021\n",
      "Epoch(6) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(6) - Fold 1 - Validation Accuracy : 0.5086\n",
      "Epoch(6) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(6) - Fold 2 - Validation Accuracy : 0.5016\n",
      "Epoch(6) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(6) - Fold 3 - Validation Accuracy : 0.5021\n",
      "Epoch(6) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 4 - Validation Loss : 0.6935\n",
      "Epoch(6) - Fold 4 - Validation Accuracy : 0.5000\n",
      "Epoch(6) - Fold 4 - Validation Utility score : 26.9373\n",
      "Epoch(6) - GLOBAL - Validation Loss: 0.6933\n",
      "Epoch(6) - GLOBAL - Validation Accuracy: 0.5029\n",
      "Epoch(6) - GLOBAL - Validation Utility score: 26.9373\n",
      "Saving model corresponding to last_utility_score == 26.937329321107438\n",
      "\n",
      "\n",
      "Epoch(7) - Training Loss: 0.6936\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(7) - Fold 0 - Validation Loss : 0.6930\n",
      "Epoch(7) - Fold 0 - Validation Accuracy : 0.5071\n",
      "Epoch(7) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 1 - Validation Loss : 0.6926\n",
      "Epoch(7) - Fold 1 - Validation Accuracy : 0.5133\n",
      "Epoch(7) - Fold 1 - Validation Utility score : 66.5838\n",
      "Epoch(7) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(7) - Fold 2 - Validation Accuracy : 0.5013\n",
      "Epoch(7) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(7) - Fold 3 - Validation Accuracy : 0.5042\n",
      "Epoch(7) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 4 - Validation Loss : 0.6933\n",
      "Epoch(7) - Fold 4 - Validation Accuracy : 0.5028\n",
      "Epoch(7) - Fold 4 - Validation Utility score : 179.2370\n",
      "Epoch(7) - GLOBAL - Validation Loss: 0.6931\n",
      "Epoch(7) - GLOBAL - Validation Accuracy: 0.5057\n",
      "Epoch(7) - GLOBAL - Validation Utility score: 245.8208\n",
      "Saving model corresponding to last_utility_score == 245.8207872264039\n",
      "\n",
      "\n",
      "Epoch(8) - Training Loss: 0.6935\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(8) - Fold 0 - Validation Loss : 0.6930\n",
      "Epoch(8) - Fold 0 - Validation Accuracy : 0.5047\n",
      "Epoch(8) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 1 - Validation Loss : 0.6926\n",
      "Epoch(8) - Fold 1 - Validation Accuracy : 0.5105\n",
      "Epoch(8) - Fold 1 - Validation Utility score : 8.0147\n",
      "Epoch(8) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(8) - Fold 2 - Validation Accuracy : 0.5018\n",
      "Epoch(8) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(8) - Fold 3 - Validation Accuracy : 0.5036\n",
      "Epoch(8) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 4 - Validation Loss : 0.6933\n",
      "Epoch(8) - Fold 4 - Validation Accuracy : 0.5014\n",
      "Epoch(8) - Fold 4 - Validation Utility score : 66.3216\n",
      "Epoch(8) - GLOBAL - Validation Loss: 0.6931\n",
      "Epoch(8) - GLOBAL - Validation Accuracy: 0.5044\n",
      "Epoch(8) - GLOBAL - Validation Utility score: 74.3362\n",
      "Intermediate early stopping : vepoch_loss = 0.6931, the_last_loss=0.6931\n",
      "\n",
      "\n",
      "Epoch(9) - Training Loss: 0.6934\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(9) - Fold 0 - Validation Loss : 0.6930\n",
      "Epoch(9) - Fold 0 - Validation Accuracy : 0.5036\n",
      "Epoch(9) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 1 - Validation Loss : 0.6926\n",
      "Epoch(9) - Fold 1 - Validation Accuracy : 0.5094\n",
      "Epoch(9) - Fold 1 - Validation Utility score : 0.4811\n",
      "Epoch(9) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(9) - Fold 2 - Validation Accuracy : 0.5017\n",
      "Epoch(9) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(9) - Fold 3 - Validation Accuracy : 0.5034\n",
      "Epoch(9) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 4 - Validation Loss : 0.6934\n",
      "Epoch(9) - Fold 4 - Validation Accuracy : 0.5017\n",
      "Epoch(9) - Fold 4 - Validation Utility score : 86.8331\n",
      "Epoch(9) - GLOBAL - Validation Loss: 0.6931\n",
      "Epoch(9) - GLOBAL - Validation Accuracy: 0.5040\n",
      "Epoch(9) - GLOBAL - Validation Utility score: 87.3141\n",
      "Intermediate early stopping : vepoch_loss = 0.6931, the_last_loss=0.6931\n",
      "\n",
      "\n",
      "Epoch(10) - Training Loss: 0.6933\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(10) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(10) - Fold 0 - Validation Accuracy : 0.5103\n",
      "Epoch(10) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(10) - Fold 1 - Validation Accuracy : 0.5149\n",
      "Epoch(10) - Fold 1 - Validation Utility score : 145.0689\n",
      "Epoch(10) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(10) - Fold 2 - Validation Accuracy : 0.5030\n",
      "Epoch(10) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(10) - Fold 3 - Validation Accuracy : 0.5053\n",
      "Epoch(10) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 4 - Validation Loss : 0.6932\n",
      "Epoch(10) - Fold 4 - Validation Accuracy : 0.5040\n",
      "Epoch(10) - Fold 4 - Validation Utility score : 285.8538\n",
      "Epoch(10) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(10) - GLOBAL - Validation Accuracy: 0.5075\n",
      "Epoch(10) - GLOBAL - Validation Utility score: 430.9227\n",
      "Saving model corresponding to last_utility_score == 430.9227353768625\n",
      "\n",
      "\n",
      "Epoch(11) - Training Loss: 0.6933\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(11) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(11) - Fold 0 - Validation Accuracy : 0.5108\n",
      "Epoch(11) - Fold 0 - Validation Utility score : 0.0043\n",
      "Epoch(11) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(11) - Fold 1 - Validation Accuracy : 0.5157\n",
      "Epoch(11) - Fold 1 - Validation Utility score : 146.8159\n",
      "Epoch(11) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(11) - Fold 2 - Validation Accuracy : 0.5035\n",
      "Epoch(11) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(11) - Fold 3 - Validation Accuracy : 0.5053\n",
      "Epoch(11) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 4 - Validation Loss : 0.6931\n",
      "Epoch(11) - Fold 4 - Validation Accuracy : 0.5046\n",
      "Epoch(11) - Fold 4 - Validation Utility score : 310.4417\n",
      "Epoch(11) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(11) - GLOBAL - Validation Accuracy: 0.5080\n",
      "Epoch(11) - GLOBAL - Validation Utility score: 457.2619\n",
      "Saving model corresponding to last_utility_score == 457.2619250904123\n",
      "\n",
      "\n",
      "Epoch(12) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(12) - Fold 0 - Validation Loss : 0.6929\n",
      "Epoch(12) - Fold 0 - Validation Accuracy : 0.5058\n",
      "Epoch(12) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 1 - Validation Loss : 0.6926\n",
      "Epoch(12) - Fold 1 - Validation Accuracy : 0.5097\n",
      "Epoch(12) - Fold 1 - Validation Utility score : 0.8554\n",
      "Epoch(12) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(12) - Fold 2 - Validation Accuracy : 0.5029\n",
      "Epoch(12) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(12) - Fold 3 - Validation Accuracy : 0.5037\n",
      "Epoch(12) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 4 - Validation Loss : 0.6932\n",
      "Epoch(12) - Fold 4 - Validation Accuracy : 0.5027\n",
      "Epoch(12) - Fold 4 - Validation Utility score : 135.8655\n",
      "Epoch(12) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(12) - GLOBAL - Validation Accuracy: 0.5050\n",
      "Epoch(12) - GLOBAL - Validation Utility score: 136.7209\n",
      "Intermediate early stopping : vepoch_loss = 0.6930, the_last_loss=0.6929\n",
      "\n",
      "\n",
      "Epoch(13) - Training Loss: 0.6931\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(13) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(13) - Fold 0 - Validation Accuracy : 0.5154\n",
      "Epoch(13) - Fold 0 - Validation Utility score : 16.1709\n",
      "Epoch(13) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(13) - Fold 1 - Validation Accuracy : 0.5198\n",
      "Epoch(13) - Fold 1 - Validation Utility score : 293.6070\n",
      "Epoch(13) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(13) - Fold 2 - Validation Accuracy : 0.5047\n",
      "Epoch(13) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(13) - Fold 3 - Validation Accuracy : 0.5075\n",
      "Epoch(13) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(13) - Fold 4 - Validation Accuracy : 0.5071\n",
      "Epoch(13) - Fold 4 - Validation Utility score : 522.8998\n",
      "Epoch(13) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(13) - GLOBAL - Validation Accuracy: 0.5109\n",
      "Epoch(13) - GLOBAL - Validation Utility score: 832.6777\n",
      "Saving model corresponding to last_utility_score == 832.6777089288923\n",
      "\n",
      "\n",
      "Epoch(14) - Training Loss: 0.6930\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(14) - Fold 0 - Validation Loss : 0.6924\n",
      "Epoch(14) - Fold 0 - Validation Accuracy : 0.5159\n",
      "Epoch(14) - Fold 0 - Validation Utility score : 12.4800\n",
      "Epoch(14) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(14) - Fold 1 - Validation Accuracy : 0.5213\n",
      "Epoch(14) - Fold 1 - Validation Utility score : 326.0582\n",
      "Epoch(14) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(14) - Fold 2 - Validation Accuracy : 0.5067\n",
      "Epoch(14) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(14) - Fold 3 - Validation Accuracy : 0.5073\n",
      "Epoch(14) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(14) - Fold 4 - Validation Accuracy : 0.5077\n",
      "Epoch(14) - Fold 4 - Validation Utility score : 566.4991\n",
      "Epoch(14) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(14) - GLOBAL - Validation Accuracy: 0.5118\n",
      "Epoch(14) - GLOBAL - Validation Utility score: 905.0373\n",
      "Saving model corresponding to last_utility_score == 905.0372776707718\n",
      "\n",
      "\n",
      "Epoch(15) - Training Loss: 0.6930\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(15) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(15) - Fold 0 - Validation Accuracy : 0.5183\n",
      "Epoch(15) - Fold 0 - Validation Utility score : 46.4449\n",
      "Epoch(15) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(15) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(15) - Fold 1 - Validation Utility score : 407.1503\n",
      "Epoch(15) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(15) - Fold 2 - Validation Accuracy : 0.5065\n",
      "Epoch(15) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(15) - Fold 3 - Validation Accuracy : 0.5074\n",
      "Epoch(15) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(15) - Fold 4 - Validation Accuracy : 0.5093\n",
      "Epoch(15) - Fold 4 - Validation Utility score : 652.8837\n",
      "Epoch(15) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(15) - GLOBAL - Validation Accuracy: 0.5130\n",
      "Epoch(15) - GLOBAL - Validation Utility score: 1106.4789\n",
      "Saving model corresponding to last_utility_score == 1106.4788514691031\n",
      "\n",
      "\n",
      "Epoch(16) - Training Loss: 0.6929\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(16) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(16) - Fold 0 - Validation Accuracy : 0.5118\n",
      "Epoch(16) - Fold 0 - Validation Utility score : 0.0240\n",
      "Epoch(16) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(16) - Fold 1 - Validation Accuracy : 0.5151\n",
      "Epoch(16) - Fold 1 - Validation Utility score : 58.9601\n",
      "Epoch(16) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(16) - Fold 2 - Validation Accuracy : 0.5049\n",
      "Epoch(16) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(16) - Fold 3 - Validation Accuracy : 0.5059\n",
      "Epoch(16) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(16) - Fold 4 - Validation Accuracy : 0.5055\n",
      "Epoch(16) - Fold 4 - Validation Utility score : 394.3176\n",
      "Epoch(16) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(16) - GLOBAL - Validation Accuracy: 0.5086\n",
      "Epoch(16) - GLOBAL - Validation Utility score: 453.3017\n",
      "Intermediate early stopping : vepoch_loss = 0.6928, the_last_loss=0.6926\n",
      "\n",
      "\n",
      "Epoch(17) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(17) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(17) - Fold 0 - Validation Accuracy : 0.5185\n",
      "Epoch(17) - Fold 0 - Validation Utility score : 40.1845\n",
      "Epoch(17) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(17) - Fold 1 - Validation Accuracy : 0.5225\n",
      "Epoch(17) - Fold 1 - Validation Utility score : 364.4902\n",
      "Epoch(17) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(17) - Fold 2 - Validation Accuracy : 0.5075\n",
      "Epoch(17) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(17) - Fold 3 - Validation Accuracy : 0.5074\n",
      "Epoch(17) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(17) - Fold 4 - Validation Accuracy : 0.5096\n",
      "Epoch(17) - Fold 4 - Validation Utility score : 676.3418\n",
      "Epoch(17) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(17) - GLOBAL - Validation Accuracy: 0.5131\n",
      "Epoch(17) - GLOBAL - Validation Utility score: 1081.0165\n",
      "Saving model corresponding to last_utility_score == 1081.016537943552\n",
      "\n",
      "\n",
      "Epoch(18) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(18) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(18) - Fold 0 - Validation Accuracy : 0.5171\n",
      "Epoch(18) - Fold 0 - Validation Utility score : 12.5517\n",
      "Epoch(18) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(18) - Fold 1 - Validation Accuracy : 0.5210\n",
      "Epoch(18) - Fold 1 - Validation Utility score : 286.9894\n",
      "Epoch(18) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(18) - Fold 2 - Validation Accuracy : 0.5068\n",
      "Epoch(18) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(18) - Fold 3 - Validation Accuracy : 0.5071\n",
      "Epoch(18) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(18) - Fold 4 - Validation Accuracy : 0.5082\n",
      "Epoch(18) - Fold 4 - Validation Utility score : 600.4796\n",
      "Epoch(18) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(18) - GLOBAL - Validation Accuracy: 0.5120\n",
      "Epoch(18) - GLOBAL - Validation Utility score: 900.0208\n",
      "Intermediate early stopping : vepoch_loss = 0.6926, the_last_loss=0.6926\n",
      "\n",
      "\n",
      "Epoch(19) - Training Loss: 0.6927\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(19) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(19) - Fold 0 - Validation Accuracy : 0.5163\n",
      "Epoch(19) - Fold 0 - Validation Utility score : 18.0998\n",
      "Epoch(19) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(19) - Fold 1 - Validation Accuracy : 0.5200\n",
      "Epoch(19) - Fold 1 - Validation Utility score : 253.1265\n",
      "Epoch(19) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(19) - Fold 2 - Validation Accuracy : 0.5067\n",
      "Epoch(19) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(19) - Fold 3 - Validation Accuracy : 0.5076\n",
      "Epoch(19) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(19) - Fold 4 - Validation Accuracy : 0.5074\n",
      "Epoch(19) - Fold 4 - Validation Utility score : 514.2185\n",
      "Epoch(19) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(19) - GLOBAL - Validation Accuracy: 0.5116\n",
      "Epoch(19) - GLOBAL - Validation Utility score: 785.4449\n",
      "Intermediate early stopping : vepoch_loss = 0.6926, the_last_loss=0.6926\n",
      "\n",
      "\n",
      "Epoch(20) - Training Loss: 0.6927\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(20) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(20) - Fold 0 - Validation Accuracy : 0.5194\n",
      "Epoch(20) - Fold 0 - Validation Utility score : 98.1008\n",
      "Epoch(20) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(20) - Fold 1 - Validation Accuracy : 0.5229\n",
      "Epoch(20) - Fold 1 - Validation Utility score : 399.6073\n",
      "Epoch(20) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(20) - Fold 2 - Validation Accuracy : 0.5077\n",
      "Epoch(20) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(20) - Fold 3 - Validation Accuracy : 0.5070\n",
      "Epoch(20) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(20) - Fold 4 - Validation Accuracy : 0.5099\n",
      "Epoch(20) - Fold 4 - Validation Utility score : 784.7024\n",
      "Epoch(20) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(20) - GLOBAL - Validation Accuracy: 0.5134\n",
      "Epoch(20) - GLOBAL - Validation Utility score: 1282.4105\n",
      "Saving model corresponding to last_utility_score == 1282.4104791781133\n",
      "\n",
      "\n",
      "Epoch(21) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(21) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(21) - Fold 0 - Validation Accuracy : 0.5176\n",
      "Epoch(21) - Fold 0 - Validation Utility score : 21.3287\n",
      "Epoch(21) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(21) - Fold 1 - Validation Accuracy : 0.5207\n",
      "Epoch(21) - Fold 1 - Validation Utility score : 271.8596\n",
      "Epoch(21) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(21) - Fold 2 - Validation Accuracy : 0.5072\n",
      "Epoch(21) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(21) - Fold 3 - Validation Accuracy : 0.5074\n",
      "Epoch(21) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(21) - Fold 4 - Validation Accuracy : 0.5086\n",
      "Epoch(21) - Fold 4 - Validation Utility score : 590.3348\n",
      "Epoch(21) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(21) - GLOBAL - Validation Accuracy: 0.5123\n",
      "Epoch(21) - GLOBAL - Validation Utility score: 883.5231\n",
      "Intermediate early stopping : vepoch_loss = 0.6925, the_last_loss=0.6924\n",
      "\n",
      "\n",
      "Epoch(22) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(22) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(22) - Fold 0 - Validation Accuracy : 0.5209\n",
      "Epoch(22) - Fold 0 - Validation Utility score : 141.7981\n",
      "Epoch(22) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(22) - Fold 1 - Validation Accuracy : 0.5231\n",
      "Epoch(22) - Fold 1 - Validation Utility score : 527.2637\n",
      "Epoch(22) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(22) - Fold 2 - Validation Accuracy : 0.5085\n",
      "Epoch(22) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(22) - Fold 3 - Validation Accuracy : 0.5072\n",
      "Epoch(22) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(22) - Fold 4 - Validation Accuracy : 0.5113\n",
      "Epoch(22) - Fold 4 - Validation Utility score : 832.6087\n",
      "Epoch(22) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(22) - GLOBAL - Validation Accuracy: 0.5142\n",
      "Epoch(22) - GLOBAL - Validation Utility score: 1501.6705\n",
      "Saving model corresponding to last_utility_score == 1501.6704714174166\n",
      "\n",
      "\n",
      "Epoch(23) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(23) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(23) - Fold 0 - Validation Accuracy : 0.5203\n",
      "Epoch(23) - Fold 0 - Validation Utility score : 110.9068\n",
      "Epoch(23) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(23) - Fold 1 - Validation Accuracy : 0.5228\n",
      "Epoch(23) - Fold 1 - Validation Utility score : 471.5252\n",
      "Epoch(23) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(23) - Fold 2 - Validation Accuracy : 0.5079\n",
      "Epoch(23) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(23) - Fold 3 - Validation Accuracy : 0.5065\n",
      "Epoch(23) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(23) - Fold 4 - Validation Accuracy : 0.5104\n",
      "Epoch(23) - Fold 4 - Validation Utility score : 786.6368\n",
      "Epoch(23) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(23) - GLOBAL - Validation Accuracy: 0.5136\n",
      "Epoch(23) - GLOBAL - Validation Utility score: 1369.0688\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6923\n",
      "\n",
      "\n",
      "Epoch(24) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(24) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(24) - Fold 0 - Validation Accuracy : 0.5192\n",
      "Epoch(24) - Fold 0 - Validation Utility score : 81.4371\n",
      "Epoch(24) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(24) - Fold 1 - Validation Accuracy : 0.5224\n",
      "Epoch(24) - Fold 1 - Validation Utility score : 448.9750\n",
      "Epoch(24) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(24) - Fold 2 - Validation Accuracy : 0.5078\n",
      "Epoch(24) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(24) - Fold 3 - Validation Accuracy : 0.5068\n",
      "Epoch(24) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(24) - Fold 4 - Validation Accuracy : 0.5102\n",
      "Epoch(24) - Fold 4 - Validation Utility score : 769.1080\n",
      "Epoch(24) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(24) - GLOBAL - Validation Accuracy: 0.5133\n",
      "Epoch(24) - GLOBAL - Validation Utility score: 1299.5201\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6923\n",
      "\n",
      "\n",
      "Epoch(25) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(25) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(25) - Fold 0 - Validation Accuracy : 0.5206\n",
      "Epoch(25) - Fold 0 - Validation Utility score : 131.6702\n",
      "Epoch(25) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(25) - Fold 1 - Validation Accuracy : 0.5237\n",
      "Epoch(25) - Fold 1 - Validation Utility score : 492.7342\n",
      "Epoch(25) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(25) - Fold 2 - Validation Accuracy : 0.5078\n",
      "Epoch(25) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(25) - Fold 3 - Validation Accuracy : 0.5069\n",
      "Epoch(25) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(25) - Fold 4 - Validation Accuracy : 0.5111\n",
      "Epoch(25) - Fold 4 - Validation Utility score : 871.2441\n",
      "Epoch(25) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(25) - GLOBAL - Validation Accuracy: 0.5140\n",
      "Epoch(25) - GLOBAL - Validation Utility score: 1495.6485\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6923\n",
      "\n",
      "\n",
      "Epoch(26) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(26) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(26) - Fold 0 - Validation Accuracy : 0.5217\n",
      "Epoch(26) - Fold 0 - Validation Utility score : 166.0859\n",
      "Epoch(26) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(26) - Fold 1 - Validation Accuracy : 0.5231\n",
      "Epoch(26) - Fold 1 - Validation Utility score : 489.7577\n",
      "Epoch(26) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(26) - Fold 2 - Validation Accuracy : 0.5070\n",
      "Epoch(26) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(26) - Fold 3 - Validation Accuracy : 0.5068\n",
      "Epoch(26) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(26) - Fold 4 - Validation Accuracy : 0.5109\n",
      "Epoch(26) - Fold 4 - Validation Utility score : 819.3615\n",
      "Epoch(26) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(26) - GLOBAL - Validation Accuracy: 0.5139\n",
      "Epoch(26) - GLOBAL - Validation Utility score: 1475.2051\n",
      "Saving model corresponding to last_utility_score == 1475.2050969246172\n",
      "\n",
      "\n",
      "Epoch(27) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(27) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(27) - Fold 0 - Validation Accuracy : 0.5189\n",
      "Epoch(27) - Fold 0 - Validation Utility score : 116.4463\n",
      "Epoch(27) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(27) - Fold 1 - Validation Accuracy : 0.5222\n",
      "Epoch(27) - Fold 1 - Validation Utility score : 342.1504\n",
      "Epoch(27) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(27) - Fold 2 - Validation Accuracy : 0.5082\n",
      "Epoch(27) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(27) - Fold 3 - Validation Accuracy : 0.5073\n",
      "Epoch(27) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(27) - Fold 4 - Validation Accuracy : 0.5103\n",
      "Epoch(27) - Fold 4 - Validation Utility score : 810.0582\n",
      "Epoch(27) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(27) - GLOBAL - Validation Accuracy: 0.5134\n",
      "Epoch(27) - GLOBAL - Validation Utility score: 1268.6549\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(28) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(28) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(28) - Fold 0 - Validation Accuracy : 0.5189\n",
      "Epoch(28) - Fold 0 - Validation Utility score : 67.8907\n",
      "Epoch(28) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(28) - Fold 1 - Validation Accuracy : 0.5217\n",
      "Epoch(28) - Fold 1 - Validation Utility score : 289.3671\n",
      "Epoch(28) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(28) - Fold 2 - Validation Accuracy : 0.5078\n",
      "Epoch(28) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(28) - Fold 3 - Validation Accuracy : 0.5071\n",
      "Epoch(28) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(28) - Fold 4 - Validation Accuracy : 0.5105\n",
      "Epoch(28) - Fold 4 - Validation Utility score : 779.6112\n",
      "Epoch(28) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(28) - GLOBAL - Validation Accuracy: 0.5132\n",
      "Epoch(28) - GLOBAL - Validation Utility score: 1136.8690\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(29) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(29) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(29) - Fold 0 - Validation Accuracy : 0.5239\n",
      "Epoch(29) - Fold 0 - Validation Utility score : 300.3769\n",
      "Epoch(29) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(29) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(29) - Fold 1 - Validation Utility score : 631.3187\n",
      "Epoch(29) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(29) - Fold 2 - Validation Accuracy : 0.5081\n",
      "Epoch(29) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(29) - Fold 3 - Validation Accuracy : 0.5067\n",
      "Epoch(29) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(29) - Fold 4 - Validation Accuracy : 0.5124\n",
      "Epoch(29) - Fold 4 - Validation Utility score : 1001.2717\n",
      "Epoch(29) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(29) - GLOBAL - Validation Accuracy: 0.5150\n",
      "Epoch(29) - GLOBAL - Validation Utility score: 1932.9673\n",
      "Saving model corresponding to last_utility_score == 1932.9673289481184\n",
      "\n",
      "\n",
      "Epoch(30) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(30) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(30) - Fold 0 - Validation Accuracy : 0.5239\n",
      "Epoch(30) - Fold 0 - Validation Utility score : 322.5505\n",
      "Epoch(30) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(30) - Fold 1 - Validation Accuracy : 0.5246\n",
      "Epoch(30) - Fold 1 - Validation Utility score : 644.8808\n",
      "Epoch(30) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(30) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(30) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(30) - Fold 3 - Validation Accuracy : 0.5076\n",
      "Epoch(30) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(30) - Fold 4 - Validation Accuracy : 0.5132\n",
      "Epoch(30) - Fold 4 - Validation Utility score : 873.6875\n",
      "Epoch(30) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(30) - GLOBAL - Validation Accuracy: 0.5155\n",
      "Epoch(30) - GLOBAL - Validation Utility score: 1841.1188\n",
      "Saving model corresponding to last_utility_score == 1841.1188247713621\n",
      "\n",
      "\n",
      "Epoch(31) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(31) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(31) - Fold 0 - Validation Accuracy : 0.5251\n",
      "Epoch(31) - Fold 0 - Validation Utility score : 450.6928\n",
      "Epoch(31) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(31) - Fold 1 - Validation Accuracy : 0.5252\n",
      "Epoch(31) - Fold 1 - Validation Utility score : 747.0462\n",
      "Epoch(31) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(31) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(31) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(31) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(31) - Fold 3 - Validation Accuracy : 0.5080\n",
      "Epoch(31) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(31) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(31) - Fold 4 - Validation Accuracy : 0.5148\n",
      "Epoch(31) - Fold 4 - Validation Utility score : 977.9787\n",
      "Epoch(31) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(31) - GLOBAL - Validation Accuracy: 0.5164\n",
      "Epoch(31) - GLOBAL - Validation Utility score: 2175.7177\n",
      "Saving model corresponding to last_utility_score == 2175.7177053468376\n",
      "\n",
      "\n",
      "Epoch(32) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(32) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(32) - Fold 0 - Validation Accuracy : 0.5238\n",
      "Epoch(32) - Fold 0 - Validation Utility score : 303.3009\n",
      "Epoch(32) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(32) - Fold 1 - Validation Accuracy : 0.5242\n",
      "Epoch(32) - Fold 1 - Validation Utility score : 595.2865\n",
      "Epoch(32) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(32) - Fold 2 - Validation Accuracy : 0.5082\n",
      "Epoch(32) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(32) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(32) - Fold 3 - Validation Accuracy : 0.5087\n",
      "Epoch(32) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(32) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(32) - Fold 4 - Validation Accuracy : 0.5136\n",
      "Epoch(32) - Fold 4 - Validation Utility score : 962.7249\n",
      "Epoch(32) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(32) - GLOBAL - Validation Accuracy: 0.5157\n",
      "Epoch(32) - GLOBAL - Validation Utility score: 1861.3123\n",
      "Saving model corresponding to last_utility_score == 1861.3123213569893\n",
      "\n",
      "\n",
      "Epoch(33) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(33) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(33) - Fold 0 - Validation Accuracy : 0.5208\n",
      "Epoch(33) - Fold 0 - Validation Utility score : 111.0354\n",
      "Epoch(33) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(33) - Fold 1 - Validation Accuracy : 0.5228\n",
      "Epoch(33) - Fold 1 - Validation Utility score : 363.6466\n",
      "Epoch(33) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(33) - Fold 2 - Validation Accuracy : 0.5091\n",
      "Epoch(33) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(33) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(33) - Fold 3 - Validation Accuracy : 0.5079\n",
      "Epoch(33) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(33) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(33) - Fold 4 - Validation Accuracy : 0.5114\n",
      "Epoch(33) - Fold 4 - Validation Utility score : 842.1687\n",
      "Epoch(33) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(33) - GLOBAL - Validation Accuracy: 0.5144\n",
      "Epoch(33) - GLOBAL - Validation Utility score: 1316.8507\n",
      "Intermediate early stopping : vepoch_loss = 0.6922, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(34) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(34) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(34) - Fold 0 - Validation Accuracy : 0.5203\n",
      "Epoch(34) - Fold 0 - Validation Utility score : 108.7340\n",
      "Epoch(34) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(34) - Fold 1 - Validation Accuracy : 0.5222\n",
      "Epoch(34) - Fold 1 - Validation Utility score : 397.3240\n",
      "Epoch(34) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(34) - Fold 2 - Validation Accuracy : 0.5073\n",
      "Epoch(34) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(34) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(34) - Fold 3 - Validation Accuracy : 0.5069\n",
      "Epoch(34) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(34) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(34) - Fold 4 - Validation Accuracy : 0.5110\n",
      "Epoch(34) - Fold 4 - Validation Utility score : 712.3721\n",
      "Epoch(34) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(34) - GLOBAL - Validation Accuracy: 0.5136\n",
      "Epoch(34) - GLOBAL - Validation Utility score: 1218.4301\n",
      "Intermediate early stopping : vepoch_loss = 0.6922, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(35) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(35) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(35) - Fold 0 - Validation Accuracy : 0.5251\n",
      "Epoch(35) - Fold 0 - Validation Utility score : 429.9003\n",
      "Epoch(35) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(35) - Fold 1 - Validation Accuracy : 0.5247\n",
      "Epoch(35) - Fold 1 - Validation Utility score : 691.5551\n",
      "Epoch(35) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(35) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(35) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(35) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(35) - Fold 3 - Validation Accuracy : 0.5095\n",
      "Epoch(35) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(35) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(35) - Fold 4 - Validation Accuracy : 0.5149\n",
      "Epoch(35) - Fold 4 - Validation Utility score : 915.8229\n",
      "Epoch(35) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(35) - GLOBAL - Validation Accuracy: 0.5166\n",
      "Epoch(35) - GLOBAL - Validation Utility score: 2037.2783\n",
      "Saving model corresponding to last_utility_score == 2037.2782906525058\n",
      "\n",
      "\n",
      "Epoch(36) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(36) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(36) - Fold 0 - Validation Accuracy : 0.5249\n",
      "Epoch(36) - Fold 0 - Validation Utility score : 507.3290\n",
      "Epoch(36) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(36) - Fold 1 - Validation Accuracy : 0.5256\n",
      "Epoch(36) - Fold 1 - Validation Utility score : 826.7058\n",
      "Epoch(36) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(36) - Fold 2 - Validation Accuracy : 0.5109\n",
      "Epoch(36) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(36) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(36) - Fold 3 - Validation Accuracy : 0.5082\n",
      "Epoch(36) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(36) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(36) - Fold 4 - Validation Accuracy : 0.5159\n",
      "Epoch(36) - Fold 4 - Validation Utility score : 1079.3256\n",
      "Epoch(36) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(36) - GLOBAL - Validation Accuracy: 0.5171\n",
      "Epoch(36) - GLOBAL - Validation Utility score: 2413.3603\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(37) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(37) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(37) - Fold 0 - Validation Accuracy : 0.5260\n",
      "Epoch(37) - Fold 0 - Validation Utility score : 547.0586\n",
      "Epoch(37) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(37) - Fold 1 - Validation Accuracy : 0.5242\n",
      "Epoch(37) - Fold 1 - Validation Utility score : 815.7761\n",
      "Epoch(37) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(37) - Fold 2 - Validation Accuracy : 0.5085\n",
      "Epoch(37) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(37) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(37) - Fold 3 - Validation Accuracy : 0.5090\n",
      "Epoch(37) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(37) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(37) - Fold 4 - Validation Accuracy : 0.5152\n",
      "Epoch(37) - Fold 4 - Validation Utility score : 1039.4543\n",
      "Epoch(37) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(37) - GLOBAL - Validation Accuracy: 0.5166\n",
      "Epoch(37) - GLOBAL - Validation Utility score: 2402.2890\n",
      "Saving model corresponding to last_utility_score == 2402.2890288958215\n",
      "\n",
      "\n",
      "Epoch(38) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(38) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(38) - Fold 0 - Validation Accuracy : 0.5205\n",
      "Epoch(38) - Fold 0 - Validation Utility score : 109.9009\n",
      "Epoch(38) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(38) - Fold 1 - Validation Accuracy : 0.5209\n",
      "Epoch(38) - Fold 1 - Validation Utility score : 294.3579\n",
      "Epoch(38) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(38) - Fold 2 - Validation Accuracy : 0.5102\n",
      "Epoch(38) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(38) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(38) - Fold 3 - Validation Accuracy : 0.5069\n",
      "Epoch(38) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(38) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(38) - Fold 4 - Validation Accuracy : 0.5118\n",
      "Epoch(38) - Fold 4 - Validation Utility score : 854.5194\n",
      "Epoch(38) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(38) - GLOBAL - Validation Accuracy: 0.5141\n",
      "Epoch(38) - GLOBAL - Validation Utility score: 1258.7782\n",
      "Intermediate early stopping : vepoch_loss = 0.6922, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(39) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(39) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(39) - Fold 0 - Validation Accuracy : 0.5241\n",
      "Epoch(39) - Fold 0 - Validation Utility score : 378.1851\n",
      "Epoch(39) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(39) - Fold 1 - Validation Accuracy : 0.5242\n",
      "Epoch(39) - Fold 1 - Validation Utility score : 710.2420\n",
      "Epoch(39) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(39) - Fold 2 - Validation Accuracy : 0.5092\n",
      "Epoch(39) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(39) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(39) - Fold 3 - Validation Accuracy : 0.5097\n",
      "Epoch(39) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(39) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(39) - Fold 4 - Validation Accuracy : 0.5156\n",
      "Epoch(39) - Fold 4 - Validation Utility score : 1042.0466\n",
      "Epoch(39) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(39) - GLOBAL - Validation Accuracy: 0.5165\n",
      "Epoch(39) - GLOBAL - Validation Utility score: 2130.4737\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(40) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(40) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(40) - Fold 0 - Validation Accuracy : 0.5246\n",
      "Epoch(40) - Fold 0 - Validation Utility score : 401.1641\n",
      "Epoch(40) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(40) - Fold 1 - Validation Accuracy : 0.5251\n",
      "Epoch(40) - Fold 1 - Validation Utility score : 717.1105\n",
      "Epoch(40) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(40) - Fold 2 - Validation Accuracy : 0.5095\n",
      "Epoch(40) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(40) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(40) - Fold 3 - Validation Accuracy : 0.5094\n",
      "Epoch(40) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(40) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(40) - Fold 4 - Validation Accuracy : 0.5160\n",
      "Epoch(40) - Fold 4 - Validation Utility score : 1110.6281\n",
      "Epoch(40) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(40) - GLOBAL - Validation Accuracy: 0.5169\n",
      "Epoch(40) - GLOBAL - Validation Utility score: 2228.9026\n",
      "Saving model corresponding to last_utility_score == 2228.9026330491097\n",
      "\n",
      "\n",
      "Epoch(41) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(41) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(41) - Fold 0 - Validation Accuracy : 0.5232\n",
      "Epoch(41) - Fold 0 - Validation Utility score : 210.8111\n",
      "Epoch(41) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(41) - Fold 1 - Validation Accuracy : 0.5238\n",
      "Epoch(41) - Fold 1 - Validation Utility score : 492.1455\n",
      "Epoch(41) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(41) - Fold 2 - Validation Accuracy : 0.5097\n",
      "Epoch(41) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(41) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(41) - Fold 3 - Validation Accuracy : 0.5081\n",
      "Epoch(41) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(41) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(41) - Fold 4 - Validation Accuracy : 0.5146\n",
      "Epoch(41) - Fold 4 - Validation Utility score : 893.5523\n",
      "Epoch(41) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(41) - GLOBAL - Validation Accuracy: 0.5159\n",
      "Epoch(41) - GLOBAL - Validation Utility score: 1596.5089\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(42) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(42) - Fold 0 - Validation Loss : 0.6912\n",
      "Epoch(42) - Fold 0 - Validation Accuracy : 0.5248\n",
      "Epoch(42) - Fold 0 - Validation Utility score : 417.7782\n",
      "Epoch(42) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(42) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(42) - Fold 1 - Validation Utility score : 688.6090\n",
      "Epoch(42) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(42) - Fold 2 - Validation Accuracy : 0.5098\n",
      "Epoch(42) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(42) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(42) - Fold 3 - Validation Accuracy : 0.5091\n",
      "Epoch(42) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(42) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(42) - Fold 4 - Validation Accuracy : 0.5161\n",
      "Epoch(42) - Fold 4 - Validation Utility score : 1121.0252\n",
      "Epoch(42) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(42) - GLOBAL - Validation Accuracy: 0.5167\n",
      "Epoch(42) - GLOBAL - Validation Utility score: 2227.4125\n",
      "Saving model corresponding to last_utility_score == 2227.4124612888268\n",
      "\n",
      "\n",
      "Epoch(43) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(43) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(43) - Fold 0 - Validation Accuracy : 0.5228\n",
      "Epoch(43) - Fold 0 - Validation Utility score : 128.2687\n",
      "Epoch(43) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(43) - Fold 1 - Validation Accuracy : 0.5232\n",
      "Epoch(43) - Fold 1 - Validation Utility score : 431.1664\n",
      "Epoch(43) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(43) - Fold 2 - Validation Accuracy : 0.5108\n",
      "Epoch(43) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(43) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(43) - Fold 3 - Validation Accuracy : 0.5083\n",
      "Epoch(43) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(43) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(43) - Fold 4 - Validation Accuracy : 0.5146\n",
      "Epoch(43) - Fold 4 - Validation Utility score : 831.0916\n",
      "Epoch(43) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(43) - GLOBAL - Validation Accuracy: 0.5159\n",
      "Epoch(43) - GLOBAL - Validation Utility score: 1390.5267\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(44) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(44) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(44) - Fold 0 - Validation Accuracy : 0.5255\n",
      "Epoch(44) - Fold 0 - Validation Utility score : 336.8032\n",
      "Epoch(44) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(44) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(44) - Fold 1 - Validation Utility score : 619.0386\n",
      "Epoch(44) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(44) - Fold 2 - Validation Accuracy : 0.5095\n",
      "Epoch(44) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(44) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(44) - Fold 3 - Validation Accuracy : 0.5102\n",
      "Epoch(44) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(44) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(44) - Fold 4 - Validation Accuracy : 0.5166\n",
      "Epoch(44) - Fold 4 - Validation Utility score : 1041.5630\n",
      "Epoch(44) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(44) - GLOBAL - Validation Accuracy: 0.5171\n",
      "Epoch(44) - GLOBAL - Validation Utility score: 1997.4048\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(45) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(45) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(45) - Fold 0 - Validation Accuracy : 0.5240\n",
      "Epoch(45) - Fold 0 - Validation Utility score : 299.4977\n",
      "Epoch(45) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(45) - Fold 1 - Validation Accuracy : 0.5243\n",
      "Epoch(45) - Fold 1 - Validation Utility score : 565.0078\n",
      "Epoch(45) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(45) - Fold 2 - Validation Accuracy : 0.5110\n",
      "Epoch(45) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(45) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(45) - Fold 3 - Validation Accuracy : 0.5098\n",
      "Epoch(45) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(45) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(45) - Fold 4 - Validation Accuracy : 0.5168\n",
      "Epoch(45) - Fold 4 - Validation Utility score : 1020.1738\n",
      "Epoch(45) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(45) - GLOBAL - Validation Accuracy: 0.5172\n",
      "Epoch(45) - GLOBAL - Validation Utility score: 1884.6793\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(46) - Training Loss: 0.6915\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(46) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(46) - Fold 0 - Validation Accuracy : 0.5232\n",
      "Epoch(46) - Fold 0 - Validation Utility score : 207.0354\n",
      "Epoch(46) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(46) - Fold 1 - Validation Accuracy : 0.5237\n",
      "Epoch(46) - Fold 1 - Validation Utility score : 503.2185\n",
      "Epoch(46) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(46) - Fold 2 - Validation Accuracy : 0.5109\n",
      "Epoch(46) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(46) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(46) - Fold 3 - Validation Accuracy : 0.5089\n",
      "Epoch(46) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(46) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(46) - Fold 4 - Validation Accuracy : 0.5164\n",
      "Epoch(46) - Fold 4 - Validation Utility score : 978.2356\n",
      "Epoch(46) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(46) - GLOBAL - Validation Accuracy: 0.5166\n",
      "Epoch(46) - GLOBAL - Validation Utility score: 1688.4895\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(47) - Training Loss: 0.6915\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(47) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(47) - Fold 0 - Validation Accuracy : 0.5231\n",
      "Epoch(47) - Fold 0 - Validation Utility score : 220.3938\n",
      "Epoch(47) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(47) - Fold 1 - Validation Accuracy : 0.5238\n",
      "Epoch(47) - Fold 1 - Validation Utility score : 660.3239\n",
      "Epoch(47) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(47) - Fold 2 - Validation Accuracy : 0.5108\n",
      "Epoch(47) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(47) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(47) - Fold 3 - Validation Accuracy : 0.5106\n",
      "Epoch(47) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(47) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(47) - Fold 4 - Validation Accuracy : 0.5175\n",
      "Epoch(47) - Fold 4 - Validation Utility score : 1180.9340\n",
      "Epoch(47) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(47) - GLOBAL - Validation Accuracy: 0.5171\n",
      "Epoch(47) - GLOBAL - Validation Utility score: 2061.6516\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "Meet Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 522578<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_082840-9a6ez55a/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_082840-9a6ez55a/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>0.69148</td></tr><tr><td>Global valid/Loss</td><td>0.69195</td></tr><tr><td>Global valid/Accuracy</td><td>0.51713</td></tr><tr><td>Global valid/Utility</td><td>2061.65164</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>0.69161</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>0.5231</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>220.39379</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>0.69124</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>0.52378</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>660.32388</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>0.69279</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>0.51076</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>0.69278</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>0.51055</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>0.69133</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>0.51747</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>1180.93397</td></tr><tr><td>Best accuracy</td><td>0.51674</td></tr><tr><td>Best utility</td><td>2227.41246</td></tr><tr><td>_runtime</td><td>2874</td></tr><tr><td>_timestamp</td><td>1613463394</td></tr><tr><td>_step</td><td>47</td></tr><tr><td>Final utility score</td><td>{'utility_score': 22...</td></tr><tr><td>Batch size</td><td>54819</td></tr><tr><td>Patience</td><td>5</td></tr><tr><td>Number of epochs</td><td>1000</td></tr><tr><td>Best epoch</td><td>42</td></tr><tr><td>Number of parameters per layer</td><td>[8384, 64, 2048, 32,...</td></tr><tr><td>Model architecture</td><td>MLP(<BR>  (AEncoder)...</td></tr><tr><td>comment</td><td>All folds MLP with a...</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Loss</td><td>█▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Accuracy</td><td>▁▂▂▂▂▂▄▃▃▄▃▆▆▆▅▆▆▇▆▇▆▇▇▇▆▇█▇▇▇██▇███████</td></tr><tr><td>Global valid/Utility</td><td>▁▁▁▁▁▁▂▁▁▂▁▃▄▄▂▄▃▅▄▅▅▅▅▅▄▆▇▆▅▅██▅▇▇▇▅▇▆▇</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>█▅▄▄▄▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▂▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>▂▁▁▁▁▂▃▂▂▄▃▅▅▆▄▆▅▆▆▇▆▇▇▆▆▇█▇▇▆██▇▇██▇█▇▇</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▂▁▃▂▃▃▂▂▅▇▅▂▂▇█▂▆▆▆▃▅▅▄</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>█▆▅▄▄▃▃▃▃▃▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▁▁▁▂▂▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>▁▂▂▂▂▃▄▃▃▅▃▆▇▇▅▇▆▇▇▇▇▇▇▇▇███▇▇██▇███▇▇█▇</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>▁▁▁▁▁▁▂▁▁▂▁▃▄▄▁▃▃▄▃▅▅▅▅▄▃▆▇▆▄▄██▃▇▇▇▅▆▆▇</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>█▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>▁▃▄▄▄▄▃▄▄▄▄▅▆▆▅▆▆▆▆▇▆▆▆▇▆▇▇▇▇▆█▇█▇▇▇█▇██</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>█▅▄▄▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>▂▂▁▁▁▃▄▄▃▅▄▆▆▆▅▆▆▆▆▆▆▆▆▆▆▆▆▇▆▆▇▇▆▇▇▇▇███</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>█▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>▁▃▃▃▃▃▄▄▄▄▄▅▅▆▅▆▅▆▆▆▆▆▆▆▆▇▇▇▆▆█▇▆▇██▇███</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>▁▁▁▁▁▁▂▁▂▃▂▄▄▅▃▅▄▆▄▆▆▆▆▆▆▆▇▇▆▅▇▇▆▇██▆▇▇█</td></tr><tr><td>Best accuracy</td><td>▁▂▂▂▂▂▂▄▄▄▆▆▆▆▇▇▇▇▇███████</td></tr><tr><td>Best utility</td><td>▁▁▁▁▁▁▁▂▂▂▃▄▄▄▅▅▅▇▆▇▆▇█▇▇▇</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 241 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">restful-sweep-7</strong>: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/9a6ez55a\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/9a6ez55a</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training summary:\n",
      "{'utility_score': 2227.4124612888268, 'utility_scores': [417.77821571032996, 688.6090172678771, -0.0, -0.0, 1121.0252283106197], 'utility_score_std': 427.35121952620324, 'accuracy_scores': [0.524790577029383, 0.5239592839592839, 0.5097664966254952, 0.5090818279025269, 0.5161008592759544]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r3athxss with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leakyrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 42274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.47920622610226726\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0016672023742966041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_autoenc: encoder\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 8.809764846168144e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">glowing-sweep-8</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/r3athxss\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/r3athxss</a><br/>\n",
       "                Run data is saved locally in <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_091640-r3athxss</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Run config :\n",
      "config: {'activation_function': 'leakyrelu', 'batch_size': 42274, 'dropout': 0.47920622610226726, 'learning_rate': 0.0016672023742966041, 'use_autoenc': 'encoder', 'weight_decay': 8.809764846168144e-05, 'epochs': 1000}\n",
      "Epoch(0) - Training Loss: 0.7628\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(0) - Fold 0 - Validation Loss : 0.6935\n",
      "Epoch(0) - Fold 0 - Validation Accuracy : 0.5149\n",
      "Epoch(0) - Fold 0 - Validation Utility score : 84.2275\n",
      "Epoch(0) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(0) - Fold 1 - Validation Accuracy : 0.5126\n",
      "Epoch(0) - Fold 1 - Validation Utility score : 366.4979\n",
      "Epoch(0) - Fold 2 - Validation Loss : 0.6944\n",
      "Epoch(0) - Fold 2 - Validation Accuracy : 0.5034\n",
      "Epoch(0) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 3 - Validation Loss : 0.6943\n",
      "Epoch(0) - Fold 3 - Validation Accuracy : 0.5049\n",
      "Epoch(0) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 4 - Validation Loss : 0.6935\n",
      "Epoch(0) - Fold 4 - Validation Accuracy : 0.5049\n",
      "Epoch(0) - Fold 4 - Validation Utility score : 66.7771\n",
      "Epoch(0) - GLOBAL - Validation Loss: 0.6937\n",
      "Epoch(0) - GLOBAL - Validation Accuracy: 0.5081\n",
      "Epoch(0) - GLOBAL - Validation Utility score: 517.5025\n",
      "Saving model corresponding to last_utility_score == 517.5024754496419\n",
      "\n",
      "\n",
      "Epoch(1) - Training Loss: 0.7074\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(1) - Fold 0 - Validation Loss : 0.6928\n",
      "Epoch(1) - Fold 0 - Validation Accuracy : 0.5080\n",
      "Epoch(1) - Fold 0 - Validation Utility score : 29.2001\n",
      "Epoch(1) - Fold 1 - Validation Loss : 0.6930\n",
      "Epoch(1) - Fold 1 - Validation Accuracy : 0.5034\n",
      "Epoch(1) - Fold 1 - Validation Utility score : 237.6928\n",
      "Epoch(1) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(1) - Fold 2 - Validation Accuracy : 0.5012\n",
      "Epoch(1) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(1) - Fold 3 - Validation Accuracy : 0.5052\n",
      "Epoch(1) - Fold 3 - Validation Utility score : 33.4483\n",
      "Epoch(1) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(1) - Fold 4 - Validation Accuracy : 0.5082\n",
      "Epoch(1) - Fold 4 - Validation Utility score : 134.0512\n",
      "Epoch(1) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(1) - GLOBAL - Validation Accuracy: 0.5052\n",
      "Epoch(1) - GLOBAL - Validation Utility score: 434.3925\n",
      "Saving model corresponding to last_utility_score == 434.3924558013335\n",
      "\n",
      "\n",
      "Epoch(2) - Training Loss: 0.6958\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(2) - Fold 0 - Validation Loss : 0.6929\n",
      "Epoch(2) - Fold 0 - Validation Accuracy : 0.5093\n",
      "Epoch(2) - Fold 0 - Validation Utility score : 87.4339\n",
      "Epoch(2) - Fold 1 - Validation Loss : 0.6930\n",
      "Epoch(2) - Fold 1 - Validation Accuracy : 0.5015\n",
      "Epoch(2) - Fold 1 - Validation Utility score : 26.5640\n",
      "Epoch(2) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(2) - Fold 2 - Validation Accuracy : 0.5024\n",
      "Epoch(2) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(2) - Fold 3 - Validation Accuracy : 0.5028\n",
      "Epoch(2) - Fold 3 - Validation Utility score : 24.4001\n",
      "Epoch(2) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(2) - Fold 4 - Validation Accuracy : 0.5080\n",
      "Epoch(2) - Fold 4 - Validation Utility score : 463.9642\n",
      "Epoch(2) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(2) - GLOBAL - Validation Accuracy: 0.5048\n",
      "Epoch(2) - GLOBAL - Validation Utility score: 602.3622\n",
      "Saving model corresponding to last_utility_score == 602.3621910801845\n",
      "\n",
      "\n",
      "Epoch(3) - Training Loss: 0.6936\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(3) - Fold 0 - Validation Loss : 0.6928\n",
      "Epoch(3) - Fold 0 - Validation Accuracy : 0.5163\n",
      "Epoch(3) - Fold 0 - Validation Utility score : 578.2685\n",
      "Epoch(3) - Fold 1 - Validation Loss : 0.6929\n",
      "Epoch(3) - Fold 1 - Validation Accuracy : 0.5110\n",
      "Epoch(3) - Fold 1 - Validation Utility score : 408.0223\n",
      "Epoch(3) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(3) - Fold 2 - Validation Accuracy : 0.5073\n",
      "Epoch(3) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(3) - Fold 3 - Validation Accuracy : 0.5037\n",
      "Epoch(3) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(3) - Fold 4 - Validation Accuracy : 0.5134\n",
      "Epoch(3) - Fold 4 - Validation Utility score : 979.4976\n",
      "Epoch(3) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(3) - GLOBAL - Validation Accuracy: 0.5103\n",
      "Epoch(3) - GLOBAL - Validation Utility score: 1965.7884\n",
      "Saving model corresponding to last_utility_score == 1965.788386761259\n",
      "\n",
      "\n",
      "Epoch(4) - Training Loss: 0.6929\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(4) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(4) - Fold 0 - Validation Accuracy : 0.5197\n",
      "Epoch(4) - Fold 0 - Validation Utility score : 580.1124\n",
      "Epoch(4) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(4) - Fold 1 - Validation Accuracy : 0.5158\n",
      "Epoch(4) - Fold 1 - Validation Utility score : 620.6660\n",
      "Epoch(4) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(4) - Fold 2 - Validation Accuracy : 0.5068\n",
      "Epoch(4) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(4) - Fold 3 - Validation Accuracy : 0.5062\n",
      "Epoch(4) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(4) - Fold 4 - Validation Accuracy : 0.5168\n",
      "Epoch(4) - Fold 4 - Validation Utility score : 1078.2464\n",
      "Epoch(4) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(4) - GLOBAL - Validation Accuracy: 0.5131\n",
      "Epoch(4) - GLOBAL - Validation Utility score: 2279.0248\n",
      "Saving model corresponding to last_utility_score == 2279.02475392807\n",
      "\n",
      "\n",
      "Epoch(5) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(5) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(5) - Fold 0 - Validation Accuracy : 0.5226\n",
      "Epoch(5) - Fold 0 - Validation Utility score : 546.7691\n",
      "Epoch(5) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(5) - Fold 1 - Validation Accuracy : 0.5194\n",
      "Epoch(5) - Fold 1 - Validation Utility score : 835.3145\n",
      "Epoch(5) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(5) - Fold 2 - Validation Accuracy : 0.5057\n",
      "Epoch(5) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(5) - Fold 3 - Validation Accuracy : 0.5071\n",
      "Epoch(5) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(5) - Fold 4 - Validation Accuracy : 0.5203\n",
      "Epoch(5) - Fold 4 - Validation Utility score : 1218.5036\n",
      "Epoch(5) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(5) - GLOBAL - Validation Accuracy: 0.5150\n",
      "Epoch(5) - GLOBAL - Validation Utility score: 2600.5873\n",
      "Saving model corresponding to last_utility_score == 2600.5872728753807\n",
      "\n",
      "\n",
      "Epoch(6) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(6) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(6) - Fold 0 - Validation Accuracy : 0.5239\n",
      "Epoch(6) - Fold 0 - Validation Utility score : 709.9685\n",
      "Epoch(6) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(6) - Fold 1 - Validation Accuracy : 0.5207\n",
      "Epoch(6) - Fold 1 - Validation Utility score : 1055.1734\n",
      "Epoch(6) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(6) - Fold 2 - Validation Accuracy : 0.5066\n",
      "Epoch(6) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(6) - Fold 3 - Validation Accuracy : 0.5094\n",
      "Epoch(6) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(6) - Fold 4 - Validation Accuracy : 0.5213\n",
      "Epoch(6) - Fold 4 - Validation Utility score : 1340.0839\n",
      "Epoch(6) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(6) - GLOBAL - Validation Accuracy: 0.5164\n",
      "Epoch(6) - GLOBAL - Validation Utility score: 3105.2258\n",
      "Saving model corresponding to last_utility_score == 3105.22578845736\n",
      "\n",
      "\n",
      "Epoch(7) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(7) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(7) - Fold 0 - Validation Accuracy : 0.5235\n",
      "Epoch(7) - Fold 0 - Validation Utility score : 706.8186\n",
      "Epoch(7) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(7) - Fold 1 - Validation Accuracy : 0.5239\n",
      "Epoch(7) - Fold 1 - Validation Utility score : 1040.7572\n",
      "Epoch(7) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(7) - Fold 2 - Validation Accuracy : 0.5076\n",
      "Epoch(7) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(7) - Fold 3 - Validation Accuracy : 0.5128\n",
      "Epoch(7) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(7) - Fold 4 - Validation Accuracy : 0.5205\n",
      "Epoch(7) - Fold 4 - Validation Utility score : 1286.8801\n",
      "Epoch(7) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(7) - GLOBAL - Validation Accuracy: 0.5177\n",
      "Epoch(7) - GLOBAL - Validation Utility score: 3034.4560\n",
      "Saving model corresponding to last_utility_score == 3034.455991671567\n",
      "\n",
      "\n",
      "Epoch(8) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(8) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(8) - Fold 0 - Validation Accuracy : 0.5244\n",
      "Epoch(8) - Fold 0 - Validation Utility score : 620.5119\n",
      "Epoch(8) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(8) - Fold 1 - Validation Accuracy : 0.5221\n",
      "Epoch(8) - Fold 1 - Validation Utility score : 905.9946\n",
      "Epoch(8) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(8) - Fold 2 - Validation Accuracy : 0.5077\n",
      "Epoch(8) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(8) - Fold 3 - Validation Accuracy : 0.5123\n",
      "Epoch(8) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(8) - Fold 4 - Validation Accuracy : 0.5222\n",
      "Epoch(8) - Fold 4 - Validation Utility score : 1393.3990\n",
      "Epoch(8) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(8) - GLOBAL - Validation Accuracy: 0.5177\n",
      "Epoch(8) - GLOBAL - Validation Utility score: 2919.9055\n",
      "Saving model corresponding to last_utility_score == 2919.9055038233755\n",
      "\n",
      "\n",
      "Epoch(9) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(9) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(9) - Fold 0 - Validation Accuracy : 0.5243\n",
      "Epoch(9) - Fold 0 - Validation Utility score : 496.1355\n",
      "Epoch(9) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(9) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(9) - Fold 1 - Validation Utility score : 989.8734\n",
      "Epoch(9) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(9) - Fold 2 - Validation Accuracy : 0.5067\n",
      "Epoch(9) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(9) - Fold 3 - Validation Accuracy : 0.5116\n",
      "Epoch(9) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(9) - Fold 4 - Validation Accuracy : 0.5224\n",
      "Epoch(9) - Fold 4 - Validation Utility score : 1384.7108\n",
      "Epoch(9) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(9) - GLOBAL - Validation Accuracy: 0.5177\n",
      "Epoch(9) - GLOBAL - Validation Utility score: 2870.7197\n",
      "Saving model corresponding to last_utility_score == 2870.719677066931\n",
      "\n",
      "\n",
      "Epoch(10) - Training Loss: 0.6915\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(10) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(10) - Fold 0 - Validation Accuracy : 0.5229\n",
      "Epoch(10) - Fold 0 - Validation Utility score : 356.2648\n",
      "Epoch(10) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(10) - Fold 1 - Validation Accuracy : 0.5236\n",
      "Epoch(10) - Fold 1 - Validation Utility score : 1167.6764\n",
      "Epoch(10) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(10) - Fold 2 - Validation Accuracy : 0.5070\n",
      "Epoch(10) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(10) - Fold 3 - Validation Accuracy : 0.5125\n",
      "Epoch(10) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(10) - Fold 4 - Validation Accuracy : 0.5239\n",
      "Epoch(10) - Fold 4 - Validation Utility score : 1354.9359\n",
      "Epoch(10) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(10) - GLOBAL - Validation Accuracy: 0.5180\n",
      "Epoch(10) - GLOBAL - Validation Utility score: 2878.8772\n",
      "Saving model corresponding to last_utility_score == 2878.8771701413734\n",
      "\n",
      "\n",
      "Epoch(11) - Training Loss: 0.6913\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(11) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(11) - Fold 0 - Validation Accuracy : 0.5221\n",
      "Epoch(11) - Fold 0 - Validation Utility score : 349.3085\n",
      "Epoch(11) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(11) - Fold 1 - Validation Accuracy : 0.5241\n",
      "Epoch(11) - Fold 1 - Validation Utility score : 984.5673\n",
      "Epoch(11) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(11) - Fold 2 - Validation Accuracy : 0.5081\n",
      "Epoch(11) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(11) - Fold 3 - Validation Accuracy : 0.5123\n",
      "Epoch(11) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(11) - Fold 4 - Validation Accuracy : 0.5238\n",
      "Epoch(11) - Fold 4 - Validation Utility score : 1390.4059\n",
      "Epoch(11) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(11) - GLOBAL - Validation Accuracy: 0.5181\n",
      "Epoch(11) - GLOBAL - Validation Utility score: 2724.2816\n",
      "Saving model corresponding to last_utility_score == 2724.281604236668\n",
      "\n",
      "\n",
      "Epoch(12) - Training Loss: 0.6912\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(12) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(12) - Fold 0 - Validation Accuracy : 0.5234\n",
      "Epoch(12) - Fold 0 - Validation Utility score : 355.0364\n",
      "Epoch(12) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(12) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(12) - Fold 1 - Validation Utility score : 1043.7622\n",
      "Epoch(12) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(12) - Fold 2 - Validation Accuracy : 0.5085\n",
      "Epoch(12) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(12) - Fold 3 - Validation Accuracy : 0.5129\n",
      "Epoch(12) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(12) - Fold 4 - Validation Accuracy : 0.5235\n",
      "Epoch(12) - Fold 4 - Validation Utility score : 1317.5717\n",
      "Epoch(12) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(12) - GLOBAL - Validation Accuracy: 0.5184\n",
      "Epoch(12) - GLOBAL - Validation Utility score: 2716.3704\n",
      "Saving model corresponding to last_utility_score == 2716.3703636440614\n",
      "\n",
      "\n",
      "Epoch(13) - Training Loss: 0.6910\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(13) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(13) - Fold 0 - Validation Accuracy : 0.5218\n",
      "Epoch(13) - Fold 0 - Validation Utility score : 282.8669\n",
      "Epoch(13) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(13) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(13) - Fold 1 - Validation Utility score : 928.7479\n",
      "Epoch(13) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(13) - Fold 2 - Validation Accuracy : 0.5092\n",
      "Epoch(13) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(13) - Fold 3 - Validation Accuracy : 0.5131\n",
      "Epoch(13) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 4 - Validation Loss : 0.6912\n",
      "Epoch(13) - Fold 4 - Validation Accuracy : 0.5246\n",
      "Epoch(13) - Fold 4 - Validation Utility score : 1318.9532\n",
      "Epoch(13) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(13) - GLOBAL - Validation Accuracy: 0.5184\n",
      "Epoch(13) - GLOBAL - Validation Utility score: 2530.5680\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(14) - Training Loss: 0.6909\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(14) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(14) - Fold 0 - Validation Accuracy : 0.5209\n",
      "Epoch(14) - Fold 0 - Validation Utility score : 260.8553\n",
      "Epoch(14) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(14) - Fold 1 - Validation Accuracy : 0.5228\n",
      "Epoch(14) - Fold 1 - Validation Utility score : 929.6791\n",
      "Epoch(14) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(14) - Fold 2 - Validation Accuracy : 0.5082\n",
      "Epoch(14) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(14) - Fold 3 - Validation Accuracy : 0.5126\n",
      "Epoch(14) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 4 - Validation Loss : 0.6910\n",
      "Epoch(14) - Fold 4 - Validation Accuracy : 0.5247\n",
      "Epoch(14) - Fold 4 - Validation Utility score : 1287.6189\n",
      "Epoch(14) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(14) - GLOBAL - Validation Accuracy: 0.5178\n",
      "Epoch(14) - GLOBAL - Validation Utility score: 2478.1533\n",
      "Saving model corresponding to last_utility_score == 2478.1533182348157\n",
      "\n",
      "\n",
      "Epoch(15) - Training Loss: 0.6907\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(15) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(15) - Fold 0 - Validation Accuracy : 0.5217\n",
      "Epoch(15) - Fold 0 - Validation Utility score : 261.7418\n",
      "Epoch(15) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(15) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(15) - Fold 1 - Validation Utility score : 808.4354\n",
      "Epoch(15) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(15) - Fold 2 - Validation Accuracy : 0.5116\n",
      "Epoch(15) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(15) - Fold 3 - Validation Accuracy : 0.5125\n",
      "Epoch(15) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 4 - Validation Loss : 0.6911\n",
      "Epoch(15) - Fold 4 - Validation Accuracy : 0.5249\n",
      "Epoch(15) - Fold 4 - Validation Utility score : 1395.1987\n",
      "Epoch(15) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(15) - GLOBAL - Validation Accuracy: 0.5188\n",
      "Epoch(15) - GLOBAL - Validation Utility score: 2465.3759\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(16) - Training Loss: 0.6905\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(16) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(16) - Fold 0 - Validation Accuracy : 0.5200\n",
      "Epoch(16) - Fold 0 - Validation Utility score : 253.0983\n",
      "Epoch(16) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(16) - Fold 1 - Validation Accuracy : 0.5223\n",
      "Epoch(16) - Fold 1 - Validation Utility score : 1001.1223\n",
      "Epoch(16) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(16) - Fold 2 - Validation Accuracy : 0.5091\n",
      "Epoch(16) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(16) - Fold 3 - Validation Accuracy : 0.5130\n",
      "Epoch(16) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 4 - Validation Loss : 0.6909\n",
      "Epoch(16) - Fold 4 - Validation Accuracy : 0.5251\n",
      "Epoch(16) - Fold 4 - Validation Utility score : 1370.2071\n",
      "Epoch(16) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(16) - GLOBAL - Validation Accuracy: 0.5179\n",
      "Epoch(16) - GLOBAL - Validation Utility score: 2624.4278\n",
      "Saving model corresponding to last_utility_score == 2624.427774963042\n",
      "\n",
      "\n",
      "Epoch(17) - Training Loss: 0.6904\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(17) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(17) - Fold 0 - Validation Accuracy : 0.5213\n",
      "Epoch(17) - Fold 0 - Validation Utility score : 302.9387\n",
      "Epoch(17) - Fold 1 - Validation Loss : 0.6909\n",
      "Epoch(17) - Fold 1 - Validation Accuracy : 0.5222\n",
      "Epoch(17) - Fold 1 - Validation Utility score : 999.8499\n",
      "Epoch(17) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(17) - Fold 2 - Validation Accuracy : 0.5101\n",
      "Epoch(17) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(17) - Fold 3 - Validation Accuracy : 0.5107\n",
      "Epoch(17) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 4 - Validation Loss : 0.6909\n",
      "Epoch(17) - Fold 4 - Validation Accuracy : 0.5246\n",
      "Epoch(17) - Fold 4 - Validation Utility score : 1362.6977\n",
      "Epoch(17) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(17) - GLOBAL - Validation Accuracy: 0.5178\n",
      "Epoch(17) - GLOBAL - Validation Utility score: 2665.4862\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(18) - Training Loss: 0.6901\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(18) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(18) - Fold 0 - Validation Accuracy : 0.5189\n",
      "Epoch(18) - Fold 0 - Validation Utility score : 183.5640\n",
      "Epoch(18) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(18) - Fold 1 - Validation Accuracy : 0.5218\n",
      "Epoch(18) - Fold 1 - Validation Utility score : 795.4952\n",
      "Epoch(18) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(18) - Fold 2 - Validation Accuracy : 0.5096\n",
      "Epoch(18) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(18) - Fold 3 - Validation Accuracy : 0.5111\n",
      "Epoch(18) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 4 - Validation Loss : 0.6909\n",
      "Epoch(18) - Fold 4 - Validation Accuracy : 0.5249\n",
      "Epoch(18) - Fold 4 - Validation Utility score : 1477.4476\n",
      "Epoch(18) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(18) - GLOBAL - Validation Accuracy: 0.5172\n",
      "Epoch(18) - GLOBAL - Validation Utility score: 2456.5068\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(19) - Training Loss: 0.6901\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(19) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(19) - Fold 0 - Validation Accuracy : 0.5196\n",
      "Epoch(19) - Fold 0 - Validation Utility score : 238.3567\n",
      "Epoch(19) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(19) - Fold 1 - Validation Accuracy : 0.5206\n",
      "Epoch(19) - Fold 1 - Validation Utility score : 872.1934\n",
      "Epoch(19) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(19) - Fold 2 - Validation Accuracy : 0.5082\n",
      "Epoch(19) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(19) - Fold 3 - Validation Accuracy : 0.5085\n",
      "Epoch(19) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 4 - Validation Loss : 0.6910\n",
      "Epoch(19) - Fold 4 - Validation Accuracy : 0.5240\n",
      "Epoch(19) - Fold 4 - Validation Utility score : 1285.6073\n",
      "Epoch(19) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(19) - GLOBAL - Validation Accuracy: 0.5162\n",
      "Epoch(19) - GLOBAL - Validation Utility score: 2396.1574\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(20) - Training Loss: 0.6899\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(20) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(20) - Fold 0 - Validation Accuracy : 0.5206\n",
      "Epoch(20) - Fold 0 - Validation Utility score : 194.4587\n",
      "Epoch(20) - Fold 1 - Validation Loss : 0.6909\n",
      "Epoch(20) - Fold 1 - Validation Accuracy : 0.5218\n",
      "Epoch(20) - Fold 1 - Validation Utility score : 799.1990\n",
      "Epoch(20) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(20) - Fold 2 - Validation Accuracy : 0.5099\n",
      "Epoch(20) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(20) - Fold 3 - Validation Accuracy : 0.5095\n",
      "Epoch(20) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 4 - Validation Loss : 0.6907\n",
      "Epoch(20) - Fold 4 - Validation Accuracy : 0.5264\n",
      "Epoch(20) - Fold 4 - Validation Utility score : 1445.2698\n",
      "Epoch(20) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(20) - GLOBAL - Validation Accuracy: 0.5176\n",
      "Epoch(20) - GLOBAL - Validation Utility score: 2438.9276\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(21) - Training Loss: 0.6897\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(21) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(21) - Fold 0 - Validation Accuracy : 0.5191\n",
      "Epoch(21) - Fold 0 - Validation Utility score : 322.6962\n",
      "Epoch(21) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(21) - Fold 1 - Validation Accuracy : 0.5212\n",
      "Epoch(21) - Fold 1 - Validation Utility score : 788.1303\n",
      "Epoch(21) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(21) - Fold 2 - Validation Accuracy : 0.5074\n",
      "Epoch(21) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(21) - Fold 3 - Validation Accuracy : 0.5098\n",
      "Epoch(21) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 4 - Validation Loss : 0.6911\n",
      "Epoch(21) - Fold 4 - Validation Accuracy : 0.5240\n",
      "Epoch(21) - Fold 4 - Validation Utility score : 1203.4321\n",
      "Epoch(21) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(21) - GLOBAL - Validation Accuracy: 0.5163\n",
      "Epoch(21) - GLOBAL - Validation Utility score: 2314.2587\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6919\n",
      "Meet Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 527085<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_091640-r3athxss/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_091640-r3athxss/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>0.68965</td></tr><tr><td>Global valid/Loss</td><td>0.69211</td></tr><tr><td>Global valid/Accuracy</td><td>0.51633</td></tr><tr><td>Global valid/Utility</td><td>2314.25869</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>0.69184</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>0.51913</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>322.69622</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>0.69118</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>0.52124</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>788.13034</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>0.69324</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>0.50743</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>0.69322</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>0.50985</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>0.69106</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>0.52401</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>1203.43212</td></tr><tr><td>Best accuracy</td><td>0.51791</td></tr><tr><td>Best utility</td><td>2624.42777</td></tr><tr><td>_runtime</td><td>1390</td></tr><tr><td>_timestamp</td><td>1613464790</td></tr><tr><td>_step</td><td>21</td></tr><tr><td>Final utility score</td><td>{'utility_score': 26...</td></tr><tr><td>Batch size</td><td>42274</td></tr><tr><td>Patience</td><td>5</td></tr><tr><td>Number of epochs</td><td>1000</td></tr><tr><td>Best epoch</td><td>16</td></tr><tr><td>Number of parameters per layer</td><td>[8384, 64, 2048, 32,...</td></tr><tr><td>Model architecture</td><td>MLP(<BR>  (AEncoder)...</td></tr><tr><td>comment</td><td>All folds MLP with a...</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Loss</td><td>█▆▅▅▄▄▃▂▂▂▁▁▁▁▁▁▁▁▂▁▁▂</td></tr><tr><td>Global valid/Accuracy</td><td>▃▁▁▄▅▆▇▇▇▇███████▇▇▇▇▇</td></tr><tr><td>Global valid/Utility</td><td>▁▁▁▅▆▇███▇▇▇▇▆▆▆▇▇▆▆▆▆</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>█▆▆▆▅▄▃▂▂▁▁▁▁▂▁▂▂▂▃▂▂▃</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>▄▁▂▅▆▇████▇▇█▇▆▇▆▇▆▆▆▆</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>▂▁▂▇▇▆██▇▆▄▄▄▄▃▃▃▄▃▃▃▄</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>▇██▇▇▆▅▄▃▃▂▂▂▂▁▂▁▁▂▂▁▂</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>▄▂▁▄▅▇▇█▇███████▇▇▇▇▇▇</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>▃▂▁▃▅▆▇▇▆▇█▇▇▇▇▆▇▇▆▆▆▆</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>█▃▂▂▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▃▃</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>▂▁▂▅▅▄▅▅▅▅▅▆▆▆▆█▆▇▇▆▇▅</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>▂▃▁▂▃▄▅█▇▇█▇█████▆▇▅▆▆</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>▁█▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>█▆▆▆▆▅▅▄▃▃▃▃▂▂▂▂▁▁▂▂▁▂</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>▁▂▂▄▅▆▆▆▇▇▇▇▇▇▇▇█▇▇▇█▇</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>▁▁▃▆▆▇▇▇██▇█▇▇▇█▇▇█▇█▇</td></tr><tr><td>Best accuracy</td><td>▃▁▁▄▅▆▇█████████</td></tr><tr><td>Best utility</td><td>▁▁▁▅▆▇███▇▇▇▇▆▇▇</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 111 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">glowing-sweep-8</strong>: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/r3athxss\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/r3athxss</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training summary:\n",
      "{'utility_score': 2624.427774963042, 'utility_scores': [253.0983139526211, 1001.122327803408, -0.0, -0.0, 1370.207133207013], 'utility_score_std': 559.6870608552715, 'accuracy_scores': [0.5199784553018384, 0.5223306423306423, 0.509134849743565, 0.5129931341099668, 0.525137343287787]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x1kzlk72 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leakyrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 60396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4318461480018635\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007970175626986542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_autoenc: encoder\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 4.870225611337393e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">magic-sweep-9</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/x1kzlk72\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/x1kzlk72</a><br/>\n",
       "                Run data is saved locally in <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_093955-x1kzlk72</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Run config :\n",
      "config: {'activation_function': 'leakyrelu', 'batch_size': 60396, 'dropout': 0.4318461480018635, 'learning_rate': 0.0007970175626986542, 'use_autoenc': 'encoder', 'weight_decay': 4.870225611337393e-05, 'epochs': 1000}\n",
      "Epoch(0) - Training Loss: 0.7699\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(0) - Fold 0 - Validation Loss : 0.6962\n",
      "Epoch(0) - Fold 0 - Validation Accuracy : 0.5062\n",
      "Epoch(0) - Fold 0 - Validation Utility score : 15.7907\n",
      "Epoch(0) - Fold 1 - Validation Loss : 0.6963\n",
      "Epoch(0) - Fold 1 - Validation Accuracy : 0.4992\n",
      "Epoch(0) - Fold 1 - Validation Utility score : 49.8888\n",
      "Epoch(0) - Fold 2 - Validation Loss : 0.6975\n",
      "Epoch(0) - Fold 2 - Validation Accuracy : 0.4999\n",
      "Epoch(0) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 3 - Validation Loss : 0.6968\n",
      "Epoch(0) - Fold 3 - Validation Accuracy : 0.4981\n",
      "Epoch(0) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 4 - Validation Loss : 0.6965\n",
      "Epoch(0) - Fold 4 - Validation Accuracy : 0.4961\n",
      "Epoch(0) - Fold 4 - Validation Utility score : -0.0000\n",
      "Epoch(0) - GLOBAL - Validation Loss: 0.6967\n",
      "Epoch(0) - GLOBAL - Validation Accuracy: 0.4999\n",
      "Epoch(0) - GLOBAL - Validation Utility score: 65.6796\n",
      "Saving model corresponding to last_utility_score == 65.6795862066141\n",
      "\n",
      "\n",
      "Epoch(1) - Training Loss: 0.7379\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(1) - Fold 0 - Validation Loss : 0.6933\n",
      "Epoch(1) - Fold 0 - Validation Accuracy : 0.5162\n",
      "Epoch(1) - Fold 0 - Validation Utility score : 139.9263\n",
      "Epoch(1) - Fold 1 - Validation Loss : 0.6930\n",
      "Epoch(1) - Fold 1 - Validation Accuracy : 0.5110\n",
      "Epoch(1) - Fold 1 - Validation Utility score : 319.3170\n",
      "Epoch(1) - Fold 2 - Validation Loss : 0.6947\n",
      "Epoch(1) - Fold 2 - Validation Accuracy : 0.5047\n",
      "Epoch(1) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 3 - Validation Loss : 0.6944\n",
      "Epoch(1) - Fold 3 - Validation Accuracy : 0.5021\n",
      "Epoch(1) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 4 - Validation Loss : 0.6937\n",
      "Epoch(1) - Fold 4 - Validation Accuracy : 0.5058\n",
      "Epoch(1) - Fold 4 - Validation Utility score : 165.2232\n",
      "Epoch(1) - GLOBAL - Validation Loss: 0.6938\n",
      "Epoch(1) - GLOBAL - Validation Accuracy: 0.5080\n",
      "Epoch(1) - GLOBAL - Validation Utility score: 624.4666\n",
      "Saving model corresponding to last_utility_score == 624.4665584038687\n",
      "\n",
      "\n",
      "Epoch(2) - Training Loss: 0.7151\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(2) - Fold 0 - Validation Loss : 0.6929\n",
      "Epoch(2) - Fold 0 - Validation Accuracy : 0.5145\n",
      "Epoch(2) - Fold 0 - Validation Utility score : 202.5231\n",
      "Epoch(2) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(2) - Fold 1 - Validation Accuracy : 0.5119\n",
      "Epoch(2) - Fold 1 - Validation Utility score : 756.1356\n",
      "Epoch(2) - Fold 2 - Validation Loss : 0.6936\n",
      "Epoch(2) - Fold 2 - Validation Accuracy : 0.5061\n",
      "Epoch(2) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(2) - Fold 3 - Validation Accuracy : 0.5050\n",
      "Epoch(2) - Fold 3 - Validation Utility score : 192.4601\n",
      "Epoch(2) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(2) - Fold 4 - Validation Accuracy : 0.5093\n",
      "Epoch(2) - Fold 4 - Validation Utility score : 360.8810\n",
      "Epoch(2) - GLOBAL - Validation Loss: 0.6931\n",
      "Epoch(2) - GLOBAL - Validation Accuracy: 0.5094\n",
      "Epoch(2) - GLOBAL - Validation Utility score: 1511.9999\n",
      "Saving model corresponding to last_utility_score == 1511.999862585228\n",
      "\n",
      "\n",
      "Epoch(3) - Training Loss: 0.7031\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(3) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(3) - Fold 0 - Validation Accuracy : 0.5129\n",
      "Epoch(3) - Fold 0 - Validation Utility score : 48.7365\n",
      "Epoch(3) - Fold 1 - Validation Loss : 0.6926\n",
      "Epoch(3) - Fold 1 - Validation Accuracy : 0.5119\n",
      "Epoch(3) - Fold 1 - Validation Utility score : 801.3283\n",
      "Epoch(3) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(3) - Fold 2 - Validation Accuracy : 0.5055\n",
      "Epoch(3) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(3) - Fold 3 - Validation Accuracy : 0.5065\n",
      "Epoch(3) - Fold 3 - Validation Utility score : 108.2138\n",
      "Epoch(3) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(3) - Fold 4 - Validation Accuracy : 0.5133\n",
      "Epoch(3) - Fold 4 - Validation Utility score : 435.2900\n",
      "Epoch(3) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(3) - GLOBAL - Validation Accuracy: 0.5100\n",
      "Epoch(3) - GLOBAL - Validation Utility score: 1393.5686\n",
      "Saving model corresponding to last_utility_score == 1393.5685616299372\n",
      "\n",
      "\n",
      "Epoch(4) - Training Loss: 0.6975\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(4) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(4) - Fold 0 - Validation Accuracy : 0.5105\n",
      "Epoch(4) - Fold 0 - Validation Utility score : 44.0192\n",
      "Epoch(4) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(4) - Fold 1 - Validation Accuracy : 0.5073\n",
      "Epoch(4) - Fold 1 - Validation Utility score : 248.1322\n",
      "Epoch(4) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(4) - Fold 2 - Validation Accuracy : 0.5029\n",
      "Epoch(4) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(4) - Fold 3 - Validation Accuracy : 0.5032\n",
      "Epoch(4) - Fold 3 - Validation Utility score : 3.0592\n",
      "Epoch(4) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(4) - Fold 4 - Validation Accuracy : 0.5099\n",
      "Epoch(4) - Fold 4 - Validation Utility score : 317.1434\n",
      "Epoch(4) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(4) - GLOBAL - Validation Accuracy: 0.5068\n",
      "Epoch(4) - GLOBAL - Validation Utility score: 612.3540\n",
      "Intermediate early stopping : vepoch_loss = 0.6929, the_last_loss=0.6928\n",
      "\n",
      "\n",
      "Epoch(5) - Training Loss: 0.6952\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(5) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(5) - Fold 0 - Validation Accuracy : 0.5109\n",
      "Epoch(5) - Fold 0 - Validation Utility score : 132.8932\n",
      "Epoch(5) - Fold 1 - Validation Loss : 0.6929\n",
      "Epoch(5) - Fold 1 - Validation Accuracy : 0.5051\n",
      "Epoch(5) - Fold 1 - Validation Utility score : 202.0856\n",
      "Epoch(5) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(5) - Fold 2 - Validation Accuracy : 0.5023\n",
      "Epoch(5) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(5) - Fold 3 - Validation Accuracy : 0.5025\n",
      "Epoch(5) - Fold 3 - Validation Utility score : 15.0708\n",
      "Epoch(5) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(5) - Fold 4 - Validation Accuracy : 0.5101\n",
      "Epoch(5) - Fold 4 - Validation Utility score : 417.0207\n",
      "Epoch(5) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(5) - GLOBAL - Validation Accuracy: 0.5062\n",
      "Epoch(5) - GLOBAL - Validation Utility score: 767.0703\n",
      "Intermediate early stopping : vepoch_loss = 0.6929, the_last_loss=0.6928\n",
      "\n",
      "\n",
      "Epoch(6) - Training Loss: 0.6939\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(6) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(6) - Fold 0 - Validation Accuracy : 0.5159\n",
      "Epoch(6) - Fold 0 - Validation Utility score : 362.4772\n",
      "Epoch(6) - Fold 1 - Validation Loss : 0.6929\n",
      "Epoch(6) - Fold 1 - Validation Accuracy : 0.5099\n",
      "Epoch(6) - Fold 1 - Validation Utility score : 279.8898\n",
      "Epoch(6) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(6) - Fold 2 - Validation Accuracy : 0.5051\n",
      "Epoch(6) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(6) - Fold 3 - Validation Accuracy : 0.5039\n",
      "Epoch(6) - Fold 3 - Validation Utility score : 1.3038\n",
      "Epoch(6) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(6) - Fold 4 - Validation Accuracy : 0.5125\n",
      "Epoch(6) - Fold 4 - Validation Utility score : 891.3728\n",
      "Epoch(6) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(6) - GLOBAL - Validation Accuracy: 0.5094\n",
      "Epoch(6) - GLOBAL - Validation Utility score: 1535.0436\n",
      "Intermediate early stopping : vepoch_loss = 0.6929, the_last_loss=0.6928\n",
      "\n",
      "\n",
      "Epoch(7) - Training Loss: 0.6934\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(7) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(7) - Fold 0 - Validation Accuracy : 0.5188\n",
      "Epoch(7) - Fold 0 - Validation Utility score : 474.7657\n",
      "Epoch(7) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(7) - Fold 1 - Validation Accuracy : 0.5133\n",
      "Epoch(7) - Fold 1 - Validation Utility score : 470.5123\n",
      "Epoch(7) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(7) - Fold 2 - Validation Accuracy : 0.5055\n",
      "Epoch(7) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(7) - Fold 3 - Validation Accuracy : 0.5051\n",
      "Epoch(7) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(7) - Fold 4 - Validation Accuracy : 0.5140\n",
      "Epoch(7) - Fold 4 - Validation Utility score : 971.4442\n",
      "Epoch(7) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(7) - GLOBAL - Validation Accuracy: 0.5113\n",
      "Epoch(7) - GLOBAL - Validation Utility score: 1916.7223\n",
      "Intermediate early stopping : vepoch_loss = 0.6928, the_last_loss=0.6928\n",
      "\n",
      "\n",
      "Epoch(8) - Training Loss: 0.6931\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(8) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(8) - Fold 0 - Validation Accuracy : 0.5195\n",
      "Epoch(8) - Fold 0 - Validation Utility score : 543.7585\n",
      "Epoch(8) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(8) - Fold 1 - Validation Accuracy : 0.5150\n",
      "Epoch(8) - Fold 1 - Validation Utility score : 616.3658\n",
      "Epoch(8) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(8) - Fold 2 - Validation Accuracy : 0.5057\n",
      "Epoch(8) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(8) - Fold 3 - Validation Accuracy : 0.5053\n",
      "Epoch(8) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(8) - Fold 4 - Validation Accuracy : 0.5156\n",
      "Epoch(8) - Fold 4 - Validation Utility score : 1031.5028\n",
      "Epoch(8) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(8) - GLOBAL - Validation Accuracy: 0.5122\n",
      "Epoch(8) - GLOBAL - Validation Utility score: 2191.6270\n",
      "Saving model corresponding to last_utility_score == 2191.6270416583784\n",
      "\n",
      "\n",
      "Epoch(9) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(9) - Fold 0 - Validation Loss : 0.6924\n",
      "Epoch(9) - Fold 0 - Validation Accuracy : 0.5230\n",
      "Epoch(9) - Fold 0 - Validation Utility score : 583.5287\n",
      "Epoch(9) - Fold 1 - Validation Loss : 0.6926\n",
      "Epoch(9) - Fold 1 - Validation Accuracy : 0.5184\n",
      "Epoch(9) - Fold 1 - Validation Utility score : 772.6595\n",
      "Epoch(9) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(9) - Fold 2 - Validation Accuracy : 0.5061\n",
      "Epoch(9) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(9) - Fold 3 - Validation Accuracy : 0.5097\n",
      "Epoch(9) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(9) - Fold 4 - Validation Accuracy : 0.5182\n",
      "Epoch(9) - Fold 4 - Validation Utility score : 1196.2127\n",
      "Epoch(9) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(9) - GLOBAL - Validation Accuracy: 0.5151\n",
      "Epoch(9) - GLOBAL - Validation Utility score: 2552.4009\n",
      "Saving model corresponding to last_utility_score == 2552.4008819389096\n",
      "\n",
      "\n",
      "Epoch(10) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(10) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(10) - Fold 0 - Validation Accuracy : 0.5229\n",
      "Epoch(10) - Fold 0 - Validation Utility score : 525.1522\n",
      "Epoch(10) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(10) - Fold 1 - Validation Accuracy : 0.5207\n",
      "Epoch(10) - Fold 1 - Validation Utility score : 918.4270\n",
      "Epoch(10) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(10) - Fold 2 - Validation Accuracy : 0.5072\n",
      "Epoch(10) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(10) - Fold 3 - Validation Accuracy : 0.5114\n",
      "Epoch(10) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(10) - Fold 4 - Validation Accuracy : 0.5178\n",
      "Epoch(10) - Fold 4 - Validation Utility score : 1134.7272\n",
      "Epoch(10) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(10) - GLOBAL - Validation Accuracy: 0.5160\n",
      "Epoch(10) - GLOBAL - Validation Utility score: 2578.3064\n",
      "Saving model corresponding to last_utility_score == 2578.3063697449534\n",
      "\n",
      "\n",
      "Epoch(11) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(11) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(11) - Fold 0 - Validation Accuracy : 0.5235\n",
      "Epoch(11) - Fold 0 - Validation Utility score : 574.7189\n",
      "Epoch(11) - Fold 1 - Validation Loss : 0.6923\n",
      "Epoch(11) - Fold 1 - Validation Accuracy : 0.5226\n",
      "Epoch(11) - Fold 1 - Validation Utility score : 979.7541\n",
      "Epoch(11) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(11) - Fold 2 - Validation Accuracy : 0.5073\n",
      "Epoch(11) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(11) - Fold 3 - Validation Accuracy : 0.5124\n",
      "Epoch(11) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(11) - Fold 4 - Validation Accuracy : 0.5186\n",
      "Epoch(11) - Fold 4 - Validation Utility score : 1179.2534\n",
      "Epoch(11) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(11) - GLOBAL - Validation Accuracy: 0.5169\n",
      "Epoch(11) - GLOBAL - Validation Utility score: 2733.7264\n",
      "Saving model corresponding to last_utility_score == 2733.7263551593305\n",
      "\n",
      "\n",
      "Epoch(12) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(12) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(12) - Fold 0 - Validation Accuracy : 0.5229\n",
      "Epoch(12) - Fold 0 - Validation Utility score : 775.1309\n",
      "Epoch(12) - Fold 1 - Validation Loss : 0.6923\n",
      "Epoch(12) - Fold 1 - Validation Accuracy : 0.5213\n",
      "Epoch(12) - Fold 1 - Validation Utility score : 1121.8169\n",
      "Epoch(12) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(12) - Fold 2 - Validation Accuracy : 0.5071\n",
      "Epoch(12) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(12) - Fold 3 - Validation Accuracy : 0.5113\n",
      "Epoch(12) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(12) - Fold 4 - Validation Accuracy : 0.5207\n",
      "Epoch(12) - Fold 4 - Validation Utility score : 1276.0427\n",
      "Epoch(12) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(12) - GLOBAL - Validation Accuracy: 0.5166\n",
      "Epoch(12) - GLOBAL - Validation Utility score: 3172.9905\n",
      "Saving model corresponding to last_utility_score == 3172.9905469396745\n",
      "\n",
      "\n",
      "Epoch(13) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(13) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(13) - Fold 0 - Validation Accuracy : 0.5242\n",
      "Epoch(13) - Fold 0 - Validation Utility score : 617.6445\n",
      "Epoch(13) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(13) - Fold 1 - Validation Accuracy : 0.5229\n",
      "Epoch(13) - Fold 1 - Validation Utility score : 1048.1884\n",
      "Epoch(13) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(13) - Fold 2 - Validation Accuracy : 0.5075\n",
      "Epoch(13) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(13) - Fold 3 - Validation Accuracy : 0.5126\n",
      "Epoch(13) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(13) - Fold 4 - Validation Accuracy : 0.5205\n",
      "Epoch(13) - Fold 4 - Validation Utility score : 1366.1605\n",
      "Epoch(13) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(13) - GLOBAL - Validation Accuracy: 0.5176\n",
      "Epoch(13) - GLOBAL - Validation Utility score: 3031.9934\n",
      "Saving model corresponding to last_utility_score == 3031.993384650409\n",
      "\n",
      "\n",
      "Epoch(14) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(14) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(14) - Fold 0 - Validation Accuracy : 0.5240\n",
      "Epoch(14) - Fold 0 - Validation Utility score : 613.3658\n",
      "Epoch(14) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(14) - Fold 1 - Validation Accuracy : 0.5222\n",
      "Epoch(14) - Fold 1 - Validation Utility score : 1036.2862\n",
      "Epoch(14) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(14) - Fold 2 - Validation Accuracy : 0.5076\n",
      "Epoch(14) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(14) - Fold 3 - Validation Accuracy : 0.5130\n",
      "Epoch(14) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(14) - Fold 4 - Validation Accuracy : 0.5216\n",
      "Epoch(14) - Fold 4 - Validation Utility score : 1425.9836\n",
      "Epoch(14) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(14) - GLOBAL - Validation Accuracy: 0.5177\n",
      "Epoch(14) - GLOBAL - Validation Utility score: 3075.6355\n",
      "Saving model corresponding to last_utility_score == 3075.63554544978\n",
      "\n",
      "\n",
      "Epoch(15) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(15) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(15) - Fold 0 - Validation Accuracy : 0.5235\n",
      "Epoch(15) - Fold 0 - Validation Utility score : 595.0423\n",
      "Epoch(15) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(15) - Fold 1 - Validation Accuracy : 0.5241\n",
      "Epoch(15) - Fold 1 - Validation Utility score : 1164.0419\n",
      "Epoch(15) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(15) - Fold 2 - Validation Accuracy : 0.5073\n",
      "Epoch(15) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(15) - Fold 3 - Validation Accuracy : 0.5130\n",
      "Epoch(15) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(15) - Fold 4 - Validation Accuracy : 0.5221\n",
      "Epoch(15) - Fold 4 - Validation Utility score : 1248.4598\n",
      "Epoch(15) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(15) - GLOBAL - Validation Accuracy: 0.5180\n",
      "Epoch(15) - GLOBAL - Validation Utility score: 3007.5439\n",
      "Saving model corresponding to last_utility_score == 3007.543924924989\n",
      "\n",
      "\n",
      "Epoch(16) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(16) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(16) - Fold 0 - Validation Accuracy : 0.5242\n",
      "Epoch(16) - Fold 0 - Validation Utility score : 560.2060\n",
      "Epoch(16) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(16) - Fold 1 - Validation Accuracy : 0.5228\n",
      "Epoch(16) - Fold 1 - Validation Utility score : 1067.6868\n",
      "Epoch(16) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(16) - Fold 2 - Validation Accuracy : 0.5069\n",
      "Epoch(16) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(16) - Fold 3 - Validation Accuracy : 0.5121\n",
      "Epoch(16) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(16) - Fold 4 - Validation Accuracy : 0.5227\n",
      "Epoch(16) - Fold 4 - Validation Utility score : 1376.3131\n",
      "Epoch(16) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(16) - GLOBAL - Validation Accuracy: 0.5178\n",
      "Epoch(16) - GLOBAL - Validation Utility score: 3004.2059\n",
      "Saving model corresponding to last_utility_score == 3004.2058791610802\n",
      "\n",
      "\n",
      "Epoch(17) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(17) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(17) - Fold 0 - Validation Accuracy : 0.5238\n",
      "Epoch(17) - Fold 0 - Validation Utility score : 495.3728\n",
      "Epoch(17) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(17) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(17) - Fold 1 - Validation Utility score : 1022.7769\n",
      "Epoch(17) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(17) - Fold 2 - Validation Accuracy : 0.5079\n",
      "Epoch(17) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(17) - Fold 3 - Validation Accuracy : 0.5133\n",
      "Epoch(17) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(17) - Fold 4 - Validation Accuracy : 0.5226\n",
      "Epoch(17) - Fold 4 - Validation Utility score : 1382.7837\n",
      "Epoch(17) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(17) - GLOBAL - Validation Accuracy: 0.5182\n",
      "Epoch(17) - GLOBAL - Validation Utility score: 2900.9334\n",
      "Saving model corresponding to last_utility_score == 2900.9334127675215\n",
      "\n",
      "\n",
      "Epoch(18) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(18) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(18) - Fold 0 - Validation Accuracy : 0.5236\n",
      "Epoch(18) - Fold 0 - Validation Utility score : 472.9601\n",
      "Epoch(18) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(18) - Fold 1 - Validation Accuracy : 0.5233\n",
      "Epoch(18) - Fold 1 - Validation Utility score : 1020.1045\n",
      "Epoch(18) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(18) - Fold 2 - Validation Accuracy : 0.5077\n",
      "Epoch(18) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(18) - Fold 3 - Validation Accuracy : 0.5125\n",
      "Epoch(18) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(18) - Fold 4 - Validation Accuracy : 0.5237\n",
      "Epoch(18) - Fold 4 - Validation Utility score : 1407.4558\n",
      "Epoch(18) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(18) - GLOBAL - Validation Accuracy: 0.5182\n",
      "Epoch(18) - GLOBAL - Validation Utility score: 2900.5204\n",
      "Saving model corresponding to last_utility_score == 2900.5203505425507\n",
      "\n",
      "\n",
      "Epoch(19) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(19) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(19) - Fold 0 - Validation Accuracy : 0.5237\n",
      "Epoch(19) - Fold 0 - Validation Utility score : 454.7893\n",
      "Epoch(19) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(19) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(19) - Fold 1 - Validation Utility score : 1116.9115\n",
      "Epoch(19) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(19) - Fold 2 - Validation Accuracy : 0.5086\n",
      "Epoch(19) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(19) - Fold 3 - Validation Accuracy : 0.5133\n",
      "Epoch(19) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(19) - Fold 4 - Validation Accuracy : 0.5227\n",
      "Epoch(19) - Fold 4 - Validation Utility score : 1357.8011\n",
      "Epoch(19) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(19) - GLOBAL - Validation Accuracy: 0.5183\n",
      "Epoch(19) - GLOBAL - Validation Utility score: 2929.5019\n",
      "Saving model corresponding to last_utility_score == 2929.501907238423\n",
      "\n",
      "\n",
      "Epoch(20) - Training Loss: 0.6915\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(20) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(20) - Fold 0 - Validation Accuracy : 0.5239\n",
      "Epoch(20) - Fold 0 - Validation Utility score : 519.7099\n",
      "Epoch(20) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(20) - Fold 1 - Validation Accuracy : 0.5237\n",
      "Epoch(20) - Fold 1 - Validation Utility score : 1091.0243\n",
      "Epoch(20) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(20) - Fold 2 - Validation Accuracy : 0.5088\n",
      "Epoch(20) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(20) - Fold 3 - Validation Accuracy : 0.5133\n",
      "Epoch(20) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(20) - Fold 4 - Validation Accuracy : 0.5241\n",
      "Epoch(20) - Fold 4 - Validation Utility score : 1285.6471\n",
      "Epoch(20) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(20) - GLOBAL - Validation Accuracy: 0.5188\n",
      "Epoch(20) - GLOBAL - Validation Utility score: 2896.3813\n",
      "Saving model corresponding to last_utility_score == 2896.381298731121\n",
      "\n",
      "\n",
      "Epoch(21) - Training Loss: 0.6913\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(21) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(21) - Fold 0 - Validation Accuracy : 0.5236\n",
      "Epoch(21) - Fold 0 - Validation Utility score : 373.5485\n",
      "Epoch(21) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(21) - Fold 1 - Validation Accuracy : 0.5248\n",
      "Epoch(21) - Fold 1 - Validation Utility score : 1120.7602\n",
      "Epoch(21) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(21) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(21) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(21) - Fold 3 - Validation Accuracy : 0.5144\n",
      "Epoch(21) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(21) - Fold 4 - Validation Accuracy : 0.5227\n",
      "Epoch(21) - Fold 4 - Validation Utility score : 1227.7666\n",
      "Epoch(21) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(21) - GLOBAL - Validation Accuracy: 0.5188\n",
      "Epoch(21) - GLOBAL - Validation Utility score: 2722.0753\n",
      "Saving model corresponding to last_utility_score == 2722.075293906788\n",
      "\n",
      "\n",
      "Epoch(22) - Training Loss: 0.6913\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(22) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(22) - Fold 0 - Validation Accuracy : 0.5241\n",
      "Epoch(22) - Fold 0 - Validation Utility score : 463.6535\n",
      "Epoch(22) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(22) - Fold 1 - Validation Accuracy : 0.5252\n",
      "Epoch(22) - Fold 1 - Validation Utility score : 1083.8266\n",
      "Epoch(22) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(22) - Fold 2 - Validation Accuracy : 0.5093\n",
      "Epoch(22) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(22) - Fold 3 - Validation Accuracy : 0.5138\n",
      "Epoch(22) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(22) - Fold 4 - Validation Accuracy : 0.5232\n",
      "Epoch(22) - Fold 4 - Validation Utility score : 1236.5446\n",
      "Epoch(22) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(22) - GLOBAL - Validation Accuracy: 0.5191\n",
      "Epoch(22) - GLOBAL - Validation Utility score: 2784.0247\n",
      "Saving model corresponding to last_utility_score == 2784.0247290860175\n",
      "\n",
      "\n",
      "Epoch(23) - Training Loss: 0.6912\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(23) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(23) - Fold 0 - Validation Accuracy : 0.5232\n",
      "Epoch(23) - Fold 0 - Validation Utility score : 303.1655\n",
      "Epoch(23) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(23) - Fold 1 - Validation Accuracy : 0.5245\n",
      "Epoch(23) - Fold 1 - Validation Utility score : 1123.0377\n",
      "Epoch(23) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(23) - Fold 2 - Validation Accuracy : 0.5091\n",
      "Epoch(23) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(23) - Fold 3 - Validation Accuracy : 0.5124\n",
      "Epoch(23) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 4 - Validation Loss : 0.6912\n",
      "Epoch(23) - Fold 4 - Validation Accuracy : 0.5239\n",
      "Epoch(23) - Fold 4 - Validation Utility score : 1337.7242\n",
      "Epoch(23) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(23) - GLOBAL - Validation Accuracy: 0.5186\n",
      "Epoch(23) - GLOBAL - Validation Utility score: 2763.9274\n",
      "Saving model corresponding to last_utility_score == 2763.927399208423\n",
      "\n",
      "\n",
      "Epoch(24) - Training Loss: 0.6911\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(24) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(24) - Fold 0 - Validation Accuracy : 0.5235\n",
      "Epoch(24) - Fold 0 - Validation Utility score : 346.7287\n",
      "Epoch(24) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(24) - Fold 1 - Validation Accuracy : 0.5241\n",
      "Epoch(24) - Fold 1 - Validation Utility score : 951.8184\n",
      "Epoch(24) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(24) - Fold 2 - Validation Accuracy : 0.5096\n",
      "Epoch(24) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(24) - Fold 3 - Validation Accuracy : 0.5121\n",
      "Epoch(24) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 4 - Validation Loss : 0.6911\n",
      "Epoch(24) - Fold 4 - Validation Accuracy : 0.5245\n",
      "Epoch(24) - Fold 4 - Validation Utility score : 1378.6214\n",
      "Epoch(24) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(24) - GLOBAL - Validation Accuracy: 0.5188\n",
      "Epoch(24) - GLOBAL - Validation Utility score: 2677.1684\n",
      "Saving model corresponding to last_utility_score == 2677.168393475342\n",
      "\n",
      "\n",
      "Epoch(25) - Training Loss: 0.6911\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(25) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(25) - Fold 0 - Validation Accuracy : 0.5230\n",
      "Epoch(25) - Fold 0 - Validation Utility score : 371.1048\n",
      "Epoch(25) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(25) - Fold 1 - Validation Accuracy : 0.5238\n",
      "Epoch(25) - Fold 1 - Validation Utility score : 1048.9614\n",
      "Epoch(25) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(25) - Fold 2 - Validation Accuracy : 0.5096\n",
      "Epoch(25) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(25) - Fold 3 - Validation Accuracy : 0.5114\n",
      "Epoch(25) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 4 - Validation Loss : 0.6912\n",
      "Epoch(25) - Fold 4 - Validation Accuracy : 0.5242\n",
      "Epoch(25) - Fold 4 - Validation Utility score : 1295.0832\n",
      "Epoch(25) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(25) - GLOBAL - Validation Accuracy: 0.5184\n",
      "Epoch(25) - GLOBAL - Validation Utility score: 2715.1494\n",
      "Saving model corresponding to last_utility_score == 2715.1493934228283\n",
      "\n",
      "\n",
      "Epoch(26) - Training Loss: 0.6909\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(26) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(26) - Fold 0 - Validation Accuracy : 0.5232\n",
      "Epoch(26) - Fold 0 - Validation Utility score : 321.3714\n",
      "Epoch(26) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(26) - Fold 1 - Validation Accuracy : 0.5237\n",
      "Epoch(26) - Fold 1 - Validation Utility score : 1095.1014\n",
      "Epoch(26) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(26) - Fold 2 - Validation Accuracy : 0.5089\n",
      "Epoch(26) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(26) - Fold 3 - Validation Accuracy : 0.5116\n",
      "Epoch(26) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 4 - Validation Loss : 0.6910\n",
      "Epoch(26) - Fold 4 - Validation Accuracy : 0.5242\n",
      "Epoch(26) - Fold 4 - Validation Utility score : 1296.9206\n",
      "Epoch(26) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(26) - GLOBAL - Validation Accuracy: 0.5183\n",
      "Epoch(26) - GLOBAL - Validation Utility score: 2713.3933\n",
      "Saving model corresponding to last_utility_score == 2713.393306126174\n",
      "\n",
      "\n",
      "Epoch(27) - Training Loss: 0.6908\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(27) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(27) - Fold 0 - Validation Accuracy : 0.5226\n",
      "Epoch(27) - Fold 0 - Validation Utility score : 340.3834\n",
      "Epoch(27) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(27) - Fold 1 - Validation Accuracy : 0.5231\n",
      "Epoch(27) - Fold 1 - Validation Utility score : 1074.9566\n",
      "Epoch(27) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(27) - Fold 2 - Validation Accuracy : 0.5088\n",
      "Epoch(27) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(27) - Fold 3 - Validation Accuracy : 0.5112\n",
      "Epoch(27) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 4 - Validation Loss : 0.6910\n",
      "Epoch(27) - Fold 4 - Validation Accuracy : 0.5249\n",
      "Epoch(27) - Fold 4 - Validation Utility score : 1346.9845\n",
      "Epoch(27) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(27) - GLOBAL - Validation Accuracy: 0.5181\n",
      "Epoch(27) - GLOBAL - Validation Utility score: 2762.3246\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(28) - Training Loss: 0.6908\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(28) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(28) - Fold 0 - Validation Accuracy : 0.5225\n",
      "Epoch(28) - Fold 0 - Validation Utility score : 326.1235\n",
      "Epoch(28) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(28) - Fold 1 - Validation Accuracy : 0.5224\n",
      "Epoch(28) - Fold 1 - Validation Utility score : 985.3609\n",
      "Epoch(28) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(28) - Fold 2 - Validation Accuracy : 0.5093\n",
      "Epoch(28) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(28) - Fold 3 - Validation Accuracy : 0.5109\n",
      "Epoch(28) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 4 - Validation Loss : 0.6910\n",
      "Epoch(28) - Fold 4 - Validation Accuracy : 0.5246\n",
      "Epoch(28) - Fold 4 - Validation Utility score : 1409.4737\n",
      "Epoch(28) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(28) - GLOBAL - Validation Accuracy: 0.5179\n",
      "Epoch(28) - GLOBAL - Validation Utility score: 2720.9581\n",
      "Saving model corresponding to last_utility_score == 2720.958094547239\n",
      "\n",
      "\n",
      "Epoch(29) - Training Loss: 0.6907\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(29) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(29) - Fold 0 - Validation Accuracy : 0.5222\n",
      "Epoch(29) - Fold 0 - Validation Utility score : 276.7683\n",
      "Epoch(29) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(29) - Fold 1 - Validation Accuracy : 0.5232\n",
      "Epoch(29) - Fold 1 - Validation Utility score : 976.1582\n",
      "Epoch(29) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(29) - Fold 2 - Validation Accuracy : 0.5108\n",
      "Epoch(29) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(29) - Fold 3 - Validation Accuracy : 0.5118\n",
      "Epoch(29) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 4 - Validation Loss : 0.6909\n",
      "Epoch(29) - Fold 4 - Validation Accuracy : 0.5261\n",
      "Epoch(29) - Fold 4 - Validation Utility score : 1363.6546\n",
      "Epoch(29) - GLOBAL - Validation Loss: 0.6918\n",
      "Epoch(29) - GLOBAL - Validation Accuracy: 0.5188\n",
      "Epoch(29) - GLOBAL - Validation Utility score: 2616.5811\n",
      "Saving model corresponding to last_utility_score == 2616.5811462196175\n",
      "\n",
      "\n",
      "Epoch(30) - Training Loss: 0.6906\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(30) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(30) - Fold 0 - Validation Accuracy : 0.5220\n",
      "Epoch(30) - Fold 0 - Validation Utility score : 288.6693\n",
      "Epoch(30) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(30) - Fold 1 - Validation Accuracy : 0.5227\n",
      "Epoch(30) - Fold 1 - Validation Utility score : 1049.7422\n",
      "Epoch(30) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(30) - Fold 2 - Validation Accuracy : 0.5100\n",
      "Epoch(30) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(30) - Fold 3 - Validation Accuracy : 0.5108\n",
      "Epoch(30) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 4 - Validation Loss : 0.6909\n",
      "Epoch(30) - Fold 4 - Validation Accuracy : 0.5260\n",
      "Epoch(30) - Fold 4 - Validation Utility score : 1421.8003\n",
      "Epoch(30) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(30) - GLOBAL - Validation Accuracy: 0.5183\n",
      "Epoch(30) - GLOBAL - Validation Utility score: 2760.2118\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(31) - Training Loss: 0.6905\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(31) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(31) - Fold 0 - Validation Accuracy : 0.5229\n",
      "Epoch(31) - Fold 0 - Validation Utility score : 329.4851\n",
      "Epoch(31) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(31) - Fold 1 - Validation Accuracy : 0.5221\n",
      "Epoch(31) - Fold 1 - Validation Utility score : 895.3728\n",
      "Epoch(31) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(31) - Fold 2 - Validation Accuracy : 0.5097\n",
      "Epoch(31) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(31) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(31) - Fold 3 - Validation Accuracy : 0.5113\n",
      "Epoch(31) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(31) - Fold 4 - Validation Loss : 0.6908\n",
      "Epoch(31) - Fold 4 - Validation Accuracy : 0.5257\n",
      "Epoch(31) - Fold 4 - Validation Utility score : 1484.6165\n",
      "Epoch(31) - GLOBAL - Validation Loss: 0.6918\n",
      "Epoch(31) - GLOBAL - Validation Accuracy: 0.5183\n",
      "Epoch(31) - GLOBAL - Validation Utility score: 2709.4744\n",
      "Saving model corresponding to last_utility_score == 2709.474444456134\n",
      "\n",
      "\n",
      "Epoch(32) - Training Loss: 0.6904\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(32) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(32) - Fold 0 - Validation Accuracy : 0.5223\n",
      "Epoch(32) - Fold 0 - Validation Utility score : 371.9846\n",
      "Epoch(32) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(32) - Fold 1 - Validation Accuracy : 0.5231\n",
      "Epoch(32) - Fold 1 - Validation Utility score : 868.2376\n",
      "Epoch(32) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(32) - Fold 2 - Validation Accuracy : 0.5111\n",
      "Epoch(32) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(32) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(32) - Fold 3 - Validation Accuracy : 0.5099\n",
      "Epoch(32) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(32) - Fold 4 - Validation Loss : 0.6909\n",
      "Epoch(32) - Fold 4 - Validation Accuracy : 0.5252\n",
      "Epoch(32) - Fold 4 - Validation Utility score : 1388.4552\n",
      "Epoch(32) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(32) - GLOBAL - Validation Accuracy: 0.5183\n",
      "Epoch(32) - GLOBAL - Validation Utility score: 2628.6774\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(33) - Training Loss: 0.6903\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(33) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(33) - Fold 0 - Validation Accuracy : 0.5228\n",
      "Epoch(33) - Fold 0 - Validation Utility score : 361.4205\n",
      "Epoch(33) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(33) - Fold 1 - Validation Accuracy : 0.5227\n",
      "Epoch(33) - Fold 1 - Validation Utility score : 873.4400\n",
      "Epoch(33) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(33) - Fold 2 - Validation Accuracy : 0.5113\n",
      "Epoch(33) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(33) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(33) - Fold 3 - Validation Accuracy : 0.5112\n",
      "Epoch(33) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(33) - Fold 4 - Validation Loss : 0.6907\n",
      "Epoch(33) - Fold 4 - Validation Accuracy : 0.5269\n",
      "Epoch(33) - Fold 4 - Validation Utility score : 1411.2980\n",
      "Epoch(33) - GLOBAL - Validation Loss: 0.6918\n",
      "Epoch(33) - GLOBAL - Validation Accuracy: 0.5190\n",
      "Epoch(33) - GLOBAL - Validation Utility score: 2646.1585\n",
      "Intermediate early stopping : vepoch_loss = 0.6918, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(34) - Training Loss: 0.6902\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(34) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(34) - Fold 0 - Validation Accuracy : 0.5213\n",
      "Epoch(34) - Fold 0 - Validation Utility score : 251.2333\n",
      "Epoch(34) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(34) - Fold 1 - Validation Accuracy : 0.5224\n",
      "Epoch(34) - Fold 1 - Validation Utility score : 924.9255\n",
      "Epoch(34) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(34) - Fold 2 - Validation Accuracy : 0.5114\n",
      "Epoch(34) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(34) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(34) - Fold 3 - Validation Accuracy : 0.5104\n",
      "Epoch(34) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(34) - Fold 4 - Validation Loss : 0.6907\n",
      "Epoch(34) - Fold 4 - Validation Accuracy : 0.5256\n",
      "Epoch(34) - Fold 4 - Validation Utility score : 1437.4499\n",
      "Epoch(34) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(34) - GLOBAL - Validation Accuracy: 0.5182\n",
      "Epoch(34) - GLOBAL - Validation Utility score: 2613.6086\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(35) - Training Loss: 0.6901\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(35) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(35) - Fold 0 - Validation Accuracy : 0.5216\n",
      "Epoch(35) - Fold 0 - Validation Utility score : 316.7931\n",
      "Epoch(35) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(35) - Fold 1 - Validation Accuracy : 0.5227\n",
      "Epoch(35) - Fold 1 - Validation Utility score : 932.0952\n",
      "Epoch(35) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(35) - Fold 2 - Validation Accuracy : 0.5107\n",
      "Epoch(35) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(35) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(35) - Fold 3 - Validation Accuracy : 0.5100\n",
      "Epoch(35) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(35) - Fold 4 - Validation Loss : 0.6908\n",
      "Epoch(35) - Fold 4 - Validation Accuracy : 0.5248\n",
      "Epoch(35) - Fold 4 - Validation Utility score : 1436.5225\n",
      "Epoch(35) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(35) - GLOBAL - Validation Accuracy: 0.5180\n",
      "Epoch(35) - GLOBAL - Validation Utility score: 2685.4108\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(36) - Training Loss: 0.6900\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(36) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(36) - Fold 0 - Validation Accuracy : 0.5221\n",
      "Epoch(36) - Fold 0 - Validation Utility score : 278.2199\n",
      "Epoch(36) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(36) - Fold 1 - Validation Accuracy : 0.5223\n",
      "Epoch(36) - Fold 1 - Validation Utility score : 950.8195\n",
      "Epoch(36) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(36) - Fold 2 - Validation Accuracy : 0.5109\n",
      "Epoch(36) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(36) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(36) - Fold 3 - Validation Accuracy : 0.5089\n",
      "Epoch(36) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(36) - Fold 4 - Validation Loss : 0.6906\n",
      "Epoch(36) - Fold 4 - Validation Accuracy : 0.5258\n",
      "Epoch(36) - Fold 4 - Validation Utility score : 1478.6569\n",
      "Epoch(36) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(36) - GLOBAL - Validation Accuracy: 0.5180\n",
      "Epoch(36) - GLOBAL - Validation Utility score: 2707.6963\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "Meet Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 529139<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_093955-x1kzlk72/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_093955-x1kzlk72/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>0.68996</td></tr><tr><td>Global valid/Loss</td><td>0.69185</td></tr><tr><td>Global valid/Accuracy</td><td>0.51801</td></tr><tr><td>Global valid/Utility</td><td>2707.69626</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>0.69151</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>0.52212</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>278.21985</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>0.69096</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>0.5223</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>950.81947</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>0.69311</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>0.51095</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>0.69304</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>0.50895</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>0.69064</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>0.52576</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>1478.65694</td></tr><tr><td>Best accuracy</td><td>0.51832</td></tr><tr><td>Best utility</td><td>2709.47444</td></tr><tr><td>_runtime</td><td>2299</td></tr><tr><td>_timestamp</td><td>1613467094</td></tr><tr><td>_step</td><td>36</td></tr><tr><td>Final utility score</td><td>{'utility_score': 27...</td></tr><tr><td>Batch size</td><td>60396</td></tr><tr><td>Patience</td><td>5</td></tr><tr><td>Number of epochs</td><td>1000</td></tr><tr><td>Best epoch</td><td>31</td></tr><tr><td>Number of parameters per layer</td><td>[8384, 64, 2048, 32,...</td></tr><tr><td>Model architecture</td><td>MLP(<BR>  (AEncoder)...</td></tr><tr><td>comment</td><td>All folds MLP with a...</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>█▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Loss</td><td>█▄▃▂▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Accuracy</td><td>▁▄▄▅▄▃▄▅▅▇▇▇▇▇▇█▇████████████████████</td></tr><tr><td>Global valid/Utility</td><td>▁▂▄▄▂▃▄▅▆▇▇▇█████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>█▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>▁▅▄▄▃▃▅▆▆█▇█▇██████████████▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>▁▂▃▁▁▂▄▅▆▆▆▆█▇▇▆▆▅▅▅▆▄▅▄▄▄▄▄▄▃▄▄▄▄▃▄▃</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>█▄▃▃▃▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>▁▄▄▄▃▃▄▅▅▆▇▇▇▇▇█▇▇▇████████▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>▁▃▅▆▂▂▂▄▅▆▆▇█▇▇█▇▇▇███▇█▇▇█▇▇▇▇▆▆▆▆▇▇</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>▁▄▅▄▃▂▄▄▅▅▅▆▅▆▆▆▅▆▆▆▆▆▇▇▇▇▇▆▇█▇▇█████</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>█▄▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▂▂</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>▁▃▄▅▃▃▃▄▄▆▇▇▇▇▇▇▇█▇█▇██▇▇▇▇▇▆▇▆▇▆▇▆▆▆</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>▁▁█▅▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>█▅▄▃▃▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>▁▃▄▅▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████████</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>▁▂▃▃▂▃▅▆▆▇▆▇▇▇█▇▇██▇▇▇▇▇█▇▇▇█▇███████</td></tr><tr><td>Best accuracy</td><td>▁▄▄▅▅▇▇▇▇▇▇█▇██████████████</td></tr><tr><td>Best utility</td><td>▁▂▄▄▆▇▇▇█████▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 186 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">magic-sweep-9</strong>: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/x1kzlk72\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/x1kzlk72</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training summary:\n",
      "{'utility_score': 2709.474444456134, 'utility_scores': [329.4851199671114, 895.3727777386796, -0.0, -0.0, 1484.6165467503429], 'utility_score_std': 573.7750069928035, 'accuracy_scores': [0.522855806437896, 0.5220638820638821, 0.5097115708096752, 0.5112977657718498, 0.5256515002112974]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p8d39wtq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leakyrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32574\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.43988979460131317\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007670875375320853\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_autoenc: encoder-only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 6.122566403735072e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">copper-sweep-10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/p8d39wtq\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/p8d39wtq</a><br/>\n",
       "                Run data is saved locally in <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_101819-p8d39wtq</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Run config :\n",
      "config: {'activation_function': 'leakyrelu', 'batch_size': 32574, 'dropout': 0.43988979460131317, 'learning_rate': 0.0007670875375320853, 'use_autoenc': 'encoder-only', 'weight_decay': 6.122566403735072e-05, 'epochs': 1000}\n",
      "Epoch(0) - Training Loss: 0.9183\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(0) - Fold 0 - Validation Loss : 0.6996\n",
      "Epoch(0) - Fold 0 - Validation Accuracy : 0.5040\n",
      "Epoch(0) - Fold 0 - Validation Utility score : 9.6152\n",
      "Epoch(0) - Fold 1 - Validation Loss : 0.6983\n",
      "Epoch(0) - Fold 1 - Validation Accuracy : 0.5036\n",
      "Epoch(0) - Fold 1 - Validation Utility score : 5.2399\n",
      "Epoch(0) - Fold 2 - Validation Loss : 0.6993\n",
      "Epoch(0) - Fold 2 - Validation Accuracy : 0.4985\n",
      "Epoch(0) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 3 - Validation Loss : 0.6989\n",
      "Epoch(0) - Fold 3 - Validation Accuracy : 0.5004\n",
      "Epoch(0) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 4 - Validation Loss : 0.7007\n",
      "Epoch(0) - Fold 4 - Validation Accuracy : 0.4928\n",
      "Epoch(0) - Fold 4 - Validation Utility score : -0.0000\n",
      "Epoch(0) - GLOBAL - Validation Loss: 0.6993\n",
      "Epoch(0) - GLOBAL - Validation Accuracy: 0.4999\n",
      "Epoch(0) - GLOBAL - Validation Utility score: 14.8552\n",
      "Saving model corresponding to last_utility_score == 14.855166731560557\n",
      "\n",
      "\n",
      "Epoch(1) - Training Loss: 0.8041\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(1) - Fold 0 - Validation Loss : 0.6964\n",
      "Epoch(1) - Fold 0 - Validation Accuracy : 0.5013\n",
      "Epoch(1) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 1 - Validation Loss : 0.6960\n",
      "Epoch(1) - Fold 1 - Validation Accuracy : 0.5063\n",
      "Epoch(1) - Fold 1 - Validation Utility score : 1.1695\n",
      "Epoch(1) - Fold 2 - Validation Loss : 0.6963\n",
      "Epoch(1) - Fold 2 - Validation Accuracy : 0.5005\n",
      "Epoch(1) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 3 - Validation Loss : 0.6968\n",
      "Epoch(1) - Fold 3 - Validation Accuracy : 0.5006\n",
      "Epoch(1) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 4 - Validation Loss : 0.6969\n",
      "Epoch(1) - Fold 4 - Validation Accuracy : 0.4982\n",
      "Epoch(1) - Fold 4 - Validation Utility score : 11.7705\n",
      "Epoch(1) - GLOBAL - Validation Loss: 0.6965\n",
      "Epoch(1) - GLOBAL - Validation Accuracy: 0.5014\n",
      "Epoch(1) - GLOBAL - Validation Utility score: 12.9399\n",
      "Saving model corresponding to last_utility_score == 12.939917048198742\n",
      "\n",
      "\n",
      "Epoch(2) - Training Loss: 0.7369\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(2) - Fold 0 - Validation Loss : 0.6951\n",
      "Epoch(2) - Fold 0 - Validation Accuracy : 0.5002\n",
      "Epoch(2) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 1 - Validation Loss : 0.6948\n",
      "Epoch(2) - Fold 1 - Validation Accuracy : 0.5060\n",
      "Epoch(2) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 2 - Validation Loss : 0.6951\n",
      "Epoch(2) - Fold 2 - Validation Accuracy : 0.5018\n",
      "Epoch(2) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 3 - Validation Loss : 0.6955\n",
      "Epoch(2) - Fold 3 - Validation Accuracy : 0.4999\n",
      "Epoch(2) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 4 - Validation Loss : 0.6955\n",
      "Epoch(2) - Fold 4 - Validation Accuracy : 0.4984\n",
      "Epoch(2) - Fold 4 - Validation Utility score : 13.0109\n",
      "Epoch(2) - GLOBAL - Validation Loss: 0.6952\n",
      "Epoch(2) - GLOBAL - Validation Accuracy: 0.5013\n",
      "Epoch(2) - GLOBAL - Validation Utility score: 13.0109\n",
      "Saving model corresponding to last_utility_score == 13.010889299240988\n",
      "\n",
      "\n",
      "Epoch(3) - Training Loss: 0.7066\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(3) - Fold 0 - Validation Loss : 0.6946\n",
      "Epoch(3) - Fold 0 - Validation Accuracy : 0.5001\n",
      "Epoch(3) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 1 - Validation Loss : 0.6938\n",
      "Epoch(3) - Fold 1 - Validation Accuracy : 0.5061\n",
      "Epoch(3) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 2 - Validation Loss : 0.6942\n",
      "Epoch(3) - Fold 2 - Validation Accuracy : 0.5018\n",
      "Epoch(3) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 3 - Validation Loss : 0.6943\n",
      "Epoch(3) - Fold 3 - Validation Accuracy : 0.4997\n",
      "Epoch(3) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 4 - Validation Loss : 0.6945\n",
      "Epoch(3) - Fold 4 - Validation Accuracy : 0.4988\n",
      "Epoch(3) - Fold 4 - Validation Utility score : 16.7390\n",
      "Epoch(3) - GLOBAL - Validation Loss: 0.6943\n",
      "Epoch(3) - GLOBAL - Validation Accuracy: 0.5013\n",
      "Epoch(3) - GLOBAL - Validation Utility score: 16.7390\n",
      "Saving model corresponding to last_utility_score == 16.739041009326883\n",
      "\n",
      "\n",
      "Epoch(4) - Training Loss: 0.6976\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(4) - Fold 0 - Validation Loss : 0.6940\n",
      "Epoch(4) - Fold 0 - Validation Accuracy : 0.5001\n",
      "Epoch(4) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 1 - Validation Loss : 0.6933\n",
      "Epoch(4) - Fold 1 - Validation Accuracy : 0.5062\n",
      "Epoch(4) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 2 - Validation Loss : 0.6938\n",
      "Epoch(4) - Fold 2 - Validation Accuracy : 0.5020\n",
      "Epoch(4) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 3 - Validation Loss : 0.6939\n",
      "Epoch(4) - Fold 3 - Validation Accuracy : 0.4997\n",
      "Epoch(4) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 4 - Validation Loss : 0.6941\n",
      "Epoch(4) - Fold 4 - Validation Accuracy : 0.4988\n",
      "Epoch(4) - Fold 4 - Validation Utility score : 18.4426\n",
      "Epoch(4) - GLOBAL - Validation Loss: 0.6938\n",
      "Epoch(4) - GLOBAL - Validation Accuracy: 0.5014\n",
      "Epoch(4) - GLOBAL - Validation Utility score: 18.4426\n",
      "Saving model corresponding to last_utility_score == 18.44262659262413\n",
      "\n",
      "\n",
      "Epoch(5) - Training Loss: 0.6952\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(5) - Fold 0 - Validation Loss : 0.6935\n",
      "Epoch(5) - Fold 0 - Validation Accuracy : 0.5008\n",
      "Epoch(5) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 1 - Validation Loss : 0.6929\n",
      "Epoch(5) - Fold 1 - Validation Accuracy : 0.5077\n",
      "Epoch(5) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 2 - Validation Loss : 0.6934\n",
      "Epoch(5) - Fold 2 - Validation Accuracy : 0.5033\n",
      "Epoch(5) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 3 - Validation Loss : 0.6936\n",
      "Epoch(5) - Fold 3 - Validation Accuracy : 0.5011\n",
      "Epoch(5) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 4 - Validation Loss : 0.6936\n",
      "Epoch(5) - Fold 4 - Validation Accuracy : 0.4999\n",
      "Epoch(5) - Fold 4 - Validation Utility score : 27.3678\n",
      "Epoch(5) - GLOBAL - Validation Loss: 0.6934\n",
      "Epoch(5) - GLOBAL - Validation Accuracy: 0.5026\n",
      "Epoch(5) - GLOBAL - Validation Utility score: 27.3678\n",
      "Saving model corresponding to last_utility_score == 27.367848977324435\n",
      "\n",
      "\n",
      "Epoch(6) - Training Loss: 0.6944\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(6) - Fold 0 - Validation Loss : 0.6934\n",
      "Epoch(6) - Fold 0 - Validation Accuracy : 0.5017\n",
      "Epoch(6) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 1 - Validation Loss : 0.6929\n",
      "Epoch(6) - Fold 1 - Validation Accuracy : 0.5075\n",
      "Epoch(6) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 2 - Validation Loss : 0.6934\n",
      "Epoch(6) - Fold 2 - Validation Accuracy : 0.5032\n",
      "Epoch(6) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 3 - Validation Loss : 0.6936\n",
      "Epoch(6) - Fold 3 - Validation Accuracy : 0.5011\n",
      "Epoch(6) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 4 - Validation Loss : 0.6936\n",
      "Epoch(6) - Fold 4 - Validation Accuracy : 0.5000\n",
      "Epoch(6) - Fold 4 - Validation Utility score : 28.9663\n",
      "Epoch(6) - GLOBAL - Validation Loss: 0.6934\n",
      "Epoch(6) - GLOBAL - Validation Accuracy: 0.5027\n",
      "Epoch(6) - GLOBAL - Validation Utility score: 28.9663\n",
      "Saving model corresponding to last_utility_score == 28.966305422377083\n",
      "\n",
      "\n",
      "Epoch(7) - Training Loss: 0.6940\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(7) - Fold 0 - Validation Loss : 0.6931\n",
      "Epoch(7) - Fold 0 - Validation Accuracy : 0.5036\n",
      "Epoch(7) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(7) - Fold 1 - Validation Accuracy : 0.5106\n",
      "Epoch(7) - Fold 1 - Validation Utility score : 6.5647\n",
      "Epoch(7) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(7) - Fold 2 - Validation Accuracy : 0.5022\n",
      "Epoch(7) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(7) - Fold 3 - Validation Accuracy : 0.5027\n",
      "Epoch(7) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 4 - Validation Loss : 0.6934\n",
      "Epoch(7) - Fold 4 - Validation Accuracy : 0.5010\n",
      "Epoch(7) - Fold 4 - Validation Utility score : 64.8815\n",
      "Epoch(7) - GLOBAL - Validation Loss: 0.6932\n",
      "Epoch(7) - GLOBAL - Validation Accuracy: 0.5040\n",
      "Epoch(7) - GLOBAL - Validation Utility score: 71.4462\n",
      "Saving model corresponding to last_utility_score == 71.44616630284449\n",
      "\n",
      "\n",
      "Epoch(8) - Training Loss: 0.6937\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(8) - Fold 0 - Validation Loss : 0.6931\n",
      "Epoch(8) - Fold 0 - Validation Accuracy : 0.5035\n",
      "Epoch(8) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(8) - Fold 1 - Validation Accuracy : 0.5093\n",
      "Epoch(8) - Fold 1 - Validation Utility score : 0.2152\n",
      "Epoch(8) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(8) - Fold 2 - Validation Accuracy : 0.5031\n",
      "Epoch(8) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 3 - Validation Loss : 0.6935\n",
      "Epoch(8) - Fold 3 - Validation Accuracy : 0.5027\n",
      "Epoch(8) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 4 - Validation Loss : 0.6934\n",
      "Epoch(8) - Fold 4 - Validation Accuracy : 0.5013\n",
      "Epoch(8) - Fold 4 - Validation Utility score : 60.3056\n",
      "Epoch(8) - GLOBAL - Validation Loss: 0.6932\n",
      "Epoch(8) - GLOBAL - Validation Accuracy: 0.5040\n",
      "Epoch(8) - GLOBAL - Validation Utility score: 60.5208\n",
      "Intermediate early stopping : vepoch_loss = 0.6932, the_last_loss=0.6932\n",
      "\n",
      "\n",
      "Epoch(9) - Training Loss: 0.6935\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(9) - Fold 0 - Validation Loss : 0.6930\n",
      "Epoch(9) - Fold 0 - Validation Accuracy : 0.5040\n",
      "Epoch(9) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 1 - Validation Loss : 0.6926\n",
      "Epoch(9) - Fold 1 - Validation Accuracy : 0.5097\n",
      "Epoch(9) - Fold 1 - Validation Utility score : 0.2048\n",
      "Epoch(9) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(9) - Fold 2 - Validation Accuracy : 0.5031\n",
      "Epoch(9) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(9) - Fold 3 - Validation Accuracy : 0.5033\n",
      "Epoch(9) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 4 - Validation Loss : 0.6934\n",
      "Epoch(9) - Fold 4 - Validation Accuracy : 0.5019\n",
      "Epoch(9) - Fold 4 - Validation Utility score : 81.3324\n",
      "Epoch(9) - GLOBAL - Validation Loss: 0.6931\n",
      "Epoch(9) - GLOBAL - Validation Accuracy: 0.5044\n",
      "Epoch(9) - GLOBAL - Validation Utility score: 81.5372\n",
      "Saving model corresponding to last_utility_score == 81.53720379103117\n",
      "\n",
      "\n",
      "Epoch(10) - Training Loss: 0.6934\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(10) - Fold 0 - Validation Loss : 0.6929\n",
      "Epoch(10) - Fold 0 - Validation Accuracy : 0.5059\n",
      "Epoch(10) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(10) - Fold 1 - Validation Accuracy : 0.5112\n",
      "Epoch(10) - Fold 1 - Validation Utility score : 3.2415\n",
      "Epoch(10) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(10) - Fold 2 - Validation Accuracy : 0.5026\n",
      "Epoch(10) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(10) - Fold 3 - Validation Accuracy : 0.5041\n",
      "Epoch(10) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 4 - Validation Loss : 0.6933\n",
      "Epoch(10) - Fold 4 - Validation Accuracy : 0.5027\n",
      "Epoch(10) - Fold 4 - Validation Utility score : 116.9861\n",
      "Epoch(10) - GLOBAL - Validation Loss: 0.6931\n",
      "Epoch(10) - GLOBAL - Validation Accuracy: 0.5053\n",
      "Epoch(10) - GLOBAL - Validation Utility score: 120.2276\n",
      "Saving model corresponding to last_utility_score == 120.22757440600891\n",
      "\n",
      "\n",
      "Epoch(11) - Training Loss: 0.6934\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(11) - Fold 0 - Validation Loss : 0.6929\n",
      "Epoch(11) - Fold 0 - Validation Accuracy : 0.5054\n",
      "Epoch(11) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(11) - Fold 1 - Validation Accuracy : 0.5107\n",
      "Epoch(11) - Fold 1 - Validation Utility score : 3.0238\n",
      "Epoch(11) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(11) - Fold 2 - Validation Accuracy : 0.5028\n",
      "Epoch(11) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(11) - Fold 3 - Validation Accuracy : 0.5036\n",
      "Epoch(11) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 4 - Validation Loss : 0.6933\n",
      "Epoch(11) - Fold 4 - Validation Accuracy : 0.5033\n",
      "Epoch(11) - Fold 4 - Validation Utility score : 131.4917\n",
      "Epoch(11) - GLOBAL - Validation Loss: 0.6931\n",
      "Epoch(11) - GLOBAL - Validation Accuracy: 0.5052\n",
      "Epoch(11) - GLOBAL - Validation Utility score: 134.5155\n",
      "Saving model corresponding to last_utility_score == 134.51551587579206\n",
      "\n",
      "\n",
      "Epoch(12) - Training Loss: 0.6933\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(12) - Fold 0 - Validation Loss : 0.6929\n",
      "Epoch(12) - Fold 0 - Validation Accuracy : 0.5072\n",
      "Epoch(12) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(12) - Fold 1 - Validation Accuracy : 0.5115\n",
      "Epoch(12) - Fold 1 - Validation Utility score : 5.7669\n",
      "Epoch(12) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(12) - Fold 2 - Validation Accuracy : 0.5031\n",
      "Epoch(12) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(12) - Fold 3 - Validation Accuracy : 0.5042\n",
      "Epoch(12) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 4 - Validation Loss : 0.6932\n",
      "Epoch(12) - Fold 4 - Validation Accuracy : 0.5037\n",
      "Epoch(12) - Fold 4 - Validation Utility score : 165.7235\n",
      "Epoch(12) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(12) - GLOBAL - Validation Accuracy: 0.5060\n",
      "Epoch(12) - GLOBAL - Validation Utility score: 171.4905\n",
      "Saving model corresponding to last_utility_score == 171.49046093563268\n",
      "\n",
      "\n",
      "Epoch(13) - Training Loss: 0.6933\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(13) - Fold 0 - Validation Loss : 0.6928\n",
      "Epoch(13) - Fold 0 - Validation Accuracy : 0.5096\n",
      "Epoch(13) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(13) - Fold 1 - Validation Accuracy : 0.5138\n",
      "Epoch(13) - Fold 1 - Validation Utility score : 79.7072\n",
      "Epoch(13) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(13) - Fold 2 - Validation Accuracy : 0.5037\n",
      "Epoch(13) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(13) - Fold 3 - Validation Accuracy : 0.5056\n",
      "Epoch(13) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 4 - Validation Loss : 0.6931\n",
      "Epoch(13) - Fold 4 - Validation Accuracy : 0.5046\n",
      "Epoch(13) - Fold 4 - Validation Utility score : 237.6487\n",
      "Epoch(13) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(13) - GLOBAL - Validation Accuracy: 0.5075\n",
      "Epoch(13) - GLOBAL - Validation Utility score: 317.3559\n",
      "Saving model corresponding to last_utility_score == 317.35586395407535\n",
      "\n",
      "\n",
      "Epoch(14) - Training Loss: 0.6931\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(14) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(14) - Fold 0 - Validation Accuracy : 0.5137\n",
      "Epoch(14) - Fold 0 - Validation Utility score : 7.6582\n",
      "Epoch(14) - Fold 1 - Validation Loss : 0.6923\n",
      "Epoch(14) - Fold 1 - Validation Accuracy : 0.5183\n",
      "Epoch(14) - Fold 1 - Validation Utility score : 244.9436\n",
      "Epoch(14) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(14) - Fold 2 - Validation Accuracy : 0.5056\n",
      "Epoch(14) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(14) - Fold 3 - Validation Accuracy : 0.5068\n",
      "Epoch(14) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 4 - Validation Loss : 0.6930\n",
      "Epoch(14) - Fold 4 - Validation Accuracy : 0.5061\n",
      "Epoch(14) - Fold 4 - Validation Utility score : 494.3465\n",
      "Epoch(14) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(14) - GLOBAL - Validation Accuracy: 0.5101\n",
      "Epoch(14) - GLOBAL - Validation Utility score: 746.9483\n",
      "Saving model corresponding to last_utility_score == 746.9482887122199\n",
      "\n",
      "\n",
      "Epoch(15) - Training Loss: 0.6931\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(15) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(15) - Fold 0 - Validation Accuracy : 0.5147\n",
      "Epoch(15) - Fold 0 - Validation Utility score : 2.7001\n",
      "Epoch(15) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(15) - Fold 1 - Validation Accuracy : 0.5193\n",
      "Epoch(15) - Fold 1 - Validation Utility score : 256.6713\n",
      "Epoch(15) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(15) - Fold 2 - Validation Accuracy : 0.5073\n",
      "Epoch(15) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(15) - Fold 3 - Validation Accuracy : 0.5075\n",
      "Epoch(15) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(15) - Fold 4 - Validation Accuracy : 0.5076\n",
      "Epoch(15) - Fold 4 - Validation Utility score : 644.0540\n",
      "Epoch(15) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(15) - GLOBAL - Validation Accuracy: 0.5113\n",
      "Epoch(15) - GLOBAL - Validation Utility score: 903.4255\n",
      "Saving model corresponding to last_utility_score == 903.425498854914\n",
      "\n",
      "\n",
      "Epoch(16) - Training Loss: 0.6930\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(16) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(16) - Fold 0 - Validation Accuracy : 0.5117\n",
      "Epoch(16) - Fold 0 - Validation Utility score : 2.6009\n",
      "Epoch(16) - Fold 1 - Validation Loss : 0.6923\n",
      "Epoch(16) - Fold 1 - Validation Accuracy : 0.5158\n",
      "Epoch(16) - Fold 1 - Validation Utility score : 130.9800\n",
      "Epoch(16) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(16) - Fold 2 - Validation Accuracy : 0.5055\n",
      "Epoch(16) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(16) - Fold 3 - Validation Accuracy : 0.5061\n",
      "Epoch(16) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(16) - Fold 4 - Validation Accuracy : 0.5060\n",
      "Epoch(16) - Fold 4 - Validation Utility score : 455.8819\n",
      "Epoch(16) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(16) - GLOBAL - Validation Accuracy: 0.5090\n",
      "Epoch(16) - GLOBAL - Validation Utility score: 589.4628\n",
      "Intermediate early stopping : vepoch_loss = 0.6928, the_last_loss=0.6927\n",
      "\n",
      "\n",
      "Epoch(17) - Training Loss: 0.6929\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(17) - Fold 0 - Validation Loss : 0.6924\n",
      "Epoch(17) - Fold 0 - Validation Accuracy : 0.5152\n",
      "Epoch(17) - Fold 0 - Validation Utility score : 10.6519\n",
      "Epoch(17) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(17) - Fold 1 - Validation Accuracy : 0.5212\n",
      "Epoch(17) - Fold 1 - Validation Utility score : 305.9635\n",
      "Epoch(17) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(17) - Fold 2 - Validation Accuracy : 0.5075\n",
      "Epoch(17) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(17) - Fold 3 - Validation Accuracy : 0.5077\n",
      "Epoch(17) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(17) - Fold 4 - Validation Accuracy : 0.5080\n",
      "Epoch(17) - Fold 4 - Validation Utility score : 628.7998\n",
      "Epoch(17) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(17) - GLOBAL - Validation Accuracy: 0.5119\n",
      "Epoch(17) - GLOBAL - Validation Utility score: 945.4152\n",
      "Saving model corresponding to last_utility_score == 945.4152223859928\n",
      "\n",
      "\n",
      "Epoch(18) - Training Loss: 0.6929\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(18) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(18) - Fold 0 - Validation Accuracy : 0.5144\n",
      "Epoch(18) - Fold 0 - Validation Utility score : 2.3445\n",
      "Epoch(18) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(18) - Fold 1 - Validation Accuracy : 0.5192\n",
      "Epoch(18) - Fold 1 - Validation Utility score : 251.0644\n",
      "Epoch(18) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(18) - Fold 2 - Validation Accuracy : 0.5075\n",
      "Epoch(18) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(18) - Fold 3 - Validation Accuracy : 0.5075\n",
      "Epoch(18) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(18) - Fold 4 - Validation Accuracy : 0.5077\n",
      "Epoch(18) - Fold 4 - Validation Utility score : 554.2237\n",
      "Epoch(18) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(18) - GLOBAL - Validation Accuracy: 0.5113\n",
      "Epoch(18) - GLOBAL - Validation Utility score: 807.6326\n",
      "Intermediate early stopping : vepoch_loss = 0.6927, the_last_loss=0.6926\n",
      "\n",
      "\n",
      "Epoch(19) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(19) - Fold 0 - Validation Loss : 0.6924\n",
      "Epoch(19) - Fold 0 - Validation Accuracy : 0.5151\n",
      "Epoch(19) - Fold 0 - Validation Utility score : 8.3342\n",
      "Epoch(19) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(19) - Fold 1 - Validation Accuracy : 0.5210\n",
      "Epoch(19) - Fold 1 - Validation Utility score : 316.1593\n",
      "Epoch(19) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(19) - Fold 2 - Validation Accuracy : 0.5078\n",
      "Epoch(19) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(19) - Fold 3 - Validation Accuracy : 0.5073\n",
      "Epoch(19) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(19) - Fold 4 - Validation Accuracy : 0.5086\n",
      "Epoch(19) - Fold 4 - Validation Utility score : 680.1174\n",
      "Epoch(19) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(19) - GLOBAL - Validation Accuracy: 0.5119\n",
      "Epoch(19) - GLOBAL - Validation Utility score: 1004.6108\n",
      "Saving model corresponding to last_utility_score == 1004.6108435375984\n",
      "\n",
      "\n",
      "Epoch(20) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(20) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(20) - Fold 0 - Validation Accuracy : 0.5183\n",
      "Epoch(20) - Fold 0 - Validation Utility score : 124.4729\n",
      "Epoch(20) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(20) - Fold 1 - Validation Accuracy : 0.5246\n",
      "Epoch(20) - Fold 1 - Validation Utility score : 575.6180\n",
      "Epoch(20) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(20) - Fold 2 - Validation Accuracy : 0.5090\n",
      "Epoch(20) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(20) - Fold 3 - Validation Accuracy : 0.5064\n",
      "Epoch(20) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(20) - Fold 4 - Validation Accuracy : 0.5104\n",
      "Epoch(20) - Fold 4 - Validation Utility score : 829.8703\n",
      "Epoch(20) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(20) - GLOBAL - Validation Accuracy: 0.5137\n",
      "Epoch(20) - GLOBAL - Validation Utility score: 1529.9612\n",
      "Saving model corresponding to last_utility_score == 1529.9612266477752\n",
      "\n",
      "\n",
      "Epoch(21) - Training Loss: 0.6927\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(21) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(21) - Fold 0 - Validation Accuracy : 0.5162\n",
      "Epoch(21) - Fold 0 - Validation Utility score : 28.3919\n",
      "Epoch(21) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(21) - Fold 1 - Validation Accuracy : 0.5222\n",
      "Epoch(21) - Fold 1 - Validation Utility score : 359.8370\n",
      "Epoch(21) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(21) - Fold 2 - Validation Accuracy : 0.5081\n",
      "Epoch(21) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(21) - Fold 3 - Validation Accuracy : 0.5074\n",
      "Epoch(21) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(21) - Fold 4 - Validation Accuracy : 0.5091\n",
      "Epoch(21) - Fold 4 - Validation Utility score : 723.8334\n",
      "Epoch(21) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(21) - GLOBAL - Validation Accuracy: 0.5126\n",
      "Epoch(21) - GLOBAL - Validation Utility score: 1112.0623\n",
      "Intermediate early stopping : vepoch_loss = 0.6926, the_last_loss=0.6925\n",
      "\n",
      "\n",
      "Epoch(22) - Training Loss: 0.6927\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(22) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(22) - Fold 0 - Validation Accuracy : 0.5168\n",
      "Epoch(22) - Fold 0 - Validation Utility score : 40.5771\n",
      "Epoch(22) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(22) - Fold 1 - Validation Accuracy : 0.5224\n",
      "Epoch(22) - Fold 1 - Validation Utility score : 383.2339\n",
      "Epoch(22) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(22) - Fold 2 - Validation Accuracy : 0.5088\n",
      "Epoch(22) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(22) - Fold 3 - Validation Accuracy : 0.5065\n",
      "Epoch(22) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(22) - Fold 4 - Validation Accuracy : 0.5100\n",
      "Epoch(22) - Fold 4 - Validation Utility score : 838.0370\n",
      "Epoch(22) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(22) - GLOBAL - Validation Accuracy: 0.5129\n",
      "Epoch(22) - GLOBAL - Validation Utility score: 1261.8480\n",
      "Saving model corresponding to last_utility_score == 1261.8479784699848\n",
      "\n",
      "\n",
      "Epoch(23) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(23) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(23) - Fold 0 - Validation Accuracy : 0.5184\n",
      "Epoch(23) - Fold 0 - Validation Utility score : 80.2434\n",
      "Epoch(23) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(23) - Fold 1 - Validation Accuracy : 0.5233\n",
      "Epoch(23) - Fold 1 - Validation Utility score : 455.8025\n",
      "Epoch(23) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(23) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(23) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(23) - Fold 3 - Validation Accuracy : 0.5066\n",
      "Epoch(23) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(23) - Fold 4 - Validation Accuracy : 0.5105\n",
      "Epoch(23) - Fold 4 - Validation Utility score : 876.0229\n",
      "Epoch(23) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(23) - GLOBAL - Validation Accuracy: 0.5135\n",
      "Epoch(23) - GLOBAL - Validation Utility score: 1412.0688\n",
      "Saving model corresponding to last_utility_score == 1412.068761252784\n",
      "\n",
      "\n",
      "Epoch(24) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(24) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(24) - Fold 0 - Validation Accuracy : 0.5207\n",
      "Epoch(24) - Fold 0 - Validation Utility score : 221.6969\n",
      "Epoch(24) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(24) - Fold 1 - Validation Accuracy : 0.5244\n",
      "Epoch(24) - Fold 1 - Validation Utility score : 539.8810\n",
      "Epoch(24) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(24) - Fold 2 - Validation Accuracy : 0.5095\n",
      "Epoch(24) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(24) - Fold 3 - Validation Accuracy : 0.5059\n",
      "Epoch(24) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(24) - Fold 4 - Validation Accuracy : 0.5114\n",
      "Epoch(24) - Fold 4 - Validation Utility score : 839.2708\n",
      "Epoch(24) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(24) - GLOBAL - Validation Accuracy: 0.5144\n",
      "Epoch(24) - GLOBAL - Validation Utility score: 1600.8486\n",
      "Saving model corresponding to last_utility_score == 1600.848632745734\n",
      "\n",
      "\n",
      "Epoch(25) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(25) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(25) - Fold 0 - Validation Accuracy : 0.5170\n",
      "Epoch(25) - Fold 0 - Validation Utility score : 35.5927\n",
      "Epoch(25) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(25) - Fold 1 - Validation Accuracy : 0.5219\n",
      "Epoch(25) - Fold 1 - Validation Utility score : 354.1067\n",
      "Epoch(25) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(25) - Fold 2 - Validation Accuracy : 0.5073\n",
      "Epoch(25) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(25) - Fold 3 - Validation Accuracy : 0.5065\n",
      "Epoch(25) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(25) - Fold 4 - Validation Accuracy : 0.5091\n",
      "Epoch(25) - Fold 4 - Validation Utility score : 579.8766\n",
      "Epoch(25) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(25) - GLOBAL - Validation Accuracy: 0.5123\n",
      "Epoch(25) - GLOBAL - Validation Utility score: 969.5760\n",
      "Intermediate early stopping : vepoch_loss = 0.6925, the_last_loss=0.6924\n",
      "\n",
      "\n",
      "Epoch(26) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(26) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(26) - Fold 0 - Validation Accuracy : 0.5196\n",
      "Epoch(26) - Fold 0 - Validation Utility score : 212.6627\n",
      "Epoch(26) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(26) - Fold 1 - Validation Accuracy : 0.5238\n",
      "Epoch(26) - Fold 1 - Validation Utility score : 494.4745\n",
      "Epoch(26) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(26) - Fold 2 - Validation Accuracy : 0.5089\n",
      "Epoch(26) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(26) - Fold 3 - Validation Accuracy : 0.5075\n",
      "Epoch(26) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(26) - Fold 4 - Validation Accuracy : 0.5123\n",
      "Epoch(26) - Fold 4 - Validation Utility score : 963.2275\n",
      "Epoch(26) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(26) - GLOBAL - Validation Accuracy: 0.5144\n",
      "Epoch(26) - GLOBAL - Validation Utility score: 1670.3647\n",
      "Saving model corresponding to last_utility_score == 1670.364677457865\n",
      "\n",
      "\n",
      "Epoch(27) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(27) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(27) - Fold 0 - Validation Accuracy : 0.5170\n",
      "Epoch(27) - Fold 0 - Validation Utility score : 37.5750\n",
      "Epoch(27) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(27) - Fold 1 - Validation Accuracy : 0.5215\n",
      "Epoch(27) - Fold 1 - Validation Utility score : 377.5266\n",
      "Epoch(27) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(27) - Fold 2 - Validation Accuracy : 0.5080\n",
      "Epoch(27) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(27) - Fold 3 - Validation Accuracy : 0.5072\n",
      "Epoch(27) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(27) - Fold 4 - Validation Accuracy : 0.5095\n",
      "Epoch(27) - Fold 4 - Validation Utility score : 732.7681\n",
      "Epoch(27) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(27) - GLOBAL - Validation Accuracy: 0.5126\n",
      "Epoch(27) - GLOBAL - Validation Utility score: 1147.8696\n",
      "Intermediate early stopping : vepoch_loss = 0.6925, the_last_loss=0.6923\n",
      "\n",
      "\n",
      "Epoch(28) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(28) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(28) - Fold 0 - Validation Accuracy : 0.5187\n",
      "Epoch(28) - Fold 0 - Validation Utility score : 82.7310\n",
      "Epoch(28) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(28) - Fold 1 - Validation Accuracy : 0.5223\n",
      "Epoch(28) - Fold 1 - Validation Utility score : 418.5209\n",
      "Epoch(28) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(28) - Fold 2 - Validation Accuracy : 0.5084\n",
      "Epoch(28) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(28) - Fold 3 - Validation Accuracy : 0.5070\n",
      "Epoch(28) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(28) - Fold 4 - Validation Accuracy : 0.5108\n",
      "Epoch(28) - Fold 4 - Validation Utility score : 925.8573\n",
      "Epoch(28) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(28) - GLOBAL - Validation Accuracy: 0.5135\n",
      "Epoch(28) - GLOBAL - Validation Utility score: 1427.1092\n",
      "Saving model corresponding to last_utility_score == 1427.1091852147815\n",
      "\n",
      "\n",
      "Epoch(29) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(29) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(29) - Fold 0 - Validation Accuracy : 0.5208\n",
      "Epoch(29) - Fold 0 - Validation Utility score : 213.8546\n",
      "Epoch(29) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(29) - Fold 1 - Validation Accuracy : 0.5236\n",
      "Epoch(29) - Fold 1 - Validation Utility score : 567.2249\n",
      "Epoch(29) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(29) - Fold 2 - Validation Accuracy : 0.5094\n",
      "Epoch(29) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(29) - Fold 3 - Validation Accuracy : 0.5070\n",
      "Epoch(29) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(29) - Fold 4 - Validation Accuracy : 0.5122\n",
      "Epoch(29) - Fold 4 - Validation Utility score : 960.1930\n",
      "Epoch(29) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(29) - GLOBAL - Validation Accuracy: 0.5146\n",
      "Epoch(29) - GLOBAL - Validation Utility score: 1741.2725\n",
      "Saving model corresponding to last_utility_score == 1741.2725329881864\n",
      "\n",
      "\n",
      "Epoch(30) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(30) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(30) - Fold 0 - Validation Accuracy : 0.5208\n",
      "Epoch(30) - Fold 0 - Validation Utility score : 210.0866\n",
      "Epoch(30) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(30) - Fold 1 - Validation Accuracy : 0.5237\n",
      "Epoch(30) - Fold 1 - Validation Utility score : 543.6305\n",
      "Epoch(30) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(30) - Fold 2 - Validation Accuracy : 0.5092\n",
      "Epoch(30) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(30) - Fold 3 - Validation Accuracy : 0.5080\n",
      "Epoch(30) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(30) - Fold 4 - Validation Accuracy : 0.5125\n",
      "Epoch(30) - Fold 4 - Validation Utility score : 938.6136\n",
      "Epoch(30) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(30) - GLOBAL - Validation Accuracy: 0.5148\n",
      "Epoch(30) - GLOBAL - Validation Utility score: 1692.3307\n",
      "Saving model corresponding to last_utility_score == 1692.3306585750558\n",
      "\n",
      "\n",
      "Epoch(31) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(31) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(31) - Fold 0 - Validation Accuracy : 0.5214\n",
      "Epoch(31) - Fold 0 - Validation Utility score : 239.9296\n",
      "Epoch(31) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(31) - Fold 1 - Validation Accuracy : 0.5238\n",
      "Epoch(31) - Fold 1 - Validation Utility score : 556.0914\n",
      "Epoch(31) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(31) - Fold 2 - Validation Accuracy : 0.5090\n",
      "Epoch(31) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(31) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(31) - Fold 3 - Validation Accuracy : 0.5076\n",
      "Epoch(31) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(31) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(31) - Fold 4 - Validation Accuracy : 0.5123\n",
      "Epoch(31) - Fold 4 - Validation Utility score : 1012.3907\n",
      "Epoch(31) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(31) - GLOBAL - Validation Accuracy: 0.5148\n",
      "Epoch(31) - GLOBAL - Validation Utility score: 1808.4117\n",
      "Saving model corresponding to last_utility_score == 1808.411688266723\n",
      "\n",
      "\n",
      "Epoch(32) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(32) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(32) - Fold 0 - Validation Accuracy : 0.5221\n",
      "Epoch(32) - Fold 0 - Validation Utility score : 269.3495\n",
      "Epoch(32) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(32) - Fold 1 - Validation Accuracy : 0.5238\n",
      "Epoch(32) - Fold 1 - Validation Utility score : 566.4525\n",
      "Epoch(32) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(32) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(32) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(32) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(32) - Fold 3 - Validation Accuracy : 0.5069\n",
      "Epoch(32) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(32) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(32) - Fold 4 - Validation Accuracy : 0.5121\n",
      "Epoch(32) - Fold 4 - Validation Utility score : 953.1351\n",
      "Epoch(32) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(32) - GLOBAL - Validation Accuracy: 0.5147\n",
      "Epoch(32) - GLOBAL - Validation Utility score: 1788.9371\n",
      "Saving model corresponding to last_utility_score == 1788.9370702541119\n",
      "\n",
      "\n",
      "Epoch(33) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(33) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(33) - Fold 0 - Validation Accuracy : 0.5177\n",
      "Epoch(33) - Fold 0 - Validation Utility score : 93.8534\n",
      "Epoch(33) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(33) - Fold 1 - Validation Accuracy : 0.5214\n",
      "Epoch(33) - Fold 1 - Validation Utility score : 341.9556\n",
      "Epoch(33) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(33) - Fold 2 - Validation Accuracy : 0.5097\n",
      "Epoch(33) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(33) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(33) - Fold 3 - Validation Accuracy : 0.5078\n",
      "Epoch(33) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(33) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(33) - Fold 4 - Validation Accuracy : 0.5099\n",
      "Epoch(33) - Fold 4 - Validation Utility score : 707.1310\n",
      "Epoch(33) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(33) - GLOBAL - Validation Accuracy: 0.5133\n",
      "Epoch(33) - GLOBAL - Validation Utility score: 1142.9400\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(34) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(34) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(34) - Fold 0 - Validation Accuracy : 0.5200\n",
      "Epoch(34) - Fold 0 - Validation Utility score : 154.3397\n",
      "Epoch(34) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(34) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(34) - Fold 1 - Validation Utility score : 521.4972\n",
      "Epoch(34) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(34) - Fold 2 - Validation Accuracy : 0.5091\n",
      "Epoch(34) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(34) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(34) - Fold 3 - Validation Accuracy : 0.5077\n",
      "Epoch(34) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(34) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(34) - Fold 4 - Validation Accuracy : 0.5109\n",
      "Epoch(34) - Fold 4 - Validation Utility score : 786.6519\n",
      "Epoch(34) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(34) - GLOBAL - Validation Accuracy: 0.5142\n",
      "Epoch(34) - GLOBAL - Validation Utility score: 1462.4888\n",
      "Intermediate early stopping : vepoch_loss = 0.6922, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(35) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(35) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(35) - Fold 0 - Validation Accuracy : 0.5242\n",
      "Epoch(35) - Fold 0 - Validation Utility score : 401.3771\n",
      "Epoch(35) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(35) - Fold 1 - Validation Accuracy : 0.5241\n",
      "Epoch(35) - Fold 1 - Validation Utility score : 669.9224\n",
      "Epoch(35) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(35) - Fold 2 - Validation Accuracy : 0.5089\n",
      "Epoch(35) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(35) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(35) - Fold 3 - Validation Accuracy : 0.5089\n",
      "Epoch(35) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(35) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(35) - Fold 4 - Validation Accuracy : 0.5146\n",
      "Epoch(35) - Fold 4 - Validation Utility score : 930.2501\n",
      "Epoch(35) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(35) - GLOBAL - Validation Accuracy: 0.5162\n",
      "Epoch(35) - GLOBAL - Validation Utility score: 2001.5496\n",
      "Saving model corresponding to last_utility_score == 2001.5495916886825\n",
      "\n",
      "\n",
      "Epoch(36) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(36) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(36) - Fold 0 - Validation Accuracy : 0.5222\n",
      "Epoch(36) - Fold 0 - Validation Utility score : 233.1602\n",
      "Epoch(36) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(36) - Fold 1 - Validation Accuracy : 0.5253\n",
      "Epoch(36) - Fold 1 - Validation Utility score : 683.5900\n",
      "Epoch(36) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(36) - Fold 2 - Validation Accuracy : 0.5098\n",
      "Epoch(36) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(36) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(36) - Fold 3 - Validation Accuracy : 0.5089\n",
      "Epoch(36) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(36) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(36) - Fold 4 - Validation Accuracy : 0.5136\n",
      "Epoch(36) - Fold 4 - Validation Utility score : 1024.1230\n",
      "Epoch(36) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(36) - GLOBAL - Validation Accuracy: 0.5159\n",
      "Epoch(36) - GLOBAL - Validation Utility score: 1940.8732\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(37) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(37) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(37) - Fold 0 - Validation Accuracy : 0.5238\n",
      "Epoch(37) - Fold 0 - Validation Utility score : 384.2547\n",
      "Epoch(37) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(37) - Fold 1 - Validation Accuracy : 0.5248\n",
      "Epoch(37) - Fold 1 - Validation Utility score : 674.0255\n",
      "Epoch(37) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(37) - Fold 2 - Validation Accuracy : 0.5092\n",
      "Epoch(37) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(37) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(37) - Fold 3 - Validation Accuracy : 0.5082\n",
      "Epoch(37) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(37) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(37) - Fold 4 - Validation Accuracy : 0.5146\n",
      "Epoch(37) - Fold 4 - Validation Utility score : 1034.4177\n",
      "Epoch(37) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(37) - GLOBAL - Validation Accuracy: 0.5161\n",
      "Epoch(37) - GLOBAL - Validation Utility score: 2092.6980\n",
      "Saving model corresponding to last_utility_score == 2092.6979829304\n",
      "\n",
      "\n",
      "Epoch(38) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(38) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(38) - Fold 0 - Validation Accuracy : 0.5159\n",
      "Epoch(38) - Fold 0 - Validation Utility score : 18.5072\n",
      "Epoch(38) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(38) - Fold 1 - Validation Accuracy : 0.5198\n",
      "Epoch(38) - Fold 1 - Validation Utility score : 187.9322\n",
      "Epoch(38) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(38) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(38) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(38) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(38) - Fold 3 - Validation Accuracy : 0.5069\n",
      "Epoch(38) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(38) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(38) - Fold 4 - Validation Accuracy : 0.5101\n",
      "Epoch(38) - Fold 4 - Validation Utility score : 757.9626\n",
      "Epoch(38) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(38) - GLOBAL - Validation Accuracy: 0.5123\n",
      "Epoch(38) - GLOBAL - Validation Utility score: 964.4020\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(39) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(39) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(39) - Fold 0 - Validation Accuracy : 0.5225\n",
      "Epoch(39) - Fold 0 - Validation Utility score : 237.0988\n",
      "Epoch(39) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(39) - Fold 1 - Validation Accuracy : 0.5241\n",
      "Epoch(39) - Fold 1 - Validation Utility score : 646.5746\n",
      "Epoch(39) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(39) - Fold 2 - Validation Accuracy : 0.5093\n",
      "Epoch(39) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(39) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(39) - Fold 3 - Validation Accuracy : 0.5081\n",
      "Epoch(39) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(39) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(39) - Fold 4 - Validation Accuracy : 0.5141\n",
      "Epoch(39) - Fold 4 - Validation Utility score : 1046.9076\n",
      "Epoch(39) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(39) - GLOBAL - Validation Accuracy: 0.5156\n",
      "Epoch(39) - GLOBAL - Validation Utility score: 1930.5810\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(40) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(40) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(40) - Fold 0 - Validation Accuracy : 0.5246\n",
      "Epoch(40) - Fold 0 - Validation Utility score : 327.9175\n",
      "Epoch(40) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(40) - Fold 1 - Validation Accuracy : 0.5239\n",
      "Epoch(40) - Fold 1 - Validation Utility score : 733.4403\n",
      "Epoch(40) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(40) - Fold 2 - Validation Accuracy : 0.5095\n",
      "Epoch(40) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(40) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(40) - Fold 3 - Validation Accuracy : 0.5088\n",
      "Epoch(40) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(40) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(40) - Fold 4 - Validation Accuracy : 0.5140\n",
      "Epoch(40) - Fold 4 - Validation Utility score : 986.1800\n",
      "Epoch(40) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(40) - GLOBAL - Validation Accuracy: 0.5162\n",
      "Epoch(40) - GLOBAL - Validation Utility score: 2047.5378\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(41) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(41) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(41) - Fold 0 - Validation Accuracy : 0.5217\n",
      "Epoch(41) - Fold 0 - Validation Utility score : 187.5064\n",
      "Epoch(41) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(41) - Fold 1 - Validation Accuracy : 0.5239\n",
      "Epoch(41) - Fold 1 - Validation Utility score : 638.7712\n",
      "Epoch(41) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(41) - Fold 2 - Validation Accuracy : 0.5102\n",
      "Epoch(41) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(41) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(41) - Fold 3 - Validation Accuracy : 0.5085\n",
      "Epoch(41) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(41) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(41) - Fold 4 - Validation Accuracy : 0.5138\n",
      "Epoch(41) - Fold 4 - Validation Utility score : 929.7767\n",
      "Epoch(41) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(41) - GLOBAL - Validation Accuracy: 0.5156\n",
      "Epoch(41) - GLOBAL - Validation Utility score: 1756.0543\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(42) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(42) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(42) - Fold 0 - Validation Accuracy : 0.5249\n",
      "Epoch(42) - Fold 0 - Validation Utility score : 497.7002\n",
      "Epoch(42) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(42) - Fold 1 - Validation Accuracy : 0.5244\n",
      "Epoch(42) - Fold 1 - Validation Utility score : 854.2601\n",
      "Epoch(42) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(42) - Fold 2 - Validation Accuracy : 0.5101\n",
      "Epoch(42) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(42) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(42) - Fold 3 - Validation Accuracy : 0.5081\n",
      "Epoch(42) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(42) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(42) - Fold 4 - Validation Accuracy : 0.5153\n",
      "Epoch(42) - Fold 4 - Validation Utility score : 1092.9708\n",
      "Epoch(42) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(42) - GLOBAL - Validation Accuracy: 0.5166\n",
      "Epoch(42) - GLOBAL - Validation Utility score: 2444.9312\n",
      "Saving model corresponding to last_utility_score == 2444.9311791077735\n",
      "\n",
      "\n",
      "Epoch(43) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(43) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(43) - Fold 0 - Validation Accuracy : 0.5220\n",
      "Epoch(43) - Fold 0 - Validation Utility score : 203.4273\n",
      "Epoch(43) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(43) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(43) - Fold 1 - Validation Utility score : 578.6468\n",
      "Epoch(43) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(43) - Fold 2 - Validation Accuracy : 0.5100\n",
      "Epoch(43) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(43) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(43) - Fold 3 - Validation Accuracy : 0.5086\n",
      "Epoch(43) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(43) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(43) - Fold 4 - Validation Accuracy : 0.5128\n",
      "Epoch(43) - Fold 4 - Validation Utility score : 870.4951\n",
      "Epoch(43) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(43) - GLOBAL - Validation Accuracy: 0.5154\n",
      "Epoch(43) - GLOBAL - Validation Utility score: 1652.5691\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(44) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(44) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(44) - Fold 0 - Validation Accuracy : 0.5212\n",
      "Epoch(44) - Fold 0 - Validation Utility score : 171.8842\n",
      "Epoch(44) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(44) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(44) - Fold 1 - Validation Utility score : 610.0017\n",
      "Epoch(44) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(44) - Fold 2 - Validation Accuracy : 0.5103\n",
      "Epoch(44) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(44) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(44) - Fold 3 - Validation Accuracy : 0.5094\n",
      "Epoch(44) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(44) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(44) - Fold 4 - Validation Accuracy : 0.5146\n",
      "Epoch(44) - Fold 4 - Validation Utility score : 1077.7849\n",
      "Epoch(44) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(44) - GLOBAL - Validation Accuracy: 0.5159\n",
      "Epoch(44) - GLOBAL - Validation Utility score: 1859.6708\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(45) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(45) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(45) - Fold 0 - Validation Accuracy : 0.5223\n",
      "Epoch(45) - Fold 0 - Validation Utility score : 197.8090\n",
      "Epoch(45) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(45) - Fold 1 - Validation Accuracy : 0.5243\n",
      "Epoch(45) - Fold 1 - Validation Utility score : 639.8005\n",
      "Epoch(45) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(45) - Fold 2 - Validation Accuracy : 0.5107\n",
      "Epoch(45) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(45) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(45) - Fold 3 - Validation Accuracy : 0.5091\n",
      "Epoch(45) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(45) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(45) - Fold 4 - Validation Accuracy : 0.5149\n",
      "Epoch(45) - Fold 4 - Validation Utility score : 979.3689\n",
      "Epoch(45) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(45) - GLOBAL - Validation Accuracy: 0.5163\n",
      "Epoch(45) - GLOBAL - Validation Utility score: 1816.9784\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(46) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(46) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(46) - Fold 0 - Validation Accuracy : 0.5237\n",
      "Epoch(46) - Fold 0 - Validation Utility score : 298.9598\n",
      "Epoch(46) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(46) - Fold 1 - Validation Accuracy : 0.5238\n",
      "Epoch(46) - Fold 1 - Validation Utility score : 778.1939\n",
      "Epoch(46) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(46) - Fold 2 - Validation Accuracy : 0.5098\n",
      "Epoch(46) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(46) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(46) - Fold 3 - Validation Accuracy : 0.5104\n",
      "Epoch(46) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(46) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(46) - Fold 4 - Validation Accuracy : 0.5161\n",
      "Epoch(46) - Fold 4 - Validation Utility score : 1094.4240\n",
      "Epoch(46) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(46) - GLOBAL - Validation Accuracy: 0.5167\n",
      "Epoch(46) - GLOBAL - Validation Utility score: 2171.5777\n",
      "Saving model corresponding to last_utility_score == 2171.5776970896222\n",
      "\n",
      "\n",
      "Epoch(47) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(47) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(47) - Fold 0 - Validation Accuracy : 0.5226\n",
      "Epoch(47) - Fold 0 - Validation Utility score : 387.0051\n",
      "Epoch(47) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(47) - Fold 1 - Validation Accuracy : 0.5241\n",
      "Epoch(47) - Fold 1 - Validation Utility score : 757.1983\n",
      "Epoch(47) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(47) - Fold 2 - Validation Accuracy : 0.5102\n",
      "Epoch(47) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(47) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(47) - Fold 3 - Validation Accuracy : 0.5097\n",
      "Epoch(47) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(47) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(47) - Fold 4 - Validation Accuracy : 0.5186\n",
      "Epoch(47) - Fold 4 - Validation Utility score : 1164.8615\n",
      "Epoch(47) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(47) - GLOBAL - Validation Accuracy: 0.5170\n",
      "Epoch(47) - GLOBAL - Validation Utility score: 2309.0649\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(48) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(48) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(48) - Fold 0 - Validation Accuracy : 0.5215\n",
      "Epoch(48) - Fold 0 - Validation Utility score : 169.8121\n",
      "Epoch(48) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(48) - Fold 1 - Validation Accuracy : 0.5238\n",
      "Epoch(48) - Fold 1 - Validation Utility score : 511.2035\n",
      "Epoch(48) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(48) - Fold 2 - Validation Accuracy : 0.5112\n",
      "Epoch(48) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(48) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(48) - Fold 3 - Validation Accuracy : 0.5094\n",
      "Epoch(48) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(48) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(48) - Fold 4 - Validation Accuracy : 0.5153\n",
      "Epoch(48) - Fold 4 - Validation Utility score : 1075.0785\n",
      "Epoch(48) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(48) - GLOBAL - Validation Accuracy: 0.5162\n",
      "Epoch(48) - GLOBAL - Validation Utility score: 1756.0940\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(49) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(49) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(49) - Fold 0 - Validation Accuracy : 0.5200\n",
      "Epoch(49) - Fold 0 - Validation Utility score : 101.7466\n",
      "Epoch(49) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(49) - Fold 1 - Validation Accuracy : 0.5222\n",
      "Epoch(49) - Fold 1 - Validation Utility score : 547.4549\n",
      "Epoch(49) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(49) - Fold 2 - Validation Accuracy : 0.5111\n",
      "Epoch(49) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(49) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(49) - Fold 3 - Validation Accuracy : 0.5097\n",
      "Epoch(49) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(49) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(49) - Fold 4 - Validation Accuracy : 0.5155\n",
      "Epoch(49) - Fold 4 - Validation Utility score : 939.1735\n",
      "Epoch(49) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(49) - GLOBAL - Validation Accuracy: 0.5157\n",
      "Epoch(49) - GLOBAL - Validation Utility score: 1588.3750\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(50) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(50) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(50) - Fold 0 - Validation Accuracy : 0.5234\n",
      "Epoch(50) - Fold 0 - Validation Utility score : 297.5320\n",
      "Epoch(50) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(50) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(50) - Fold 1 - Validation Utility score : 640.0743\n",
      "Epoch(50) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(50) - Fold 2 - Validation Accuracy : 0.5101\n",
      "Epoch(50) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(50) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(50) - Fold 3 - Validation Accuracy : 0.5102\n",
      "Epoch(50) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(50) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(50) - Fold 4 - Validation Accuracy : 0.5195\n",
      "Epoch(50) - Fold 4 - Validation Utility score : 972.8829\n",
      "Epoch(50) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(50) - GLOBAL - Validation Accuracy: 0.5173\n",
      "Epoch(50) - GLOBAL - Validation Utility score: 1910.4893\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(51) - Training Loss: 0.6915\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(51) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(51) - Fold 0 - Validation Accuracy : 0.5216\n",
      "Epoch(51) - Fold 0 - Validation Utility score : 207.9521\n",
      "Epoch(51) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(51) - Fold 1 - Validation Accuracy : 0.5233\n",
      "Epoch(51) - Fold 1 - Validation Utility score : 628.3248\n",
      "Epoch(51) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(51) - Fold 2 - Validation Accuracy : 0.5114\n",
      "Epoch(51) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(51) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(51) - Fold 3 - Validation Accuracy : 0.5100\n",
      "Epoch(51) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(51) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(51) - Fold 4 - Validation Accuracy : 0.5160\n",
      "Epoch(51) - Fold 4 - Validation Utility score : 942.1961\n",
      "Epoch(51) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(51) - GLOBAL - Validation Accuracy: 0.5165\n",
      "Epoch(51) - GLOBAL - Validation Utility score: 1778.4730\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "Meet Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 532459<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_101819-p8d39wtq/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_101819-p8d39wtq/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>0.6915</td></tr><tr><td>Global valid/Loss</td><td>0.69203</td></tr><tr><td>Global valid/Accuracy</td><td>0.51647</td></tr><tr><td>Global valid/Utility</td><td>1778.47303</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>0.69169</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>0.52164</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>207.9521</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>0.69121</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>0.52329</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>628.32483</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>0.69292</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>0.51137</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>0.69289</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>0.51005</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>0.69146</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>0.51602</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>942.19611</td></tr><tr><td>Best accuracy</td><td>0.51675</td></tr><tr><td>Best utility</td><td>2171.5777</td></tr><tr><td>_runtime</td><td>3635</td></tr><tr><td>_timestamp</td><td>1613470734</td></tr><tr><td>_step</td><td>51</td></tr><tr><td>Final utility score</td><td>{'utility_score': 21...</td></tr><tr><td>Batch size</td><td>32574</td></tr><tr><td>Patience</td><td>5</td></tr><tr><td>Number of epochs</td><td>1000</td></tr><tr><td>Best epoch</td><td>46</td></tr><tr><td>Number of parameters per layer</td><td>[8384, 64, 2048, 32,...</td></tr><tr><td>Model architecture</td><td>MLP(<BR>  (AEncoder)...</td></tr><tr><td>comment</td><td>All folds MLP with a...</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Loss</td><td>█▅▄▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Accuracy</td><td>▁▂▂▂▂▂▃▃▃▃▄▅▆▆▆▆▇▆▇▇▇▆▇▇▇▇▇███▇█▇▇████▇█</td></tr><tr><td>Global valid/Utility</td><td>▁▁▁▁▁▁▁▁▁▁▂▃▄▄▃▄▆▅▅▆▆▄▅▆▆▆▅▇▇▇▇▇▆▆▇▆█▆▆▆</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>█▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>▂▁▁▁▁▁▂▂▃▃▄▅▅▅▅▅▆▆▆▇▇▆▆▇▇▇▇█▇█▇█▇▇▇▇▇▇▇▇</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▂▂▅▅▂▂▅▅▆▄█▅█▅▇▄▅▄▄█▄▃▅</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>█▆▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>▁▂▂▂▂▂▃▃▃▃▄▆▆▇▆▇█▇▇██▇▇▇██▇██████▇████▇▇</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>▁▁▁▁▁▁▁▁▁▁▂▃▃▄▃▄▆▅▅▆▆▄▅▆▆▆▆▇▇▇▇█▇▆▇▇█▆▆▇</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>█▅▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>▁▂▃▃▄▄▃▃▃▃▄▅▆▆▆▆▇▇▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇███</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>█▆▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>▁▂▁▁▂▂▃▃▄▄▅▆▆▆▆▆▆▆▆▅▆▆▆▇▆▆▆▇▇▇▇▇▇▇█▇████</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>█▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>▁▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▆▇▇█▇▇▇</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>▁▁▁▁▁▁▁▁▂▂▂▄▅▅▄▅▆▆▆▆▇▅▇▇▇▇▆▇▇▇▇▇▇▆▇▇█▇▇▇</td></tr><tr><td>Best accuracy</td><td>▁▂▂▂▂▂▂▃▃▃▃▄▄▅▆▆▆▇▆▇▇▇▇▇▇▇▇█████</td></tr><tr><td>Best utility</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▄▅▅▅▆▆▅▆▆▆▆▇▇█▇▇</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 261 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">copper-sweep-10</strong>: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/p8d39wtq\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/p8d39wtq</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training summary:\n",
      "{'utility_score': 2171.5776970896222, 'utility_scores': [298.9597510413924, 778.1939334783124, -0.0, -0.0, 1094.4240125699177], 'utility_score_std': 435.79277443193234, 'accuracy_scores': [0.5236708196907202, 0.5238118638118638, 0.5097939595334052, 0.5103973211773313, 0.5160585998027891]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l82zicq9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leakyrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 62480\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4289222066880878\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005708812731792326\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_autoenc: encoder-only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.7115383950617598e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">devoted-sweep-11</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/l82zicq9\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/l82zicq9</a><br/>\n",
       "                Run data is saved locally in <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_111918-l82zicq9</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Run config :\n",
      "config: {'activation_function': 'leakyrelu', 'batch_size': 62480, 'dropout': 0.4289222066880878, 'learning_rate': 0.0005708812731792326, 'use_autoenc': 'encoder-only', 'weight_decay': 1.7115383950617598e-05, 'epochs': 1000}\n",
      "Epoch(0) - Training Loss: 0.9755\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(0) - Fold 0 - Validation Loss : 0.7023\n",
      "Epoch(0) - Fold 0 - Validation Accuracy : 0.5028\n",
      "Epoch(0) - Fold 0 - Validation Utility score : 34.7101\n",
      "Epoch(0) - Fold 1 - Validation Loss : 0.6993\n",
      "Epoch(0) - Fold 1 - Validation Accuracy : 0.4988\n",
      "Epoch(0) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 2 - Validation Loss : 0.7014\n",
      "Epoch(0) - Fold 2 - Validation Accuracy : 0.4968\n",
      "Epoch(0) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 3 - Validation Loss : 0.6993\n",
      "Epoch(0) - Fold 3 - Validation Accuracy : 0.5004\n",
      "Epoch(0) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 4 - Validation Loss : 0.7020\n",
      "Epoch(0) - Fold 4 - Validation Accuracy : 0.4912\n",
      "Epoch(0) - Fold 4 - Validation Utility score : -0.0000\n",
      "Epoch(0) - GLOBAL - Validation Loss: 0.7009\n",
      "Epoch(0) - GLOBAL - Validation Accuracy: 0.4980\n",
      "Epoch(0) - GLOBAL - Validation Utility score: 34.7101\n",
      "Saving model corresponding to last_utility_score == 34.71008870064913\n",
      "\n",
      "\n",
      "Epoch(1) - Training Loss: 0.8783\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(1) - Fold 0 - Validation Loss : 0.7047\n",
      "Epoch(1) - Fold 0 - Validation Accuracy : 0.5005\n",
      "Epoch(1) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 1 - Validation Loss : 0.7026\n",
      "Epoch(1) - Fold 1 - Validation Accuracy : 0.5051\n",
      "Epoch(1) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 2 - Validation Loss : 0.7031\n",
      "Epoch(1) - Fold 2 - Validation Accuracy : 0.4974\n",
      "Epoch(1) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 3 - Validation Loss : 0.7036\n",
      "Epoch(1) - Fold 3 - Validation Accuracy : 0.5003\n",
      "Epoch(1) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 4 - Validation Loss : 0.7050\n",
      "Epoch(1) - Fold 4 - Validation Accuracy : 0.4960\n",
      "Epoch(1) - Fold 4 - Validation Utility score : 9.2642\n",
      "Epoch(1) - GLOBAL - Validation Loss: 0.7038\n",
      "Epoch(1) - GLOBAL - Validation Accuracy: 0.4998\n",
      "Epoch(1) - GLOBAL - Validation Utility score: 9.2642\n",
      "Intermediate early stopping : vepoch_loss = 0.7038, the_last_loss=0.7009\n",
      "\n",
      "\n",
      "Epoch(2) - Training Loss: 0.8399\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(2) - Fold 0 - Validation Loss : 0.6980\n",
      "Epoch(2) - Fold 0 - Validation Accuracy : 0.5040\n",
      "Epoch(2) - Fold 0 - Validation Utility score : 0.3607\n",
      "Epoch(2) - Fold 1 - Validation Loss : 0.6973\n",
      "Epoch(2) - Fold 1 - Validation Accuracy : 0.5032\n",
      "Epoch(2) - Fold 1 - Validation Utility score : 17.6286\n",
      "Epoch(2) - Fold 2 - Validation Loss : 0.6982\n",
      "Epoch(2) - Fold 2 - Validation Accuracy : 0.4978\n",
      "Epoch(2) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 3 - Validation Loss : 0.6977\n",
      "Epoch(2) - Fold 3 - Validation Accuracy : 0.5008\n",
      "Epoch(2) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 4 - Validation Loss : 0.6992\n",
      "Epoch(2) - Fold 4 - Validation Accuracy : 0.4932\n",
      "Epoch(2) - Fold 4 - Validation Utility score : -0.0000\n",
      "Epoch(2) - GLOBAL - Validation Loss: 0.6981\n",
      "Epoch(2) - GLOBAL - Validation Accuracy: 0.4998\n",
      "Epoch(2) - GLOBAL - Validation Utility score: 17.9893\n",
      "Saving model corresponding to last_utility_score == 17.989279051444058\n",
      "\n",
      "\n",
      "Epoch(3) - Training Loss: 0.8005\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(3) - Fold 0 - Validation Loss : 0.6982\n",
      "Epoch(3) - Fold 0 - Validation Accuracy : 0.5007\n",
      "Epoch(3) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 1 - Validation Loss : 0.6976\n",
      "Epoch(3) - Fold 1 - Validation Accuracy : 0.5062\n",
      "Epoch(3) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 2 - Validation Loss : 0.6981\n",
      "Epoch(3) - Fold 2 - Validation Accuracy : 0.4991\n",
      "Epoch(3) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 3 - Validation Loss : 0.6985\n",
      "Epoch(3) - Fold 3 - Validation Accuracy : 0.5004\n",
      "Epoch(3) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 4 - Validation Loss : 0.6991\n",
      "Epoch(3) - Fold 4 - Validation Accuracy : 0.4982\n",
      "Epoch(3) - Fold 4 - Validation Utility score : 20.9693\n",
      "Epoch(3) - GLOBAL - Validation Loss: 0.6983\n",
      "Epoch(3) - GLOBAL - Validation Accuracy: 0.5009\n",
      "Epoch(3) - GLOBAL - Validation Utility score: 20.9693\n",
      "Intermediate early stopping : vepoch_loss = 0.6983, the_last_loss=0.6981\n",
      "\n",
      "\n",
      "Epoch(4) - Training Loss: 0.7686\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(4) - Fold 0 - Validation Loss : 0.6973\n",
      "Epoch(4) - Fold 0 - Validation Accuracy : 0.5009\n",
      "Epoch(4) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 1 - Validation Loss : 0.6967\n",
      "Epoch(4) - Fold 1 - Validation Accuracy : 0.5063\n",
      "Epoch(4) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 2 - Validation Loss : 0.6969\n",
      "Epoch(4) - Fold 2 - Validation Accuracy : 0.5013\n",
      "Epoch(4) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 3 - Validation Loss : 0.6977\n",
      "Epoch(4) - Fold 3 - Validation Accuracy : 0.5002\n",
      "Epoch(4) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 4 - Validation Loss : 0.6976\n",
      "Epoch(4) - Fold 4 - Validation Accuracy : 0.4983\n",
      "Epoch(4) - Fold 4 - Validation Utility score : 13.5171\n",
      "Epoch(4) - GLOBAL - Validation Loss: 0.6972\n",
      "Epoch(4) - GLOBAL - Validation Accuracy: 0.5014\n",
      "Epoch(4) - GLOBAL - Validation Utility score: 13.5171\n",
      "Saving model corresponding to last_utility_score == 13.51710549118573\n",
      "\n",
      "\n",
      "Epoch(5) - Training Loss: 0.7422\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(5) - Fold 0 - Validation Loss : 0.6967\n",
      "Epoch(5) - Fold 0 - Validation Accuracy : 0.5014\n",
      "Epoch(5) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 1 - Validation Loss : 0.6963\n",
      "Epoch(5) - Fold 1 - Validation Accuracy : 0.5060\n",
      "Epoch(5) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 2 - Validation Loss : 0.6966\n",
      "Epoch(5) - Fold 2 - Validation Accuracy : 0.5017\n",
      "Epoch(5) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 3 - Validation Loss : 0.6972\n",
      "Epoch(5) - Fold 3 - Validation Accuracy : 0.5003\n",
      "Epoch(5) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 4 - Validation Loss : 0.6970\n",
      "Epoch(5) - Fold 4 - Validation Accuracy : 0.4984\n",
      "Epoch(5) - Fold 4 - Validation Utility score : 10.7871\n",
      "Epoch(5) - GLOBAL - Validation Loss: 0.6967\n",
      "Epoch(5) - GLOBAL - Validation Accuracy: 0.5016\n",
      "Epoch(5) - GLOBAL - Validation Utility score: 10.7871\n",
      "Saving model corresponding to last_utility_score == 10.787122030833942\n",
      "\n",
      "\n",
      "Epoch(6) - Training Loss: 0.7228\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(6) - Fold 0 - Validation Loss : 0.6953\n",
      "Epoch(6) - Fold 0 - Validation Accuracy : 0.5002\n",
      "Epoch(6) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 1 - Validation Loss : 0.6949\n",
      "Epoch(6) - Fold 1 - Validation Accuracy : 0.5058\n",
      "Epoch(6) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 2 - Validation Loss : 0.6952\n",
      "Epoch(6) - Fold 2 - Validation Accuracy : 0.5018\n",
      "Epoch(6) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 3 - Validation Loss : 0.6956\n",
      "Epoch(6) - Fold 3 - Validation Accuracy : 0.5001\n",
      "Epoch(6) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 4 - Validation Loss : 0.6956\n",
      "Epoch(6) - Fold 4 - Validation Accuracy : 0.4984\n",
      "Epoch(6) - Fold 4 - Validation Utility score : 13.6278\n",
      "Epoch(6) - GLOBAL - Validation Loss: 0.6953\n",
      "Epoch(6) - GLOBAL - Validation Accuracy: 0.5013\n",
      "Epoch(6) - GLOBAL - Validation Utility score: 13.6278\n",
      "Saving model corresponding to last_utility_score == 13.627832590754346\n",
      "\n",
      "\n",
      "Epoch(7) - Training Loss: 0.7104\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(7) - Fold 0 - Validation Loss : 0.6946\n",
      "Epoch(7) - Fold 0 - Validation Accuracy : 0.5005\n",
      "Epoch(7) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 1 - Validation Loss : 0.6941\n",
      "Epoch(7) - Fold 1 - Validation Accuracy : 0.5058\n",
      "Epoch(7) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 2 - Validation Loss : 0.6943\n",
      "Epoch(7) - Fold 2 - Validation Accuracy : 0.5019\n",
      "Epoch(7) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 3 - Validation Loss : 0.6946\n",
      "Epoch(7) - Fold 3 - Validation Accuracy : 0.4997\n",
      "Epoch(7) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 4 - Validation Loss : 0.6946\n",
      "Epoch(7) - Fold 4 - Validation Accuracy : 0.4990\n",
      "Epoch(7) - Fold 4 - Validation Utility score : 18.8275\n",
      "Epoch(7) - GLOBAL - Validation Loss: 0.6944\n",
      "Epoch(7) - GLOBAL - Validation Accuracy: 0.5014\n",
      "Epoch(7) - GLOBAL - Validation Utility score: 18.8275\n",
      "Saving model corresponding to last_utility_score == 18.827510341702858\n",
      "\n",
      "\n",
      "Epoch(8) - Training Loss: 0.7029\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(8) - Fold 0 - Validation Loss : 0.6945\n",
      "Epoch(8) - Fold 0 - Validation Accuracy : 0.5002\n",
      "Epoch(8) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 1 - Validation Loss : 0.6938\n",
      "Epoch(8) - Fold 1 - Validation Accuracy : 0.5062\n",
      "Epoch(8) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 2 - Validation Loss : 0.6942\n",
      "Epoch(8) - Fold 2 - Validation Accuracy : 0.5019\n",
      "Epoch(8) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 3 - Validation Loss : 0.6944\n",
      "Epoch(8) - Fold 3 - Validation Accuracy : 0.4997\n",
      "Epoch(8) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 4 - Validation Loss : 0.6945\n",
      "Epoch(8) - Fold 4 - Validation Accuracy : 0.4988\n",
      "Epoch(8) - Fold 4 - Validation Utility score : 17.3321\n",
      "Epoch(8) - GLOBAL - Validation Loss: 0.6943\n",
      "Epoch(8) - GLOBAL - Validation Accuracy: 0.5014\n",
      "Epoch(8) - GLOBAL - Validation Utility score: 17.3321\n",
      "Saving model corresponding to last_utility_score == 17.332052676921933\n",
      "\n",
      "\n",
      "Epoch(9) - Training Loss: 0.6987\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(9) - Fold 0 - Validation Loss : 0.6943\n",
      "Epoch(9) - Fold 0 - Validation Accuracy : 0.5001\n",
      "Epoch(9) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 1 - Validation Loss : 0.6935\n",
      "Epoch(9) - Fold 1 - Validation Accuracy : 0.5064\n",
      "Epoch(9) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 2 - Validation Loss : 0.6939\n",
      "Epoch(9) - Fold 2 - Validation Accuracy : 0.5020\n",
      "Epoch(9) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 3 - Validation Loss : 0.6941\n",
      "Epoch(9) - Fold 3 - Validation Accuracy : 0.4997\n",
      "Epoch(9) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 4 - Validation Loss : 0.6942\n",
      "Epoch(9) - Fold 4 - Validation Accuracy : 0.4990\n",
      "Epoch(9) - Fold 4 - Validation Utility score : 19.7100\n",
      "Epoch(9) - GLOBAL - Validation Loss: 0.6940\n",
      "Epoch(9) - GLOBAL - Validation Accuracy: 0.5014\n",
      "Epoch(9) - GLOBAL - Validation Utility score: 19.7100\n",
      "Saving model corresponding to last_utility_score == 19.710010402065475\n",
      "\n",
      "\n",
      "Epoch(10) - Training Loss: 0.6968\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(10) - Fold 0 - Validation Loss : 0.6939\n",
      "Epoch(10) - Fold 0 - Validation Accuracy : 0.4997\n",
      "Epoch(10) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 1 - Validation Loss : 0.6932\n",
      "Epoch(10) - Fold 1 - Validation Accuracy : 0.5067\n",
      "Epoch(10) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 2 - Validation Loss : 0.6937\n",
      "Epoch(10) - Fold 2 - Validation Accuracy : 0.5025\n",
      "Epoch(10) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 3 - Validation Loss : 0.6938\n",
      "Epoch(10) - Fold 3 - Validation Accuracy : 0.5003\n",
      "Epoch(10) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 4 - Validation Loss : 0.6939\n",
      "Epoch(10) - Fold 4 - Validation Accuracy : 0.4995\n",
      "Epoch(10) - Fold 4 - Validation Utility score : 23.2884\n",
      "Epoch(10) - GLOBAL - Validation Loss: 0.6937\n",
      "Epoch(10) - GLOBAL - Validation Accuracy: 0.5017\n",
      "Epoch(10) - GLOBAL - Validation Utility score: 23.2884\n",
      "Saving model corresponding to last_utility_score == 23.288396305665362\n",
      "\n",
      "\n",
      "Epoch(11) - Training Loss: 0.6955\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(11) - Fold 0 - Validation Loss : 0.6938\n",
      "Epoch(11) - Fold 0 - Validation Accuracy : 0.4998\n",
      "Epoch(11) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 1 - Validation Loss : 0.6931\n",
      "Epoch(11) - Fold 1 - Validation Accuracy : 0.5065\n",
      "Epoch(11) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 2 - Validation Loss : 0.6936\n",
      "Epoch(11) - Fold 2 - Validation Accuracy : 0.5024\n",
      "Epoch(11) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 3 - Validation Loss : 0.6938\n",
      "Epoch(11) - Fold 3 - Validation Accuracy : 0.5001\n",
      "Epoch(11) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 4 - Validation Loss : 0.6939\n",
      "Epoch(11) - Fold 4 - Validation Accuracy : 0.4994\n",
      "Epoch(11) - Fold 4 - Validation Utility score : 20.8875\n",
      "Epoch(11) - GLOBAL - Validation Loss: 0.6936\n",
      "Epoch(11) - GLOBAL - Validation Accuracy: 0.5017\n",
      "Epoch(11) - GLOBAL - Validation Utility score: 20.8875\n",
      "Saving model corresponding to last_utility_score == 20.88749152154109\n",
      "\n",
      "\n",
      "Epoch(12) - Training Loss: 0.6948\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(12) - Fold 0 - Validation Loss : 0.6936\n",
      "Epoch(12) - Fold 0 - Validation Accuracy : 0.5006\n",
      "Epoch(12) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 1 - Validation Loss : 0.6930\n",
      "Epoch(12) - Fold 1 - Validation Accuracy : 0.5070\n",
      "Epoch(12) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 2 - Validation Loss : 0.6935\n",
      "Epoch(12) - Fold 2 - Validation Accuracy : 0.5029\n",
      "Epoch(12) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 3 - Validation Loss : 0.6937\n",
      "Epoch(12) - Fold 3 - Validation Accuracy : 0.5005\n",
      "Epoch(12) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 4 - Validation Loss : 0.6938\n",
      "Epoch(12) - Fold 4 - Validation Accuracy : 0.4995\n",
      "Epoch(12) - Fold 4 - Validation Utility score : 19.6583\n",
      "Epoch(12) - GLOBAL - Validation Loss: 0.6935\n",
      "Epoch(12) - GLOBAL - Validation Accuracy: 0.5021\n",
      "Epoch(12) - GLOBAL - Validation Utility score: 19.6583\n",
      "Saving model corresponding to last_utility_score == 19.65828917022085\n",
      "\n",
      "\n",
      "Epoch(13) - Training Loss: 0.6943\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(13) - Fold 0 - Validation Loss : 0.6935\n",
      "Epoch(13) - Fold 0 - Validation Accuracy : 0.5011\n",
      "Epoch(13) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 1 - Validation Loss : 0.6929\n",
      "Epoch(13) - Fold 1 - Validation Accuracy : 0.5073\n",
      "Epoch(13) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 2 - Validation Loss : 0.6935\n",
      "Epoch(13) - Fold 2 - Validation Accuracy : 0.5032\n",
      "Epoch(13) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 3 - Validation Loss : 0.6936\n",
      "Epoch(13) - Fold 3 - Validation Accuracy : 0.5009\n",
      "Epoch(13) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 4 - Validation Loss : 0.6937\n",
      "Epoch(13) - Fold 4 - Validation Accuracy : 0.4997\n",
      "Epoch(13) - Fold 4 - Validation Utility score : 23.9459\n",
      "Epoch(13) - GLOBAL - Validation Loss: 0.6934\n",
      "Epoch(13) - GLOBAL - Validation Accuracy: 0.5024\n",
      "Epoch(13) - GLOBAL - Validation Utility score: 23.9459\n",
      "Saving model corresponding to last_utility_score == 23.945857233205416\n",
      "\n",
      "\n",
      "Epoch(14) - Training Loss: 0.6940\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(14) - Fold 0 - Validation Loss : 0.6934\n",
      "Epoch(14) - Fold 0 - Validation Accuracy : 0.5014\n",
      "Epoch(14) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 1 - Validation Loss : 0.6929\n",
      "Epoch(14) - Fold 1 - Validation Accuracy : 0.5076\n",
      "Epoch(14) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 2 - Validation Loss : 0.6934\n",
      "Epoch(14) - Fold 2 - Validation Accuracy : 0.5032\n",
      "Epoch(14) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 3 - Validation Loss : 0.6936\n",
      "Epoch(14) - Fold 3 - Validation Accuracy : 0.5013\n",
      "Epoch(14) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 4 - Validation Loss : 0.6936\n",
      "Epoch(14) - Fold 4 - Validation Accuracy : 0.5000\n",
      "Epoch(14) - Fold 4 - Validation Utility score : 29.6902\n",
      "Epoch(14) - GLOBAL - Validation Loss: 0.6934\n",
      "Epoch(14) - GLOBAL - Validation Accuracy: 0.5027\n",
      "Epoch(14) - GLOBAL - Validation Utility score: 29.6902\n",
      "Saving model corresponding to last_utility_score == 29.690187146215294\n",
      "\n",
      "\n",
      "Epoch(15) - Training Loss: 0.6940\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(15) - Fold 0 - Validation Loss : 0.6934\n",
      "Epoch(15) - Fold 0 - Validation Accuracy : 0.5014\n",
      "Epoch(15) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 1 - Validation Loss : 0.6929\n",
      "Epoch(15) - Fold 1 - Validation Accuracy : 0.5073\n",
      "Epoch(15) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 2 - Validation Loss : 0.6935\n",
      "Epoch(15) - Fold 2 - Validation Accuracy : 0.5029\n",
      "Epoch(15) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 3 - Validation Loss : 0.6936\n",
      "Epoch(15) - Fold 3 - Validation Accuracy : 0.5013\n",
      "Epoch(15) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 4 - Validation Loss : 0.6937\n",
      "Epoch(15) - Fold 4 - Validation Accuracy : 0.4999\n",
      "Epoch(15) - Fold 4 - Validation Utility score : 29.2446\n",
      "Epoch(15) - GLOBAL - Validation Loss: 0.6934\n",
      "Epoch(15) - GLOBAL - Validation Accuracy: 0.5026\n",
      "Epoch(15) - GLOBAL - Validation Utility score: 29.2446\n",
      "Intermediate early stopping : vepoch_loss = 0.6934, the_last_loss=0.6934\n",
      "\n",
      "\n",
      "Epoch(16) - Training Loss: 0.6938\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(16) - Fold 0 - Validation Loss : 0.6934\n",
      "Epoch(16) - Fold 0 - Validation Accuracy : 0.5017\n",
      "Epoch(16) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(16) - Fold 1 - Validation Accuracy : 0.5073\n",
      "Epoch(16) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 2 - Validation Loss : 0.6934\n",
      "Epoch(16) - Fold 2 - Validation Accuracy : 0.5027\n",
      "Epoch(16) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 3 - Validation Loss : 0.6936\n",
      "Epoch(16) - Fold 3 - Validation Accuracy : 0.5015\n",
      "Epoch(16) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 4 - Validation Loss : 0.6936\n",
      "Epoch(16) - Fold 4 - Validation Accuracy : 0.5003\n",
      "Epoch(16) - Fold 4 - Validation Utility score : 36.8683\n",
      "Epoch(16) - GLOBAL - Validation Loss: 0.6934\n",
      "Epoch(16) - GLOBAL - Validation Accuracy: 0.5027\n",
      "Epoch(16) - GLOBAL - Validation Utility score: 36.8683\n",
      "Saving model corresponding to last_utility_score == 36.86828066108467\n",
      "\n",
      "\n",
      "Epoch(17) - Training Loss: 0.6937\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(17) - Fold 0 - Validation Loss : 0.6933\n",
      "Epoch(17) - Fold 0 - Validation Accuracy : 0.5024\n",
      "Epoch(17) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(17) - Fold 1 - Validation Accuracy : 0.5079\n",
      "Epoch(17) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 2 - Validation Loss : 0.6934\n",
      "Epoch(17) - Fold 2 - Validation Accuracy : 0.5027\n",
      "Epoch(17) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 3 - Validation Loss : 0.6935\n",
      "Epoch(17) - Fold 3 - Validation Accuracy : 0.5021\n",
      "Epoch(17) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 4 - Validation Loss : 0.6935\n",
      "Epoch(17) - Fold 4 - Validation Accuracy : 0.5007\n",
      "Epoch(17) - Fold 4 - Validation Utility score : 33.5741\n",
      "Epoch(17) - GLOBAL - Validation Loss: 0.6933\n",
      "Epoch(17) - GLOBAL - Validation Accuracy: 0.5032\n",
      "Epoch(17) - GLOBAL - Validation Utility score: 33.5741\n",
      "Saving model corresponding to last_utility_score == 33.57414018502035\n",
      "\n",
      "\n",
      "Epoch(18) - Training Loss: 0.6937\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(18) - Fold 0 - Validation Loss : 0.6933\n",
      "Epoch(18) - Fold 0 - Validation Accuracy : 0.5020\n",
      "Epoch(18) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(18) - Fold 1 - Validation Accuracy : 0.5077\n",
      "Epoch(18) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 2 - Validation Loss : 0.6934\n",
      "Epoch(18) - Fold 2 - Validation Accuracy : 0.5028\n",
      "Epoch(18) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 3 - Validation Loss : 0.6935\n",
      "Epoch(18) - Fold 3 - Validation Accuracy : 0.5019\n",
      "Epoch(18) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 4 - Validation Loss : 0.6935\n",
      "Epoch(18) - Fold 4 - Validation Accuracy : 0.5006\n",
      "Epoch(18) - Fold 4 - Validation Utility score : 41.3919\n",
      "Epoch(18) - GLOBAL - Validation Loss: 0.6933\n",
      "Epoch(18) - GLOBAL - Validation Accuracy: 0.5030\n",
      "Epoch(18) - GLOBAL - Validation Utility score: 41.3919\n",
      "Saving model corresponding to last_utility_score == 41.39186426527155\n",
      "\n",
      "\n",
      "Epoch(19) - Training Loss: 0.6936\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(19) - Fold 0 - Validation Loss : 0.6932\n",
      "Epoch(19) - Fold 0 - Validation Accuracy : 0.5030\n",
      "Epoch(19) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(19) - Fold 1 - Validation Accuracy : 0.5084\n",
      "Epoch(19) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(19) - Fold 2 - Validation Accuracy : 0.5021\n",
      "Epoch(19) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 3 - Validation Loss : 0.6935\n",
      "Epoch(19) - Fold 3 - Validation Accuracy : 0.5027\n",
      "Epoch(19) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 4 - Validation Loss : 0.6935\n",
      "Epoch(19) - Fold 4 - Validation Accuracy : 0.5012\n",
      "Epoch(19) - Fold 4 - Validation Utility score : 56.3176\n",
      "Epoch(19) - GLOBAL - Validation Loss: 0.6932\n",
      "Epoch(19) - GLOBAL - Validation Accuracy: 0.5035\n",
      "Epoch(19) - GLOBAL - Validation Utility score: 56.3176\n",
      "Saving model corresponding to last_utility_score == 56.31763336173532\n",
      "\n",
      "\n",
      "Epoch(20) - Training Loss: 0.6935\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(20) - Fold 0 - Validation Loss : 0.6931\n",
      "Epoch(20) - Fold 0 - Validation Accuracy : 0.5032\n",
      "Epoch(20) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(20) - Fold 1 - Validation Accuracy : 0.5087\n",
      "Epoch(20) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(20) - Fold 2 - Validation Accuracy : 0.5017\n",
      "Epoch(20) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 3 - Validation Loss : 0.6935\n",
      "Epoch(20) - Fold 3 - Validation Accuracy : 0.5030\n",
      "Epoch(20) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 4 - Validation Loss : 0.6934\n",
      "Epoch(20) - Fold 4 - Validation Accuracy : 0.5016\n",
      "Epoch(20) - Fold 4 - Validation Utility score : 66.9436\n",
      "Epoch(20) - GLOBAL - Validation Loss: 0.6932\n",
      "Epoch(20) - GLOBAL - Validation Accuracy: 0.5036\n",
      "Epoch(20) - GLOBAL - Validation Utility score: 66.9436\n",
      "Saving model corresponding to last_utility_score == 66.94356177365451\n",
      "\n",
      "\n",
      "Epoch(21) - Training Loss: 0.6934\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(21) - Fold 0 - Validation Loss : 0.6931\n",
      "Epoch(21) - Fold 0 - Validation Accuracy : 0.5033\n",
      "Epoch(21) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(21) - Fold 1 - Validation Accuracy : 0.5087\n",
      "Epoch(21) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(21) - Fold 2 - Validation Accuracy : 0.5019\n",
      "Epoch(21) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 3 - Validation Loss : 0.6935\n",
      "Epoch(21) - Fold 3 - Validation Accuracy : 0.5031\n",
      "Epoch(21) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 4 - Validation Loss : 0.6934\n",
      "Epoch(21) - Fold 4 - Validation Accuracy : 0.5017\n",
      "Epoch(21) - Fold 4 - Validation Utility score : 78.4750\n",
      "Epoch(21) - GLOBAL - Validation Loss: 0.6932\n",
      "Epoch(21) - GLOBAL - Validation Accuracy: 0.5037\n",
      "Epoch(21) - GLOBAL - Validation Utility score: 78.4750\n",
      "Saving model corresponding to last_utility_score == 78.4750168345745\n",
      "\n",
      "\n",
      "Epoch(22) - Training Loss: 0.6934\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(22) - Fold 0 - Validation Loss : 0.6930\n",
      "Epoch(22) - Fold 0 - Validation Accuracy : 0.5053\n",
      "Epoch(22) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 1 - Validation Loss : 0.6926\n",
      "Epoch(22) - Fold 1 - Validation Accuracy : 0.5100\n",
      "Epoch(22) - Fold 1 - Validation Utility score : 1.2798\n",
      "Epoch(22) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(22) - Fold 2 - Validation Accuracy : 0.5026\n",
      "Epoch(22) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(22) - Fold 3 - Validation Accuracy : 0.5040\n",
      "Epoch(22) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 4 - Validation Loss : 0.6933\n",
      "Epoch(22) - Fold 4 - Validation Accuracy : 0.5022\n",
      "Epoch(22) - Fold 4 - Validation Utility score : 99.1739\n",
      "Epoch(22) - GLOBAL - Validation Loss: 0.6931\n",
      "Epoch(22) - GLOBAL - Validation Accuracy: 0.5048\n",
      "Epoch(22) - GLOBAL - Validation Utility score: 100.4537\n",
      "Saving model corresponding to last_utility_score == 100.4536631672143\n",
      "\n",
      "\n",
      "Epoch(23) - Training Loss: 0.6934\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(23) - Fold 0 - Validation Loss : 0.6929\n",
      "Epoch(23) - Fold 0 - Validation Accuracy : 0.5064\n",
      "Epoch(23) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(23) - Fold 1 - Validation Accuracy : 0.5111\n",
      "Epoch(23) - Fold 1 - Validation Utility score : 5.2448\n",
      "Epoch(23) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(23) - Fold 2 - Validation Accuracy : 0.5028\n",
      "Epoch(23) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(23) - Fold 3 - Validation Accuracy : 0.5041\n",
      "Epoch(23) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 4 - Validation Loss : 0.6933\n",
      "Epoch(23) - Fold 4 - Validation Accuracy : 0.5027\n",
      "Epoch(23) - Fold 4 - Validation Utility score : 151.1165\n",
      "Epoch(23) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(23) - GLOBAL - Validation Accuracy: 0.5054\n",
      "Epoch(23) - GLOBAL - Validation Utility score: 156.3612\n",
      "Saving model corresponding to last_utility_score == 156.3612399231377\n",
      "\n",
      "\n",
      "Epoch(24) - Training Loss: 0.6934\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(24) - Fold 0 - Validation Loss : 0.6929\n",
      "Epoch(24) - Fold 0 - Validation Accuracy : 0.5063\n",
      "Epoch(24) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(24) - Fold 1 - Validation Accuracy : 0.5113\n",
      "Epoch(24) - Fold 1 - Validation Utility score : 10.8070\n",
      "Epoch(24) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(24) - Fold 2 - Validation Accuracy : 0.5027\n",
      "Epoch(24) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(24) - Fold 3 - Validation Accuracy : 0.5041\n",
      "Epoch(24) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 4 - Validation Loss : 0.6933\n",
      "Epoch(24) - Fold 4 - Validation Accuracy : 0.5026\n",
      "Epoch(24) - Fold 4 - Validation Utility score : 159.7622\n",
      "Epoch(24) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(24) - GLOBAL - Validation Accuracy: 0.5054\n",
      "Epoch(24) - GLOBAL - Validation Utility score: 170.5692\n",
      "Saving model corresponding to last_utility_score == 170.56919252559229\n",
      "\n",
      "\n",
      "Epoch(25) - Training Loss: 0.6933\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(25) - Fold 0 - Validation Loss : 0.6928\n",
      "Epoch(25) - Fold 0 - Validation Accuracy : 0.5073\n",
      "Epoch(25) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(25) - Fold 1 - Validation Accuracy : 0.5119\n",
      "Epoch(25) - Fold 1 - Validation Utility score : 15.1509\n",
      "Epoch(25) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(25) - Fold 2 - Validation Accuracy : 0.5028\n",
      "Epoch(25) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(25) - Fold 3 - Validation Accuracy : 0.5046\n",
      "Epoch(25) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 4 - Validation Loss : 0.6932\n",
      "Epoch(25) - Fold 4 - Validation Accuracy : 0.5030\n",
      "Epoch(25) - Fold 4 - Validation Utility score : 186.2560\n",
      "Epoch(25) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(25) - GLOBAL - Validation Accuracy: 0.5059\n",
      "Epoch(25) - GLOBAL - Validation Utility score: 201.4069\n",
      "Saving model corresponding to last_utility_score == 201.40687114310387\n",
      "\n",
      "\n",
      "Epoch(26) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(26) - Fold 0 - Validation Loss : 0.6928\n",
      "Epoch(26) - Fold 0 - Validation Accuracy : 0.5085\n",
      "Epoch(26) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(26) - Fold 1 - Validation Accuracy : 0.5123\n",
      "Epoch(26) - Fold 1 - Validation Utility score : 34.8291\n",
      "Epoch(26) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(26) - Fold 2 - Validation Accuracy : 0.5030\n",
      "Epoch(26) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(26) - Fold 3 - Validation Accuracy : 0.5046\n",
      "Epoch(26) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 4 - Validation Loss : 0.6932\n",
      "Epoch(26) - Fold 4 - Validation Accuracy : 0.5037\n",
      "Epoch(26) - Fold 4 - Validation Utility score : 212.9577\n",
      "Epoch(26) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(26) - GLOBAL - Validation Accuracy: 0.5064\n",
      "Epoch(26) - GLOBAL - Validation Utility score: 247.7868\n",
      "Saving model corresponding to last_utility_score == 247.7867726782655\n",
      "\n",
      "\n",
      "Epoch(27) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(27) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(27) - Fold 0 - Validation Accuracy : 0.5100\n",
      "Epoch(27) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(27) - Fold 1 - Validation Accuracy : 0.5146\n",
      "Epoch(27) - Fold 1 - Validation Utility score : 90.1996\n",
      "Epoch(27) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(27) - Fold 2 - Validation Accuracy : 0.5037\n",
      "Epoch(27) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(27) - Fold 3 - Validation Accuracy : 0.5051\n",
      "Epoch(27) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 4 - Validation Loss : 0.6931\n",
      "Epoch(27) - Fold 4 - Validation Accuracy : 0.5044\n",
      "Epoch(27) - Fold 4 - Validation Utility score : 302.8309\n",
      "Epoch(27) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(27) - GLOBAL - Validation Accuracy: 0.5076\n",
      "Epoch(27) - GLOBAL - Validation Utility score: 393.0305\n",
      "Saving model corresponding to last_utility_score == 393.03051851472287\n",
      "\n",
      "\n",
      "Epoch(28) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(28) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(28) - Fold 0 - Validation Accuracy : 0.5147\n",
      "Epoch(28) - Fold 0 - Validation Utility score : 11.6091\n",
      "Epoch(28) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(28) - Fold 1 - Validation Accuracy : 0.5183\n",
      "Epoch(28) - Fold 1 - Validation Utility score : 309.6473\n",
      "Epoch(28) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(28) - Fold 2 - Validation Accuracy : 0.5055\n",
      "Epoch(28) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(28) - Fold 3 - Validation Accuracy : 0.5077\n",
      "Epoch(28) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 4 - Validation Loss : 0.6930\n",
      "Epoch(28) - Fold 4 - Validation Accuracy : 0.5068\n",
      "Epoch(28) - Fold 4 - Validation Utility score : 554.3327\n",
      "Epoch(28) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(28) - GLOBAL - Validation Accuracy: 0.5106\n",
      "Epoch(28) - GLOBAL - Validation Utility score: 875.5892\n",
      "Saving model corresponding to last_utility_score == 875.5891839790206\n",
      "\n",
      "\n",
      "Epoch(29) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(29) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(29) - Fold 0 - Validation Accuracy : 0.5106\n",
      "Epoch(29) - Fold 0 - Validation Utility score : 0.2709\n",
      "Epoch(29) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(29) - Fold 1 - Validation Accuracy : 0.5144\n",
      "Epoch(29) - Fold 1 - Validation Utility score : 102.0988\n",
      "Epoch(29) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(29) - Fold 2 - Validation Accuracy : 0.5040\n",
      "Epoch(29) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(29) - Fold 3 - Validation Accuracy : 0.5051\n",
      "Epoch(29) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 4 - Validation Loss : 0.6931\n",
      "Epoch(29) - Fold 4 - Validation Accuracy : 0.5049\n",
      "Epoch(29) - Fold 4 - Validation Utility score : 373.6956\n",
      "Epoch(29) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(29) - GLOBAL - Validation Accuracy: 0.5078\n",
      "Epoch(29) - GLOBAL - Validation Utility score: 476.0653\n",
      "Intermediate early stopping : vepoch_loss = 0.6929, the_last_loss=0.6928\n",
      "\n",
      "\n",
      "Epoch(30) - Training Loss: 0.6931\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(30) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(30) - Fold 0 - Validation Accuracy : 0.5123\n",
      "Epoch(30) - Fold 0 - Validation Utility score : 3.6226\n",
      "Epoch(30) - Fold 1 - Validation Loss : 0.6923\n",
      "Epoch(30) - Fold 1 - Validation Accuracy : 0.5153\n",
      "Epoch(30) - Fold 1 - Validation Utility score : 125.6886\n",
      "Epoch(30) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(30) - Fold 2 - Validation Accuracy : 0.5047\n",
      "Epoch(30) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(30) - Fold 3 - Validation Accuracy : 0.5073\n",
      "Epoch(30) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 4 - Validation Loss : 0.6930\n",
      "Epoch(30) - Fold 4 - Validation Accuracy : 0.5060\n",
      "Epoch(30) - Fold 4 - Validation Utility score : 474.4149\n",
      "Epoch(30) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(30) - GLOBAL - Validation Accuracy: 0.5091\n",
      "Epoch(30) - GLOBAL - Validation Utility score: 603.7262\n",
      "Intermediate early stopping : vepoch_loss = 0.6928, the_last_loss=0.6928\n",
      "\n",
      "\n",
      "Epoch(31) - Training Loss: 0.6931\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(31) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(31) - Fold 0 - Validation Accuracy : 0.5139\n",
      "Epoch(31) - Fold 0 - Validation Utility score : 16.8250\n",
      "Epoch(31) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(31) - Fold 1 - Validation Accuracy : 0.5175\n",
      "Epoch(31) - Fold 1 - Validation Utility score : 214.7111\n",
      "Epoch(31) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(31) - Fold 2 - Validation Accuracy : 0.5055\n",
      "Epoch(31) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(31) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(31) - Fold 3 - Validation Accuracy : 0.5077\n",
      "Epoch(31) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(31) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(31) - Fold 4 - Validation Accuracy : 0.5064\n",
      "Epoch(31) - Fold 4 - Validation Utility score : 574.8539\n",
      "Epoch(31) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(31) - GLOBAL - Validation Accuracy: 0.5102\n",
      "Epoch(31) - GLOBAL - Validation Utility score: 806.3900\n",
      "Saving model corresponding to last_utility_score == 806.3900304858457\n",
      "\n",
      "\n",
      "Epoch(32) - Training Loss: 0.6931\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(32) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(32) - Fold 0 - Validation Accuracy : 0.5130\n",
      "Epoch(32) - Fold 0 - Validation Utility score : 3.5942\n",
      "Epoch(32) - Fold 1 - Validation Loss : 0.6923\n",
      "Epoch(32) - Fold 1 - Validation Accuracy : 0.5161\n",
      "Epoch(32) - Fold 1 - Validation Utility score : 177.9109\n",
      "Epoch(32) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(32) - Fold 2 - Validation Accuracy : 0.5055\n",
      "Epoch(32) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(32) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(32) - Fold 3 - Validation Accuracy : 0.5077\n",
      "Epoch(32) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(32) - Fold 4 - Validation Loss : 0.6930\n",
      "Epoch(32) - Fold 4 - Validation Accuracy : 0.5064\n",
      "Epoch(32) - Fold 4 - Validation Utility score : 512.2859\n",
      "Epoch(32) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(32) - GLOBAL - Validation Accuracy: 0.5097\n",
      "Epoch(32) - GLOBAL - Validation Utility score: 693.7910\n",
      "Intermediate early stopping : vepoch_loss = 0.6928, the_last_loss=0.6928\n",
      "\n",
      "\n",
      "Epoch(33) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(33) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(33) - Fold 0 - Validation Accuracy : 0.5134\n",
      "Epoch(33) - Fold 0 - Validation Utility score : 6.6121\n",
      "Epoch(33) - Fold 1 - Validation Loss : 0.6923\n",
      "Epoch(33) - Fold 1 - Validation Accuracy : 0.5173\n",
      "Epoch(33) - Fold 1 - Validation Utility score : 177.3876\n",
      "Epoch(33) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(33) - Fold 2 - Validation Accuracy : 0.5058\n",
      "Epoch(33) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(33) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(33) - Fold 3 - Validation Accuracy : 0.5076\n",
      "Epoch(33) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(33) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(33) - Fold 4 - Validation Accuracy : 0.5067\n",
      "Epoch(33) - Fold 4 - Validation Utility score : 576.5417\n",
      "Epoch(33) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(33) - GLOBAL - Validation Accuracy: 0.5101\n",
      "Epoch(33) - GLOBAL - Validation Utility score: 760.5414\n",
      "Intermediate early stopping : vepoch_loss = 0.6928, the_last_loss=0.6928\n",
      "\n",
      "\n",
      "Epoch(34) - Training Loss: 0.6931\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(34) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(34) - Fold 0 - Validation Accuracy : 0.5143\n",
      "Epoch(34) - Fold 0 - Validation Utility score : 6.4036\n",
      "Epoch(34) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(34) - Fold 1 - Validation Accuracy : 0.5178\n",
      "Epoch(34) - Fold 1 - Validation Utility score : 240.1588\n",
      "Epoch(34) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(34) - Fold 2 - Validation Accuracy : 0.5061\n",
      "Epoch(34) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(34) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(34) - Fold 3 - Validation Accuracy : 0.5077\n",
      "Epoch(34) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(34) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(34) - Fold 4 - Validation Accuracy : 0.5069\n",
      "Epoch(34) - Fold 4 - Validation Utility score : 598.0381\n",
      "Epoch(34) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(34) - GLOBAL - Validation Accuracy: 0.5106\n",
      "Epoch(34) - GLOBAL - Validation Utility score: 844.6005\n",
      "Saving model corresponding to last_utility_score == 844.6005170889684\n",
      "\n",
      "\n",
      "Epoch(35) - Training Loss: 0.6931\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(35) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(35) - Fold 0 - Validation Accuracy : 0.5140\n",
      "Epoch(35) - Fold 0 - Validation Utility score : 9.0029\n",
      "Epoch(35) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(35) - Fold 1 - Validation Accuracy : 0.5172\n",
      "Epoch(35) - Fold 1 - Validation Utility score : 211.4566\n",
      "Epoch(35) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(35) - Fold 2 - Validation Accuracy : 0.5060\n",
      "Epoch(35) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(35) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(35) - Fold 3 - Validation Accuracy : 0.5078\n",
      "Epoch(35) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(35) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(35) - Fold 4 - Validation Accuracy : 0.5068\n",
      "Epoch(35) - Fold 4 - Validation Utility score : 573.1820\n",
      "Epoch(35) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(35) - GLOBAL - Validation Accuracy: 0.5104\n",
      "Epoch(35) - GLOBAL - Validation Utility score: 793.6415\n",
      "Intermediate early stopping : vepoch_loss = 0.6928, the_last_loss=0.6928\n",
      "\n",
      "\n",
      "Epoch(36) - Training Loss: 0.6930\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(36) - Fold 0 - Validation Loss : 0.6924\n",
      "Epoch(36) - Fold 0 - Validation Accuracy : 0.5153\n",
      "Epoch(36) - Fold 0 - Validation Utility score : 38.2493\n",
      "Epoch(36) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(36) - Fold 1 - Validation Accuracy : 0.5201\n",
      "Epoch(36) - Fold 1 - Validation Utility score : 278.8715\n",
      "Epoch(36) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(36) - Fold 2 - Validation Accuracy : 0.5076\n",
      "Epoch(36) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(36) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(36) - Fold 3 - Validation Accuracy : 0.5083\n",
      "Epoch(36) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(36) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(36) - Fold 4 - Validation Accuracy : 0.5078\n",
      "Epoch(36) - Fold 4 - Validation Utility score : 702.6063\n",
      "Epoch(36) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(36) - GLOBAL - Validation Accuracy: 0.5118\n",
      "Epoch(36) - GLOBAL - Validation Utility score: 1019.7271\n",
      "Saving model corresponding to last_utility_score == 1019.7271270876654\n",
      "\n",
      "\n",
      "Epoch(37) - Training Loss: 0.6930\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(37) - Fold 0 - Validation Loss : 0.6924\n",
      "Epoch(37) - Fold 0 - Validation Accuracy : 0.5167\n",
      "Epoch(37) - Fold 0 - Validation Utility score : 76.6282\n",
      "Epoch(37) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(37) - Fold 1 - Validation Accuracy : 0.5216\n",
      "Epoch(37) - Fold 1 - Validation Utility score : 327.3556\n",
      "Epoch(37) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(37) - Fold 2 - Validation Accuracy : 0.5076\n",
      "Epoch(37) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(37) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(37) - Fold 3 - Validation Accuracy : 0.5080\n",
      "Epoch(37) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(37) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(37) - Fold 4 - Validation Accuracy : 0.5085\n",
      "Epoch(37) - Fold 4 - Validation Utility score : 719.6140\n",
      "Epoch(37) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(37) - GLOBAL - Validation Accuracy: 0.5125\n",
      "Epoch(37) - GLOBAL - Validation Utility score: 1123.5979\n",
      "Saving model corresponding to last_utility_score == 1123.5978755645524\n",
      "\n",
      "\n",
      "Epoch(38) - Training Loss: 0.6930\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(38) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(38) - Fold 0 - Validation Accuracy : 0.5134\n",
      "Epoch(38) - Fold 0 - Validation Utility score : 2.8353\n",
      "Epoch(38) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(38) - Fold 1 - Validation Accuracy : 0.5174\n",
      "Epoch(38) - Fold 1 - Validation Utility score : 214.1872\n",
      "Epoch(38) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(38) - Fold 2 - Validation Accuracy : 0.5069\n",
      "Epoch(38) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(38) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(38) - Fold 3 - Validation Accuracy : 0.5081\n",
      "Epoch(38) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(38) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(38) - Fold 4 - Validation Accuracy : 0.5067\n",
      "Epoch(38) - Fold 4 - Validation Utility score : 561.5494\n",
      "Epoch(38) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(38) - GLOBAL - Validation Accuracy: 0.5105\n",
      "Epoch(38) - GLOBAL - Validation Utility score: 778.5719\n",
      "Intermediate early stopping : vepoch_loss = 0.6927, the_last_loss=0.6927\n",
      "\n",
      "\n",
      "Epoch(39) - Training Loss: 0.6929\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(39) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(39) - Fold 0 - Validation Accuracy : 0.5139\n",
      "Epoch(39) - Fold 0 - Validation Utility score : 4.8815\n",
      "Epoch(39) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(39) - Fold 1 - Validation Accuracy : 0.5184\n",
      "Epoch(39) - Fold 1 - Validation Utility score : 275.7537\n",
      "Epoch(39) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(39) - Fold 2 - Validation Accuracy : 0.5078\n",
      "Epoch(39) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(39) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(39) - Fold 3 - Validation Accuracy : 0.5087\n",
      "Epoch(39) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(39) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(39) - Fold 4 - Validation Accuracy : 0.5076\n",
      "Epoch(39) - Fold 4 - Validation Utility score : 580.2239\n",
      "Epoch(39) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(39) - GLOBAL - Validation Accuracy: 0.5113\n",
      "Epoch(39) - GLOBAL - Validation Utility score: 860.8591\n",
      "Intermediate early stopping : vepoch_loss = 0.6927, the_last_loss=0.6927\n",
      "\n",
      "\n",
      "Epoch(40) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(40) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(40) - Fold 0 - Validation Accuracy : 0.5141\n",
      "Epoch(40) - Fold 0 - Validation Utility score : 13.3977\n",
      "Epoch(40) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(40) - Fold 1 - Validation Accuracy : 0.5185\n",
      "Epoch(40) - Fold 1 - Validation Utility score : 264.8645\n",
      "Epoch(40) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(40) - Fold 2 - Validation Accuracy : 0.5077\n",
      "Epoch(40) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(40) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(40) - Fold 3 - Validation Accuracy : 0.5081\n",
      "Epoch(40) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(40) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(40) - Fold 4 - Validation Accuracy : 0.5075\n",
      "Epoch(40) - Fold 4 - Validation Utility score : 587.4152\n",
      "Epoch(40) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(40) - GLOBAL - Validation Accuracy: 0.5112\n",
      "Epoch(40) - GLOBAL - Validation Utility score: 865.6774\n",
      "Intermediate early stopping : vepoch_loss = 0.6927, the_last_loss=0.6927\n",
      "\n",
      "\n",
      "Epoch(41) - Training Loss: 0.6929\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(41) - Fold 0 - Validation Loss : 0.6924\n",
      "Epoch(41) - Fold 0 - Validation Accuracy : 0.5158\n",
      "Epoch(41) - Fold 0 - Validation Utility score : 23.9213\n",
      "Epoch(41) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(41) - Fold 1 - Validation Accuracy : 0.5203\n",
      "Epoch(41) - Fold 1 - Validation Utility score : 316.1598\n",
      "Epoch(41) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(41) - Fold 2 - Validation Accuracy : 0.5075\n",
      "Epoch(41) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(41) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(41) - Fold 3 - Validation Accuracy : 0.5079\n",
      "Epoch(41) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(41) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(41) - Fold 4 - Validation Accuracy : 0.5083\n",
      "Epoch(41) - Fold 4 - Validation Utility score : 610.2580\n",
      "Epoch(41) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(41) - GLOBAL - Validation Accuracy: 0.5119\n",
      "Epoch(41) - GLOBAL - Validation Utility score: 950.3392\n",
      "Saving model corresponding to last_utility_score == 950.3391540809588\n",
      "\n",
      "\n",
      "Epoch(42) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(42) - Fold 0 - Validation Loss : 0.6924\n",
      "Epoch(42) - Fold 0 - Validation Accuracy : 0.5163\n",
      "Epoch(42) - Fold 0 - Validation Utility score : 26.6608\n",
      "Epoch(42) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(42) - Fold 1 - Validation Accuracy : 0.5212\n",
      "Epoch(42) - Fold 1 - Validation Utility score : 305.1523\n",
      "Epoch(42) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(42) - Fold 2 - Validation Accuracy : 0.5080\n",
      "Epoch(42) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(42) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(42) - Fold 3 - Validation Accuracy : 0.5076\n",
      "Epoch(42) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(42) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(42) - Fold 4 - Validation Accuracy : 0.5087\n",
      "Epoch(42) - Fold 4 - Validation Utility score : 654.9887\n",
      "Epoch(42) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(42) - GLOBAL - Validation Accuracy: 0.5124\n",
      "Epoch(42) - GLOBAL - Validation Utility score: 986.8018\n",
      "Saving model corresponding to last_utility_score == 986.801800042449\n",
      "\n",
      "\n",
      "Epoch(43) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(43) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(43) - Fold 0 - Validation Accuracy : 0.5144\n",
      "Epoch(43) - Fold 0 - Validation Utility score : 9.7623\n",
      "Epoch(43) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(43) - Fold 1 - Validation Accuracy : 0.5185\n",
      "Epoch(43) - Fold 1 - Validation Utility score : 213.3791\n",
      "Epoch(43) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(43) - Fold 2 - Validation Accuracy : 0.5072\n",
      "Epoch(43) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(43) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(43) - Fold 3 - Validation Accuracy : 0.5073\n",
      "Epoch(43) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(43) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(43) - Fold 4 - Validation Accuracy : 0.5072\n",
      "Epoch(43) - Fold 4 - Validation Utility score : 536.6806\n",
      "Epoch(43) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(43) - GLOBAL - Validation Accuracy: 0.5109\n",
      "Epoch(43) - GLOBAL - Validation Utility score: 759.8220\n",
      "Intermediate early stopping : vepoch_loss = 0.6927, the_last_loss=0.6926\n",
      "\n",
      "\n",
      "Epoch(44) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(44) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(44) - Fold 0 - Validation Accuracy : 0.5194\n",
      "Epoch(44) - Fold 0 - Validation Utility score : 175.1133\n",
      "Epoch(44) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(44) - Fold 1 - Validation Accuracy : 0.5237\n",
      "Epoch(44) - Fold 1 - Validation Utility score : 443.1652\n",
      "Epoch(44) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(44) - Fold 2 - Validation Accuracy : 0.5082\n",
      "Epoch(44) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(44) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(44) - Fold 3 - Validation Accuracy : 0.5077\n",
      "Epoch(44) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(44) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(44) - Fold 4 - Validation Accuracy : 0.5110\n",
      "Epoch(44) - Fold 4 - Validation Utility score : 933.3586\n",
      "Epoch(44) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(44) - GLOBAL - Validation Accuracy: 0.5140\n",
      "Epoch(44) - GLOBAL - Validation Utility score: 1551.6370\n",
      "Saving model corresponding to last_utility_score == 1551.6370275531376\n",
      "\n",
      "\n",
      "Epoch(45) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(45) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(45) - Fold 0 - Validation Accuracy : 0.5165\n",
      "Epoch(45) - Fold 0 - Validation Utility score : 38.9404\n",
      "Epoch(45) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(45) - Fold 1 - Validation Accuracy : 0.5215\n",
      "Epoch(45) - Fold 1 - Validation Utility score : 356.4326\n",
      "Epoch(45) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(45) - Fold 2 - Validation Accuracy : 0.5081\n",
      "Epoch(45) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(45) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(45) - Fold 3 - Validation Accuracy : 0.5080\n",
      "Epoch(45) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(45) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(45) - Fold 4 - Validation Accuracy : 0.5090\n",
      "Epoch(45) - Fold 4 - Validation Utility score : 674.6190\n",
      "Epoch(45) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(45) - GLOBAL - Validation Accuracy: 0.5126\n",
      "Epoch(45) - GLOBAL - Validation Utility score: 1069.9920\n",
      "Intermediate early stopping : vepoch_loss = 0.6926, the_last_loss=0.6925\n",
      "\n",
      "\n",
      "Epoch(46) - Training Loss: 0.6927\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(46) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(46) - Fold 0 - Validation Accuracy : 0.5164\n",
      "Epoch(46) - Fold 0 - Validation Utility score : 30.7424\n",
      "Epoch(46) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(46) - Fold 1 - Validation Accuracy : 0.5210\n",
      "Epoch(46) - Fold 1 - Validation Utility score : 342.9968\n",
      "Epoch(46) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(46) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(46) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(46) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(46) - Fold 3 - Validation Accuracy : 0.5076\n",
      "Epoch(46) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(46) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(46) - Fold 4 - Validation Accuracy : 0.5090\n",
      "Epoch(46) - Fold 4 - Validation Utility score : 631.9959\n",
      "Epoch(46) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(46) - GLOBAL - Validation Accuracy: 0.5125\n",
      "Epoch(46) - GLOBAL - Validation Utility score: 1005.7351\n",
      "Intermediate early stopping : vepoch_loss = 0.6926, the_last_loss=0.6925\n",
      "\n",
      "\n",
      "Epoch(47) - Training Loss: 0.6927\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(47) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(47) - Fold 0 - Validation Accuracy : 0.5186\n",
      "Epoch(47) - Fold 0 - Validation Utility score : 102.6183\n",
      "Epoch(47) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(47) - Fold 1 - Validation Accuracy : 0.5228\n",
      "Epoch(47) - Fold 1 - Validation Utility score : 474.8066\n",
      "Epoch(47) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(47) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(47) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(47) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(47) - Fold 3 - Validation Accuracy : 0.5069\n",
      "Epoch(47) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(47) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(47) - Fold 4 - Validation Accuracy : 0.5104\n",
      "Epoch(47) - Fold 4 - Validation Utility score : 809.9463\n",
      "Epoch(47) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(47) - GLOBAL - Validation Accuracy: 0.5135\n",
      "Epoch(47) - GLOBAL - Validation Utility score: 1387.3713\n",
      "Saving model corresponding to last_utility_score == 1387.371255039067\n",
      "\n",
      "\n",
      "Epoch(48) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(48) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(48) - Fold 0 - Validation Accuracy : 0.5195\n",
      "Epoch(48) - Fold 0 - Validation Utility score : 204.8050\n",
      "Epoch(48) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(48) - Fold 1 - Validation Accuracy : 0.5229\n",
      "Epoch(48) - Fold 1 - Validation Utility score : 467.7258\n",
      "Epoch(48) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(48) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(48) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(48) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(48) - Fold 3 - Validation Accuracy : 0.5074\n",
      "Epoch(48) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(48) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(48) - Fold 4 - Validation Accuracy : 0.5120\n",
      "Epoch(48) - Fold 4 - Validation Utility score : 873.3492\n",
      "Epoch(48) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(48) - GLOBAL - Validation Accuracy: 0.5141\n",
      "Epoch(48) - GLOBAL - Validation Utility score: 1545.8800\n",
      "Saving model corresponding to last_utility_score == 1545.879987515295\n",
      "\n",
      "\n",
      "Epoch(49) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(49) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(49) - Fold 0 - Validation Accuracy : 0.5192\n",
      "Epoch(49) - Fold 0 - Validation Utility score : 183.7479\n",
      "Epoch(49) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(49) - Fold 1 - Validation Accuracy : 0.5230\n",
      "Epoch(49) - Fold 1 - Validation Utility score : 451.6066\n",
      "Epoch(49) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(49) - Fold 2 - Validation Accuracy : 0.5094\n",
      "Epoch(49) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(49) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(49) - Fold 3 - Validation Accuracy : 0.5072\n",
      "Epoch(49) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(49) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(49) - Fold 4 - Validation Accuracy : 0.5121\n",
      "Epoch(49) - Fold 4 - Validation Utility score : 1031.6475\n",
      "Epoch(49) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(49) - GLOBAL - Validation Accuracy: 0.5142\n",
      "Epoch(49) - GLOBAL - Validation Utility score: 1667.0020\n",
      "Saving model corresponding to last_utility_score == 1667.0019967090984\n",
      "\n",
      "\n",
      "Epoch(50) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(50) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(50) - Fold 0 - Validation Accuracy : 0.5195\n",
      "Epoch(50) - Fold 0 - Validation Utility score : 148.3780\n",
      "Epoch(50) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(50) - Fold 1 - Validation Accuracy : 0.5227\n",
      "Epoch(50) - Fold 1 - Validation Utility score : 466.6914\n",
      "Epoch(50) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(50) - Fold 2 - Validation Accuracy : 0.5088\n",
      "Epoch(50) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(50) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(50) - Fold 3 - Validation Accuracy : 0.5072\n",
      "Epoch(50) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(50) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(50) - Fold 4 - Validation Accuracy : 0.5115\n",
      "Epoch(50) - Fold 4 - Validation Utility score : 904.1980\n",
      "Epoch(50) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(50) - GLOBAL - Validation Accuracy: 0.5139\n",
      "Epoch(50) - GLOBAL - Validation Utility score: 1519.2675\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6924\n",
      "\n",
      "\n",
      "Epoch(51) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(51) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(51) - Fold 0 - Validation Accuracy : 0.5204\n",
      "Epoch(51) - Fold 0 - Validation Utility score : 249.5473\n",
      "Epoch(51) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(51) - Fold 1 - Validation Accuracy : 0.5233\n",
      "Epoch(51) - Fold 1 - Validation Utility score : 500.9849\n",
      "Epoch(51) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(51) - Fold 2 - Validation Accuracy : 0.5093\n",
      "Epoch(51) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(51) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(51) - Fold 3 - Validation Accuracy : 0.5069\n",
      "Epoch(51) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(51) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(51) - Fold 4 - Validation Accuracy : 0.5125\n",
      "Epoch(51) - Fold 4 - Validation Utility score : 907.6841\n",
      "Epoch(51) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(51) - GLOBAL - Validation Accuracy: 0.5145\n",
      "Epoch(51) - GLOBAL - Validation Utility score: 1658.2162\n",
      "Saving model corresponding to last_utility_score == 1658.216204342737\n",
      "\n",
      "\n",
      "Epoch(52) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(52) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(52) - Fold 0 - Validation Accuracy : 0.5192\n",
      "Epoch(52) - Fold 0 - Validation Utility score : 122.6788\n",
      "Epoch(52) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(52) - Fold 1 - Validation Accuracy : 0.5225\n",
      "Epoch(52) - Fold 1 - Validation Utility score : 446.1460\n",
      "Epoch(52) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(52) - Fold 2 - Validation Accuracy : 0.5089\n",
      "Epoch(52) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(52) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(52) - Fold 3 - Validation Accuracy : 0.5076\n",
      "Epoch(52) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(52) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(52) - Fold 4 - Validation Accuracy : 0.5115\n",
      "Epoch(52) - Fold 4 - Validation Utility score : 816.3224\n",
      "Epoch(52) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(52) - GLOBAL - Validation Accuracy: 0.5139\n",
      "Epoch(52) - GLOBAL - Validation Utility score: 1385.1471\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6923\n",
      "\n",
      "\n",
      "Epoch(53) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(53) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(53) - Fold 0 - Validation Accuracy : 0.5188\n",
      "Epoch(53) - Fold 0 - Validation Utility score : 87.2199\n",
      "Epoch(53) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(53) - Fold 1 - Validation Accuracy : 0.5212\n",
      "Epoch(53) - Fold 1 - Validation Utility score : 350.2008\n",
      "Epoch(53) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(53) - Fold 2 - Validation Accuracy : 0.5091\n",
      "Epoch(53) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(53) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(53) - Fold 3 - Validation Accuracy : 0.5073\n",
      "Epoch(53) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(53) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(53) - Fold 4 - Validation Accuracy : 0.5102\n",
      "Epoch(53) - Fold 4 - Validation Utility score : 675.8136\n",
      "Epoch(53) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(53) - GLOBAL - Validation Accuracy: 0.5133\n",
      "Epoch(53) - GLOBAL - Validation Utility score: 1113.2343\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6923\n",
      "\n",
      "\n",
      "Epoch(54) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(54) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(54) - Fold 0 - Validation Accuracy : 0.5201\n",
      "Epoch(54) - Fold 0 - Validation Utility score : 211.5206\n",
      "Epoch(54) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(54) - Fold 1 - Validation Accuracy : 0.5228\n",
      "Epoch(54) - Fold 1 - Validation Utility score : 460.6892\n",
      "Epoch(54) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(54) - Fold 2 - Validation Accuracy : 0.5097\n",
      "Epoch(54) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(54) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(54) - Fold 3 - Validation Accuracy : 0.5076\n",
      "Epoch(54) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(54) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(54) - Fold 4 - Validation Accuracy : 0.5118\n",
      "Epoch(54) - Fold 4 - Validation Utility score : 917.3255\n",
      "Epoch(54) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(54) - GLOBAL - Validation Accuracy: 0.5144\n",
      "Epoch(54) - GLOBAL - Validation Utility score: 1589.5354\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6923\n",
      "\n",
      "\n",
      "Epoch(55) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(55) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(55) - Fold 0 - Validation Accuracy : 0.5197\n",
      "Epoch(55) - Fold 0 - Validation Utility score : 139.1766\n",
      "Epoch(55) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(55) - Fold 1 - Validation Accuracy : 0.5221\n",
      "Epoch(55) - Fold 1 - Validation Utility score : 443.8869\n",
      "Epoch(55) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(55) - Fold 2 - Validation Accuracy : 0.5089\n",
      "Epoch(55) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(55) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(55) - Fold 3 - Validation Accuracy : 0.5074\n",
      "Epoch(55) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(55) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(55) - Fold 4 - Validation Accuracy : 0.5119\n",
      "Epoch(55) - Fold 4 - Validation Utility score : 813.3861\n",
      "Epoch(55) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(55) - GLOBAL - Validation Accuracy: 0.5140\n",
      "Epoch(55) - GLOBAL - Validation Utility score: 1396.4496\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6923\n",
      "\n",
      "\n",
      "Epoch(56) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(56) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(56) - Fold 0 - Validation Accuracy : 0.5207\n",
      "Epoch(56) - Fold 0 - Validation Utility score : 243.7955\n",
      "Epoch(56) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(56) - Fold 1 - Validation Accuracy : 0.5228\n",
      "Epoch(56) - Fold 1 - Validation Utility score : 507.1431\n",
      "Epoch(56) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(56) - Fold 2 - Validation Accuracy : 0.5092\n",
      "Epoch(56) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(56) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(56) - Fold 3 - Validation Accuracy : 0.5071\n",
      "Epoch(56) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(56) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(56) - Fold 4 - Validation Accuracy : 0.5125\n",
      "Epoch(56) - Fold 4 - Validation Utility score : 869.5215\n",
      "Epoch(56) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(56) - GLOBAL - Validation Accuracy: 0.5144\n",
      "Epoch(56) - GLOBAL - Validation Utility score: 1620.4601\n",
      "Saving model corresponding to last_utility_score == 1620.4600625533442\n",
      "\n",
      "\n",
      "Epoch(57) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(57) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(57) - Fold 0 - Validation Accuracy : 0.5217\n",
      "Epoch(57) - Fold 0 - Validation Utility score : 331.6479\n",
      "Epoch(57) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(57) - Fold 1 - Validation Accuracy : 0.5239\n",
      "Epoch(57) - Fold 1 - Validation Utility score : 554.8707\n",
      "Epoch(57) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(57) - Fold 2 - Validation Accuracy : 0.5089\n",
      "Epoch(57) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(57) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(57) - Fold 3 - Validation Accuracy : 0.5072\n",
      "Epoch(57) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(57) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(57) - Fold 4 - Validation Accuracy : 0.5123\n",
      "Epoch(57) - Fold 4 - Validation Utility score : 891.6561\n",
      "Epoch(57) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(57) - GLOBAL - Validation Accuracy: 0.5148\n",
      "Epoch(57) - GLOBAL - Validation Utility score: 1778.1747\n",
      "Saving model corresponding to last_utility_score == 1778.1747347713401\n",
      "\n",
      "\n",
      "Epoch(58) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(58) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(58) - Fold 0 - Validation Accuracy : 0.5205\n",
      "Epoch(58) - Fold 0 - Validation Utility score : 143.5895\n",
      "Epoch(58) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(58) - Fold 1 - Validation Accuracy : 0.5224\n",
      "Epoch(58) - Fold 1 - Validation Utility score : 426.7411\n",
      "Epoch(58) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(58) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(58) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(58) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(58) - Fold 3 - Validation Accuracy : 0.5071\n",
      "Epoch(58) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(58) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(58) - Fold 4 - Validation Accuracy : 0.5113\n",
      "Epoch(58) - Fold 4 - Validation Utility score : 802.2430\n",
      "Epoch(58) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(58) - GLOBAL - Validation Accuracy: 0.5139\n",
      "Epoch(58) - GLOBAL - Validation Utility score: 1372.5736\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6923\n",
      "\n",
      "\n",
      "Epoch(59) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(59) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(59) - Fold 0 - Validation Accuracy : 0.5204\n",
      "Epoch(59) - Fold 0 - Validation Utility score : 157.8451\n",
      "Epoch(59) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(59) - Fold 1 - Validation Accuracy : 0.5224\n",
      "Epoch(59) - Fold 1 - Validation Utility score : 446.2657\n",
      "Epoch(59) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(59) - Fold 2 - Validation Accuracy : 0.5088\n",
      "Epoch(59) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(59) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(59) - Fold 3 - Validation Accuracy : 0.5073\n",
      "Epoch(59) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(59) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(59) - Fold 4 - Validation Accuracy : 0.5119\n",
      "Epoch(59) - Fold 4 - Validation Utility score : 884.8786\n",
      "Epoch(59) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(59) - GLOBAL - Validation Accuracy: 0.5142\n",
      "Epoch(59) - GLOBAL - Validation Utility score: 1488.9894\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6923\n",
      "\n",
      "\n",
      "Epoch(60) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(60) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(60) - Fold 0 - Validation Accuracy : 0.5208\n",
      "Epoch(60) - Fold 0 - Validation Utility score : 149.1885\n",
      "Epoch(60) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(60) - Fold 1 - Validation Accuracy : 0.5229\n",
      "Epoch(60) - Fold 1 - Validation Utility score : 520.7729\n",
      "Epoch(60) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(60) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(60) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(60) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(60) - Fold 3 - Validation Accuracy : 0.5071\n",
      "Epoch(60) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(60) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(60) - Fold 4 - Validation Accuracy : 0.5127\n",
      "Epoch(60) - Fold 4 - Validation Utility score : 903.9204\n",
      "Epoch(60) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(60) - GLOBAL - Validation Accuracy: 0.5144\n",
      "Epoch(60) - GLOBAL - Validation Utility score: 1573.8818\n",
      "Saving model corresponding to last_utility_score == 1573.8818405806817\n",
      "\n",
      "\n",
      "Epoch(61) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(61) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(61) - Fold 0 - Validation Accuracy : 0.5212\n",
      "Epoch(61) - Fold 0 - Validation Utility score : 260.4755\n",
      "Epoch(61) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(61) - Fold 1 - Validation Accuracy : 0.5233\n",
      "Epoch(61) - Fold 1 - Validation Utility score : 500.8722\n",
      "Epoch(61) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(61) - Fold 2 - Validation Accuracy : 0.5090\n",
      "Epoch(61) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(61) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(61) - Fold 3 - Validation Accuracy : 0.5074\n",
      "Epoch(61) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(61) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(61) - Fold 4 - Validation Accuracy : 0.5123\n",
      "Epoch(61) - Fold 4 - Validation Utility score : 830.7320\n",
      "Epoch(61) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(61) - GLOBAL - Validation Accuracy: 0.5146\n",
      "Epoch(61) - GLOBAL - Validation Utility score: 1592.0796\n",
      "Saving model corresponding to last_utility_score == 1592.079647736054\n",
      "\n",
      "\n",
      "Epoch(62) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(62) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(62) - Fold 0 - Validation Accuracy : 0.5209\n",
      "Epoch(62) - Fold 0 - Validation Utility score : 193.4675\n",
      "Epoch(62) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(62) - Fold 1 - Validation Accuracy : 0.5232\n",
      "Epoch(62) - Fold 1 - Validation Utility score : 549.6219\n",
      "Epoch(62) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(62) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(62) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(62) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(62) - Fold 3 - Validation Accuracy : 0.5081\n",
      "Epoch(62) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(62) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(62) - Fold 4 - Validation Accuracy : 0.5121\n",
      "Epoch(62) - Fold 4 - Validation Utility score : 759.2077\n",
      "Epoch(62) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(62) - GLOBAL - Validation Accuracy: 0.5145\n",
      "Epoch(62) - GLOBAL - Validation Utility score: 1502.2971\n",
      "Saving model corresponding to last_utility_score == 1502.2971144659805\n",
      "\n",
      "\n",
      "Epoch(63) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(63) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(63) - Fold 0 - Validation Accuracy : 0.5208\n",
      "Epoch(63) - Fold 0 - Validation Utility score : 181.0722\n",
      "Epoch(63) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(63) - Fold 1 - Validation Accuracy : 0.5238\n",
      "Epoch(63) - Fold 1 - Validation Utility score : 572.2760\n",
      "Epoch(63) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(63) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(63) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(63) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(63) - Fold 3 - Validation Accuracy : 0.5075\n",
      "Epoch(63) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(63) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(63) - Fold 4 - Validation Accuracy : 0.5122\n",
      "Epoch(63) - Fold 4 - Validation Utility score : 843.7777\n",
      "Epoch(63) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(63) - GLOBAL - Validation Accuracy: 0.5146\n",
      "Epoch(63) - GLOBAL - Validation Utility score: 1597.1260\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(64) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(64) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(64) - Fold 0 - Validation Accuracy : 0.5202\n",
      "Epoch(64) - Fold 0 - Validation Utility score : 153.0236\n",
      "Epoch(64) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(64) - Fold 1 - Validation Accuracy : 0.5223\n",
      "Epoch(64) - Fold 1 - Validation Utility score : 472.8755\n",
      "Epoch(64) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(64) - Fold 2 - Validation Accuracy : 0.5085\n",
      "Epoch(64) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(64) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(64) - Fold 3 - Validation Accuracy : 0.5072\n",
      "Epoch(64) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(64) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(64) - Fold 4 - Validation Accuracy : 0.5111\n",
      "Epoch(64) - Fold 4 - Validation Utility score : 839.8838\n",
      "Epoch(64) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(64) - GLOBAL - Validation Accuracy: 0.5139\n",
      "Epoch(64) - GLOBAL - Validation Utility score: 1465.7829\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(65) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(65) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(65) - Fold 0 - Validation Accuracy : 0.5210\n",
      "Epoch(65) - Fold 0 - Validation Utility score : 162.6268\n",
      "Epoch(65) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(65) - Fold 1 - Validation Accuracy : 0.5232\n",
      "Epoch(65) - Fold 1 - Validation Utility score : 535.5000\n",
      "Epoch(65) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(65) - Fold 2 - Validation Accuracy : 0.5081\n",
      "Epoch(65) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(65) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(65) - Fold 3 - Validation Accuracy : 0.5081\n",
      "Epoch(65) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(65) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(65) - Fold 4 - Validation Accuracy : 0.5121\n",
      "Epoch(65) - Fold 4 - Validation Utility score : 869.3619\n",
      "Epoch(65) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(65) - GLOBAL - Validation Accuracy: 0.5145\n",
      "Epoch(65) - GLOBAL - Validation Utility score: 1567.4887\n",
      "Saving model corresponding to last_utility_score == 1567.4887307117592\n",
      "\n",
      "\n",
      "Epoch(66) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(66) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(66) - Fold 0 - Validation Accuracy : 0.5201\n",
      "Epoch(66) - Fold 0 - Validation Utility score : 140.6117\n",
      "Epoch(66) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(66) - Fold 1 - Validation Accuracy : 0.5221\n",
      "Epoch(66) - Fold 1 - Validation Utility score : 472.9931\n",
      "Epoch(66) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(66) - Fold 2 - Validation Accuracy : 0.5085\n",
      "Epoch(66) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(66) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(66) - Fold 3 - Validation Accuracy : 0.5075\n",
      "Epoch(66) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(66) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(66) - Fold 4 - Validation Accuracy : 0.5120\n",
      "Epoch(66) - Fold 4 - Validation Utility score : 869.7922\n",
      "Epoch(66) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(66) - GLOBAL - Validation Accuracy: 0.5140\n",
      "Epoch(66) - GLOBAL - Validation Utility score: 1483.3970\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(67) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(67) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(67) - Fold 0 - Validation Accuracy : 0.5214\n",
      "Epoch(67) - Fold 0 - Validation Utility score : 180.9380\n",
      "Epoch(67) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(67) - Fold 1 - Validation Accuracy : 0.5232\n",
      "Epoch(67) - Fold 1 - Validation Utility score : 528.4347\n",
      "Epoch(67) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(67) - Fold 2 - Validation Accuracy : 0.5080\n",
      "Epoch(67) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(67) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(67) - Fold 3 - Validation Accuracy : 0.5074\n",
      "Epoch(67) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(67) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(67) - Fold 4 - Validation Accuracy : 0.5118\n",
      "Epoch(67) - Fold 4 - Validation Utility score : 894.1438\n",
      "Epoch(67) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(67) - GLOBAL - Validation Accuracy: 0.5144\n",
      "Epoch(67) - GLOBAL - Validation Utility score: 1603.5165\n",
      "Saving model corresponding to last_utility_score == 1603.5165190503944\n",
      "\n",
      "\n",
      "Epoch(68) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(68) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(68) - Fold 0 - Validation Accuracy : 0.5199\n",
      "Epoch(68) - Fold 0 - Validation Utility score : 148.5626\n",
      "Epoch(68) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(68) - Fold 1 - Validation Accuracy : 0.5216\n",
      "Epoch(68) - Fold 1 - Validation Utility score : 406.8479\n",
      "Epoch(68) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(68) - Fold 2 - Validation Accuracy : 0.5094\n",
      "Epoch(68) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(68) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(68) - Fold 3 - Validation Accuracy : 0.5081\n",
      "Epoch(68) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(68) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(68) - Fold 4 - Validation Accuracy : 0.5118\n",
      "Epoch(68) - Fold 4 - Validation Utility score : 876.9423\n",
      "Epoch(68) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(68) - GLOBAL - Validation Accuracy: 0.5142\n",
      "Epoch(68) - GLOBAL - Validation Utility score: 1432.3529\n",
      "Intermediate early stopping : vepoch_loss = 0.6922, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(69) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(69) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(69) - Fold 0 - Validation Accuracy : 0.5219\n",
      "Epoch(69) - Fold 0 - Validation Utility score : 181.5735\n",
      "Epoch(69) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(69) - Fold 1 - Validation Accuracy : 0.5238\n",
      "Epoch(69) - Fold 1 - Validation Utility score : 572.5177\n",
      "Epoch(69) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(69) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(69) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(69) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(69) - Fold 3 - Validation Accuracy : 0.5082\n",
      "Epoch(69) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(69) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(69) - Fold 4 - Validation Accuracy : 0.5126\n",
      "Epoch(69) - Fold 4 - Validation Utility score : 891.7509\n",
      "Epoch(69) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(69) - GLOBAL - Validation Accuracy: 0.5150\n",
      "Epoch(69) - GLOBAL - Validation Utility score: 1645.8420\n",
      "Saving model corresponding to last_utility_score == 1645.8420225125415\n",
      "\n",
      "\n",
      "Epoch(70) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(70) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(70) - Fold 0 - Validation Accuracy : 0.5226\n",
      "Epoch(70) - Fold 0 - Validation Utility score : 204.0474\n",
      "Epoch(70) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(70) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(70) - Fold 1 - Validation Utility score : 519.9493\n",
      "Epoch(70) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(70) - Fold 2 - Validation Accuracy : 0.5091\n",
      "Epoch(70) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(70) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(70) - Fold 3 - Validation Accuracy : 0.5083\n",
      "Epoch(70) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(70) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(70) - Fold 4 - Validation Accuracy : 0.5122\n",
      "Epoch(70) - Fold 4 - Validation Utility score : 853.5437\n",
      "Epoch(70) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(70) - GLOBAL - Validation Accuracy: 0.5151\n",
      "Epoch(70) - GLOBAL - Validation Utility score: 1577.5404\n",
      "Saving model corresponding to last_utility_score == 1577.5403915993393\n",
      "\n",
      "\n",
      "Epoch(71) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(71) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(71) - Fold 0 - Validation Accuracy : 0.5229\n",
      "Epoch(71) - Fold 0 - Validation Utility score : 235.2510\n",
      "Epoch(71) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(71) - Fold 1 - Validation Accuracy : 0.5248\n",
      "Epoch(71) - Fold 1 - Validation Utility score : 622.7300\n",
      "Epoch(71) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(71) - Fold 2 - Validation Accuracy : 0.5081\n",
      "Epoch(71) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(71) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(71) - Fold 3 - Validation Accuracy : 0.5081\n",
      "Epoch(71) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(71) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(71) - Fold 4 - Validation Accuracy : 0.5133\n",
      "Epoch(71) - Fold 4 - Validation Utility score : 855.6179\n",
      "Epoch(71) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(71) - GLOBAL - Validation Accuracy: 0.5154\n",
      "Epoch(71) - GLOBAL - Validation Utility score: 1713.5989\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(72) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(72) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(72) - Fold 0 - Validation Accuracy : 0.5189\n",
      "Epoch(72) - Fold 0 - Validation Utility score : 109.9477\n",
      "Epoch(72) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(72) - Fold 1 - Validation Accuracy : 0.5220\n",
      "Epoch(72) - Fold 1 - Validation Utility score : 437.7417\n",
      "Epoch(72) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(72) - Fold 2 - Validation Accuracy : 0.5085\n",
      "Epoch(72) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(72) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(72) - Fold 3 - Validation Accuracy : 0.5074\n",
      "Epoch(72) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(72) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(72) - Fold 4 - Validation Accuracy : 0.5114\n",
      "Epoch(72) - Fold 4 - Validation Utility score : 821.9319\n",
      "Epoch(72) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(72) - GLOBAL - Validation Accuracy: 0.5136\n",
      "Epoch(72) - GLOBAL - Validation Utility score: 1369.6213\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(73) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(73) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(73) - Fold 0 - Validation Accuracy : 0.5233\n",
      "Epoch(73) - Fold 0 - Validation Utility score : 309.2325\n",
      "Epoch(73) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(73) - Fold 1 - Validation Accuracy : 0.5245\n",
      "Epoch(73) - Fold 1 - Validation Utility score : 674.5364\n",
      "Epoch(73) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(73) - Fold 2 - Validation Accuracy : 0.5084\n",
      "Epoch(73) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(73) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(73) - Fold 3 - Validation Accuracy : 0.5079\n",
      "Epoch(73) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(73) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(73) - Fold 4 - Validation Accuracy : 0.5137\n",
      "Epoch(73) - Fold 4 - Validation Utility score : 908.8700\n",
      "Epoch(73) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(73) - GLOBAL - Validation Accuracy: 0.5156\n",
      "Epoch(73) - GLOBAL - Validation Utility score: 1892.6389\n",
      "Saving model corresponding to last_utility_score == 1892.6389307557808\n",
      "\n",
      "\n",
      "Epoch(74) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(74) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(74) - Fold 0 - Validation Accuracy : 0.5233\n",
      "Epoch(74) - Fold 0 - Validation Utility score : 275.3251\n",
      "Epoch(74) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(74) - Fold 1 - Validation Accuracy : 0.5248\n",
      "Epoch(74) - Fold 1 - Validation Utility score : 705.7736\n",
      "Epoch(74) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(74) - Fold 2 - Validation Accuracy : 0.5084\n",
      "Epoch(74) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(74) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(74) - Fold 3 - Validation Accuracy : 0.5087\n",
      "Epoch(74) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(74) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(74) - Fold 4 - Validation Accuracy : 0.5138\n",
      "Epoch(74) - Fold 4 - Validation Utility score : 859.4911\n",
      "Epoch(74) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(74) - GLOBAL - Validation Accuracy: 0.5158\n",
      "Epoch(74) - GLOBAL - Validation Utility score: 1840.5899\n",
      "Saving model corresponding to last_utility_score == 1840.5898509636197\n",
      "\n",
      "\n",
      "Epoch(75) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(75) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(75) - Fold 0 - Validation Accuracy : 0.5237\n",
      "Epoch(75) - Fold 0 - Validation Utility score : 238.3046\n",
      "Epoch(75) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(75) - Fold 1 - Validation Accuracy : 0.5239\n",
      "Epoch(75) - Fold 1 - Validation Utility score : 726.4015\n",
      "Epoch(75) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(75) - Fold 2 - Validation Accuracy : 0.5081\n",
      "Epoch(75) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(75) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(75) - Fold 3 - Validation Accuracy : 0.5086\n",
      "Epoch(75) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(75) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(75) - Fold 4 - Validation Accuracy : 0.5138\n",
      "Epoch(75) - Fold 4 - Validation Utility score : 897.5224\n",
      "Epoch(75) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(75) - GLOBAL - Validation Accuracy: 0.5156\n",
      "Epoch(75) - GLOBAL - Validation Utility score: 1862.2285\n",
      "Saving model corresponding to last_utility_score == 1862.2284593784884\n",
      "\n",
      "\n",
      "Epoch(76) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(76) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(76) - Fold 0 - Validation Accuracy : 0.5193\n",
      "Epoch(76) - Fold 0 - Validation Utility score : 121.0072\n",
      "Epoch(76) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(76) - Fold 1 - Validation Accuracy : 0.5214\n",
      "Epoch(76) - Fold 1 - Validation Utility score : 389.9178\n",
      "Epoch(76) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(76) - Fold 2 - Validation Accuracy : 0.5100\n",
      "Epoch(76) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(76) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(76) - Fold 3 - Validation Accuracy : 0.5071\n",
      "Epoch(76) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(76) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(76) - Fold 4 - Validation Accuracy : 0.5118\n",
      "Epoch(76) - Fold 4 - Validation Utility score : 703.7650\n",
      "Epoch(76) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(76) - GLOBAL - Validation Accuracy: 0.5139\n",
      "Epoch(76) - GLOBAL - Validation Utility score: 1214.6900\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(77) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(77) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(77) - Fold 0 - Validation Accuracy : 0.5232\n",
      "Epoch(77) - Fold 0 - Validation Utility score : 260.2638\n",
      "Epoch(77) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(77) - Fold 1 - Validation Accuracy : 0.5233\n",
      "Epoch(77) - Fold 1 - Validation Utility score : 636.0412\n",
      "Epoch(77) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(77) - Fold 2 - Validation Accuracy : 0.5082\n",
      "Epoch(77) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(77) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(77) - Fold 3 - Validation Accuracy : 0.5088\n",
      "Epoch(77) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(77) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(77) - Fold 4 - Validation Accuracy : 0.5134\n",
      "Epoch(77) - Fold 4 - Validation Utility score : 850.5929\n",
      "Epoch(77) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(77) - GLOBAL - Validation Accuracy: 0.5154\n",
      "Epoch(77) - GLOBAL - Validation Utility score: 1746.8979\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(78) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(78) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(78) - Fold 0 - Validation Accuracy : 0.5243\n",
      "Epoch(78) - Fold 0 - Validation Utility score : 365.7917\n",
      "Epoch(78) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(78) - Fold 1 - Validation Accuracy : 0.5246\n",
      "Epoch(78) - Fold 1 - Validation Utility score : 805.6314\n",
      "Epoch(78) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(78) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(78) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(78) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(78) - Fold 3 - Validation Accuracy : 0.5082\n",
      "Epoch(78) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(78) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(78) - Fold 4 - Validation Accuracy : 0.5154\n",
      "Epoch(78) - Fold 4 - Validation Utility score : 1046.8595\n",
      "Epoch(78) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(78) - GLOBAL - Validation Accuracy: 0.5162\n",
      "Epoch(78) - GLOBAL - Validation Utility score: 2218.2827\n",
      "Saving model corresponding to last_utility_score == 2218.2827308975893\n",
      "\n",
      "\n",
      "Epoch(79) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(79) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(79) - Fold 0 - Validation Accuracy : 0.5202\n",
      "Epoch(79) - Fold 0 - Validation Utility score : 123.0831\n",
      "Epoch(79) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(79) - Fold 1 - Validation Accuracy : 0.5222\n",
      "Epoch(79) - Fold 1 - Validation Utility score : 434.8420\n",
      "Epoch(79) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(79) - Fold 2 - Validation Accuracy : 0.5096\n",
      "Epoch(79) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(79) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(79) - Fold 3 - Validation Accuracy : 0.5079\n",
      "Epoch(79) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(79) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(79) - Fold 4 - Validation Accuracy : 0.5131\n",
      "Epoch(79) - Fold 4 - Validation Utility score : 883.1287\n",
      "Epoch(79) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(79) - GLOBAL - Validation Accuracy: 0.5146\n",
      "Epoch(79) - GLOBAL - Validation Utility score: 1441.0538\n",
      "Intermediate early stopping : vepoch_loss = 0.6922, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(80) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(80) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(80) - Fold 0 - Validation Accuracy : 0.5228\n",
      "Epoch(80) - Fold 0 - Validation Utility score : 228.9659\n",
      "Epoch(80) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(80) - Fold 1 - Validation Accuracy : 0.5244\n",
      "Epoch(80) - Fold 1 - Validation Utility score : 708.0379\n",
      "Epoch(80) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(80) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(80) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(80) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(80) - Fold 3 - Validation Accuracy : 0.5088\n",
      "Epoch(80) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(80) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(80) - Fold 4 - Validation Accuracy : 0.5142\n",
      "Epoch(80) - Fold 4 - Validation Utility score : 952.3502\n",
      "Epoch(80) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(80) - GLOBAL - Validation Accuracy: 0.5158\n",
      "Epoch(80) - GLOBAL - Validation Utility score: 1889.3541\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(81) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(81) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(81) - Fold 0 - Validation Accuracy : 0.5238\n",
      "Epoch(81) - Fold 0 - Validation Utility score : 303.6849\n",
      "Epoch(81) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(81) - Fold 1 - Validation Accuracy : 0.5243\n",
      "Epoch(81) - Fold 1 - Validation Utility score : 678.1456\n",
      "Epoch(81) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(81) - Fold 2 - Validation Accuracy : 0.5086\n",
      "Epoch(81) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(81) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(81) - Fold 3 - Validation Accuracy : 0.5077\n",
      "Epoch(81) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(81) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(81) - Fold 4 - Validation Accuracy : 0.5143\n",
      "Epoch(81) - Fold 4 - Validation Utility score : 960.4745\n",
      "Epoch(81) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(81) - GLOBAL - Validation Accuracy: 0.5157\n",
      "Epoch(81) - GLOBAL - Validation Utility score: 1942.3050\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(82) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(82) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(82) - Fold 0 - Validation Accuracy : 0.5235\n",
      "Epoch(82) - Fold 0 - Validation Utility score : 282.4625\n",
      "Epoch(82) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(82) - Fold 1 - Validation Accuracy : 0.5245\n",
      "Epoch(82) - Fold 1 - Validation Utility score : 720.3097\n",
      "Epoch(82) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(82) - Fold 2 - Validation Accuracy : 0.5091\n",
      "Epoch(82) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(82) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(82) - Fold 3 - Validation Accuracy : 0.5090\n",
      "Epoch(82) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(82) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(82) - Fold 4 - Validation Accuracy : 0.5160\n",
      "Epoch(82) - Fold 4 - Validation Utility score : 1043.1586\n",
      "Epoch(82) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(82) - GLOBAL - Validation Accuracy: 0.5164\n",
      "Epoch(82) - GLOBAL - Validation Utility score: 2045.9308\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(83) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(83) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(83) - Fold 0 - Validation Accuracy : 0.5230\n",
      "Epoch(83) - Fold 0 - Validation Utility score : 211.1746\n",
      "Epoch(83) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(83) - Fold 1 - Validation Accuracy : 0.5251\n",
      "Epoch(83) - Fold 1 - Validation Utility score : 734.9514\n",
      "Epoch(83) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(83) - Fold 2 - Validation Accuracy : 0.5091\n",
      "Epoch(83) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(83) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(83) - Fold 3 - Validation Accuracy : 0.5087\n",
      "Epoch(83) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(83) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(83) - Fold 4 - Validation Accuracy : 0.5156\n",
      "Epoch(83) - Fold 4 - Validation Utility score : 1016.2516\n",
      "Epoch(83) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(83) - GLOBAL - Validation Accuracy: 0.5163\n",
      "Epoch(83) - GLOBAL - Validation Utility score: 1962.3776\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "Meet Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 537713<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_111918-l82zicq9/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_111918-l82zicq9/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>0.69187</td></tr><tr><td>Global valid/Loss</td><td>0.69205</td></tr><tr><td>Global valid/Accuracy</td><td>0.5163</td></tr><tr><td>Global valid/Utility</td><td>1962.37758</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>0.69171</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>0.52299</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>211.17457</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>0.69128</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>0.52508</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>734.95142</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>0.69277</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>0.50914</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>0.69281</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>0.50871</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>0.69168</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>0.51558</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>1016.2516</td></tr><tr><td>Best accuracy</td><td>0.51625</td></tr><tr><td>Best utility</td><td>2218.28273</td></tr><tr><td>_runtime</td><td>5774</td></tr><tr><td>_timestamp</td><td>1613476532</td></tr><tr><td>_step</td><td>83</td></tr><tr><td>Final utility score</td><td>{'utility_score': 22...</td></tr><tr><td>Batch size</td><td>62480</td></tr><tr><td>Patience</td><td>5</td></tr><tr><td>Number of epochs</td><td>1000</td></tr><tr><td>Best epoch</td><td>78</td></tr><tr><td>Number of parameters per layer</td><td>[8384, 64, 2048, 32,...</td></tr><tr><td>Model architecture</td><td>MLP(<BR>  (AEncoder)...</td></tr><tr><td>comment</td><td>All folds MLP with a...</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>█▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Loss</td><td>█▆▅▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Accuracy</td><td>▁▂▂▂▂▂▃▃▃▃▃▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇███</td></tr><tr><td>Global valid/Utility</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▄▄▄▃▄▄▆▄▆▆▄▅▇▆▆▆▆▆▆▅▇▅█▇▇</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>█▅▅▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>▂▂▁▁▁▁▁▁▂▂▂▃▃▄▄▅▅▅▅▅▆▇▆▇▇▆▇▇▇▇▇▇▇█▆█▇███</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▄▂▅▆▃▄▇▄▆▄▄▄▅▃▆▃█▅▅</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>█▆▆▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>▁▂▃▃▃▃▃▃▃▄▄▄▄▅▅▆▆▇▆▆▇█▇▇█▇▇█▇██▇▇█▇█▇███</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▃▃▃▄▅▄▅▅▄▅▆▅▅▆▆▅▆▅▇▄█▇▇</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>█▅▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>▁▂▃▄▄▄▄▄▄▄▄▄▄▅▅▆▆▇▆▇▇▇▇▇█▇▇▇▇▇▇▇█▇▇▇█▇▇█</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>█▆▆▄▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>▂▂▁▁▁▁▂▂▃▃▄▄▅▅▅▇▇███▇▇▇▇▇▇▇▇▇▇▇█▇█▇█▇███</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>█▆▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>▁▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▆▆▅▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▅▅▆▅▅▅▇▅▇▇▆▆▇▇▇▇▇▇▇▆▇▆█▇█</td></tr><tr><td>Best accuracy</td><td>▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>Best utility</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▄▄▄▅▄▆▅▆▆▆▇▆▆▆▆▆▇▇▇█</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 421 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">devoted-sweep-11</strong>: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/l82zicq9\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/l82zicq9</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training summary:\n",
      "{'utility_score': 2218.2827308975893, 'utility_scores': [365.79174741592954, 805.6314483747626, -0.0, -0.0, 1046.859535106897], 'utility_score_std': 422.9905115939487, 'accuracy_scores': [0.5242873949341611, 0.5246402246402246, 0.5087297718518925, 0.5082024874781924, 0.5153683617410902]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ibbovoi0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leakyrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 58941\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.42267029038219267\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0010383073779096188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_autoenc: encoder\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.0772553056456805e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">robust-sweep-12</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/ibbovoi0\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/ibbovoi0</a><br/>\n",
       "                Run data is saved locally in <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_125537-ibbovoi0</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Run config :\n",
      "config: {'activation_function': 'leakyrelu', 'batch_size': 58941, 'dropout': 0.42267029038219267, 'learning_rate': 0.0010383073779096188, 'use_autoenc': 'encoder', 'weight_decay': 1.0772553056456805e-05, 'epochs': 1000}\n",
      "Epoch(0) - Training Loss: 0.7636\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(0) - Fold 0 - Validation Loss : 0.6951\n",
      "Epoch(0) - Fold 0 - Validation Accuracy : 0.5083\n",
      "Epoch(0) - Fold 0 - Validation Utility score : 27.2556\n",
      "Epoch(0) - Fold 1 - Validation Loss : 0.6951\n",
      "Epoch(0) - Fold 1 - Validation Accuracy : 0.5021\n",
      "Epoch(0) - Fold 1 - Validation Utility score : 188.0461\n",
      "Epoch(0) - Fold 2 - Validation Loss : 0.6966\n",
      "Epoch(0) - Fold 2 - Validation Accuracy : 0.5000\n",
      "Epoch(0) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 3 - Validation Loss : 0.6960\n",
      "Epoch(0) - Fold 3 - Validation Accuracy : 0.4983\n",
      "Epoch(0) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 4 - Validation Loss : 0.6957\n",
      "Epoch(0) - Fold 4 - Validation Accuracy : 0.4976\n",
      "Epoch(0) - Fold 4 - Validation Utility score : 17.0986\n",
      "Epoch(0) - GLOBAL - Validation Loss: 0.6957\n",
      "Epoch(0) - GLOBAL - Validation Accuracy: 0.5013\n",
      "Epoch(0) - GLOBAL - Validation Utility score: 232.4003\n",
      "Saving model corresponding to last_utility_score == 232.40025709170547\n",
      "\n",
      "\n",
      "Epoch(1) - Training Loss: 0.7296\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(1) - Fold 0 - Validation Loss : 0.6934\n",
      "Epoch(1) - Fold 0 - Validation Accuracy : 0.5127\n",
      "Epoch(1) - Fold 0 - Validation Utility score : 45.6521\n",
      "Epoch(1) - Fold 1 - Validation Loss : 0.6933\n",
      "Epoch(1) - Fold 1 - Validation Accuracy : 0.5084\n",
      "Epoch(1) - Fold 1 - Validation Utility score : 402.7848\n",
      "Epoch(1) - Fold 2 - Validation Loss : 0.6946\n",
      "Epoch(1) - Fold 2 - Validation Accuracy : 0.5048\n",
      "Epoch(1) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 3 - Validation Loss : 0.6942\n",
      "Epoch(1) - Fold 3 - Validation Accuracy : 0.5014\n",
      "Epoch(1) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 4 - Validation Loss : 0.6936\n",
      "Epoch(1) - Fold 4 - Validation Accuracy : 0.5056\n",
      "Epoch(1) - Fold 4 - Validation Utility score : 151.3926\n",
      "Epoch(1) - GLOBAL - Validation Loss: 0.6938\n",
      "Epoch(1) - GLOBAL - Validation Accuracy: 0.5066\n",
      "Epoch(1) - GLOBAL - Validation Utility score: 599.8295\n",
      "Saving model corresponding to last_utility_score == 599.8294642421794\n",
      "\n",
      "\n",
      "Epoch(2) - Training Loss: 0.7081\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(2) - Fold 0 - Validation Loss : 0.6928\n",
      "Epoch(2) - Fold 0 - Validation Accuracy : 0.5142\n",
      "Epoch(2) - Fold 0 - Validation Utility score : 136.2179\n",
      "Epoch(2) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(2) - Fold 1 - Validation Accuracy : 0.5111\n",
      "Epoch(2) - Fold 1 - Validation Utility score : 714.1652\n",
      "Epoch(2) - Fold 2 - Validation Loss : 0.6934\n",
      "Epoch(2) - Fold 2 - Validation Accuracy : 0.5065\n",
      "Epoch(2) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(2) - Fold 3 - Validation Accuracy : 0.5066\n",
      "Epoch(2) - Fold 3 - Validation Utility score : 154.4031\n",
      "Epoch(2) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(2) - Fold 4 - Validation Accuracy : 0.5107\n",
      "Epoch(2) - Fold 4 - Validation Utility score : 425.1433\n",
      "Epoch(2) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(2) - GLOBAL - Validation Accuracy: 0.5098\n",
      "Epoch(2) - GLOBAL - Validation Utility score: 1429.9295\n",
      "Saving model corresponding to last_utility_score == 1429.9295122864887\n",
      "\n",
      "\n",
      "Epoch(3) - Training Loss: 0.6989\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(3) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(3) - Fold 0 - Validation Accuracy : 0.5123\n",
      "Epoch(3) - Fold 0 - Validation Utility score : 68.9610\n",
      "Epoch(3) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(3) - Fold 1 - Validation Accuracy : 0.5093\n",
      "Epoch(3) - Fold 1 - Validation Utility score : 296.3881\n",
      "Epoch(3) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(3) - Fold 2 - Validation Accuracy : 0.5047\n",
      "Epoch(3) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(3) - Fold 3 - Validation Accuracy : 0.5052\n",
      "Epoch(3) - Fold 3 - Validation Utility score : 6.8534\n",
      "Epoch(3) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(3) - Fold 4 - Validation Accuracy : 0.5110\n",
      "Epoch(3) - Fold 4 - Validation Utility score : 572.0088\n",
      "Epoch(3) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(3) - GLOBAL - Validation Accuracy: 0.5085\n",
      "Epoch(3) - GLOBAL - Validation Utility score: 944.2113\n",
      "Saving model corresponding to last_utility_score == 944.2113080085142\n",
      "\n",
      "\n",
      "Epoch(4) - Training Loss: 0.6952\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(4) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(4) - Fold 0 - Validation Accuracy : 0.5119\n",
      "Epoch(4) - Fold 0 - Validation Utility score : 117.4198\n",
      "Epoch(4) - Fold 1 - Validation Loss : 0.6930\n",
      "Epoch(4) - Fold 1 - Validation Accuracy : 0.5046\n",
      "Epoch(4) - Fold 1 - Validation Utility score : 101.2504\n",
      "Epoch(4) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(4) - Fold 2 - Validation Accuracy : 0.5031\n",
      "Epoch(4) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(4) - Fold 3 - Validation Accuracy : 0.5026\n",
      "Epoch(4) - Fold 3 - Validation Utility score : 11.1824\n",
      "Epoch(4) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(4) - Fold 4 - Validation Accuracy : 0.5095\n",
      "Epoch(4) - Fold 4 - Validation Utility score : 379.2841\n",
      "Epoch(4) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(4) - GLOBAL - Validation Accuracy: 0.5063\n",
      "Epoch(4) - GLOBAL - Validation Utility score: 609.1367\n",
      "Intermediate early stopping : vepoch_loss = 0.6929, the_last_loss=0.6928\n",
      "\n",
      "\n",
      "Epoch(5) - Training Loss: 0.6938\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(5) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(5) - Fold 0 - Validation Accuracy : 0.5162\n",
      "Epoch(5) - Fold 0 - Validation Utility score : 393.3561\n",
      "Epoch(5) - Fold 1 - Validation Loss : 0.6929\n",
      "Epoch(5) - Fold 1 - Validation Accuracy : 0.5082\n",
      "Epoch(5) - Fold 1 - Validation Utility score : 190.7285\n",
      "Epoch(5) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(5) - Fold 2 - Validation Accuracy : 0.5053\n",
      "Epoch(5) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(5) - Fold 3 - Validation Accuracy : 0.5038\n",
      "Epoch(5) - Fold 3 - Validation Utility score : 9.0888\n",
      "Epoch(5) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(5) - Fold 4 - Validation Accuracy : 0.5116\n",
      "Epoch(5) - Fold 4 - Validation Utility score : 852.6554\n",
      "Epoch(5) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(5) - GLOBAL - Validation Accuracy: 0.5090\n",
      "Epoch(5) - GLOBAL - Validation Utility score: 1445.8289\n",
      "Intermediate early stopping : vepoch_loss = 0.6929, the_last_loss=0.6928\n",
      "\n",
      "\n",
      "Epoch(6) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(6) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(6) - Fold 0 - Validation Accuracy : 0.5185\n",
      "Epoch(6) - Fold 0 - Validation Utility score : 476.5294\n",
      "Epoch(6) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(6) - Fold 1 - Validation Accuracy : 0.5145\n",
      "Epoch(6) - Fold 1 - Validation Utility score : 521.6827\n",
      "Epoch(6) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(6) - Fold 2 - Validation Accuracy : 0.5062\n",
      "Epoch(6) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(6) - Fold 3 - Validation Accuracy : 0.5064\n",
      "Epoch(6) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(6) - Fold 4 - Validation Accuracy : 0.5151\n",
      "Epoch(6) - Fold 4 - Validation Utility score : 1047.1353\n",
      "Epoch(6) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(6) - GLOBAL - Validation Accuracy: 0.5121\n",
      "Epoch(6) - GLOBAL - Validation Utility score: 2045.3473\n",
      "Saving model corresponding to last_utility_score == 2045.3473468428085\n",
      "\n",
      "\n",
      "Epoch(7) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(7) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(7) - Fold 0 - Validation Accuracy : 0.5211\n",
      "Epoch(7) - Fold 0 - Validation Utility score : 473.3410\n",
      "Epoch(7) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(7) - Fold 1 - Validation Accuracy : 0.5177\n",
      "Epoch(7) - Fold 1 - Validation Utility score : 804.8576\n",
      "Epoch(7) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(7) - Fold 2 - Validation Accuracy : 0.5050\n",
      "Epoch(7) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(7) - Fold 3 - Validation Accuracy : 0.5078\n",
      "Epoch(7) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(7) - Fold 4 - Validation Accuracy : 0.5182\n",
      "Epoch(7) - Fold 4 - Validation Utility score : 1129.5525\n",
      "Epoch(7) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(7) - GLOBAL - Validation Accuracy: 0.5140\n",
      "Epoch(7) - GLOBAL - Validation Utility score: 2407.7512\n",
      "Saving model corresponding to last_utility_score == 2407.7511976478772\n",
      "\n",
      "\n",
      "Epoch(8) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(8) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(8) - Fold 0 - Validation Accuracy : 0.5227\n",
      "Epoch(8) - Fold 0 - Validation Utility score : 620.8503\n",
      "Epoch(8) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(8) - Fold 1 - Validation Accuracy : 0.5189\n",
      "Epoch(8) - Fold 1 - Validation Utility score : 889.3679\n",
      "Epoch(8) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(8) - Fold 2 - Validation Accuracy : 0.5060\n",
      "Epoch(8) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(8) - Fold 3 - Validation Accuracy : 0.5077\n",
      "Epoch(8) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(8) - Fold 4 - Validation Accuracy : 0.5196\n",
      "Epoch(8) - Fold 4 - Validation Utility score : 1201.9107\n",
      "Epoch(8) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(8) - GLOBAL - Validation Accuracy: 0.5150\n",
      "Epoch(8) - GLOBAL - Validation Utility score: 2712.1289\n",
      "Saving model corresponding to last_utility_score == 2712.128862052395\n",
      "\n",
      "\n",
      "Epoch(9) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(9) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(9) - Fold 0 - Validation Accuracy : 0.5252\n",
      "Epoch(9) - Fold 0 - Validation Utility score : 654.7024\n",
      "Epoch(9) - Fold 1 - Validation Loss : 0.6923\n",
      "Epoch(9) - Fold 1 - Validation Accuracy : 0.5208\n",
      "Epoch(9) - Fold 1 - Validation Utility score : 1066.9626\n",
      "Epoch(9) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(9) - Fold 2 - Validation Accuracy : 0.5065\n",
      "Epoch(9) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(9) - Fold 3 - Validation Accuracy : 0.5098\n",
      "Epoch(9) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(9) - Fold 4 - Validation Accuracy : 0.5209\n",
      "Epoch(9) - Fold 4 - Validation Utility score : 1456.9352\n",
      "Epoch(9) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(9) - GLOBAL - Validation Accuracy: 0.5166\n",
      "Epoch(9) - GLOBAL - Validation Utility score: 3178.6002\n",
      "Saving model corresponding to last_utility_score == 3178.6002065344883\n",
      "\n",
      "\n",
      "Epoch(10) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(10) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(10) - Fold 0 - Validation Accuracy : 0.5240\n",
      "Epoch(10) - Fold 0 - Validation Utility score : 650.5967\n",
      "Epoch(10) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(10) - Fold 1 - Validation Accuracy : 0.5223\n",
      "Epoch(10) - Fold 1 - Validation Utility score : 1192.0452\n",
      "Epoch(10) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(10) - Fold 2 - Validation Accuracy : 0.5069\n",
      "Epoch(10) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(10) - Fold 3 - Validation Accuracy : 0.5100\n",
      "Epoch(10) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(10) - Fold 4 - Validation Accuracy : 0.5207\n",
      "Epoch(10) - Fold 4 - Validation Utility score : 1467.7851\n",
      "Epoch(10) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(10) - GLOBAL - Validation Accuracy: 0.5168\n",
      "Epoch(10) - GLOBAL - Validation Utility score: 3310.4270\n",
      "Saving model corresponding to last_utility_score == 3310.426975016526\n",
      "\n",
      "\n",
      "Epoch(11) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(11) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(11) - Fold 0 - Validation Accuracy : 0.5237\n",
      "Epoch(11) - Fold 0 - Validation Utility score : 648.4386\n",
      "Epoch(11) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(11) - Fold 1 - Validation Accuracy : 0.5227\n",
      "Epoch(11) - Fold 1 - Validation Utility score : 1165.7368\n",
      "Epoch(11) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(11) - Fold 2 - Validation Accuracy : 0.5071\n",
      "Epoch(11) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(11) - Fold 3 - Validation Accuracy : 0.5119\n",
      "Epoch(11) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(11) - Fold 4 - Validation Accuracy : 0.5223\n",
      "Epoch(11) - Fold 4 - Validation Utility score : 1500.4959\n",
      "Epoch(11) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(11) - GLOBAL - Validation Accuracy: 0.5175\n",
      "Epoch(11) - GLOBAL - Validation Utility score: 3314.6714\n",
      "Saving model corresponding to last_utility_score == 3314.671366618406\n",
      "\n",
      "\n",
      "Epoch(12) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(12) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(12) - Fold 0 - Validation Accuracy : 0.5248\n",
      "Epoch(12) - Fold 0 - Validation Utility score : 559.0047\n",
      "Epoch(12) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(12) - Fold 1 - Validation Accuracy : 0.5233\n",
      "Epoch(12) - Fold 1 - Validation Utility score : 1098.8010\n",
      "Epoch(12) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(12) - Fold 2 - Validation Accuracy : 0.5072\n",
      "Epoch(12) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(12) - Fold 3 - Validation Accuracy : 0.5127\n",
      "Epoch(12) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(12) - Fold 4 - Validation Accuracy : 0.5224\n",
      "Epoch(12) - Fold 4 - Validation Utility score : 1536.8295\n",
      "Epoch(12) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(12) - GLOBAL - Validation Accuracy: 0.5181\n",
      "Epoch(12) - GLOBAL - Validation Utility score: 3194.6352\n",
      "Saving model corresponding to last_utility_score == 3194.6352292159368\n",
      "\n",
      "\n",
      "Epoch(13) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(13) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(13) - Fold 0 - Validation Accuracy : 0.5238\n",
      "Epoch(13) - Fold 0 - Validation Utility score : 618.8651\n",
      "Epoch(13) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(13) - Fold 1 - Validation Accuracy : 0.5226\n",
      "Epoch(13) - Fold 1 - Validation Utility score : 1045.0915\n",
      "Epoch(13) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(13) - Fold 2 - Validation Accuracy : 0.5080\n",
      "Epoch(13) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(13) - Fold 3 - Validation Accuracy : 0.5128\n",
      "Epoch(13) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(13) - Fold 4 - Validation Accuracy : 0.5229\n",
      "Epoch(13) - Fold 4 - Validation Utility score : 1450.3463\n",
      "Epoch(13) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(13) - GLOBAL - Validation Accuracy: 0.5180\n",
      "Epoch(13) - GLOBAL - Validation Utility score: 3114.3029\n",
      "Saving model corresponding to last_utility_score == 3114.3028658614794\n",
      "\n",
      "\n",
      "Epoch(14) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(14) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(14) - Fold 0 - Validation Accuracy : 0.5249\n",
      "Epoch(14) - Fold 0 - Validation Utility score : 461.6239\n",
      "Epoch(14) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(14) - Fold 1 - Validation Accuracy : 0.5225\n",
      "Epoch(14) - Fold 1 - Validation Utility score : 1063.3894\n",
      "Epoch(14) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(14) - Fold 2 - Validation Accuracy : 0.5075\n",
      "Epoch(14) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(14) - Fold 3 - Validation Accuracy : 0.5124\n",
      "Epoch(14) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(14) - Fold 4 - Validation Accuracy : 0.5238\n",
      "Epoch(14) - Fold 4 - Validation Utility score : 1445.1754\n",
      "Epoch(14) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(14) - GLOBAL - Validation Accuracy: 0.5182\n",
      "Epoch(14) - GLOBAL - Validation Utility score: 2970.1887\n",
      "Saving model corresponding to last_utility_score == 2970.1886823400364\n",
      "\n",
      "\n",
      "Epoch(15) - Training Loss: 0.6915\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(15) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(15) - Fold 0 - Validation Accuracy : 0.5231\n",
      "Epoch(15) - Fold 0 - Validation Utility score : 410.4037\n",
      "Epoch(15) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(15) - Fold 1 - Validation Accuracy : 0.5232\n",
      "Epoch(15) - Fold 1 - Validation Utility score : 1053.2291\n",
      "Epoch(15) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(15) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(15) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(15) - Fold 3 - Validation Accuracy : 0.5130\n",
      "Epoch(15) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(15) - Fold 4 - Validation Accuracy : 0.5233\n",
      "Epoch(15) - Fold 4 - Validation Utility score : 1381.6130\n",
      "Epoch(15) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(15) - GLOBAL - Validation Accuracy: 0.5183\n",
      "Epoch(15) - GLOBAL - Validation Utility score: 2845.2457\n",
      "Saving model corresponding to last_utility_score == 2845.245737256113\n",
      "\n",
      "\n",
      "Epoch(16) - Training Loss: 0.6914\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(16) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(16) - Fold 0 - Validation Accuracy : 0.5223\n",
      "Epoch(16) - Fold 0 - Validation Utility score : 480.9754\n",
      "Epoch(16) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(16) - Fold 1 - Validation Accuracy : 0.5219\n",
      "Epoch(16) - Fold 1 - Validation Utility score : 1026.9997\n",
      "Epoch(16) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(16) - Fold 2 - Validation Accuracy : 0.5077\n",
      "Epoch(16) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(16) - Fold 3 - Validation Accuracy : 0.5118\n",
      "Epoch(16) - Fold 3 - Validation Utility score : 0.5220\n",
      "Epoch(16) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(16) - Fold 4 - Validation Accuracy : 0.5236\n",
      "Epoch(16) - Fold 4 - Validation Utility score : 1234.2431\n",
      "Epoch(16) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(16) - GLOBAL - Validation Accuracy: 0.5174\n",
      "Epoch(16) - GLOBAL - Validation Utility score: 2742.7401\n",
      "Saving model corresponding to last_utility_score == 2742.740089367321\n",
      "\n",
      "\n",
      "Epoch(17) - Training Loss: 0.6913\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(17) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(17) - Fold 0 - Validation Accuracy : 0.5224\n",
      "Epoch(17) - Fold 0 - Validation Utility score : 406.5296\n",
      "Epoch(17) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(17) - Fold 1 - Validation Accuracy : 0.5237\n",
      "Epoch(17) - Fold 1 - Validation Utility score : 1104.4772\n",
      "Epoch(17) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(17) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(17) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(17) - Fold 3 - Validation Accuracy : 0.5124\n",
      "Epoch(17) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(17) - Fold 4 - Validation Accuracy : 0.5234\n",
      "Epoch(17) - Fold 4 - Validation Utility score : 1345.2958\n",
      "Epoch(17) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(17) - GLOBAL - Validation Accuracy: 0.5181\n",
      "Epoch(17) - GLOBAL - Validation Utility score: 2856.3026\n",
      "Saving model corresponding to last_utility_score == 2856.3025637689825\n",
      "\n",
      "\n",
      "Epoch(18) - Training Loss: 0.6912\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(18) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(18) - Fold 0 - Validation Accuracy : 0.5223\n",
      "Epoch(18) - Fold 0 - Validation Utility score : 371.0477\n",
      "Epoch(18) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(18) - Fold 1 - Validation Accuracy : 0.5237\n",
      "Epoch(18) - Fold 1 - Validation Utility score : 1016.3815\n",
      "Epoch(18) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(18) - Fold 2 - Validation Accuracy : 0.5095\n",
      "Epoch(18) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(18) - Fold 3 - Validation Accuracy : 0.5124\n",
      "Epoch(18) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 4 - Validation Loss : 0.6912\n",
      "Epoch(18) - Fold 4 - Validation Accuracy : 0.5237\n",
      "Epoch(18) - Fold 4 - Validation Utility score : 1358.0594\n",
      "Epoch(18) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(18) - GLOBAL - Validation Accuracy: 0.5183\n",
      "Epoch(18) - GLOBAL - Validation Utility score: 2745.4886\n",
      "Saving model corresponding to last_utility_score == 2745.4886268008204\n",
      "\n",
      "\n",
      "Epoch(19) - Training Loss: 0.6911\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(19) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(19) - Fold 0 - Validation Accuracy : 0.5221\n",
      "Epoch(19) - Fold 0 - Validation Utility score : 397.4584\n",
      "Epoch(19) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(19) - Fold 1 - Validation Accuracy : 0.5228\n",
      "Epoch(19) - Fold 1 - Validation Utility score : 1106.8010\n",
      "Epoch(19) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(19) - Fold 2 - Validation Accuracy : 0.5086\n",
      "Epoch(19) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(19) - Fold 3 - Validation Accuracy : 0.5116\n",
      "Epoch(19) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 4 - Validation Loss : 0.6912\n",
      "Epoch(19) - Fold 4 - Validation Accuracy : 0.5238\n",
      "Epoch(19) - Fold 4 - Validation Utility score : 1405.1781\n",
      "Epoch(19) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(19) - GLOBAL - Validation Accuracy: 0.5178\n",
      "Epoch(19) - GLOBAL - Validation Utility score: 2909.4375\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(20) - Training Loss: 0.6910\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(20) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(20) - Fold 0 - Validation Accuracy : 0.5220\n",
      "Epoch(20) - Fold 0 - Validation Utility score : 364.3752\n",
      "Epoch(20) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(20) - Fold 1 - Validation Accuracy : 0.5233\n",
      "Epoch(20) - Fold 1 - Validation Utility score : 1042.4771\n",
      "Epoch(20) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(20) - Fold 2 - Validation Accuracy : 0.5098\n",
      "Epoch(20) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(20) - Fold 3 - Validation Accuracy : 0.5123\n",
      "Epoch(20) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 4 - Validation Loss : 0.6910\n",
      "Epoch(20) - Fold 4 - Validation Accuracy : 0.5245\n",
      "Epoch(20) - Fold 4 - Validation Utility score : 1374.9186\n",
      "Epoch(20) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(20) - GLOBAL - Validation Accuracy: 0.5184\n",
      "Epoch(20) - GLOBAL - Validation Utility score: 2781.7709\n",
      "Saving model corresponding to last_utility_score == 2781.7708826272437\n",
      "\n",
      "\n",
      "Epoch(21) - Training Loss: 0.6909\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(21) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(21) - Fold 0 - Validation Accuracy : 0.5223\n",
      "Epoch(21) - Fold 0 - Validation Utility score : 345.0811\n",
      "Epoch(21) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(21) - Fold 1 - Validation Accuracy : 0.5246\n",
      "Epoch(21) - Fold 1 - Validation Utility score : 1016.2528\n",
      "Epoch(21) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(21) - Fold 2 - Validation Accuracy : 0.5098\n",
      "Epoch(21) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(21) - Fold 3 - Validation Accuracy : 0.5120\n",
      "Epoch(21) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 4 - Validation Loss : 0.6911\n",
      "Epoch(21) - Fold 4 - Validation Accuracy : 0.5236\n",
      "Epoch(21) - Fold 4 - Validation Utility score : 1275.5394\n",
      "Epoch(21) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(21) - GLOBAL - Validation Accuracy: 0.5185\n",
      "Epoch(21) - GLOBAL - Validation Utility score: 2636.8733\n",
      "Saving model corresponding to last_utility_score == 2636.873262943105\n",
      "\n",
      "\n",
      "Epoch(22) - Training Loss: 0.6908\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(22) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(22) - Fold 0 - Validation Accuracy : 0.5222\n",
      "Epoch(22) - Fold 0 - Validation Utility score : 334.6703\n",
      "Epoch(22) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(22) - Fold 1 - Validation Accuracy : 0.5236\n",
      "Epoch(22) - Fold 1 - Validation Utility score : 1189.5138\n",
      "Epoch(22) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(22) - Fold 2 - Validation Accuracy : 0.5090\n",
      "Epoch(22) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(22) - Fold 3 - Validation Accuracy : 0.5123\n",
      "Epoch(22) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 4 - Validation Loss : 0.6909\n",
      "Epoch(22) - Fold 4 - Validation Accuracy : 0.5235\n",
      "Epoch(22) - Fold 4 - Validation Utility score : 1367.5298\n",
      "Epoch(22) - GLOBAL - Validation Loss: 0.6918\n",
      "Epoch(22) - GLOBAL - Validation Accuracy: 0.5181\n",
      "Epoch(22) - GLOBAL - Validation Utility score: 2891.7140\n",
      "Saving model corresponding to last_utility_score == 2891.7139643411774\n",
      "\n",
      "\n",
      "Epoch(23) - Training Loss: 0.6906\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(23) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(23) - Fold 0 - Validation Accuracy : 0.5229\n",
      "Epoch(23) - Fold 0 - Validation Utility score : 407.5659\n",
      "Epoch(23) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(23) - Fold 1 - Validation Accuracy : 0.5223\n",
      "Epoch(23) - Fold 1 - Validation Utility score : 973.0511\n",
      "Epoch(23) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(23) - Fold 2 - Validation Accuracy : 0.5095\n",
      "Epoch(23) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(23) - Fold 3 - Validation Accuracy : 0.5120\n",
      "Epoch(23) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 4 - Validation Loss : 0.6909\n",
      "Epoch(23) - Fold 4 - Validation Accuracy : 0.5241\n",
      "Epoch(23) - Fold 4 - Validation Utility score : 1353.9151\n",
      "Epoch(23) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(23) - GLOBAL - Validation Accuracy: 0.5182\n",
      "Epoch(23) - GLOBAL - Validation Utility score: 2734.5321\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(24) - Training Loss: 0.6905\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(24) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(24) - Fold 0 - Validation Accuracy : 0.5203\n",
      "Epoch(24) - Fold 0 - Validation Utility score : 272.0538\n",
      "Epoch(24) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(24) - Fold 1 - Validation Accuracy : 0.5221\n",
      "Epoch(24) - Fold 1 - Validation Utility score : 1100.3137\n",
      "Epoch(24) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(24) - Fold 2 - Validation Accuracy : 0.5079\n",
      "Epoch(24) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(24) - Fold 3 - Validation Accuracy : 0.5111\n",
      "Epoch(24) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 4 - Validation Loss : 0.6909\n",
      "Epoch(24) - Fold 4 - Validation Accuracy : 0.5251\n",
      "Epoch(24) - Fold 4 - Validation Utility score : 1351.3654\n",
      "Epoch(24) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(24) - GLOBAL - Validation Accuracy: 0.5173\n",
      "Epoch(24) - GLOBAL - Validation Utility score: 2723.7328\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(25) - Training Loss: 0.6904\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(25) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(25) - Fold 0 - Validation Accuracy : 0.5204\n",
      "Epoch(25) - Fold 0 - Validation Utility score : 325.4330\n",
      "Epoch(25) - Fold 1 - Validation Loss : 0.6909\n",
      "Epoch(25) - Fold 1 - Validation Accuracy : 0.5230\n",
      "Epoch(25) - Fold 1 - Validation Utility score : 959.8702\n",
      "Epoch(25) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(25) - Fold 2 - Validation Accuracy : 0.5096\n",
      "Epoch(25) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(25) - Fold 3 - Validation Accuracy : 0.5115\n",
      "Epoch(25) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 4 - Validation Loss : 0.6908\n",
      "Epoch(25) - Fold 4 - Validation Accuracy : 0.5246\n",
      "Epoch(25) - Fold 4 - Validation Utility score : 1395.2972\n",
      "Epoch(25) - GLOBAL - Validation Loss: 0.6918\n",
      "Epoch(25) - GLOBAL - Validation Accuracy: 0.5178\n",
      "Epoch(25) - GLOBAL - Validation Utility score: 2680.6004\n",
      "Saving model corresponding to last_utility_score == 2680.600395558561\n",
      "\n",
      "\n",
      "Epoch(26) - Training Loss: 0.6903\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(26) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(26) - Fold 0 - Validation Accuracy : 0.5224\n",
      "Epoch(26) - Fold 0 - Validation Utility score : 368.9510\n",
      "Epoch(26) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(26) - Fold 1 - Validation Accuracy : 0.5231\n",
      "Epoch(26) - Fold 1 - Validation Utility score : 924.6027\n",
      "Epoch(26) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(26) - Fold 2 - Validation Accuracy : 0.5107\n",
      "Epoch(26) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(26) - Fold 3 - Validation Accuracy : 0.5099\n",
      "Epoch(26) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 4 - Validation Loss : 0.6908\n",
      "Epoch(26) - Fold 4 - Validation Accuracy : 0.5251\n",
      "Epoch(26) - Fold 4 - Validation Utility score : 1423.0576\n",
      "Epoch(26) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(26) - GLOBAL - Validation Accuracy: 0.5182\n",
      "Epoch(26) - GLOBAL - Validation Utility score: 2716.6114\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(27) - Training Loss: 0.6902\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(27) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(27) - Fold 0 - Validation Accuracy : 0.5215\n",
      "Epoch(27) - Fold 0 - Validation Utility score : 310.8926\n",
      "Epoch(27) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(27) - Fold 1 - Validation Accuracy : 0.5225\n",
      "Epoch(27) - Fold 1 - Validation Utility score : 1012.1518\n",
      "Epoch(27) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(27) - Fold 2 - Validation Accuracy : 0.5093\n",
      "Epoch(27) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(27) - Fold 3 - Validation Accuracy : 0.5098\n",
      "Epoch(27) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 4 - Validation Loss : 0.6908\n",
      "Epoch(27) - Fold 4 - Validation Accuracy : 0.5241\n",
      "Epoch(27) - Fold 4 - Validation Utility score : 1326.7003\n",
      "Epoch(27) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(27) - GLOBAL - Validation Accuracy: 0.5174\n",
      "Epoch(27) - GLOBAL - Validation Utility score: 2649.7448\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(28) - Training Loss: 0.6901\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(28) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(28) - Fold 0 - Validation Accuracy : 0.5216\n",
      "Epoch(28) - Fold 0 - Validation Utility score : 409.2779\n",
      "Epoch(28) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(28) - Fold 1 - Validation Accuracy : 0.5228\n",
      "Epoch(28) - Fold 1 - Validation Utility score : 896.3952\n",
      "Epoch(28) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(28) - Fold 2 - Validation Accuracy : 0.5101\n",
      "Epoch(28) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(28) - Fold 3 - Validation Accuracy : 0.5101\n",
      "Epoch(28) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 4 - Validation Loss : 0.6907\n",
      "Epoch(28) - Fold 4 - Validation Accuracy : 0.5247\n",
      "Epoch(28) - Fold 4 - Validation Utility score : 1448.4487\n",
      "Epoch(28) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(28) - GLOBAL - Validation Accuracy: 0.5179\n",
      "Epoch(28) - GLOBAL - Validation Utility score: 2754.1218\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(29) - Training Loss: 0.6900\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(29) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(29) - Fold 0 - Validation Accuracy : 0.5217\n",
      "Epoch(29) - Fold 0 - Validation Utility score : 379.0316\n",
      "Epoch(29) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(29) - Fold 1 - Validation Accuracy : 0.5227\n",
      "Epoch(29) - Fold 1 - Validation Utility score : 836.7689\n",
      "Epoch(29) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(29) - Fold 2 - Validation Accuracy : 0.5111\n",
      "Epoch(29) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(29) - Fold 3 - Validation Accuracy : 0.5104\n",
      "Epoch(29) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 4 - Validation Loss : 0.6907\n",
      "Epoch(29) - Fold 4 - Validation Accuracy : 0.5253\n",
      "Epoch(29) - Fold 4 - Validation Utility score : 1473.2308\n",
      "Epoch(29) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(29) - GLOBAL - Validation Accuracy: 0.5182\n",
      "Epoch(29) - GLOBAL - Validation Utility score: 2689.0313\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(30) - Training Loss: 0.6898\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(30) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(30) - Fold 0 - Validation Accuracy : 0.5221\n",
      "Epoch(30) - Fold 0 - Validation Utility score : 298.7618\n",
      "Epoch(30) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(30) - Fold 1 - Validation Accuracy : 0.5219\n",
      "Epoch(30) - Fold 1 - Validation Utility score : 864.7490\n",
      "Epoch(30) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(30) - Fold 2 - Validation Accuracy : 0.5101\n",
      "Epoch(30) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(30) - Fold 3 - Validation Accuracy : 0.5100\n",
      "Epoch(30) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 4 - Validation Loss : 0.6906\n",
      "Epoch(30) - Fold 4 - Validation Accuracy : 0.5255\n",
      "Epoch(30) - Fold 4 - Validation Utility score : 1477.5116\n",
      "Epoch(30) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(30) - GLOBAL - Validation Accuracy: 0.5179\n",
      "Epoch(30) - GLOBAL - Validation Utility score: 2641.0224\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6918\n",
      "Meet Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 546061<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_125537-ibbovoi0/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_125537-ibbovoi0/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>0.68976</td></tr><tr><td>Global valid/Loss</td><td>0.69198</td></tr><tr><td>Global valid/Accuracy</td><td>0.5179</td></tr><tr><td>Global valid/Utility</td><td>2641.02235</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>0.69171</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>0.52206</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>298.7618</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>0.69097</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>0.52191</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>864.74895</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>0.69328</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>0.51011</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>0.69338</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>0.50995</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>0.69059</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>0.52548</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>1477.5116</td></tr><tr><td>Best accuracy</td><td>0.51782</td></tr><tr><td>Best utility</td><td>2680.6004</td></tr><tr><td>_runtime</td><td>2150</td></tr><tr><td>_timestamp</td><td>1613478687</td></tr><tr><td>_step</td><td>30</td></tr><tr><td>Final utility score</td><td>{'utility_score': 26...</td></tr><tr><td>Batch size</td><td>58941</td></tr><tr><td>Patience</td><td>5</td></tr><tr><td>Number of epochs</td><td>1000</td></tr><tr><td>Best epoch</td><td>25</td></tr><tr><td>Number of parameters per layer</td><td>[8384, 64, 2048, 32,...</td></tr><tr><td>Model architecture</td><td>MLP(<BR>  (AEncoder)...</td></tr><tr><td>comment</td><td>All folds MLP with a...</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>█▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Loss</td><td>█▅▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Accuracy</td><td>▁▃▄▄▃▄▅▆▇▇▇████████████████████</td></tr><tr><td>Global valid/Utility</td><td>▁▂▄▃▂▄▅▆▇█████▇▇▇▇▇▇▇▆▇▇▇▇▇▆▇▇▆</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>█▅▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>▁▃▃▃▂▄▅▆▇██▇█▇█▇▇▇▇▇▇▇▇▇▆▆▇▆▇▇▇</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>▁▁▂▁▂▅▆▆████▇█▆▅▆▅▅▅▅▅▄▅▄▄▅▄▅▅▄</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>█▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>▁▃▄▃▂▃▅▆▆▇▇▇█▇▇█▇██▇███▇▇██▇▇▇▇</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>▂▃▅▂▁▂▄▆▆▇██▇▇▇▇▇▇▇▇▇▇█▇▇▇▆▇▆▆▆</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▂▂▂▂▂▂▂</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>▁▄▅▄▃▄▅▄▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▆▇█▇▇█▇</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>█▄▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>▁▂▅▄▃▄▅▆▅▆▇▇████▇██▇████▇▇▇▆▇▇▇</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>▁▁█▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>█▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>▁▃▄▄▄▅▅▆▇▇▇▇▇▇█▇█▇████▇████████</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>▁▂▃▄▃▅▆▆▆██████▇▇▇▇▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>Best accuracy</td><td>▁▃▄▄▅▆▇▇▇█████████████</td></tr><tr><td>Best utility</td><td>▁▂▄▃▅▆▇█████▇▇▇▇▇▇▆▇▇▇</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 156 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">robust-sweep-12</strong>: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/ibbovoi0\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/ibbovoi0</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training summary:\n",
      "{'utility_score': 2680.600395558561, 'utility_scores': [325.43298311656844, 959.8701907565696, -0.0, -0.0, 1395.2972216854232], 'utility_score_std': 554.4344957364251, 'accuracy_scores': [0.5204178537511871, 0.523004563004563, 0.5095605248161702, 0.5115228769204795, 0.524602056627694]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ga0zxbzk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leakyrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 58472\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.449672691047448\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001148847281352236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_autoenc: encoder\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 4.862391473879987e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">jolly-sweep-13</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/ga0zxbzk\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/ga0zxbzk</a><br/>\n",
       "                Run data is saved locally in <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_133135-ga0zxbzk</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Run config :\n",
      "config: {'activation_function': 'leakyrelu', 'batch_size': 58472, 'dropout': 0.449672691047448, 'learning_rate': 0.001148847281352236, 'use_autoenc': 'encoder', 'weight_decay': 4.862391473879987e-05, 'epochs': 1000}\n",
      "Epoch(0) - Training Loss: 0.7708\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(0) - Fold 0 - Validation Loss : 0.6948\n",
      "Epoch(0) - Fold 0 - Validation Accuracy : 0.5094\n",
      "Epoch(0) - Fold 0 - Validation Utility score : 27.1812\n",
      "Epoch(0) - Fold 1 - Validation Loss : 0.6947\n",
      "Epoch(0) - Fold 1 - Validation Accuracy : 0.5028\n",
      "Epoch(0) - Fold 1 - Validation Utility score : 160.1190\n",
      "Epoch(0) - Fold 2 - Validation Loss : 0.6964\n",
      "Epoch(0) - Fold 2 - Validation Accuracy : 0.5003\n",
      "Epoch(0) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 3 - Validation Loss : 0.6958\n",
      "Epoch(0) - Fold 3 - Validation Accuracy : 0.4986\n",
      "Epoch(0) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 4 - Validation Loss : 0.6954\n",
      "Epoch(0) - Fold 4 - Validation Accuracy : 0.4987\n",
      "Epoch(0) - Fold 4 - Validation Utility score : 64.0396\n",
      "Epoch(0) - GLOBAL - Validation Loss: 0.6954\n",
      "Epoch(0) - GLOBAL - Validation Accuracy: 0.5020\n",
      "Epoch(0) - GLOBAL - Validation Utility score: 251.3398\n",
      "Saving model corresponding to last_utility_score == 251.33977424309876\n",
      "\n",
      "\n",
      "Epoch(1) - Training Loss: 0.7307\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(1) - Fold 0 - Validation Loss : 0.6935\n",
      "Epoch(1) - Fold 0 - Validation Accuracy : 0.5105\n",
      "Epoch(1) - Fold 0 - Validation Utility score : 1.4725\n",
      "Epoch(1) - Fold 1 - Validation Loss : 0.6935\n",
      "Epoch(1) - Fold 1 - Validation Accuracy : 0.5068\n",
      "Epoch(1) - Fold 1 - Validation Utility score : 488.9340\n",
      "Epoch(1) - Fold 2 - Validation Loss : 0.6946\n",
      "Epoch(1) - Fold 2 - Validation Accuracy : 0.5038\n",
      "Epoch(1) - Fold 2 - Validation Utility score : 0.3362\n",
      "Epoch(1) - Fold 3 - Validation Loss : 0.6942\n",
      "Epoch(1) - Fold 3 - Validation Accuracy : 0.5015\n",
      "Epoch(1) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 4 - Validation Loss : 0.6935\n",
      "Epoch(1) - Fold 4 - Validation Accuracy : 0.5053\n",
      "Epoch(1) - Fold 4 - Validation Utility score : 133.2692\n",
      "Epoch(1) - GLOBAL - Validation Loss: 0.6938\n",
      "Epoch(1) - GLOBAL - Validation Accuracy: 0.5056\n",
      "Epoch(1) - GLOBAL - Validation Utility score: 624.0119\n",
      "Saving model corresponding to last_utility_score == 624.0118946838037\n",
      "\n",
      "\n",
      "Epoch(2) - Training Loss: 0.7071\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(2) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(2) - Fold 0 - Validation Accuracy : 0.5110\n",
      "Epoch(2) - Fold 0 - Validation Utility score : 137.6251\n",
      "Epoch(2) - Fold 1 - Validation Loss : 0.6929\n",
      "Epoch(2) - Fold 1 - Validation Accuracy : 0.5082\n",
      "Epoch(2) - Fold 1 - Validation Utility score : 527.6041\n",
      "Epoch(2) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(2) - Fold 2 - Validation Accuracy : 0.5049\n",
      "Epoch(2) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(2) - Fold 3 - Validation Accuracy : 0.5061\n",
      "Epoch(2) - Fold 3 - Validation Utility score : 88.5915\n",
      "Epoch(2) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(2) - Fold 4 - Validation Accuracy : 0.5113\n",
      "Epoch(2) - Fold 4 - Validation Utility score : 445.5440\n",
      "Epoch(2) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(2) - GLOBAL - Validation Accuracy: 0.5083\n",
      "Epoch(2) - GLOBAL - Validation Utility score: 1199.3648\n",
      "Saving model corresponding to last_utility_score == 1199.3647787749512\n",
      "\n",
      "\n",
      "Epoch(3) - Training Loss: 0.6981\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(3) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(3) - Fold 0 - Validation Accuracy : 0.5120\n",
      "Epoch(3) - Fold 0 - Validation Utility score : 106.2464\n",
      "Epoch(3) - Fold 1 - Validation Loss : 0.6929\n",
      "Epoch(3) - Fold 1 - Validation Accuracy : 0.5084\n",
      "Epoch(3) - Fold 1 - Validation Utility score : 310.8398\n",
      "Epoch(3) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(3) - Fold 2 - Validation Accuracy : 0.5057\n",
      "Epoch(3) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(3) - Fold 3 - Validation Accuracy : 0.5022\n",
      "Epoch(3) - Fold 3 - Validation Utility score : 29.4341\n",
      "Epoch(3) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(3) - Fold 4 - Validation Accuracy : 0.5098\n",
      "Epoch(3) - Fold 4 - Validation Utility score : 427.3774\n",
      "Epoch(3) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(3) - GLOBAL - Validation Accuracy: 0.5076\n",
      "Epoch(3) - GLOBAL - Validation Utility score: 873.8977\n",
      "Saving model corresponding to last_utility_score == 873.8977359881953\n",
      "\n",
      "\n",
      "Epoch(4) - Training Loss: 0.6948\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(4) - Fold 0 - Validation Loss : 0.6928\n",
      "Epoch(4) - Fold 0 - Validation Accuracy : 0.5149\n",
      "Epoch(4) - Fold 0 - Validation Utility score : 228.1328\n",
      "Epoch(4) - Fold 1 - Validation Loss : 0.6929\n",
      "Epoch(4) - Fold 1 - Validation Accuracy : 0.5097\n",
      "Epoch(4) - Fold 1 - Validation Utility score : 262.3428\n",
      "Epoch(4) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(4) - Fold 2 - Validation Accuracy : 0.5046\n",
      "Epoch(4) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(4) - Fold 3 - Validation Accuracy : 0.5033\n",
      "Epoch(4) - Fold 3 - Validation Utility score : 8.8455\n",
      "Epoch(4) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(4) - Fold 4 - Validation Accuracy : 0.5116\n",
      "Epoch(4) - Fold 4 - Validation Utility score : 765.9367\n",
      "Epoch(4) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(4) - GLOBAL - Validation Accuracy: 0.5088\n",
      "Epoch(4) - GLOBAL - Validation Utility score: 1265.2578\n",
      "Intermediate early stopping : vepoch_loss = 0.6929, the_last_loss=0.6929\n",
      "\n",
      "\n",
      "Epoch(5) - Training Loss: 0.6937\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(5) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(5) - Fold 0 - Validation Accuracy : 0.5164\n",
      "Epoch(5) - Fold 0 - Validation Utility score : 433.1613\n",
      "Epoch(5) - Fold 1 - Validation Loss : 0.6929\n",
      "Epoch(5) - Fold 1 - Validation Accuracy : 0.5091\n",
      "Epoch(5) - Fold 1 - Validation Utility score : 281.2200\n",
      "Epoch(5) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(5) - Fold 2 - Validation Accuracy : 0.5052\n",
      "Epoch(5) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(5) - Fold 3 - Validation Accuracy : 0.5041\n",
      "Epoch(5) - Fold 3 - Validation Utility score : 7.7548\n",
      "Epoch(5) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(5) - Fold 4 - Validation Accuracy : 0.5118\n",
      "Epoch(5) - Fold 4 - Validation Utility score : 764.5151\n",
      "Epoch(5) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(5) - GLOBAL - Validation Accuracy: 0.5093\n",
      "Epoch(5) - GLOBAL - Validation Utility score: 1486.6512\n",
      "Intermediate early stopping : vepoch_loss = 0.6929, the_last_loss=0.6929\n",
      "\n",
      "\n",
      "Epoch(6) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(6) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(6) - Fold 0 - Validation Accuracy : 0.5189\n",
      "Epoch(6) - Fold 0 - Validation Utility score : 438.5561\n",
      "Epoch(6) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(6) - Fold 1 - Validation Accuracy : 0.5131\n",
      "Epoch(6) - Fold 1 - Validation Utility score : 466.1227\n",
      "Epoch(6) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(6) - Fold 2 - Validation Accuracy : 0.5059\n",
      "Epoch(6) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(6) - Fold 3 - Validation Accuracy : 0.5038\n",
      "Epoch(6) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(6) - Fold 4 - Validation Accuracy : 0.5156\n",
      "Epoch(6) - Fold 4 - Validation Utility score : 979.7062\n",
      "Epoch(6) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(6) - GLOBAL - Validation Accuracy: 0.5115\n",
      "Epoch(6) - GLOBAL - Validation Utility score: 1884.3850\n",
      "Saving model corresponding to last_utility_score == 1884.3850257298263\n",
      "\n",
      "\n",
      "Epoch(7) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(7) - Fold 0 - Validation Loss : 0.6924\n",
      "Epoch(7) - Fold 0 - Validation Accuracy : 0.5223\n",
      "Epoch(7) - Fold 0 - Validation Utility score : 730.3576\n",
      "Epoch(7) - Fold 1 - Validation Loss : 0.6926\n",
      "Epoch(7) - Fold 1 - Validation Accuracy : 0.5180\n",
      "Epoch(7) - Fold 1 - Validation Utility score : 791.6463\n",
      "Epoch(7) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(7) - Fold 2 - Validation Accuracy : 0.5061\n",
      "Epoch(7) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(7) - Fold 3 - Validation Accuracy : 0.5079\n",
      "Epoch(7) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(7) - Fold 4 - Validation Accuracy : 0.5185\n",
      "Epoch(7) - Fold 4 - Validation Utility score : 1190.5918\n",
      "Epoch(7) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(7) - GLOBAL - Validation Accuracy: 0.5146\n",
      "Epoch(7) - GLOBAL - Validation Utility score: 2712.5957\n",
      "Saving model corresponding to last_utility_score == 2712.5957135753333\n",
      "\n",
      "\n",
      "Epoch(8) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(8) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(8) - Fold 0 - Validation Accuracy : 0.5225\n",
      "Epoch(8) - Fold 0 - Validation Utility score : 749.3164\n",
      "Epoch(8) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(8) - Fold 1 - Validation Accuracy : 0.5177\n",
      "Epoch(8) - Fold 1 - Validation Utility score : 829.4461\n",
      "Epoch(8) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(8) - Fold 2 - Validation Accuracy : 0.5061\n",
      "Epoch(8) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(8) - Fold 3 - Validation Accuracy : 0.5070\n",
      "Epoch(8) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(8) - Fold 4 - Validation Accuracy : 0.5196\n",
      "Epoch(8) - Fold 4 - Validation Utility score : 1170.6575\n",
      "Epoch(8) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(8) - GLOBAL - Validation Accuracy: 0.5146\n",
      "Epoch(8) - GLOBAL - Validation Utility score: 2749.4200\n",
      "Saving model corresponding to last_utility_score == 2749.419991184047\n",
      "\n",
      "\n",
      "Epoch(9) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(9) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(9) - Fold 0 - Validation Accuracy : 0.5239\n",
      "Epoch(9) - Fold 0 - Validation Utility score : 769.9228\n",
      "Epoch(9) - Fold 1 - Validation Loss : 0.6923\n",
      "Epoch(9) - Fold 1 - Validation Accuracy : 0.5202\n",
      "Epoch(9) - Fold 1 - Validation Utility score : 1028.4620\n",
      "Epoch(9) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(9) - Fold 2 - Validation Accuracy : 0.5058\n",
      "Epoch(9) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(9) - Fold 3 - Validation Accuracy : 0.5106\n",
      "Epoch(9) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(9) - Fold 4 - Validation Accuracy : 0.5205\n",
      "Epoch(9) - Fold 4 - Validation Utility score : 1357.4637\n",
      "Epoch(9) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(9) - GLOBAL - Validation Accuracy: 0.5162\n",
      "Epoch(9) - GLOBAL - Validation Utility score: 3155.8484\n",
      "Saving model corresponding to last_utility_score == 3155.8484262452284\n",
      "\n",
      "\n",
      "Epoch(10) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(10) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(10) - Fold 0 - Validation Accuracy : 0.5238\n",
      "Epoch(10) - Fold 0 - Validation Utility score : 729.7810\n",
      "Epoch(10) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(10) - Fold 1 - Validation Accuracy : 0.5209\n",
      "Epoch(10) - Fold 1 - Validation Utility score : 1032.5857\n",
      "Epoch(10) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(10) - Fold 2 - Validation Accuracy : 0.5069\n",
      "Epoch(10) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(10) - Fold 3 - Validation Accuracy : 0.5129\n",
      "Epoch(10) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(10) - Fold 4 - Validation Accuracy : 0.5211\n",
      "Epoch(10) - Fold 4 - Validation Utility score : 1402.8470\n",
      "Epoch(10) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(10) - GLOBAL - Validation Accuracy: 0.5171\n",
      "Epoch(10) - GLOBAL - Validation Utility score: 3165.2137\n",
      "Saving model corresponding to last_utility_score == 3165.2136990922654\n",
      "\n",
      "\n",
      "Epoch(11) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(11) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(11) - Fold 0 - Validation Accuracy : 0.5230\n",
      "Epoch(11) - Fold 0 - Validation Utility score : 554.5457\n",
      "Epoch(11) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(11) - Fold 1 - Validation Accuracy : 0.5226\n",
      "Epoch(11) - Fold 1 - Validation Utility score : 1077.1115\n",
      "Epoch(11) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(11) - Fold 2 - Validation Accuracy : 0.5074\n",
      "Epoch(11) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(11) - Fold 3 - Validation Accuracy : 0.5138\n",
      "Epoch(11) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(11) - Fold 4 - Validation Accuracy : 0.5220\n",
      "Epoch(11) - Fold 4 - Validation Utility score : 1385.3166\n",
      "Epoch(11) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(11) - GLOBAL - Validation Accuracy: 0.5178\n",
      "Epoch(11) - GLOBAL - Validation Utility score: 3016.9738\n",
      "Saving model corresponding to last_utility_score == 3016.973828582682\n",
      "\n",
      "\n",
      "Epoch(12) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(12) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(12) - Fold 0 - Validation Accuracy : 0.5235\n",
      "Epoch(12) - Fold 0 - Validation Utility score : 514.5516\n",
      "Epoch(12) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(12) - Fold 1 - Validation Accuracy : 0.5221\n",
      "Epoch(12) - Fold 1 - Validation Utility score : 1003.0351\n",
      "Epoch(12) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(12) - Fold 2 - Validation Accuracy : 0.5080\n",
      "Epoch(12) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(12) - Fold 3 - Validation Accuracy : 0.5138\n",
      "Epoch(12) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(12) - Fold 4 - Validation Accuracy : 0.5229\n",
      "Epoch(12) - Fold 4 - Validation Utility score : 1468.8615\n",
      "Epoch(12) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(12) - GLOBAL - Validation Accuracy: 0.5180\n",
      "Epoch(12) - GLOBAL - Validation Utility score: 2986.4482\n",
      "Saving model corresponding to last_utility_score == 2986.448180516787\n",
      "\n",
      "\n",
      "Epoch(13) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(13) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(13) - Fold 0 - Validation Accuracy : 0.5229\n",
      "Epoch(13) - Fold 0 - Validation Utility score : 609.7996\n",
      "Epoch(13) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(13) - Fold 1 - Validation Accuracy : 0.5223\n",
      "Epoch(13) - Fold 1 - Validation Utility score : 1139.2913\n",
      "Epoch(13) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(13) - Fold 2 - Validation Accuracy : 0.5082\n",
      "Epoch(13) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(13) - Fold 3 - Validation Accuracy : 0.5127\n",
      "Epoch(13) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(13) - Fold 4 - Validation Accuracy : 0.5235\n",
      "Epoch(13) - Fold 4 - Validation Utility score : 1367.2917\n",
      "Epoch(13) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(13) - GLOBAL - Validation Accuracy: 0.5179\n",
      "Epoch(13) - GLOBAL - Validation Utility score: 3116.3827\n",
      "Saving model corresponding to last_utility_score == 3116.3827095915653\n",
      "\n",
      "\n",
      "Epoch(14) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(14) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(14) - Fold 0 - Validation Accuracy : 0.5232\n",
      "Epoch(14) - Fold 0 - Validation Utility score : 533.3499\n",
      "Epoch(14) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(14) - Fold 1 - Validation Accuracy : 0.5220\n",
      "Epoch(14) - Fold 1 - Validation Utility score : 1075.3249\n",
      "Epoch(14) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(14) - Fold 2 - Validation Accuracy : 0.5081\n",
      "Epoch(14) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(14) - Fold 3 - Validation Accuracy : 0.5125\n",
      "Epoch(14) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(14) - Fold 4 - Validation Accuracy : 0.5235\n",
      "Epoch(14) - Fold 4 - Validation Utility score : 1385.0673\n",
      "Epoch(14) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(14) - GLOBAL - Validation Accuracy: 0.5178\n",
      "Epoch(14) - GLOBAL - Validation Utility score: 2993.7422\n",
      "Saving model corresponding to last_utility_score == 2993.7422198272534\n",
      "\n",
      "\n",
      "Epoch(15) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(15) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(15) - Fold 0 - Validation Accuracy : 0.5224\n",
      "Epoch(15) - Fold 0 - Validation Utility score : 452.0945\n",
      "Epoch(15) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(15) - Fold 1 - Validation Accuracy : 0.5237\n",
      "Epoch(15) - Fold 1 - Validation Utility score : 1121.9196\n",
      "Epoch(15) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(15) - Fold 2 - Validation Accuracy : 0.5078\n",
      "Epoch(15) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(15) - Fold 3 - Validation Accuracy : 0.5130\n",
      "Epoch(15) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(15) - Fold 4 - Validation Accuracy : 0.5240\n",
      "Epoch(15) - Fold 4 - Validation Utility score : 1386.5987\n",
      "Epoch(15) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(15) - GLOBAL - Validation Accuracy: 0.5182\n",
      "Epoch(15) - GLOBAL - Validation Utility score: 2960.6127\n",
      "Saving model corresponding to last_utility_score == 2960.612743874899\n",
      "\n",
      "\n",
      "Epoch(16) - Training Loss: 0.6915\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(16) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(16) - Fold 0 - Validation Accuracy : 0.5223\n",
      "Epoch(16) - Fold 0 - Validation Utility score : 468.1462\n",
      "Epoch(16) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(16) - Fold 1 - Validation Accuracy : 0.5224\n",
      "Epoch(16) - Fold 1 - Validation Utility score : 1072.0128\n",
      "Epoch(16) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(16) - Fold 2 - Validation Accuracy : 0.5080\n",
      "Epoch(16) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(16) - Fold 3 - Validation Accuracy : 0.5125\n",
      "Epoch(16) - Fold 3 - Validation Utility score : 7.5297\n",
      "Epoch(16) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(16) - Fold 4 - Validation Accuracy : 0.5243\n",
      "Epoch(16) - Fold 4 - Validation Utility score : 1249.6068\n",
      "Epoch(16) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(16) - GLOBAL - Validation Accuracy: 0.5179\n",
      "Epoch(16) - GLOBAL - Validation Utility score: 2797.2955\n",
      "Saving model corresponding to last_utility_score == 2797.2954963330085\n",
      "\n",
      "\n",
      "Epoch(17) - Training Loss: 0.6913\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(17) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(17) - Fold 0 - Validation Accuracy : 0.5220\n",
      "Epoch(17) - Fold 0 - Validation Utility score : 401.7359\n",
      "Epoch(17) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(17) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(17) - Fold 1 - Validation Utility score : 1125.4761\n",
      "Epoch(17) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(17) - Fold 2 - Validation Accuracy : 0.5084\n",
      "Epoch(17) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(17) - Fold 3 - Validation Accuracy : 0.5132\n",
      "Epoch(17) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(17) - Fold 4 - Validation Accuracy : 0.5250\n",
      "Epoch(17) - Fold 4 - Validation Utility score : 1352.3054\n",
      "Epoch(17) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(17) - GLOBAL - Validation Accuracy: 0.5185\n",
      "Epoch(17) - GLOBAL - Validation Utility score: 2879.5174\n",
      "Saving model corresponding to last_utility_score == 2879.5174449360784\n",
      "\n",
      "\n",
      "Epoch(18) - Training Loss: 0.6912\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(18) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(18) - Fold 0 - Validation Accuracy : 0.5227\n",
      "Epoch(18) - Fold 0 - Validation Utility score : 365.5629\n",
      "Epoch(18) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(18) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(18) - Fold 1 - Validation Utility score : 1173.8891\n",
      "Epoch(18) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(18) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(18) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(18) - Fold 3 - Validation Accuracy : 0.5131\n",
      "Epoch(18) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 4 - Validation Loss : 0.6912\n",
      "Epoch(18) - Fold 4 - Validation Accuracy : 0.5251\n",
      "Epoch(18) - Fold 4 - Validation Utility score : 1409.3011\n",
      "Epoch(18) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(18) - GLOBAL - Validation Accuracy: 0.5186\n",
      "Epoch(18) - GLOBAL - Validation Utility score: 2948.7531\n",
      "Saving model corresponding to last_utility_score == 2948.7530830633186\n",
      "\n",
      "\n",
      "Epoch(19) - Training Loss: 0.6912\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(19) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(19) - Fold 0 - Validation Accuracy : 0.5226\n",
      "Epoch(19) - Fold 0 - Validation Utility score : 350.1330\n",
      "Epoch(19) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(19) - Fold 1 - Validation Accuracy : 0.5223\n",
      "Epoch(19) - Fold 1 - Validation Utility score : 1102.3998\n",
      "Epoch(19) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(19) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(19) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(19) - Fold 3 - Validation Accuracy : 0.5131\n",
      "Epoch(19) - Fold 3 - Validation Utility score : 0.9746\n",
      "Epoch(19) - Fold 4 - Validation Loss : 0.6911\n",
      "Epoch(19) - Fold 4 - Validation Accuracy : 0.5247\n",
      "Epoch(19) - Fold 4 - Validation Utility score : 1339.8582\n",
      "Epoch(19) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(19) - GLOBAL - Validation Accuracy: 0.5182\n",
      "Epoch(19) - GLOBAL - Validation Utility score: 2793.3656\n",
      "Saving model corresponding to last_utility_score == 2793.365585592614\n",
      "\n",
      "\n",
      "Epoch(20) - Training Loss: 0.6910\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(20) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(20) - Fold 0 - Validation Accuracy : 0.5225\n",
      "Epoch(20) - Fold 0 - Validation Utility score : 343.5036\n",
      "Epoch(20) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(20) - Fold 1 - Validation Accuracy : 0.5233\n",
      "Epoch(20) - Fold 1 - Validation Utility score : 1035.7568\n",
      "Epoch(20) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(20) - Fold 2 - Validation Accuracy : 0.5096\n",
      "Epoch(20) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(20) - Fold 3 - Validation Accuracy : 0.5135\n",
      "Epoch(20) - Fold 3 - Validation Utility score : 0.8966\n",
      "Epoch(20) - Fold 4 - Validation Loss : 0.6910\n",
      "Epoch(20) - Fold 4 - Validation Accuracy : 0.5254\n",
      "Epoch(20) - Fold 4 - Validation Utility score : 1352.8275\n",
      "Epoch(20) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(20) - GLOBAL - Validation Accuracy: 0.5188\n",
      "Epoch(20) - GLOBAL - Validation Utility score: 2732.9845\n",
      "Saving model corresponding to last_utility_score == 2732.984469391502\n",
      "\n",
      "\n",
      "Epoch(21) - Training Loss: 0.6910\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(21) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(21) - Fold 0 - Validation Accuracy : 0.5223\n",
      "Epoch(21) - Fold 0 - Validation Utility score : 310.1787\n",
      "Epoch(21) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(21) - Fold 1 - Validation Accuracy : 0.5236\n",
      "Epoch(21) - Fold 1 - Validation Utility score : 1011.7209\n",
      "Epoch(21) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(21) - Fold 2 - Validation Accuracy : 0.5095\n",
      "Epoch(21) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(21) - Fold 3 - Validation Accuracy : 0.5130\n",
      "Epoch(21) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 4 - Validation Loss : 0.6910\n",
      "Epoch(21) - Fold 4 - Validation Accuracy : 0.5258\n",
      "Epoch(21) - Fold 4 - Validation Utility score : 1386.1801\n",
      "Epoch(21) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(21) - GLOBAL - Validation Accuracy: 0.5188\n",
      "Epoch(21) - GLOBAL - Validation Utility score: 2708.0798\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(22) - Training Loss: 0.6909\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(22) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(22) - Fold 0 - Validation Accuracy : 0.5229\n",
      "Epoch(22) - Fold 0 - Validation Utility score : 364.5868\n",
      "Epoch(22) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(22) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(22) - Fold 1 - Validation Utility score : 977.5625\n",
      "Epoch(22) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(22) - Fold 2 - Validation Accuracy : 0.5091\n",
      "Epoch(22) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(22) - Fold 3 - Validation Accuracy : 0.5125\n",
      "Epoch(22) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 4 - Validation Loss : 0.6909\n",
      "Epoch(22) - Fold 4 - Validation Accuracy : 0.5249\n",
      "Epoch(22) - Fold 4 - Validation Utility score : 1362.2016\n",
      "Epoch(22) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(22) - GLOBAL - Validation Accuracy: 0.5186\n",
      "Epoch(22) - GLOBAL - Validation Utility score: 2704.3509\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(23) - Training Loss: 0.6907\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(23) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(23) - Fold 0 - Validation Accuracy : 0.5222\n",
      "Epoch(23) - Fold 0 - Validation Utility score : 340.2997\n",
      "Epoch(23) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(23) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(23) - Fold 1 - Validation Utility score : 1056.8814\n",
      "Epoch(23) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(23) - Fold 2 - Validation Accuracy : 0.5082\n",
      "Epoch(23) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(23) - Fold 3 - Validation Accuracy : 0.5110\n",
      "Epoch(23) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 4 - Validation Loss : 0.6909\n",
      "Epoch(23) - Fold 4 - Validation Accuracy : 0.5254\n",
      "Epoch(23) - Fold 4 - Validation Utility score : 1433.0118\n",
      "Epoch(23) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(23) - GLOBAL - Validation Accuracy: 0.5181\n",
      "Epoch(23) - GLOBAL - Validation Utility score: 2830.1930\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(24) - Training Loss: 0.6906\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(24) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(24) - Fold 0 - Validation Accuracy : 0.5212\n",
      "Epoch(24) - Fold 0 - Validation Utility score : 279.0299\n",
      "Epoch(24) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(24) - Fold 1 - Validation Accuracy : 0.5223\n",
      "Epoch(24) - Fold 1 - Validation Utility score : 890.2752\n",
      "Epoch(24) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(24) - Fold 2 - Validation Accuracy : 0.5085\n",
      "Epoch(24) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(24) - Fold 3 - Validation Accuracy : 0.5116\n",
      "Epoch(24) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 4 - Validation Loss : 0.6908\n",
      "Epoch(24) - Fold 4 - Validation Accuracy : 0.5257\n",
      "Epoch(24) - Fold 4 - Validation Utility score : 1363.9552\n",
      "Epoch(24) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(24) - GLOBAL - Validation Accuracy: 0.5178\n",
      "Epoch(24) - GLOBAL - Validation Utility score: 2533.2602\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(25) - Training Loss: 0.6905\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(25) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(25) - Fold 0 - Validation Accuracy : 0.5213\n",
      "Epoch(25) - Fold 0 - Validation Utility score : 302.2702\n",
      "Epoch(25) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(25) - Fold 1 - Validation Accuracy : 0.5226\n",
      "Epoch(25) - Fold 1 - Validation Utility score : 964.6876\n",
      "Epoch(25) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(25) - Fold 2 - Validation Accuracy : 0.5094\n",
      "Epoch(25) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(25) - Fold 3 - Validation Accuracy : 0.5109\n",
      "Epoch(25) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 4 - Validation Loss : 0.6908\n",
      "Epoch(25) - Fold 4 - Validation Accuracy : 0.5255\n",
      "Epoch(25) - Fold 4 - Validation Utility score : 1468.5361\n",
      "Epoch(25) - GLOBAL - Validation Loss: 0.6918\n",
      "Epoch(25) - GLOBAL - Validation Accuracy: 0.5179\n",
      "Epoch(25) - GLOBAL - Validation Utility score: 2735.4939\n",
      "Saving model corresponding to last_utility_score == 2735.493918680001\n",
      "\n",
      "\n",
      "Epoch(26) - Training Loss: 0.6903\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(26) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(26) - Fold 0 - Validation Accuracy : 0.5209\n",
      "Epoch(26) - Fold 0 - Validation Utility score : 267.6407\n",
      "Epoch(26) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(26) - Fold 1 - Validation Accuracy : 0.5227\n",
      "Epoch(26) - Fold 1 - Validation Utility score : 1002.6586\n",
      "Epoch(26) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(26) - Fold 2 - Validation Accuracy : 0.5082\n",
      "Epoch(26) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(26) - Fold 3 - Validation Accuracy : 0.5096\n",
      "Epoch(26) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 4 - Validation Loss : 0.6908\n",
      "Epoch(26) - Fold 4 - Validation Accuracy : 0.5261\n",
      "Epoch(26) - Fold 4 - Validation Utility score : 1449.1874\n",
      "Epoch(26) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(26) - GLOBAL - Validation Accuracy: 0.5175\n",
      "Epoch(26) - GLOBAL - Validation Utility score: 2719.4868\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(27) - Training Loss: 0.6902\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(27) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(27) - Fold 0 - Validation Accuracy : 0.5214\n",
      "Epoch(27) - Fold 0 - Validation Utility score : 278.9489\n",
      "Epoch(27) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(27) - Fold 1 - Validation Accuracy : 0.5221\n",
      "Epoch(27) - Fold 1 - Validation Utility score : 866.4057\n",
      "Epoch(27) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(27) - Fold 2 - Validation Accuracy : 0.5085\n",
      "Epoch(27) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(27) - Fold 3 - Validation Accuracy : 0.5095\n",
      "Epoch(27) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 4 - Validation Loss : 0.6908\n",
      "Epoch(27) - Fold 4 - Validation Accuracy : 0.5260\n",
      "Epoch(27) - Fold 4 - Validation Utility score : 1398.8286\n",
      "Epoch(27) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(27) - GLOBAL - Validation Accuracy: 0.5175\n",
      "Epoch(27) - GLOBAL - Validation Utility score: 2544.1832\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(28) - Training Loss: 0.6901\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(28) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(28) - Fold 0 - Validation Accuracy : 0.5209\n",
      "Epoch(28) - Fold 0 - Validation Utility score : 258.6134\n",
      "Epoch(28) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(28) - Fold 1 - Validation Accuracy : 0.5225\n",
      "Epoch(28) - Fold 1 - Validation Utility score : 857.7856\n",
      "Epoch(28) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(28) - Fold 2 - Validation Accuracy : 0.5095\n",
      "Epoch(28) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(28) - Fold 3 - Validation Accuracy : 0.5105\n",
      "Epoch(28) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 4 - Validation Loss : 0.6909\n",
      "Epoch(28) - Fold 4 - Validation Accuracy : 0.5254\n",
      "Epoch(28) - Fold 4 - Validation Utility score : 1413.0745\n",
      "Epoch(28) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(28) - GLOBAL - Validation Accuracy: 0.5178\n",
      "Epoch(28) - GLOBAL - Validation Utility score: 2529.4735\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(29) - Training Loss: 0.6900\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(29) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(29) - Fold 0 - Validation Accuracy : 0.5217\n",
      "Epoch(29) - Fold 0 - Validation Utility score : 301.3625\n",
      "Epoch(29) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(29) - Fold 1 - Validation Accuracy : 0.5221\n",
      "Epoch(29) - Fold 1 - Validation Utility score : 809.6305\n",
      "Epoch(29) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(29) - Fold 2 - Validation Accuracy : 0.5118\n",
      "Epoch(29) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(29) - Fold 3 - Validation Accuracy : 0.5112\n",
      "Epoch(29) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 4 - Validation Loss : 0.6907\n",
      "Epoch(29) - Fold 4 - Validation Accuracy : 0.5263\n",
      "Epoch(29) - Fold 4 - Validation Utility score : 1546.9921\n",
      "Epoch(29) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(29) - GLOBAL - Validation Accuracy: 0.5186\n",
      "Epoch(29) - GLOBAL - Validation Utility score: 2657.9852\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(30) - Training Loss: 0.6898\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(30) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(30) - Fold 0 - Validation Accuracy : 0.5208\n",
      "Epoch(30) - Fold 0 - Validation Utility score : 241.7615\n",
      "Epoch(30) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(30) - Fold 1 - Validation Accuracy : 0.5224\n",
      "Epoch(30) - Fold 1 - Validation Utility score : 970.8342\n",
      "Epoch(30) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(30) - Fold 2 - Validation Accuracy : 0.5105\n",
      "Epoch(30) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(30) - Fold 3 - Validation Accuracy : 0.5102\n",
      "Epoch(30) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 4 - Validation Loss : 0.6907\n",
      "Epoch(30) - Fold 4 - Validation Accuracy : 0.5256\n",
      "Epoch(30) - Fold 4 - Validation Utility score : 1488.7021\n",
      "Epoch(30) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(30) - GLOBAL - Validation Accuracy: 0.5179\n",
      "Epoch(30) - GLOBAL - Validation Utility score: 2701.2978\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6918\n",
      "Meet Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 549332<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_133135-ga0zxbzk/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_133135-ga0zxbzk/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>0.6898</td></tr><tr><td>Global valid/Loss</td><td>0.69198</td></tr><tr><td>Global valid/Accuracy</td><td>0.51791</td></tr><tr><td>Global valid/Utility</td><td>2701.29784</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>0.69162</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>0.5208</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>241.76152</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>0.69108</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>0.52244</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>970.83418</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>0.69315</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>0.51054</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>0.69337</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>0.51017</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>0.69069</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>0.5256</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>1488.70215</td></tr><tr><td>Best accuracy</td><td>0.51792</td></tr><tr><td>Best utility</td><td>2735.49392</td></tr><tr><td>_runtime</td><td>2210</td></tr><tr><td>_timestamp</td><td>1613480905</td></tr><tr><td>_step</td><td>30</td></tr><tr><td>Final utility score</td><td>{'utility_score': 27...</td></tr><tr><td>Batch size</td><td>58472</td></tr><tr><td>Patience</td><td>5</td></tr><tr><td>Number of epochs</td><td>1000</td></tr><tr><td>Best epoch</td><td>25</td></tr><tr><td>Number of parameters per layer</td><td>[8384, 64, 2048, 32,...</td></tr><tr><td>Model architecture</td><td>MLP(<BR>  (AEncoder)...</td></tr><tr><td>comment</td><td>All folds MLP with a...</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>█▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Loss</td><td>█▅▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Accuracy</td><td>▁▂▄▃▄▄▅▆▆▇▇███████████████▇▇███</td></tr><tr><td>Global valid/Utility</td><td>▁▂▃▂▃▄▅▇▇███████▇▇▇▇▇▇▇▇▆▇▇▇▆▇▇</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>█▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>▁▂▂▂▄▄▆▇▇████▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>▁▁▂▂▃▅▅████▆▆▇▆▅▅▅▄▄▄▄▄▄▄▄▃▄▃▄▃</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>█▆▅▅▅▅▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>▁▂▃▃▃▃▄▆▆▇▇█▇▇▇█▇██▇████▇██▇█▇▇</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>▁▃▄▂▂▂▃▅▆▇▇▇▇█▇█▇███▇▇▇▇▆▇▇▆▆▅▇</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂▂▁▂▁▂</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>▁▃▄▄▄▄▄▅▅▄▅▅▆▆▆▆▆▆▆▆▇▇▆▆▆▇▆▆▇█▇</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>█▄▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>▁▂▄▃▃▄▃▅▅▇███▇▇█▇█████▇▇▇▇▆▆▆▇▆</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>▁▁█▃▂▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>█▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>▁▃▄▄▄▄▅▆▆▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>▁▁▃▃▄▄▅▆▆▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇██▇▇██</td></tr><tr><td>Best accuracy</td><td>▁▂▄▃▅▆▆▇▇████████████</td></tr><tr><td>Best utility</td><td>▁▂▃▂▅▇▇███████▇▇▇▇▇▇▇</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 156 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">jolly-sweep-13</strong>: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/ga0zxbzk\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/ga0zxbzk</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training summary:\n",
      "{'utility_score': 2735.493918680001, 'utility_scores': [302.27022257971663, 964.6876066925153, -0.0, -0.0, 1468.536089407769], 'utility_score_std': 580.0003993154718, 'accuracy_scores': [0.5212824765063571, 0.5225623025623025, 0.5093545530068452, 0.5108756823681693, 0.5255317650373292]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vxk09tdh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leakyrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 41442\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.42420803306174415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0011582237794864384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_autoenc: encoder\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5.8407924859980665e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">bright-sweep-14</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/vxk09tdh\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/vxk09tdh</a><br/>\n",
       "                Run data is saved locally in <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_140831-vxk09tdh</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Run config :\n",
      "config: {'activation_function': 'leakyrelu', 'batch_size': 41442, 'dropout': 0.42420803306174415, 'learning_rate': 0.0011582237794864384, 'use_autoenc': 'encoder', 'weight_decay': 5.8407924859980665e-05, 'epochs': 1000}\n",
      "Epoch(0) - Training Loss: 0.7555\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(0) - Fold 0 - Validation Loss : 0.6948\n",
      "Epoch(0) - Fold 0 - Validation Accuracy : 0.5141\n",
      "Epoch(0) - Fold 0 - Validation Utility score : 9.6131\n",
      "Epoch(0) - Fold 1 - Validation Loss : 0.6934\n",
      "Epoch(0) - Fold 1 - Validation Accuracy : 0.5098\n",
      "Epoch(0) - Fold 1 - Validation Utility score : 162.2573\n",
      "Epoch(0) - Fold 2 - Validation Loss : 0.6956\n",
      "Epoch(0) - Fold 2 - Validation Accuracy : 0.5014\n",
      "Epoch(0) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 3 - Validation Loss : 0.6955\n",
      "Epoch(0) - Fold 3 - Validation Accuracy : 0.5049\n",
      "Epoch(0) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 4 - Validation Loss : 0.6947\n",
      "Epoch(0) - Fold 4 - Validation Accuracy : 0.5028\n",
      "Epoch(0) - Fold 4 - Validation Utility score : 38.5548\n",
      "Epoch(0) - GLOBAL - Validation Loss: 0.6948\n",
      "Epoch(0) - GLOBAL - Validation Accuracy: 0.5066\n",
      "Epoch(0) - GLOBAL - Validation Utility score: 210.4252\n",
      "Saving model corresponding to last_utility_score == 210.42515137501212\n",
      "\n",
      "\n",
      "Epoch(1) - Training Loss: 0.7125\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(1) - Fold 0 - Validation Loss : 0.6928\n",
      "Epoch(1) - Fold 0 - Validation Accuracy : 0.5130\n",
      "Epoch(1) - Fold 0 - Validation Utility score : 87.0643\n",
      "Epoch(1) - Fold 1 - Validation Loss : 0.6926\n",
      "Epoch(1) - Fold 1 - Validation Accuracy : 0.5121\n",
      "Epoch(1) - Fold 1 - Validation Utility score : 848.8807\n",
      "Epoch(1) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(1) - Fold 2 - Validation Accuracy : 0.5064\n",
      "Epoch(1) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(1) - Fold 3 - Validation Accuracy : 0.5071\n",
      "Epoch(1) - Fold 3 - Validation Utility score : 151.8494\n",
      "Epoch(1) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(1) - Fold 4 - Validation Accuracy : 0.5100\n",
      "Epoch(1) - Fold 4 - Validation Utility score : 333.7485\n",
      "Epoch(1) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(1) - GLOBAL - Validation Accuracy: 0.5097\n",
      "Epoch(1) - GLOBAL - Validation Utility score: 1421.5428\n",
      "Saving model corresponding to last_utility_score == 1421.5427852006073\n",
      "\n",
      "\n",
      "Epoch(2) - Training Loss: 0.6979\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(2) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(2) - Fold 0 - Validation Accuracy : 0.5099\n",
      "Epoch(2) - Fold 0 - Validation Utility score : 43.9237\n",
      "Epoch(2) - Fold 1 - Validation Loss : 0.6929\n",
      "Epoch(2) - Fold 1 - Validation Accuracy : 0.5042\n",
      "Epoch(2) - Fold 1 - Validation Utility score : 138.6685\n",
      "Epoch(2) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(2) - Fold 2 - Validation Accuracy : 0.5025\n",
      "Epoch(2) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(2) - Fold 3 - Validation Accuracy : 0.5030\n",
      "Epoch(2) - Fold 3 - Validation Utility score : 2.2438\n",
      "Epoch(2) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(2) - Fold 4 - Validation Accuracy : 0.5084\n",
      "Epoch(2) - Fold 4 - Validation Utility score : 301.4002\n",
      "Epoch(2) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(2) - GLOBAL - Validation Accuracy: 0.5056\n",
      "Epoch(2) - GLOBAL - Validation Utility score: 486.2362\n",
      "Saving model corresponding to last_utility_score == 486.2362417032923\n",
      "\n",
      "\n",
      "Epoch(3) - Training Loss: 0.6942\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(3) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(3) - Fold 0 - Validation Accuracy : 0.5156\n",
      "Epoch(3) - Fold 0 - Validation Utility score : 392.7900\n",
      "Epoch(3) - Fold 1 - Validation Loss : 0.6929\n",
      "Epoch(3) - Fold 1 - Validation Accuracy : 0.5096\n",
      "Epoch(3) - Fold 1 - Validation Utility score : 269.2676\n",
      "Epoch(3) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(3) - Fold 2 - Validation Accuracy : 0.5067\n",
      "Epoch(3) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(3) - Fold 3 - Validation Accuracy : 0.5028\n",
      "Epoch(3) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(3) - Fold 4 - Validation Accuracy : 0.5135\n",
      "Epoch(3) - Fold 4 - Validation Utility score : 1002.6700\n",
      "Epoch(3) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(3) - GLOBAL - Validation Accuracy: 0.5096\n",
      "Epoch(3) - GLOBAL - Validation Utility score: 1664.7276\n",
      "Saving model corresponding to last_utility_score == 1664.7276412814686\n",
      "\n",
      "\n",
      "Epoch(4) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(4) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(4) - Fold 0 - Validation Accuracy : 0.5181\n",
      "Epoch(4) - Fold 0 - Validation Utility score : 678.0066\n",
      "Epoch(4) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(4) - Fold 1 - Validation Accuracy : 0.5139\n",
      "Epoch(4) - Fold 1 - Validation Utility score : 438.3221\n",
      "Epoch(4) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(4) - Fold 2 - Validation Accuracy : 0.5058\n",
      "Epoch(4) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(4) - Fold 3 - Validation Accuracy : 0.5069\n",
      "Epoch(4) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(4) - Fold 4 - Validation Accuracy : 0.5146\n",
      "Epoch(4) - Fold 4 - Validation Utility score : 993.4824\n",
      "Epoch(4) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(4) - GLOBAL - Validation Accuracy: 0.5119\n",
      "Epoch(4) - GLOBAL - Validation Utility score: 2109.8111\n",
      "Saving model corresponding to last_utility_score == 2109.811068779397\n",
      "\n",
      "\n",
      "Epoch(5) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(5) - Fold 0 - Validation Loss : 0.6924\n",
      "Epoch(5) - Fold 0 - Validation Accuracy : 0.5202\n",
      "Epoch(5) - Fold 0 - Validation Utility score : 676.2994\n",
      "Epoch(5) - Fold 1 - Validation Loss : 0.6926\n",
      "Epoch(5) - Fold 1 - Validation Accuracy : 0.5170\n",
      "Epoch(5) - Fold 1 - Validation Utility score : 749.7737\n",
      "Epoch(5) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(5) - Fold 2 - Validation Accuracy : 0.5049\n",
      "Epoch(5) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(5) - Fold 3 - Validation Accuracy : 0.5070\n",
      "Epoch(5) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(5) - Fold 4 - Validation Accuracy : 0.5178\n",
      "Epoch(5) - Fold 4 - Validation Utility score : 1132.7483\n",
      "Epoch(5) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(5) - GLOBAL - Validation Accuracy: 0.5134\n",
      "Epoch(5) - GLOBAL - Validation Utility score: 2558.8214\n",
      "Saving model corresponding to last_utility_score == 2558.8213579730336\n",
      "\n",
      "\n",
      "Epoch(6) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(6) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(6) - Fold 0 - Validation Accuracy : 0.5225\n",
      "Epoch(6) - Fold 0 - Validation Utility score : 608.1845\n",
      "Epoch(6) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(6) - Fold 1 - Validation Accuracy : 0.5200\n",
      "Epoch(6) - Fold 1 - Validation Utility score : 905.2710\n",
      "Epoch(6) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(6) - Fold 2 - Validation Accuracy : 0.5058\n",
      "Epoch(6) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(6) - Fold 3 - Validation Accuracy : 0.5093\n",
      "Epoch(6) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(6) - Fold 4 - Validation Accuracy : 0.5201\n",
      "Epoch(6) - Fold 4 - Validation Utility score : 1259.5629\n",
      "Epoch(6) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(6) - GLOBAL - Validation Accuracy: 0.5155\n",
      "Epoch(6) - GLOBAL - Validation Utility score: 2773.0185\n",
      "Saving model corresponding to last_utility_score == 2773.0184645334084\n",
      "\n",
      "\n",
      "Epoch(7) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(7) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(7) - Fold 0 - Validation Accuracy : 0.5241\n",
      "Epoch(7) - Fold 0 - Validation Utility score : 732.2460\n",
      "Epoch(7) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(7) - Fold 1 - Validation Accuracy : 0.5223\n",
      "Epoch(7) - Fold 1 - Validation Utility score : 1138.6942\n",
      "Epoch(7) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(7) - Fold 2 - Validation Accuracy : 0.5071\n",
      "Epoch(7) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(7) - Fold 3 - Validation Accuracy : 0.5127\n",
      "Epoch(7) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(7) - Fold 4 - Validation Accuracy : 0.5214\n",
      "Epoch(7) - Fold 4 - Validation Utility score : 1444.0744\n",
      "Epoch(7) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(7) - GLOBAL - Validation Accuracy: 0.5175\n",
      "Epoch(7) - GLOBAL - Validation Utility score: 3315.0146\n",
      "Saving model corresponding to last_utility_score == 3315.0146350161376\n",
      "\n",
      "\n",
      "Epoch(8) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(8) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(8) - Fold 0 - Validation Accuracy : 0.5250\n",
      "Epoch(8) - Fold 0 - Validation Utility score : 610.2440\n",
      "Epoch(8) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(8) - Fold 1 - Validation Accuracy : 0.5227\n",
      "Epoch(8) - Fold 1 - Validation Utility score : 1046.4495\n",
      "Epoch(8) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(8) - Fold 2 - Validation Accuracy : 0.5073\n",
      "Epoch(8) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(8) - Fold 3 - Validation Accuracy : 0.5128\n",
      "Epoch(8) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(8) - Fold 4 - Validation Accuracy : 0.5223\n",
      "Epoch(8) - Fold 4 - Validation Utility score : 1512.2461\n",
      "Epoch(8) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(8) - GLOBAL - Validation Accuracy: 0.5180\n",
      "Epoch(8) - GLOBAL - Validation Utility score: 3168.9396\n",
      "Saving model corresponding to last_utility_score == 3168.9396245648195\n",
      "\n",
      "\n",
      "Epoch(9) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(9) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(9) - Fold 0 - Validation Accuracy : 0.5243\n",
      "Epoch(9) - Fold 0 - Validation Utility score : 617.8696\n",
      "Epoch(9) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(9) - Fold 1 - Validation Accuracy : 0.5243\n",
      "Epoch(9) - Fold 1 - Validation Utility score : 1151.7515\n",
      "Epoch(9) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(9) - Fold 2 - Validation Accuracy : 0.5078\n",
      "Epoch(9) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 3 - Validation Loss : 0.6926\n",
      "Epoch(9) - Fold 3 - Validation Accuracy : 0.5130\n",
      "Epoch(9) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(9) - Fold 4 - Validation Accuracy : 0.5221\n",
      "Epoch(9) - Fold 4 - Validation Utility score : 1390.5658\n",
      "Epoch(9) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(9) - GLOBAL - Validation Accuracy: 0.5183\n",
      "Epoch(9) - GLOBAL - Validation Utility score: 3160.1869\n",
      "Saving model corresponding to last_utility_score == 3160.1869386363155\n",
      "\n",
      "\n",
      "Epoch(10) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(10) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(10) - Fold 0 - Validation Accuracy : 0.5242\n",
      "Epoch(10) - Fold 0 - Validation Utility score : 611.7100\n",
      "Epoch(10) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(10) - Fold 1 - Validation Accuracy : 0.5229\n",
      "Epoch(10) - Fold 1 - Validation Utility score : 1100.5039\n",
      "Epoch(10) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(10) - Fold 2 - Validation Accuracy : 0.5075\n",
      "Epoch(10) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 3 - Validation Loss : 0.6926\n",
      "Epoch(10) - Fold 3 - Validation Accuracy : 0.5126\n",
      "Epoch(10) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(10) - Fold 4 - Validation Accuracy : 0.5239\n",
      "Epoch(10) - Fold 4 - Validation Utility score : 1414.2721\n",
      "Epoch(10) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(10) - GLOBAL - Validation Accuracy: 0.5182\n",
      "Epoch(10) - GLOBAL - Validation Utility score: 3126.4860\n",
      "Saving model corresponding to last_utility_score == 3126.485958384116\n",
      "\n",
      "\n",
      "Epoch(11) - Training Loss: 0.6914\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(11) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(11) - Fold 0 - Validation Accuracy : 0.5234\n",
      "Epoch(11) - Fold 0 - Validation Utility score : 514.6796\n",
      "Epoch(11) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(11) - Fold 1 - Validation Accuracy : 0.5250\n",
      "Epoch(11) - Fold 1 - Validation Utility score : 1031.6998\n",
      "Epoch(11) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(11) - Fold 2 - Validation Accuracy : 0.5084\n",
      "Epoch(11) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 3 - Validation Loss : 0.6926\n",
      "Epoch(11) - Fold 3 - Validation Accuracy : 0.5125\n",
      "Epoch(11) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(11) - Fold 4 - Validation Accuracy : 0.5228\n",
      "Epoch(11) - Fold 4 - Validation Utility score : 1375.8424\n",
      "Epoch(11) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(11) - GLOBAL - Validation Accuracy: 0.5184\n",
      "Epoch(11) - GLOBAL - Validation Utility score: 2922.2217\n",
      "Saving model corresponding to last_utility_score == 2922.2216861275365\n",
      "\n",
      "\n",
      "Epoch(12) - Training Loss: 0.6913\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(12) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(12) - Fold 0 - Validation Accuracy : 0.5241\n",
      "Epoch(12) - Fold 0 - Validation Utility score : 485.7233\n",
      "Epoch(12) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(12) - Fold 1 - Validation Accuracy : 0.5246\n",
      "Epoch(12) - Fold 1 - Validation Utility score : 1056.0827\n",
      "Epoch(12) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(12) - Fold 2 - Validation Accuracy : 0.5086\n",
      "Epoch(12) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(12) - Fold 3 - Validation Accuracy : 0.5133\n",
      "Epoch(12) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(12) - Fold 4 - Validation Accuracy : 0.5237\n",
      "Epoch(12) - Fold 4 - Validation Utility score : 1365.0921\n",
      "Epoch(12) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(12) - GLOBAL - Validation Accuracy: 0.5189\n",
      "Epoch(12) - GLOBAL - Validation Utility score: 2906.8980\n",
      "Saving model corresponding to last_utility_score == 2906.8980443562396\n",
      "\n",
      "\n",
      "Epoch(13) - Training Loss: 0.6912\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(13) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(13) - Fold 0 - Validation Accuracy : 0.5235\n",
      "Epoch(13) - Fold 0 - Validation Utility score : 375.7986\n",
      "Epoch(13) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(13) - Fold 1 - Validation Accuracy : 0.5243\n",
      "Epoch(13) - Fold 1 - Validation Utility score : 1147.1654\n",
      "Epoch(13) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(13) - Fold 2 - Validation Accuracy : 0.5101\n",
      "Epoch(13) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(13) - Fold 3 - Validation Accuracy : 0.5135\n",
      "Epoch(13) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 4 - Validation Loss : 0.6912\n",
      "Epoch(13) - Fold 4 - Validation Accuracy : 0.5242\n",
      "Epoch(13) - Fold 4 - Validation Utility score : 1369.6115\n",
      "Epoch(13) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(13) - GLOBAL - Validation Accuracy: 0.5191\n",
      "Epoch(13) - GLOBAL - Validation Utility score: 2892.5755\n",
      "Saving model corresponding to last_utility_score == 2892.5755152550582\n",
      "\n",
      "\n",
      "Epoch(14) - Training Loss: 0.6910\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(14) - Fold 0 - Validation Loss : 0.6913\n",
      "Epoch(14) - Fold 0 - Validation Accuracy : 0.5218\n",
      "Epoch(14) - Fold 0 - Validation Utility score : 379.7799\n",
      "Epoch(14) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(14) - Fold 1 - Validation Accuracy : 0.5241\n",
      "Epoch(14) - Fold 1 - Validation Utility score : 1097.3132\n",
      "Epoch(14) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(14) - Fold 2 - Validation Accuracy : 0.5090\n",
      "Epoch(14) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(14) - Fold 3 - Validation Accuracy : 0.5115\n",
      "Epoch(14) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 4 - Validation Loss : 0.6911\n",
      "Epoch(14) - Fold 4 - Validation Accuracy : 0.5247\n",
      "Epoch(14) - Fold 4 - Validation Utility score : 1323.9139\n",
      "Epoch(14) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(14) - GLOBAL - Validation Accuracy: 0.5182\n",
      "Epoch(14) - GLOBAL - Validation Utility score: 2801.0070\n",
      "Saving model corresponding to last_utility_score == 2801.0069836722755\n",
      "\n",
      "\n",
      "Epoch(15) - Training Loss: 0.6908\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(15) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(15) - Fold 0 - Validation Accuracy : 0.5222\n",
      "Epoch(15) - Fold 0 - Validation Utility score : 290.3566\n",
      "Epoch(15) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(15) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(15) - Fold 1 - Validation Utility score : 1018.4063\n",
      "Epoch(15) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(15) - Fold 2 - Validation Accuracy : 0.5100\n",
      "Epoch(15) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(15) - Fold 3 - Validation Accuracy : 0.5124\n",
      "Epoch(15) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 4 - Validation Loss : 0.6909\n",
      "Epoch(15) - Fold 4 - Validation Accuracy : 0.5247\n",
      "Epoch(15) - Fold 4 - Validation Utility score : 1348.2147\n",
      "Epoch(15) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(15) - GLOBAL - Validation Accuracy: 0.5185\n",
      "Epoch(15) - GLOBAL - Validation Utility score: 2656.9776\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(16) - Training Loss: 0.6907\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(16) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(16) - Fold 0 - Validation Accuracy : 0.5228\n",
      "Epoch(16) - Fold 0 - Validation Utility score : 361.3498\n",
      "Epoch(16) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(16) - Fold 1 - Validation Accuracy : 0.5239\n",
      "Epoch(16) - Fold 1 - Validation Utility score : 963.2939\n",
      "Epoch(16) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(16) - Fold 2 - Validation Accuracy : 0.5095\n",
      "Epoch(16) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(16) - Fold 3 - Validation Accuracy : 0.5127\n",
      "Epoch(16) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 4 - Validation Loss : 0.6907\n",
      "Epoch(16) - Fold 4 - Validation Accuracy : 0.5260\n",
      "Epoch(16) - Fold 4 - Validation Utility score : 1425.3975\n",
      "Epoch(16) - GLOBAL - Validation Loss: 0.6918\n",
      "Epoch(16) - GLOBAL - Validation Accuracy: 0.5190\n",
      "Epoch(16) - GLOBAL - Validation Utility score: 2750.0412\n",
      "Saving model corresponding to last_utility_score == 2750.0412268209775\n",
      "\n",
      "\n",
      "Epoch(17) - Training Loss: 0.6905\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(17) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(17) - Fold 0 - Validation Accuracy : 0.5222\n",
      "Epoch(17) - Fold 0 - Validation Utility score : 333.2988\n",
      "Epoch(17) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(17) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(17) - Fold 1 - Validation Utility score : 910.1115\n",
      "Epoch(17) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(17) - Fold 2 - Validation Accuracy : 0.5101\n",
      "Epoch(17) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(17) - Fold 3 - Validation Accuracy : 0.5109\n",
      "Epoch(17) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 4 - Validation Loss : 0.6908\n",
      "Epoch(17) - Fold 4 - Validation Accuracy : 0.5260\n",
      "Epoch(17) - Fold 4 - Validation Utility score : 1439.9359\n",
      "Epoch(17) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(17) - GLOBAL - Validation Accuracy: 0.5185\n",
      "Epoch(17) - GLOBAL - Validation Utility score: 2683.3462\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(18) - Training Loss: 0.6903\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(18) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(18) - Fold 0 - Validation Accuracy : 0.5223\n",
      "Epoch(18) - Fold 0 - Validation Utility score : 339.5293\n",
      "Epoch(18) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(18) - Fold 1 - Validation Accuracy : 0.5227\n",
      "Epoch(18) - Fold 1 - Validation Utility score : 849.1167\n",
      "Epoch(18) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(18) - Fold 2 - Validation Accuracy : 0.5104\n",
      "Epoch(18) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(18) - Fold 3 - Validation Accuracy : 0.5102\n",
      "Epoch(18) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 4 - Validation Loss : 0.6907\n",
      "Epoch(18) - Fold 4 - Validation Accuracy : 0.5259\n",
      "Epoch(18) - Fold 4 - Validation Utility score : 1395.9712\n",
      "Epoch(18) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(18) - GLOBAL - Validation Accuracy: 0.5183\n",
      "Epoch(18) - GLOBAL - Validation Utility score: 2584.6171\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(19) - Training Loss: 0.6902\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(19) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(19) - Fold 0 - Validation Accuracy : 0.5203\n",
      "Epoch(19) - Fold 0 - Validation Utility score : 255.9629\n",
      "Epoch(19) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(19) - Fold 1 - Validation Accuracy : 0.5215\n",
      "Epoch(19) - Fold 1 - Validation Utility score : 833.5919\n",
      "Epoch(19) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(19) - Fold 2 - Validation Accuracy : 0.5086\n",
      "Epoch(19) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(19) - Fold 3 - Validation Accuracy : 0.5095\n",
      "Epoch(19) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 4 - Validation Loss : 0.6908\n",
      "Epoch(19) - Fold 4 - Validation Accuracy : 0.5238\n",
      "Epoch(19) - Fold 4 - Validation Utility score : 1258.1804\n",
      "Epoch(19) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(19) - GLOBAL - Validation Accuracy: 0.5167\n",
      "Epoch(19) - GLOBAL - Validation Utility score: 2347.7352\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(20) - Training Loss: 0.6900\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(20) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(20) - Fold 0 - Validation Accuracy : 0.5213\n",
      "Epoch(20) - Fold 0 - Validation Utility score : 263.6425\n",
      "Epoch(20) - Fold 1 - Validation Loss : 0.6909\n",
      "Epoch(20) - Fold 1 - Validation Accuracy : 0.5216\n",
      "Epoch(20) - Fold 1 - Validation Utility score : 834.3203\n",
      "Epoch(20) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(20) - Fold 2 - Validation Accuracy : 0.5110\n",
      "Epoch(20) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(20) - Fold 3 - Validation Accuracy : 0.5097\n",
      "Epoch(20) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 4 - Validation Loss : 0.6906\n",
      "Epoch(20) - Fold 4 - Validation Accuracy : 0.5265\n",
      "Epoch(20) - Fold 4 - Validation Utility score : 1369.6518\n",
      "Epoch(20) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(20) - GLOBAL - Validation Accuracy: 0.5180\n",
      "Epoch(20) - GLOBAL - Validation Utility score: 2467.6146\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(21) - Training Loss: 0.6899\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(21) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(21) - Fold 0 - Validation Accuracy : 0.5187\n",
      "Epoch(21) - Fold 0 - Validation Utility score : 149.5091\n",
      "Epoch(21) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(21) - Fold 1 - Validation Accuracy : 0.5209\n",
      "Epoch(21) - Fold 1 - Validation Utility score : 794.7085\n",
      "Epoch(21) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(21) - Fold 2 - Validation Accuracy : 0.5092\n",
      "Epoch(21) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(21) - Fold 3 - Validation Accuracy : 0.5092\n",
      "Epoch(21) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 4 - Validation Loss : 0.6908\n",
      "Epoch(21) - Fold 4 - Validation Accuracy : 0.5249\n",
      "Epoch(21) - Fold 4 - Validation Utility score : 1333.5162\n",
      "Epoch(21) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(21) - GLOBAL - Validation Accuracy: 0.5166\n",
      "Epoch(21) - GLOBAL - Validation Utility score: 2277.7338\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6918\n",
      "Meet Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 553473<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_140831-vxk09tdh/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_140831-vxk09tdh/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>0.6899</td></tr><tr><td>Global valid/Loss</td><td>0.69204</td></tr><tr><td>Global valid/Accuracy</td><td>0.51657</td></tr><tr><td>Global valid/Utility</td><td>2277.73378</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>0.69176</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>0.51871</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>149.50907</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>0.69116</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>0.52092</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>794.70854</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>0.69306</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>0.50916</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>0.69341</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>0.50921</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>0.69081</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>0.52488</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>1333.51617</td></tr><tr><td>Best accuracy</td><td>0.51897</td></tr><tr><td>Best utility</td><td>2750.04123</td></tr><tr><td>_runtime</td><td>1654</td></tr><tr><td>_timestamp</td><td>1613482565</td></tr><tr><td>_step</td><td>21</td></tr><tr><td>Final utility score</td><td>{'utility_score': 27...</td></tr><tr><td>Batch size</td><td>41442</td></tr><tr><td>Patience</td><td>5</td></tr><tr><td>Number of epochs</td><td>1000</td></tr><tr><td>Best epoch</td><td>16</td></tr><tr><td>Number of parameters per layer</td><td>[8384, 64, 2048, 32,...</td></tr><tr><td>Model architecture</td><td>MLP(<BR>  (AEncoder)...</td></tr><tr><td>comment</td><td>All folds MLP with a...</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Loss</td><td>█▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>Global valid/Accuracy</td><td>▂▃▁▃▄▅▆▇▇██████████▇▇▇</td></tr><tr><td>Global valid/Utility</td><td>▁▄▂▄▅▆▇████▇▇▇▇▇▇▇▆▆▆▆</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>█▄▄▄▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>▃▂▁▄▅▆▇████▇█▇▇▇▇▇▇▆▆▅</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>▁▂▁▅▇▇▇█▇▇▇▆▆▅▅▄▄▄▄▃▃▂</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>█▆▇▇▆▆▅▄▄▃▃▂▂▂▂▂▁▁▂▁▁▂</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>▃▄▁▃▄▅▆▇▇█▇████▇█▇▇▇▇▇</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>▁▆▁▂▃▅▆█▇██▇▇██▇▇▆▆▆▆▆</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>█▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>▁▅▂▅▄▄▄▅▅▆▅▆▆▇▇▇▇▇█▆█▇</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>█▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>▂▄▁▁▄▄▅▇██▇▇██▇▇▇▆▆▅▆▅</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>█▅▅▅▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>▁▃▃▄▄▅▆▆▇▇▇▇▇▇▇▇███▇██</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>▁▂▂▆▆▆▇██▇█▇▇▇▇▇██▇▇▇▇</td></tr><tr><td>Best accuracy</td><td>▂▃▁▃▄▅▆▇▇████████</td></tr><tr><td>Best utility</td><td>▁▄▂▄▅▆▇████▇▇▇▇▇▇</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 111 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">bright-sweep-14</strong>: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/vxk09tdh\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/vxk09tdh</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training summary:\n",
      "{'utility_score': 2750.0412268209775, 'utility_scores': [361.34982784312615, 963.2938623224017, -0.0, -0.0, 1425.3975366554494], 'utility_score_std': 561.7333087739563, 'accuracy_scores': [0.5227565874332043, 0.5239241839241839, 0.5094644046384852, 0.5126695368338117, 0.5260177489787294]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jvy0xunm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leakyrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 52685\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4324967482873284\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0011745257925109128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_autoenc: encoder\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 5.566527054835323e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">sweet-sweep-15</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/jvy0xunm\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/jvy0xunm</a><br/>\n",
       "                Run data is saved locally in <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_143611-jvy0xunm</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Run config :\n",
      "config: {'activation_function': 'leakyrelu', 'batch_size': 52685, 'dropout': 0.4324967482873284, 'learning_rate': 0.0011745257925109128, 'use_autoenc': 'encoder', 'weight_decay': 5.566527054835323e-05, 'epochs': 1000}\n",
      "Epoch(0) - Training Loss: 0.7640\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(0) - Fold 0 - Validation Loss : 0.6941\n",
      "Epoch(0) - Fold 0 - Validation Accuracy : 0.5138\n",
      "Epoch(0) - Fold 0 - Validation Utility score : 54.1458\n",
      "Epoch(0) - Fold 1 - Validation Loss : 0.6935\n",
      "Epoch(0) - Fold 1 - Validation Accuracy : 0.5095\n",
      "Epoch(0) - Fold 1 - Validation Utility score : 234.0472\n",
      "Epoch(0) - Fold 2 - Validation Loss : 0.6956\n",
      "Epoch(0) - Fold 2 - Validation Accuracy : 0.5011\n",
      "Epoch(0) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 3 - Validation Loss : 0.6952\n",
      "Epoch(0) - Fold 3 - Validation Accuracy : 0.5037\n",
      "Epoch(0) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 4 - Validation Loss : 0.6946\n",
      "Epoch(0) - Fold 4 - Validation Accuracy : 0.5009\n",
      "Epoch(0) - Fold 4 - Validation Utility score : 17.1562\n",
      "Epoch(0) - GLOBAL - Validation Loss: 0.6946\n",
      "Epoch(0) - GLOBAL - Validation Accuracy: 0.5058\n",
      "Epoch(0) - GLOBAL - Validation Utility score: 305.3493\n",
      "Saving model corresponding to last_utility_score == 305.3492679108308\n",
      "\n",
      "\n",
      "Epoch(1) - Training Loss: 0.7222\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(1) - Fold 0 - Validation Loss : 0.6930\n",
      "Epoch(1) - Fold 0 - Validation Accuracy : 0.5138\n",
      "Epoch(1) - Fold 0 - Validation Utility score : 41.4708\n",
      "Epoch(1) - Fold 1 - Validation Loss : 0.6930\n",
      "Epoch(1) - Fold 1 - Validation Accuracy : 0.5103\n",
      "Epoch(1) - Fold 1 - Validation Utility score : 661.1621\n",
      "Epoch(1) - Fold 2 - Validation Loss : 0.6938\n",
      "Epoch(1) - Fold 2 - Validation Accuracy : 0.5058\n",
      "Epoch(1) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 3 - Validation Loss : 0.6936\n",
      "Epoch(1) - Fold 3 - Validation Accuracy : 0.5048\n",
      "Epoch(1) - Fold 3 - Validation Utility score : 225.5050\n",
      "Epoch(1) - Fold 4 - Validation Loss : 0.6930\n",
      "Epoch(1) - Fold 4 - Validation Accuracy : 0.5092\n",
      "Epoch(1) - Fold 4 - Validation Utility score : 232.0074\n",
      "Epoch(1) - GLOBAL - Validation Loss: 0.6933\n",
      "Epoch(1) - GLOBAL - Validation Accuracy: 0.5088\n",
      "Epoch(1) - GLOBAL - Validation Utility score: 1160.1453\n",
      "Saving model corresponding to last_utility_score == 1160.1452932642608\n",
      "\n",
      "\n",
      "Epoch(2) - Training Loss: 0.7023\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(2) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(2) - Fold 0 - Validation Accuracy : 0.5110\n",
      "Epoch(2) - Fold 0 - Validation Utility score : 30.0412\n",
      "Epoch(2) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(2) - Fold 1 - Validation Accuracy : 0.5091\n",
      "Epoch(2) - Fold 1 - Validation Utility score : 576.1141\n",
      "Epoch(2) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(2) - Fold 2 - Validation Accuracy : 0.5052\n",
      "Epoch(2) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(2) - Fold 3 - Validation Accuracy : 0.5057\n",
      "Epoch(2) - Fold 3 - Validation Utility score : 29.5283\n",
      "Epoch(2) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(2) - Fold 4 - Validation Accuracy : 0.5118\n",
      "Epoch(2) - Fold 4 - Validation Utility score : 451.1843\n",
      "Epoch(2) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(2) - GLOBAL - Validation Accuracy: 0.5086\n",
      "Epoch(2) - GLOBAL - Validation Utility score: 1086.8680\n",
      "Saving model corresponding to last_utility_score == 1086.8680314030034\n",
      "\n",
      "\n",
      "Epoch(3) - Training Loss: 0.6963\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(3) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(3) - Fold 0 - Validation Accuracy : 0.5105\n",
      "Epoch(3) - Fold 0 - Validation Utility score : 56.3479\n",
      "Epoch(3) - Fold 1 - Validation Loss : 0.6930\n",
      "Epoch(3) - Fold 1 - Validation Accuracy : 0.5053\n",
      "Epoch(3) - Fold 1 - Validation Utility score : 147.9594\n",
      "Epoch(3) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(3) - Fold 2 - Validation Accuracy : 0.5040\n",
      "Epoch(3) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(3) - Fold 3 - Validation Accuracy : 0.5021\n",
      "Epoch(3) - Fold 3 - Validation Utility score : 18.5502\n",
      "Epoch(3) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(3) - Fold 4 - Validation Accuracy : 0.5087\n",
      "Epoch(3) - Fold 4 - Validation Utility score : 449.4417\n",
      "Epoch(3) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(3) - GLOBAL - Validation Accuracy: 0.5061\n",
      "Epoch(3) - GLOBAL - Validation Utility score: 672.2993\n",
      "Intermediate early stopping : vepoch_loss = 0.6929, the_last_loss=0.6929\n",
      "\n",
      "\n",
      "Epoch(4) - Training Loss: 0.6940\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(4) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(4) - Fold 0 - Validation Accuracy : 0.5132\n",
      "Epoch(4) - Fold 0 - Validation Utility score : 175.5379\n",
      "Epoch(4) - Fold 1 - Validation Loss : 0.6929\n",
      "Epoch(4) - Fold 1 - Validation Accuracy : 0.5056\n",
      "Epoch(4) - Fold 1 - Validation Utility score : 267.5274\n",
      "Epoch(4) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(4) - Fold 2 - Validation Accuracy : 0.5056\n",
      "Epoch(4) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(4) - Fold 3 - Validation Accuracy : 0.5030\n",
      "Epoch(4) - Fold 3 - Validation Utility score : 0.0874\n",
      "Epoch(4) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(4) - Fold 4 - Validation Accuracy : 0.5093\n",
      "Epoch(4) - Fold 4 - Validation Utility score : 713.9785\n",
      "Epoch(4) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(4) - GLOBAL - Validation Accuracy: 0.5074\n",
      "Epoch(4) - GLOBAL - Validation Utility score: 1157.1312\n",
      "Intermediate early stopping : vepoch_loss = 0.6929, the_last_loss=0.6929\n",
      "\n",
      "\n",
      "Epoch(5) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(5) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(5) - Fold 0 - Validation Accuracy : 0.5179\n",
      "Epoch(5) - Fold 0 - Validation Utility score : 429.5316\n",
      "Epoch(5) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(5) - Fold 1 - Validation Accuracy : 0.5138\n",
      "Epoch(5) - Fold 1 - Validation Utility score : 588.5845\n",
      "Epoch(5) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(5) - Fold 2 - Validation Accuracy : 0.5057\n",
      "Epoch(5) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(5) - Fold 3 - Validation Accuracy : 0.5054\n",
      "Epoch(5) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(5) - Fold 4 - Validation Accuracy : 0.5145\n",
      "Epoch(5) - Fold 4 - Validation Utility score : 931.7367\n",
      "Epoch(5) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(5) - GLOBAL - Validation Accuracy: 0.5114\n",
      "Epoch(5) - GLOBAL - Validation Utility score: 1949.8528\n",
      "Saving model corresponding to last_utility_score == 1949.8528126284323\n",
      "\n",
      "\n",
      "Epoch(6) - Training Loss: 0.6929\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(6) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(6) - Fold 0 - Validation Accuracy : 0.5218\n",
      "Epoch(6) - Fold 0 - Validation Utility score : 442.7306\n",
      "Epoch(6) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(6) - Fold 1 - Validation Accuracy : 0.5182\n",
      "Epoch(6) - Fold 1 - Validation Utility score : 799.4656\n",
      "Epoch(6) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(6) - Fold 2 - Validation Accuracy : 0.5051\n",
      "Epoch(6) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(6) - Fold 3 - Validation Accuracy : 0.5062\n",
      "Epoch(6) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(6) - Fold 4 - Validation Accuracy : 0.5185\n",
      "Epoch(6) - Fold 4 - Validation Utility score : 1177.1437\n",
      "Epoch(6) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(6) - GLOBAL - Validation Accuracy: 0.5140\n",
      "Epoch(6) - GLOBAL - Validation Utility score: 2419.3399\n",
      "Saving model corresponding to last_utility_score == 2419.339914937872\n",
      "\n",
      "\n",
      "Epoch(7) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(7) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(7) - Fold 0 - Validation Accuracy : 0.5235\n",
      "Epoch(7) - Fold 0 - Validation Utility score : 503.0419\n",
      "Epoch(7) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(7) - Fold 1 - Validation Accuracy : 0.5216\n",
      "Epoch(7) - Fold 1 - Validation Utility score : 809.7862\n",
      "Epoch(7) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(7) - Fold 2 - Validation Accuracy : 0.5074\n",
      "Epoch(7) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(7) - Fold 3 - Validation Accuracy : 0.5108\n",
      "Epoch(7) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(7) - Fold 4 - Validation Accuracy : 0.5189\n",
      "Epoch(7) - Fold 4 - Validation Utility score : 1236.8227\n",
      "Epoch(7) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(7) - GLOBAL - Validation Accuracy: 0.5164\n",
      "Epoch(7) - GLOBAL - Validation Utility score: 2549.6509\n",
      "Saving model corresponding to last_utility_score == 2549.6508756842186\n",
      "\n",
      "\n",
      "Epoch(8) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(8) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(8) - Fold 0 - Validation Accuracy : 0.5249\n",
      "Epoch(8) - Fold 0 - Validation Utility score : 589.1766\n",
      "Epoch(8) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(8) - Fold 1 - Validation Accuracy : 0.5232\n",
      "Epoch(8) - Fold 1 - Validation Utility score : 899.5208\n",
      "Epoch(8) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(8) - Fold 2 - Validation Accuracy : 0.5076\n",
      "Epoch(8) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(8) - Fold 3 - Validation Accuracy : 0.5118\n",
      "Epoch(8) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(8) - Fold 4 - Validation Accuracy : 0.5196\n",
      "Epoch(8) - Fold 4 - Validation Utility score : 1154.5205\n",
      "Epoch(8) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(8) - GLOBAL - Validation Accuracy: 0.5174\n",
      "Epoch(8) - GLOBAL - Validation Utility score: 2643.2179\n",
      "Saving model corresponding to last_utility_score == 2643.217897284375\n",
      "\n",
      "\n",
      "Epoch(9) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(9) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(9) - Fold 0 - Validation Accuracy : 0.5248\n",
      "Epoch(9) - Fold 0 - Validation Utility score : 682.3827\n",
      "Epoch(9) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(9) - Fold 1 - Validation Accuracy : 0.5228\n",
      "Epoch(9) - Fold 1 - Validation Utility score : 1053.3861\n",
      "Epoch(9) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(9) - Fold 2 - Validation Accuracy : 0.5071\n",
      "Epoch(9) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(9) - Fold 3 - Validation Accuracy : 0.5123\n",
      "Epoch(9) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(9) - Fold 4 - Validation Accuracy : 0.5219\n",
      "Epoch(9) - Fold 4 - Validation Utility score : 1419.6975\n",
      "Epoch(9) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(9) - GLOBAL - Validation Accuracy: 0.5178\n",
      "Epoch(9) - GLOBAL - Validation Utility score: 3155.4663\n",
      "Saving model corresponding to last_utility_score == 3155.4662986239077\n",
      "\n",
      "\n",
      "Epoch(10) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(10) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(10) - Fold 0 - Validation Accuracy : 0.5245\n",
      "Epoch(10) - Fold 0 - Validation Utility score : 661.9099\n",
      "Epoch(10) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(10) - Fold 1 - Validation Accuracy : 0.5237\n",
      "Epoch(10) - Fold 1 - Validation Utility score : 1229.3346\n",
      "Epoch(10) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(10) - Fold 2 - Validation Accuracy : 0.5076\n",
      "Epoch(10) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(10) - Fold 3 - Validation Accuracy : 0.5126\n",
      "Epoch(10) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(10) - Fold 4 - Validation Accuracy : 0.5230\n",
      "Epoch(10) - Fold 4 - Validation Utility score : 1411.8200\n",
      "Epoch(10) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(10) - GLOBAL - Validation Accuracy: 0.5183\n",
      "Epoch(10) - GLOBAL - Validation Utility score: 3303.0646\n",
      "Saving model corresponding to last_utility_score == 3303.064594003724\n",
      "\n",
      "\n",
      "Epoch(11) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(11) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(11) - Fold 0 - Validation Accuracy : 0.5239\n",
      "Epoch(11) - Fold 0 - Validation Utility score : 552.0040\n",
      "Epoch(11) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(11) - Fold 1 - Validation Accuracy : 0.5253\n",
      "Epoch(11) - Fold 1 - Validation Utility score : 1152.0642\n",
      "Epoch(11) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(11) - Fold 2 - Validation Accuracy : 0.5084\n",
      "Epoch(11) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(11) - Fold 3 - Validation Accuracy : 0.5139\n",
      "Epoch(11) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(11) - Fold 4 - Validation Accuracy : 0.5229\n",
      "Epoch(11) - Fold 4 - Validation Utility score : 1431.2106\n",
      "Epoch(11) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(11) - GLOBAL - Validation Accuracy: 0.5189\n",
      "Epoch(11) - GLOBAL - Validation Utility score: 3135.2788\n",
      "Saving model corresponding to last_utility_score == 3135.2787996628404\n",
      "\n",
      "\n",
      "Epoch(12) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(12) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(12) - Fold 0 - Validation Accuracy : 0.5237\n",
      "Epoch(12) - Fold 0 - Validation Utility score : 495.9250\n",
      "Epoch(12) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(12) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(12) - Fold 1 - Validation Utility score : 1188.3582\n",
      "Epoch(12) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(12) - Fold 2 - Validation Accuracy : 0.5081\n",
      "Epoch(12) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(12) - Fold 3 - Validation Accuracy : 0.5134\n",
      "Epoch(12) - Fold 3 - Validation Utility score : 1.3834\n",
      "Epoch(12) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(12) - Fold 4 - Validation Accuracy : 0.5239\n",
      "Epoch(12) - Fold 4 - Validation Utility score : 1425.6740\n",
      "Epoch(12) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(12) - GLOBAL - Validation Accuracy: 0.5185\n",
      "Epoch(12) - GLOBAL - Validation Utility score: 3111.3405\n",
      "Saving model corresponding to last_utility_score == 3111.3405160480283\n",
      "\n",
      "\n",
      "Epoch(13) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(13) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(13) - Fold 0 - Validation Accuracy : 0.5231\n",
      "Epoch(13) - Fold 0 - Validation Utility score : 403.1794\n",
      "Epoch(13) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(13) - Fold 1 - Validation Accuracy : 0.5233\n",
      "Epoch(13) - Fold 1 - Validation Utility score : 1137.0431\n",
      "Epoch(13) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(13) - Fold 2 - Validation Accuracy : 0.5076\n",
      "Epoch(13) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(13) - Fold 3 - Validation Accuracy : 0.5123\n",
      "Epoch(13) - Fold 3 - Validation Utility score : 1.3827\n",
      "Epoch(13) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(13) - Fold 4 - Validation Accuracy : 0.5238\n",
      "Epoch(13) - Fold 4 - Validation Utility score : 1349.9991\n",
      "Epoch(13) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(13) - GLOBAL - Validation Accuracy: 0.5181\n",
      "Epoch(13) - GLOBAL - Validation Utility score: 2891.6044\n",
      "Saving model corresponding to last_utility_score == 2891.60436069399\n",
      "\n",
      "\n",
      "Epoch(14) - Training Loss: 0.6914\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(14) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(14) - Fold 0 - Validation Accuracy : 0.5224\n",
      "Epoch(14) - Fold 0 - Validation Utility score : 348.9984\n",
      "Epoch(14) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(14) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(14) - Fold 1 - Validation Utility score : 1150.1840\n",
      "Epoch(14) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(14) - Fold 2 - Validation Accuracy : 0.5075\n",
      "Epoch(14) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(14) - Fold 3 - Validation Accuracy : 0.5122\n",
      "Epoch(14) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(14) - Fold 4 - Validation Accuracy : 0.5242\n",
      "Epoch(14) - Fold 4 - Validation Utility score : 1357.4184\n",
      "Epoch(14) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(14) - GLOBAL - Validation Accuracy: 0.5181\n",
      "Epoch(14) - GLOBAL - Validation Utility score: 2856.6009\n",
      "Saving model corresponding to last_utility_score == 2856.60086224703\n",
      "\n",
      "\n",
      "Epoch(15) - Training Loss: 0.6913\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(15) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(15) - Fold 0 - Validation Accuracy : 0.5218\n",
      "Epoch(15) - Fold 0 - Validation Utility score : 375.5627\n",
      "Epoch(15) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(15) - Fold 1 - Validation Accuracy : 0.5236\n",
      "Epoch(15) - Fold 1 - Validation Utility score : 1145.9237\n",
      "Epoch(15) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(15) - Fold 2 - Validation Accuracy : 0.5079\n",
      "Epoch(15) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(15) - Fold 3 - Validation Accuracy : 0.5122\n",
      "Epoch(15) - Fold 3 - Validation Utility score : 0.0238\n",
      "Epoch(15) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(15) - Fold 4 - Validation Accuracy : 0.5240\n",
      "Epoch(15) - Fold 4 - Validation Utility score : 1248.9343\n",
      "Epoch(15) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(15) - GLOBAL - Validation Accuracy: 0.5179\n",
      "Epoch(15) - GLOBAL - Validation Utility score: 2770.4446\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(16) - Training Loss: 0.6911\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(16) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(16) - Fold 0 - Validation Accuracy : 0.5219\n",
      "Epoch(16) - Fold 0 - Validation Utility score : 337.4650\n",
      "Epoch(16) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(16) - Fold 1 - Validation Accuracy : 0.5227\n",
      "Epoch(16) - Fold 1 - Validation Utility score : 1115.6913\n",
      "Epoch(16) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(16) - Fold 2 - Validation Accuracy : 0.5082\n",
      "Epoch(16) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(16) - Fold 3 - Validation Accuracy : 0.5098\n",
      "Epoch(16) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(16) - Fold 4 - Validation Accuracy : 0.5240\n",
      "Epoch(16) - Fold 4 - Validation Utility score : 1303.2928\n",
      "Epoch(16) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(16) - GLOBAL - Validation Accuracy: 0.5173\n",
      "Epoch(16) - GLOBAL - Validation Utility score: 2756.4491\n",
      "Saving model corresponding to last_utility_score == 2756.4491319762456\n",
      "\n",
      "\n",
      "Epoch(17) - Training Loss: 0.6910\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(17) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(17) - Fold 0 - Validation Accuracy : 0.5218\n",
      "Epoch(17) - Fold 0 - Validation Utility score : 319.9391\n",
      "Epoch(17) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(17) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(17) - Fold 1 - Validation Utility score : 988.2546\n",
      "Epoch(17) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(17) - Fold 2 - Validation Accuracy : 0.5094\n",
      "Epoch(17) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(17) - Fold 3 - Validation Accuracy : 0.5123\n",
      "Epoch(17) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 4 - Validation Loss : 0.6912\n",
      "Epoch(17) - Fold 4 - Validation Accuracy : 0.5247\n",
      "Epoch(17) - Fold 4 - Validation Utility score : 1420.3256\n",
      "Epoch(17) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(17) - GLOBAL - Validation Accuracy: 0.5183\n",
      "Epoch(17) - GLOBAL - Validation Utility score: 2728.5193\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(18) - Training Loss: 0.6909\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(18) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(18) - Fold 0 - Validation Accuracy : 0.5224\n",
      "Epoch(18) - Fold 0 - Validation Utility score : 314.5492\n",
      "Epoch(18) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(18) - Fold 1 - Validation Accuracy : 0.5232\n",
      "Epoch(18) - Fold 1 - Validation Utility score : 1017.3434\n",
      "Epoch(18) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(18) - Fold 2 - Validation Accuracy : 0.5085\n",
      "Epoch(18) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(18) - Fold 3 - Validation Accuracy : 0.5114\n",
      "Epoch(18) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 4 - Validation Loss : 0.6911\n",
      "Epoch(18) - Fold 4 - Validation Accuracy : 0.5244\n",
      "Epoch(18) - Fold 4 - Validation Utility score : 1397.0844\n",
      "Epoch(18) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(18) - GLOBAL - Validation Accuracy: 0.5180\n",
      "Epoch(18) - GLOBAL - Validation Utility score: 2728.9771\n",
      "Saving model corresponding to last_utility_score == 2728.977066708968\n",
      "\n",
      "\n",
      "Epoch(19) - Training Loss: 0.6908\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(19) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(19) - Fold 0 - Validation Accuracy : 0.5200\n",
      "Epoch(19) - Fold 0 - Validation Utility score : 260.2408\n",
      "Epoch(19) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(19) - Fold 1 - Validation Accuracy : 0.5219\n",
      "Epoch(19) - Fold 1 - Validation Utility score : 985.3515\n",
      "Epoch(19) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(19) - Fold 2 - Validation Accuracy : 0.5090\n",
      "Epoch(19) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(19) - Fold 3 - Validation Accuracy : 0.5106\n",
      "Epoch(19) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 4 - Validation Loss : 0.6911\n",
      "Epoch(19) - Fold 4 - Validation Accuracy : 0.5234\n",
      "Epoch(19) - Fold 4 - Validation Utility score : 1222.8362\n",
      "Epoch(19) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(19) - GLOBAL - Validation Accuracy: 0.5170\n",
      "Epoch(19) - GLOBAL - Validation Utility score: 2468.4284\n",
      "Saving model corresponding to last_utility_score == 2468.42842123279\n",
      "\n",
      "\n",
      "Epoch(20) - Training Loss: 0.6906\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(20) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(20) - Fold 0 - Validation Accuracy : 0.5221\n",
      "Epoch(20) - Fold 0 - Validation Utility score : 311.7225\n",
      "Epoch(20) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(20) - Fold 1 - Validation Accuracy : 0.5226\n",
      "Epoch(20) - Fold 1 - Validation Utility score : 1083.4218\n",
      "Epoch(20) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(20) - Fold 2 - Validation Accuracy : 0.5090\n",
      "Epoch(20) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(20) - Fold 3 - Validation Accuracy : 0.5099\n",
      "Epoch(20) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 4 - Validation Loss : 0.6909\n",
      "Epoch(20) - Fold 4 - Validation Accuracy : 0.5250\n",
      "Epoch(20) - Fold 4 - Validation Utility score : 1448.1435\n",
      "Epoch(20) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(20) - GLOBAL - Validation Accuracy: 0.5177\n",
      "Epoch(20) - GLOBAL - Validation Utility score: 2843.2879\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(21) - Training Loss: 0.6906\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(21) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(21) - Fold 0 - Validation Accuracy : 0.5200\n",
      "Epoch(21) - Fold 0 - Validation Utility score : 316.8319\n",
      "Epoch(21) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(21) - Fold 1 - Validation Accuracy : 0.5222\n",
      "Epoch(21) - Fold 1 - Validation Utility score : 947.2215\n",
      "Epoch(21) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(21) - Fold 2 - Validation Accuracy : 0.5090\n",
      "Epoch(21) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(21) - Fold 3 - Validation Accuracy : 0.5101\n",
      "Epoch(21) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 4 - Validation Loss : 0.6911\n",
      "Epoch(21) - Fold 4 - Validation Accuracy : 0.5249\n",
      "Epoch(21) - Fold 4 - Validation Utility score : 1366.2229\n",
      "Epoch(21) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(21) - GLOBAL - Validation Accuracy: 0.5172\n",
      "Epoch(21) - GLOBAL - Validation Utility score: 2630.2763\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(22) - Training Loss: 0.6904\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(22) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(22) - Fold 0 - Validation Accuracy : 0.5213\n",
      "Epoch(22) - Fold 0 - Validation Utility score : 256.9003\n",
      "Epoch(22) - Fold 1 - Validation Loss : 0.6910\n",
      "Epoch(22) - Fold 1 - Validation Accuracy : 0.5224\n",
      "Epoch(22) - Fold 1 - Validation Utility score : 954.5647\n",
      "Epoch(22) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(22) - Fold 2 - Validation Accuracy : 0.5099\n",
      "Epoch(22) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(22) - Fold 3 - Validation Accuracy : 0.5090\n",
      "Epoch(22) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 4 - Validation Loss : 0.6908\n",
      "Epoch(22) - Fold 4 - Validation Accuracy : 0.5244\n",
      "Epoch(22) - Fold 4 - Validation Utility score : 1430.8272\n",
      "Epoch(22) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(22) - GLOBAL - Validation Accuracy: 0.5174\n",
      "Epoch(22) - GLOBAL - Validation Utility score: 2642.2922\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(23) - Training Loss: 0.6902\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(23) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(23) - Fold 0 - Validation Accuracy : 0.5206\n",
      "Epoch(23) - Fold 0 - Validation Utility score : 193.7535\n",
      "Epoch(23) - Fold 1 - Validation Loss : 0.6909\n",
      "Epoch(23) - Fold 1 - Validation Accuracy : 0.5227\n",
      "Epoch(23) - Fold 1 - Validation Utility score : 892.9291\n",
      "Epoch(23) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(23) - Fold 2 - Validation Accuracy : 0.5095\n",
      "Epoch(23) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(23) - Fold 3 - Validation Accuracy : 0.5090\n",
      "Epoch(23) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 4 - Validation Loss : 0.6907\n",
      "Epoch(23) - Fold 4 - Validation Accuracy : 0.5251\n",
      "Epoch(23) - Fold 4 - Validation Utility score : 1464.4127\n",
      "Epoch(23) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(23) - GLOBAL - Validation Accuracy: 0.5174\n",
      "Epoch(23) - GLOBAL - Validation Utility score: 2551.0954\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(24) - Training Loss: 0.6901\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(24) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(24) - Fold 0 - Validation Accuracy : 0.5200\n",
      "Epoch(24) - Fold 0 - Validation Utility score : 247.0141\n",
      "Epoch(24) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(24) - Fold 1 - Validation Accuracy : 0.5208\n",
      "Epoch(24) - Fold 1 - Validation Utility score : 837.5600\n",
      "Epoch(24) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(24) - Fold 2 - Validation Accuracy : 0.5081\n",
      "Epoch(24) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(24) - Fold 3 - Validation Accuracy : 0.5081\n",
      "Epoch(24) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 4 - Validation Loss : 0.6908\n",
      "Epoch(24) - Fold 4 - Validation Accuracy : 0.5242\n",
      "Epoch(24) - Fold 4 - Validation Utility score : 1373.7044\n",
      "Epoch(24) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(24) - GLOBAL - Validation Accuracy: 0.5162\n",
      "Epoch(24) - GLOBAL - Validation Utility score: 2458.2784\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "Meet Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 555968<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_143611-jvy0xunm/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_143611-jvy0xunm/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>0.69014</td></tr><tr><td>Global valid/Loss</td><td>0.69194</td></tr><tr><td>Global valid/Accuracy</td><td>0.51622</td></tr><tr><td>Global valid/Utility</td><td>2458.27845</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>0.69148</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>0.52003</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>247.01412</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>0.69106</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>0.52077</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>837.55997</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>0.69307</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>0.50806</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>0.69322</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>0.50808</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>0.69085</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>0.52418</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>1373.70436</td></tr><tr><td>Best accuracy</td><td>0.51699</td></tr><tr><td>Best utility</td><td>2468.42842</td></tr><tr><td>_runtime</td><td>1839</td></tr><tr><td>_timestamp</td><td>1613484410</td></tr><tr><td>_step</td><td>24</td></tr><tr><td>Final utility score</td><td>{'utility_score': 24...</td></tr><tr><td>Batch size</td><td>52685</td></tr><tr><td>Patience</td><td>5</td></tr><tr><td>Number of epochs</td><td>1000</td></tr><tr><td>Best epoch</td><td>19</td></tr><tr><td>Number of parameters per layer</td><td>[8384, 64, 2048, 32,...</td></tr><tr><td>Model architecture</td><td>MLP(<BR>  (AEncoder)...</td></tr><tr><td>comment</td><td>All folds MLP with a...</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Loss</td><td>█▅▃▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Accuracy</td><td>▁▃▂▁▂▄▅▇▇▇█████▇▇██▇▇▇▇▇▇</td></tr><tr><td>Global valid/Utility</td><td>▁▃▃▂▃▅▆▆▆████▇▇▇▇▇▇▆▇▆▆▆▆</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>█▅▄▄▄▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▂▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>▃▃▁▁▂▅▆▇████▇▇▇▇▇▆▇▆▇▆▆▆▆</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>▁▁▁▁▃▅▅▆▇██▇▆▅▄▅▄▄▄▃▄▄▃▃▃</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>█▇▆▇▇▆▆▅▄▄▄▃▃▃▂▂▂▂▁▂▁▂▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>▂▃▂▁▁▄▆▇▇▇▇█▇▇█▇▇▇▇▇▇▇▇▇▆</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>▂▄▄▁▂▄▅▅▆▇█▇█▇▇▇▇▆▇▆▇▆▆▆▅</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>█▄▂▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▂▁▁▁▂▂▂</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>▁▅▄▃▅▅▄▆▆▆▆▇▇▆▆▆▇█▇▇▇▇██▇</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>█▄▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▂</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>▂▃▃▁▂▃▃▆▇▇▇██▇▇▇▆▇▇▆▆▆▅▅▅</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>▁█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>█▅▄▅▅▅▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>▁▃▄▃▃▅▆▆▆▇▇▇█████████████</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>▁▂▃▃▄▅▇▇▇████▇▇▇▇██▇█████</td></tr><tr><td>Best accuracy</td><td>▁▃▂▄▅▇▇▇█████▇█▇▇</td></tr><tr><td>Best utility</td><td>▁▃▃▅▆▆▆████▇▇▇▇▆▆</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 126 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">sweet-sweep-15</strong>: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/jvy0xunm\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/jvy0xunm</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training summary:\n",
      "{'utility_score': 2468.42842123279, 'utility_scores': [260.2407603870512, 985.3515075212731, -0.0, -0.0, 1222.8361533244656], 'utility_score_std': 512.90219934578, 'accuracy_scores': [0.5199997165171295, 0.5219024219024219, 0.50901126665797, 0.5106083628791716, 0.5234399211156501]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: huxbitdb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leakyrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 43931\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.49013283583420697\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0016576940094994838\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_autoenc: encoder-only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 9.883049906499183e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">earnest-sweep-16</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/huxbitdb\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/huxbitdb</a><br/>\n",
       "                Run data is saved locally in <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_150655-huxbitdb</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Run config :\n",
      "config: {'activation_function': 'leakyrelu', 'batch_size': 43931, 'dropout': 0.49013283583420697, 'learning_rate': 0.0016576940094994838, 'use_autoenc': 'encoder-only', 'weight_decay': 9.883049906499183e-05, 'epochs': 1000}\n",
      "Epoch(0) - Training Loss: 0.9286\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(0) - Fold 0 - Validation Loss : 0.6972\n",
      "Epoch(0) - Fold 0 - Validation Accuracy : 0.5069\n",
      "Epoch(0) - Fold 0 - Validation Utility score : 131.5186\n",
      "Epoch(0) - Fold 1 - Validation Loss : 0.6962\n",
      "Epoch(0) - Fold 1 - Validation Accuracy : 0.5014\n",
      "Epoch(0) - Fold 1 - Validation Utility score : 17.9452\n",
      "Epoch(0) - Fold 2 - Validation Loss : 0.6975\n",
      "Epoch(0) - Fold 2 - Validation Accuracy : 0.4975\n",
      "Epoch(0) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 3 - Validation Loss : 0.6965\n",
      "Epoch(0) - Fold 3 - Validation Accuracy : 0.5017\n",
      "Epoch(0) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 4 - Validation Loss : 0.6980\n",
      "Epoch(0) - Fold 4 - Validation Accuracy : 0.4930\n",
      "Epoch(0) - Fold 4 - Validation Utility score : -0.0000\n",
      "Epoch(0) - GLOBAL - Validation Loss: 0.6971\n",
      "Epoch(0) - GLOBAL - Validation Accuracy: 0.5001\n",
      "Epoch(0) - GLOBAL - Validation Utility score: 149.4637\n",
      "Saving model corresponding to last_utility_score == 149.4637476441733\n",
      "\n",
      "\n",
      "Epoch(1) - Training Loss: 0.7830\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(1) - Fold 0 - Validation Loss : 0.6956\n",
      "Epoch(1) - Fold 0 - Validation Accuracy : 0.5014\n",
      "Epoch(1) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 1 - Validation Loss : 0.6954\n",
      "Epoch(1) - Fold 1 - Validation Accuracy : 0.5060\n",
      "Epoch(1) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 2 - Validation Loss : 0.6957\n",
      "Epoch(1) - Fold 2 - Validation Accuracy : 0.5015\n",
      "Epoch(1) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 3 - Validation Loss : 0.6960\n",
      "Epoch(1) - Fold 3 - Validation Accuracy : 0.5003\n",
      "Epoch(1) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 4 - Validation Loss : 0.6960\n",
      "Epoch(1) - Fold 4 - Validation Accuracy : 0.4984\n",
      "Epoch(1) - Fold 4 - Validation Utility score : 15.3080\n",
      "Epoch(1) - GLOBAL - Validation Loss: 0.6957\n",
      "Epoch(1) - GLOBAL - Validation Accuracy: 0.5015\n",
      "Epoch(1) - GLOBAL - Validation Utility score: 15.3080\n",
      "Saving model corresponding to last_utility_score == 15.308045484617736\n",
      "\n",
      "\n",
      "Epoch(2) - Training Loss: 0.7157\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(2) - Fold 0 - Validation Loss : 0.6949\n",
      "Epoch(2) - Fold 0 - Validation Accuracy : 0.5001\n",
      "Epoch(2) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 1 - Validation Loss : 0.6942\n",
      "Epoch(2) - Fold 1 - Validation Accuracy : 0.5061\n",
      "Epoch(2) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 2 - Validation Loss : 0.6944\n",
      "Epoch(2) - Fold 2 - Validation Accuracy : 0.5018\n",
      "Epoch(2) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 3 - Validation Loss : 0.6946\n",
      "Epoch(2) - Fold 3 - Validation Accuracy : 0.4998\n",
      "Epoch(2) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 4 - Validation Loss : 0.6947\n",
      "Epoch(2) - Fold 4 - Validation Accuracy : 0.4988\n",
      "Epoch(2) - Fold 4 - Validation Utility score : 17.5754\n",
      "Epoch(2) - GLOBAL - Validation Loss: 0.6946\n",
      "Epoch(2) - GLOBAL - Validation Accuracy: 0.5013\n",
      "Epoch(2) - GLOBAL - Validation Utility score: 17.5754\n",
      "Saving model corresponding to last_utility_score == 17.57540155121808\n",
      "\n",
      "\n",
      "Epoch(3) - Training Loss: 0.6983\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(3) - Fold 0 - Validation Loss : 0.6941\n",
      "Epoch(3) - Fold 0 - Validation Accuracy : 0.5002\n",
      "Epoch(3) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 1 - Validation Loss : 0.6935\n",
      "Epoch(3) - Fold 1 - Validation Accuracy : 0.5063\n",
      "Epoch(3) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 2 - Validation Loss : 0.6939\n",
      "Epoch(3) - Fold 2 - Validation Accuracy : 0.5018\n",
      "Epoch(3) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 3 - Validation Loss : 0.6941\n",
      "Epoch(3) - Fold 3 - Validation Accuracy : 0.4998\n",
      "Epoch(3) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 4 - Validation Loss : 0.6942\n",
      "Epoch(3) - Fold 4 - Validation Accuracy : 0.4988\n",
      "Epoch(3) - Fold 4 - Validation Utility score : 17.6140\n",
      "Epoch(3) - GLOBAL - Validation Loss: 0.6940\n",
      "Epoch(3) - GLOBAL - Validation Accuracy: 0.5014\n",
      "Epoch(3) - GLOBAL - Validation Utility score: 17.6140\n",
      "Saving model corresponding to last_utility_score == 17.61398595491091\n",
      "\n",
      "\n",
      "Epoch(4) - Training Loss: 0.6950\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(4) - Fold 0 - Validation Loss : 0.6938\n",
      "Epoch(4) - Fold 0 - Validation Accuracy : 0.5004\n",
      "Epoch(4) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 1 - Validation Loss : 0.6932\n",
      "Epoch(4) - Fold 1 - Validation Accuracy : 0.5062\n",
      "Epoch(4) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 2 - Validation Loss : 0.6937\n",
      "Epoch(4) - Fold 2 - Validation Accuracy : 0.5019\n",
      "Epoch(4) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 3 - Validation Loss : 0.6938\n",
      "Epoch(4) - Fold 3 - Validation Accuracy : 0.4997\n",
      "Epoch(4) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 4 - Validation Loss : 0.6939\n",
      "Epoch(4) - Fold 4 - Validation Accuracy : 0.4988\n",
      "Epoch(4) - Fold 4 - Validation Utility score : 17.7554\n",
      "Epoch(4) - GLOBAL - Validation Loss: 0.6937\n",
      "Epoch(4) - GLOBAL - Validation Accuracy: 0.5014\n",
      "Epoch(4) - GLOBAL - Validation Utility score: 17.7554\n",
      "Saving model corresponding to last_utility_score == 17.755398536116648\n",
      "\n",
      "\n",
      "Epoch(5) - Training Loss: 0.6942\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(5) - Fold 0 - Validation Loss : 0.6935\n",
      "Epoch(5) - Fold 0 - Validation Accuracy : 0.5009\n",
      "Epoch(5) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 1 - Validation Loss : 0.6930\n",
      "Epoch(5) - Fold 1 - Validation Accuracy : 0.5066\n",
      "Epoch(5) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 2 - Validation Loss : 0.6934\n",
      "Epoch(5) - Fold 2 - Validation Accuracy : 0.5027\n",
      "Epoch(5) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 3 - Validation Loss : 0.6936\n",
      "Epoch(5) - Fold 3 - Validation Accuracy : 0.5007\n",
      "Epoch(5) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 4 - Validation Loss : 0.6937\n",
      "Epoch(5) - Fold 4 - Validation Accuracy : 0.4994\n",
      "Epoch(5) - Fold 4 - Validation Utility score : 20.4517\n",
      "Epoch(5) - GLOBAL - Validation Loss: 0.6934\n",
      "Epoch(5) - GLOBAL - Validation Accuracy: 0.5020\n",
      "Epoch(5) - GLOBAL - Validation Utility score: 20.4517\n",
      "Saving model corresponding to last_utility_score == 20.45165419327378\n",
      "\n",
      "\n",
      "Epoch(6) - Training Loss: 0.6939\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(6) - Fold 0 - Validation Loss : 0.6934\n",
      "Epoch(6) - Fold 0 - Validation Accuracy : 0.5009\n",
      "Epoch(6) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 1 - Validation Loss : 0.6929\n",
      "Epoch(6) - Fold 1 - Validation Accuracy : 0.5068\n",
      "Epoch(6) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 2 - Validation Loss : 0.6934\n",
      "Epoch(6) - Fold 2 - Validation Accuracy : 0.5027\n",
      "Epoch(6) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 3 - Validation Loss : 0.6935\n",
      "Epoch(6) - Fold 3 - Validation Accuracy : 0.5006\n",
      "Epoch(6) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 4 - Validation Loss : 0.6936\n",
      "Epoch(6) - Fold 4 - Validation Accuracy : 0.4998\n",
      "Epoch(6) - Fold 4 - Validation Utility score : 27.6901\n",
      "Epoch(6) - GLOBAL - Validation Loss: 0.6934\n",
      "Epoch(6) - GLOBAL - Validation Accuracy: 0.5021\n",
      "Epoch(6) - GLOBAL - Validation Utility score: 27.6901\n",
      "Saving model corresponding to last_utility_score == 27.69010470611315\n",
      "\n",
      "\n",
      "Epoch(7) - Training Loss: 0.6937\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(7) - Fold 0 - Validation Loss : 0.6931\n",
      "Epoch(7) - Fold 0 - Validation Accuracy : 0.5035\n",
      "Epoch(7) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(7) - Fold 1 - Validation Accuracy : 0.5094\n",
      "Epoch(7) - Fold 1 - Validation Utility score : 1.8625\n",
      "Epoch(7) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(7) - Fold 2 - Validation Accuracy : 0.5022\n",
      "Epoch(7) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(7) - Fold 3 - Validation Accuracy : 0.5031\n",
      "Epoch(7) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 4 - Validation Loss : 0.6933\n",
      "Epoch(7) - Fold 4 - Validation Accuracy : 0.5014\n",
      "Epoch(7) - Fold 4 - Validation Utility score : 62.7275\n",
      "Epoch(7) - GLOBAL - Validation Loss: 0.6931\n",
      "Epoch(7) - GLOBAL - Validation Accuracy: 0.5039\n",
      "Epoch(7) - GLOBAL - Validation Utility score: 64.5900\n",
      "Saving model corresponding to last_utility_score == 64.59002373277245\n",
      "\n",
      "\n",
      "Epoch(8) - Training Loss: 0.6936\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(8) - Fold 0 - Validation Loss : 0.6932\n",
      "Epoch(8) - Fold 0 - Validation Accuracy : 0.5017\n",
      "Epoch(8) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(8) - Fold 1 - Validation Accuracy : 0.5070\n",
      "Epoch(8) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(8) - Fold 2 - Validation Accuracy : 0.5022\n",
      "Epoch(8) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(8) - Fold 3 - Validation Accuracy : 0.5017\n",
      "Epoch(8) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 4 - Validation Loss : 0.6934\n",
      "Epoch(8) - Fold 4 - Validation Accuracy : 0.5007\n",
      "Epoch(8) - Fold 4 - Validation Utility score : 44.1428\n",
      "Epoch(8) - GLOBAL - Validation Loss: 0.6932\n",
      "Epoch(8) - GLOBAL - Validation Accuracy: 0.5026\n",
      "Epoch(8) - GLOBAL - Validation Utility score: 44.1428\n",
      "Intermediate early stopping : vepoch_loss = 0.6932, the_last_loss=0.6931\n",
      "\n",
      "\n",
      "Epoch(9) - Training Loss: 0.6935\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(9) - Fold 0 - Validation Loss : 0.6930\n",
      "Epoch(9) - Fold 0 - Validation Accuracy : 0.5040\n",
      "Epoch(9) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 1 - Validation Loss : 0.6927\n",
      "Epoch(9) - Fold 1 - Validation Accuracy : 0.5094\n",
      "Epoch(9) - Fold 1 - Validation Utility score : 1.3512\n",
      "Epoch(9) - Fold 2 - Validation Loss : 0.6932\n",
      "Epoch(9) - Fold 2 - Validation Accuracy : 0.5025\n",
      "Epoch(9) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(9) - Fold 3 - Validation Accuracy : 0.5036\n",
      "Epoch(9) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 4 - Validation Loss : 0.6933\n",
      "Epoch(9) - Fold 4 - Validation Accuracy : 0.5017\n",
      "Epoch(9) - Fold 4 - Validation Utility score : 79.2634\n",
      "Epoch(9) - GLOBAL - Validation Loss: 0.6931\n",
      "Epoch(9) - GLOBAL - Validation Accuracy: 0.5042\n",
      "Epoch(9) - GLOBAL - Validation Utility score: 80.6146\n",
      "Saving model corresponding to last_utility_score == 80.6146283962896\n",
      "\n",
      "\n",
      "Epoch(10) - Training Loss: 0.6934\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(10) - Fold 0 - Validation Loss : 0.6928\n",
      "Epoch(10) - Fold 0 - Validation Accuracy : 0.5073\n",
      "Epoch(10) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(10) - Fold 1 - Validation Accuracy : 0.5120\n",
      "Epoch(10) - Fold 1 - Validation Utility score : 11.9383\n",
      "Epoch(10) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(10) - Fold 2 - Validation Accuracy : 0.5026\n",
      "Epoch(10) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(10) - Fold 3 - Validation Accuracy : 0.5044\n",
      "Epoch(10) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 4 - Validation Loss : 0.6932\n",
      "Epoch(10) - Fold 4 - Validation Accuracy : 0.5030\n",
      "Epoch(10) - Fold 4 - Validation Utility score : 131.5002\n",
      "Epoch(10) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(10) - GLOBAL - Validation Accuracy: 0.5059\n",
      "Epoch(10) - GLOBAL - Validation Utility score: 143.4384\n",
      "Saving model corresponding to last_utility_score == 143.4384276443313\n",
      "\n",
      "\n",
      "Epoch(11) - Training Loss: 0.6933\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(11) - Fold 0 - Validation Loss : 0.6928\n",
      "Epoch(11) - Fold 0 - Validation Accuracy : 0.5091\n",
      "Epoch(11) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(11) - Fold 1 - Validation Accuracy : 0.5134\n",
      "Epoch(11) - Fold 1 - Validation Utility score : 27.4178\n",
      "Epoch(11) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(11) - Fold 2 - Validation Accuracy : 0.5029\n",
      "Epoch(11) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(11) - Fold 3 - Validation Accuracy : 0.5047\n",
      "Epoch(11) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 4 - Validation Loss : 0.6931\n",
      "Epoch(11) - Fold 4 - Validation Accuracy : 0.5045\n",
      "Epoch(11) - Fold 4 - Validation Utility score : 239.1038\n",
      "Epoch(11) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(11) - GLOBAL - Validation Accuracy: 0.5069\n",
      "Epoch(11) - GLOBAL - Validation Utility score: 266.5216\n",
      "Saving model corresponding to last_utility_score == 266.5215859615102\n",
      "\n",
      "\n",
      "Epoch(12) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(12) - Fold 0 - Validation Loss : 0.6928\n",
      "Epoch(12) - Fold 0 - Validation Accuracy : 0.5092\n",
      "Epoch(12) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(12) - Fold 1 - Validation Accuracy : 0.5128\n",
      "Epoch(12) - Fold 1 - Validation Utility score : 29.9546\n",
      "Epoch(12) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(12) - Fold 2 - Validation Accuracy : 0.5034\n",
      "Epoch(12) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(12) - Fold 3 - Validation Accuracy : 0.5046\n",
      "Epoch(12) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 4 - Validation Loss : 0.6931\n",
      "Epoch(12) - Fold 4 - Validation Accuracy : 0.5049\n",
      "Epoch(12) - Fold 4 - Validation Utility score : 262.7819\n",
      "Epoch(12) - GLOBAL - Validation Loss: 0.6929\n",
      "Epoch(12) - GLOBAL - Validation Accuracy: 0.5070\n",
      "Epoch(12) - GLOBAL - Validation Utility score: 292.7365\n",
      "Saving model corresponding to last_utility_score == 292.7364566346722\n",
      "\n",
      "\n",
      "Epoch(13) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(13) - Fold 0 - Validation Loss : 0.6926\n",
      "Epoch(13) - Fold 0 - Validation Accuracy : 0.5128\n",
      "Epoch(13) - Fold 0 - Validation Utility score : 0.2549\n",
      "Epoch(13) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(13) - Fold 1 - Validation Accuracy : 0.5159\n",
      "Epoch(13) - Fold 1 - Validation Utility score : 125.5678\n",
      "Epoch(13) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(13) - Fold 2 - Validation Accuracy : 0.5046\n",
      "Epoch(13) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(13) - Fold 3 - Validation Accuracy : 0.5063\n",
      "Epoch(13) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 4 - Validation Loss : 0.6930\n",
      "Epoch(13) - Fold 4 - Validation Accuracy : 0.5058\n",
      "Epoch(13) - Fold 4 - Validation Utility score : 466.5272\n",
      "Epoch(13) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(13) - GLOBAL - Validation Accuracy: 0.5091\n",
      "Epoch(13) - GLOBAL - Validation Utility score: 592.3498\n",
      "Saving model corresponding to last_utility_score == 592.3498120512564\n",
      "\n",
      "\n",
      "Epoch(14) - Training Loss: 0.6931\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(14) - Fold 0 - Validation Loss : 0.6924\n",
      "Epoch(14) - Fold 0 - Validation Accuracy : 0.5166\n",
      "Epoch(14) - Fold 0 - Validation Utility score : 30.2213\n",
      "Epoch(14) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(14) - Fold 1 - Validation Accuracy : 0.5226\n",
      "Epoch(14) - Fold 1 - Validation Utility score : 326.6606\n",
      "Epoch(14) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(14) - Fold 2 - Validation Accuracy : 0.5058\n",
      "Epoch(14) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(14) - Fold 3 - Validation Accuracy : 0.5063\n",
      "Epoch(14) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(14) - Fold 4 - Validation Accuracy : 0.5080\n",
      "Epoch(14) - Fold 4 - Validation Utility score : 684.3949\n",
      "Epoch(14) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(14) - GLOBAL - Validation Accuracy: 0.5118\n",
      "Epoch(14) - GLOBAL - Validation Utility score: 1041.2768\n",
      "Saving model corresponding to last_utility_score == 1041.2768084369488\n",
      "\n",
      "\n",
      "Epoch(15) - Training Loss: 0.6930\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(15) - Fold 0 - Validation Loss : 0.6922\n",
      "Epoch(15) - Fold 0 - Validation Accuracy : 0.5203\n",
      "Epoch(15) - Fold 0 - Validation Utility score : 201.1671\n",
      "Epoch(15) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(15) - Fold 1 - Validation Accuracy : 0.5238\n",
      "Epoch(15) - Fold 1 - Validation Utility score : 479.0486\n",
      "Epoch(15) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(15) - Fold 2 - Validation Accuracy : 0.5077\n",
      "Epoch(15) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(15) - Fold 3 - Validation Accuracy : 0.5069\n",
      "Epoch(15) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(15) - Fold 4 - Validation Accuracy : 0.5105\n",
      "Epoch(15) - Fold 4 - Validation Utility score : 889.5904\n",
      "Epoch(15) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(15) - GLOBAL - Validation Accuracy: 0.5138\n",
      "Epoch(15) - GLOBAL - Validation Utility score: 1569.8060\n",
      "Saving model corresponding to last_utility_score == 1569.80601844164\n",
      "\n",
      "\n",
      "Epoch(16) - Training Loss: 0.6930\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(16) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(16) - Fold 0 - Validation Accuracy : 0.5149\n",
      "Epoch(16) - Fold 0 - Validation Utility score : 6.3367\n",
      "Epoch(16) - Fold 1 - Validation Loss : 0.6923\n",
      "Epoch(16) - Fold 1 - Validation Accuracy : 0.5188\n",
      "Epoch(16) - Fold 1 - Validation Utility score : 211.3884\n",
      "Epoch(16) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(16) - Fold 2 - Validation Accuracy : 0.5057\n",
      "Epoch(16) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(16) - Fold 3 - Validation Accuracy : 0.5061\n",
      "Epoch(16) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(16) - Fold 4 - Validation Accuracy : 0.5075\n",
      "Epoch(16) - Fold 4 - Validation Utility score : 627.2105\n",
      "Epoch(16) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(16) - GLOBAL - Validation Accuracy: 0.5106\n",
      "Epoch(16) - GLOBAL - Validation Utility score: 844.9355\n",
      "Intermediate early stopping : vepoch_loss = 0.6927, the_last_loss=0.6926\n",
      "\n",
      "\n",
      "Epoch(17) - Training Loss: 0.6929\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(17) - Fold 0 - Validation Loss : 0.6924\n",
      "Epoch(17) - Fold 0 - Validation Accuracy : 0.5169\n",
      "Epoch(17) - Fold 0 - Validation Utility score : 25.3687\n",
      "Epoch(17) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(17) - Fold 1 - Validation Accuracy : 0.5216\n",
      "Epoch(17) - Fold 1 - Validation Utility score : 333.5646\n",
      "Epoch(17) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(17) - Fold 2 - Validation Accuracy : 0.5067\n",
      "Epoch(17) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(17) - Fold 3 - Validation Accuracy : 0.5070\n",
      "Epoch(17) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 4 - Validation Loss : 0.6927\n",
      "Epoch(17) - Fold 4 - Validation Accuracy : 0.5077\n",
      "Epoch(17) - Fold 4 - Validation Utility score : 635.4573\n",
      "Epoch(17) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(17) - GLOBAL - Validation Accuracy: 0.5120\n",
      "Epoch(17) - GLOBAL - Validation Utility score: 994.3905\n",
      "Intermediate early stopping : vepoch_loss = 0.6926, the_last_loss=0.6926\n",
      "\n",
      "\n",
      "Epoch(18) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(18) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(18) - Fold 0 - Validation Accuracy : 0.5185\n",
      "Epoch(18) - Fold 0 - Validation Utility score : 68.4166\n",
      "Epoch(18) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(18) - Fold 1 - Validation Accuracy : 0.5223\n",
      "Epoch(18) - Fold 1 - Validation Utility score : 338.3980\n",
      "Epoch(18) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(18) - Fold 2 - Validation Accuracy : 0.5073\n",
      "Epoch(18) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(18) - Fold 3 - Validation Accuracy : 0.5066\n",
      "Epoch(18) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(18) - Fold 4 - Validation Accuracy : 0.5091\n",
      "Epoch(18) - Fold 4 - Validation Utility score : 755.2969\n",
      "Epoch(18) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(18) - GLOBAL - Validation Accuracy: 0.5128\n",
      "Epoch(18) - GLOBAL - Validation Utility score: 1162.1115\n",
      "Saving model corresponding to last_utility_score == 1162.111542736854\n",
      "\n",
      "\n",
      "Epoch(19) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(19) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(19) - Fold 0 - Validation Accuracy : 0.5205\n",
      "Epoch(19) - Fold 0 - Validation Utility score : 216.3227\n",
      "Epoch(19) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(19) - Fold 1 - Validation Accuracy : 0.5238\n",
      "Epoch(19) - Fold 1 - Validation Utility score : 450.3375\n",
      "Epoch(19) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(19) - Fold 2 - Validation Accuracy : 0.5086\n",
      "Epoch(19) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(19) - Fold 3 - Validation Accuracy : 0.5066\n",
      "Epoch(19) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(19) - Fold 4 - Validation Accuracy : 0.5113\n",
      "Epoch(19) - Fold 4 - Validation Utility score : 983.9768\n",
      "Epoch(19) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(19) - GLOBAL - Validation Accuracy: 0.5142\n",
      "Epoch(19) - GLOBAL - Validation Utility score: 1650.6370\n",
      "Saving model corresponding to last_utility_score == 1650.6370460144087\n",
      "\n",
      "\n",
      "Epoch(20) - Training Loss: 0.6927\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(20) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(20) - Fold 0 - Validation Accuracy : 0.5210\n",
      "Epoch(20) - Fold 0 - Validation Utility score : 262.6432\n",
      "Epoch(20) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(20) - Fold 1 - Validation Accuracy : 0.5237\n",
      "Epoch(20) - Fold 1 - Validation Utility score : 479.6791\n",
      "Epoch(20) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(20) - Fold 2 - Validation Accuracy : 0.5085\n",
      "Epoch(20) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(20) - Fold 3 - Validation Accuracy : 0.5061\n",
      "Epoch(20) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(20) - Fold 4 - Validation Accuracy : 0.5113\n",
      "Epoch(20) - Fold 4 - Validation Utility score : 944.6273\n",
      "Epoch(20) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(20) - GLOBAL - Validation Accuracy: 0.5141\n",
      "Epoch(20) - GLOBAL - Validation Utility score: 1686.9495\n",
      "Saving model corresponding to last_utility_score == 1686.9495314000974\n",
      "\n",
      "\n",
      "Epoch(21) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(21) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(21) - Fold 0 - Validation Accuracy : 0.5192\n",
      "Epoch(21) - Fold 0 - Validation Utility score : 92.3662\n",
      "Epoch(21) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(21) - Fold 1 - Validation Accuracy : 0.5226\n",
      "Epoch(21) - Fold 1 - Validation Utility score : 339.0798\n",
      "Epoch(21) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(21) - Fold 2 - Validation Accuracy : 0.5081\n",
      "Epoch(21) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(21) - Fold 3 - Validation Accuracy : 0.5069\n",
      "Epoch(21) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(21) - Fold 4 - Validation Accuracy : 0.5101\n",
      "Epoch(21) - Fold 4 - Validation Utility score : 847.0392\n",
      "Epoch(21) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(21) - GLOBAL - Validation Accuracy: 0.5134\n",
      "Epoch(21) - GLOBAL - Validation Utility score: 1278.4851\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6924\n",
      "\n",
      "\n",
      "Epoch(22) - Training Loss: 0.6926\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(22) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(22) - Fold 0 - Validation Accuracy : 0.5222\n",
      "Epoch(22) - Fold 0 - Validation Utility score : 290.3102\n",
      "Epoch(22) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(22) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(22) - Fold 1 - Validation Utility score : 505.1311\n",
      "Epoch(22) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(22) - Fold 2 - Validation Accuracy : 0.5081\n",
      "Epoch(22) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(22) - Fold 3 - Validation Accuracy : 0.5062\n",
      "Epoch(22) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(22) - Fold 4 - Validation Accuracy : 0.5110\n",
      "Epoch(22) - Fold 4 - Validation Utility score : 967.3665\n",
      "Epoch(22) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(22) - GLOBAL - Validation Accuracy: 0.5142\n",
      "Epoch(22) - GLOBAL - Validation Utility score: 1762.8078\n",
      "Saving model corresponding to last_utility_score == 1762.8078470535766\n",
      "\n",
      "\n",
      "Epoch(23) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(23) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(23) - Fold 0 - Validation Accuracy : 0.5198\n",
      "Epoch(23) - Fold 0 - Validation Utility score : 146.7672\n",
      "Epoch(23) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(23) - Fold 1 - Validation Accuracy : 0.5231\n",
      "Epoch(23) - Fold 1 - Validation Utility score : 482.3024\n",
      "Epoch(23) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(23) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(23) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(23) - Fold 3 - Validation Accuracy : 0.5067\n",
      "Epoch(23) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(23) - Fold 4 - Validation Accuracy : 0.5109\n",
      "Epoch(23) - Fold 4 - Validation Utility score : 918.1174\n",
      "Epoch(23) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(23) - GLOBAL - Validation Accuracy: 0.5138\n",
      "Epoch(23) - GLOBAL - Validation Utility score: 1547.1870\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6923\n",
      "\n",
      "\n",
      "Epoch(24) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(24) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(24) - Fold 0 - Validation Accuracy : 0.5208\n",
      "Epoch(24) - Fold 0 - Validation Utility score : 151.2277\n",
      "Epoch(24) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(24) - Fold 1 - Validation Accuracy : 0.5230\n",
      "Epoch(24) - Fold 1 - Validation Utility score : 415.9100\n",
      "Epoch(24) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(24) - Fold 2 - Validation Accuracy : 0.5084\n",
      "Epoch(24) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(24) - Fold 3 - Validation Accuracy : 0.5070\n",
      "Epoch(24) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(24) - Fold 4 - Validation Accuracy : 0.5108\n",
      "Epoch(24) - Fold 4 - Validation Utility score : 891.8118\n",
      "Epoch(24) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(24) - GLOBAL - Validation Accuracy: 0.5140\n",
      "Epoch(24) - GLOBAL - Validation Utility score: 1458.9496\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6923\n",
      "\n",
      "\n",
      "Epoch(25) - Training Loss: 0.6924\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(25) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(25) - Fold 0 - Validation Accuracy : 0.5189\n",
      "Epoch(25) - Fold 0 - Validation Utility score : 57.2386\n",
      "Epoch(25) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(25) - Fold 1 - Validation Accuracy : 0.5218\n",
      "Epoch(25) - Fold 1 - Validation Utility score : 345.9200\n",
      "Epoch(25) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(25) - Fold 2 - Validation Accuracy : 0.5077\n",
      "Epoch(25) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(25) - Fold 3 - Validation Accuracy : 0.5061\n",
      "Epoch(25) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(25) - Fold 4 - Validation Accuracy : 0.5109\n",
      "Epoch(25) - Fold 4 - Validation Utility score : 737.8510\n",
      "Epoch(25) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(25) - GLOBAL - Validation Accuracy: 0.5131\n",
      "Epoch(25) - GLOBAL - Validation Utility score: 1141.0096\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6923\n",
      "\n",
      "\n",
      "Epoch(26) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(26) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(26) - Fold 0 - Validation Accuracy : 0.5214\n",
      "Epoch(26) - Fold 0 - Validation Utility score : 191.5759\n",
      "Epoch(26) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(26) - Fold 1 - Validation Accuracy : 0.5236\n",
      "Epoch(26) - Fold 1 - Validation Utility score : 442.5694\n",
      "Epoch(26) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(26) - Fold 2 - Validation Accuracy : 0.5080\n",
      "Epoch(26) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(26) - Fold 3 - Validation Accuracy : 0.5072\n",
      "Epoch(26) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(26) - Fold 4 - Validation Accuracy : 0.5109\n",
      "Epoch(26) - Fold 4 - Validation Utility score : 941.2374\n",
      "Epoch(26) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(26) - GLOBAL - Validation Accuracy: 0.5142\n",
      "Epoch(26) - GLOBAL - Validation Utility score: 1575.3826\n",
      "Saving model corresponding to last_utility_score == 1575.3826220215788\n",
      "\n",
      "\n",
      "Epoch(27) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(27) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(27) - Fold 0 - Validation Accuracy : 0.5183\n",
      "Epoch(27) - Fold 0 - Validation Utility score : 52.2252\n",
      "Epoch(27) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(27) - Fold 1 - Validation Accuracy : 0.5208\n",
      "Epoch(27) - Fold 1 - Validation Utility score : 209.1768\n",
      "Epoch(27) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(27) - Fold 2 - Validation Accuracy : 0.5085\n",
      "Epoch(27) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(27) - Fold 3 - Validation Accuracy : 0.5062\n",
      "Epoch(27) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(27) - Fold 4 - Validation Accuracy : 0.5102\n",
      "Epoch(27) - Fold 4 - Validation Utility score : 661.2896\n",
      "Epoch(27) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(27) - GLOBAL - Validation Accuracy: 0.5128\n",
      "Epoch(27) - GLOBAL - Validation Utility score: 922.6916\n",
      "Intermediate early stopping : vepoch_loss = 0.6924, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(28) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(28) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(28) - Fold 0 - Validation Accuracy : 0.5185\n",
      "Epoch(28) - Fold 0 - Validation Utility score : 55.4246\n",
      "Epoch(28) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(28) - Fold 1 - Validation Accuracy : 0.5222\n",
      "Epoch(28) - Fold 1 - Validation Utility score : 383.5387\n",
      "Epoch(28) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(28) - Fold 2 - Validation Accuracy : 0.5093\n",
      "Epoch(28) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(28) - Fold 3 - Validation Accuracy : 0.5063\n",
      "Epoch(28) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(28) - Fold 4 - Validation Accuracy : 0.5113\n",
      "Epoch(28) - Fold 4 - Validation Utility score : 813.1230\n",
      "Epoch(28) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(28) - GLOBAL - Validation Accuracy: 0.5135\n",
      "Epoch(28) - GLOBAL - Validation Utility score: 1252.0863\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6922\n",
      "\n",
      "\n",
      "Epoch(29) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(29) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(29) - Fold 0 - Validation Accuracy : 0.5228\n",
      "Epoch(29) - Fold 0 - Validation Utility score : 204.3156\n",
      "Epoch(29) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(29) - Fold 1 - Validation Accuracy : 0.5233\n",
      "Epoch(29) - Fold 1 - Validation Utility score : 478.3950\n",
      "Epoch(29) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(29) - Fold 2 - Validation Accuracy : 0.5085\n",
      "Epoch(29) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(29) - Fold 3 - Validation Accuracy : 0.5067\n",
      "Epoch(29) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(29) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(29) - Fold 4 - Validation Accuracy : 0.5112\n",
      "Epoch(29) - Fold 4 - Validation Utility score : 967.6043\n",
      "Epoch(29) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(29) - GLOBAL - Validation Accuracy: 0.5145\n",
      "Epoch(29) - GLOBAL - Validation Utility score: 1650.3150\n",
      "Saving model corresponding to last_utility_score == 1650.3149995191072\n",
      "\n",
      "\n",
      "Epoch(30) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(30) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(30) - Fold 0 - Validation Accuracy : 0.5225\n",
      "Epoch(30) - Fold 0 - Validation Utility score : 232.1579\n",
      "Epoch(30) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(30) - Fold 1 - Validation Accuracy : 0.5233\n",
      "Epoch(30) - Fold 1 - Validation Utility score : 474.3756\n",
      "Epoch(30) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(30) - Fold 2 - Validation Accuracy : 0.5086\n",
      "Epoch(30) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(30) - Fold 3 - Validation Accuracy : 0.5078\n",
      "Epoch(30) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(30) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(30) - Fold 4 - Validation Accuracy : 0.5116\n",
      "Epoch(30) - Fold 4 - Validation Utility score : 898.1703\n",
      "Epoch(30) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(30) - GLOBAL - Validation Accuracy: 0.5148\n",
      "Epoch(30) - GLOBAL - Validation Utility score: 1604.7038\n",
      "Saving model corresponding to last_utility_score == 1604.7037618072543\n",
      "\n",
      "\n",
      "Epoch(31) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(31) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(31) - Fold 0 - Validation Accuracy : 0.5231\n",
      "Epoch(31) - Fold 0 - Validation Utility score : 255.6507\n",
      "Epoch(31) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(31) - Fold 1 - Validation Accuracy : 0.5239\n",
      "Epoch(31) - Fold 1 - Validation Utility score : 586.2550\n",
      "Epoch(31) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(31) - Fold 2 - Validation Accuracy : 0.5093\n",
      "Epoch(31) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(31) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(31) - Fold 3 - Validation Accuracy : 0.5075\n",
      "Epoch(31) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(31) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(31) - Fold 4 - Validation Accuracy : 0.5126\n",
      "Epoch(31) - Fold 4 - Validation Utility score : 1016.4051\n",
      "Epoch(31) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(31) - GLOBAL - Validation Accuracy: 0.5153\n",
      "Epoch(31) - GLOBAL - Validation Utility score: 1858.3107\n",
      "Saving model corresponding to last_utility_score == 1858.3107084821706\n",
      "\n",
      "\n",
      "Epoch(32) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(32) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(32) - Fold 0 - Validation Accuracy : 0.5220\n",
      "Epoch(32) - Fold 0 - Validation Utility score : 174.3053\n",
      "Epoch(32) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(32) - Fold 1 - Validation Accuracy : 0.5228\n",
      "Epoch(32) - Fold 1 - Validation Utility score : 375.7405\n",
      "Epoch(32) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(32) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(32) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(32) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(32) - Fold 3 - Validation Accuracy : 0.5073\n",
      "Epoch(32) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(32) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(32) - Fold 4 - Validation Accuracy : 0.5123\n",
      "Epoch(32) - Fold 4 - Validation Utility score : 767.9589\n",
      "Epoch(32) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(32) - GLOBAL - Validation Accuracy: 0.5146\n",
      "Epoch(32) - GLOBAL - Validation Utility score: 1318.0047\n",
      "Intermediate early stopping : vepoch_loss = 0.6922, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(33) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(33) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(33) - Fold 0 - Validation Accuracy : 0.5168\n",
      "Epoch(33) - Fold 0 - Validation Utility score : 34.8215\n",
      "Epoch(33) - Fold 1 - Validation Loss : 0.6916\n",
      "Epoch(33) - Fold 1 - Validation Accuracy : 0.5207\n",
      "Epoch(33) - Fold 1 - Validation Utility score : 246.7609\n",
      "Epoch(33) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(33) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(33) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(33) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(33) - Fold 3 - Validation Accuracy : 0.5053\n",
      "Epoch(33) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(33) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(33) - Fold 4 - Validation Accuracy : 0.5103\n",
      "Epoch(33) - Fold 4 - Validation Utility score : 692.6854\n",
      "Epoch(33) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(33) - GLOBAL - Validation Accuracy: 0.5123\n",
      "Epoch(33) - GLOBAL - Validation Utility score: 974.2678\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(34) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(34) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(34) - Fold 0 - Validation Accuracy : 0.5245\n",
      "Epoch(34) - Fold 0 - Validation Utility score : 423.1980\n",
      "Epoch(34) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(34) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(34) - Fold 1 - Validation Utility score : 820.1290\n",
      "Epoch(34) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(34) - Fold 2 - Validation Accuracy : 0.5099\n",
      "Epoch(34) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(34) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(34) - Fold 3 - Validation Accuracy : 0.5092\n",
      "Epoch(34) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(34) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(34) - Fold 4 - Validation Accuracy : 0.5149\n",
      "Epoch(34) - Fold 4 - Validation Utility score : 998.9441\n",
      "Epoch(34) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(34) - GLOBAL - Validation Accuracy: 0.5165\n",
      "Epoch(34) - GLOBAL - Validation Utility score: 2242.2711\n",
      "Saving model corresponding to last_utility_score == 2242.271117706923\n",
      "\n",
      "\n",
      "Epoch(35) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(35) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(35) - Fold 0 - Validation Accuracy : 0.5234\n",
      "Epoch(35) - Fold 0 - Validation Utility score : 296.4374\n",
      "Epoch(35) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(35) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(35) - Fold 1 - Validation Utility score : 550.2914\n",
      "Epoch(35) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(35) - Fold 2 - Validation Accuracy : 0.5084\n",
      "Epoch(35) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(35) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(35) - Fold 3 - Validation Accuracy : 0.5075\n",
      "Epoch(35) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(35) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(35) - Fold 4 - Validation Accuracy : 0.5129\n",
      "Epoch(35) - Fold 4 - Validation Utility score : 970.0547\n",
      "Epoch(35) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(35) - GLOBAL - Validation Accuracy: 0.5151\n",
      "Epoch(35) - GLOBAL - Validation Utility score: 1816.7835\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(36) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(36) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(36) - Fold 0 - Validation Accuracy : 0.5241\n",
      "Epoch(36) - Fold 0 - Validation Utility score : 373.7407\n",
      "Epoch(36) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(36) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(36) - Fold 1 - Validation Utility score : 705.4564\n",
      "Epoch(36) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(36) - Fold 2 - Validation Accuracy : 0.5098\n",
      "Epoch(36) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(36) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(36) - Fold 3 - Validation Accuracy : 0.5089\n",
      "Epoch(36) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(36) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(36) - Fold 4 - Validation Accuracy : 0.5143\n",
      "Epoch(36) - Fold 4 - Validation Utility score : 1143.6104\n",
      "Epoch(36) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(36) - GLOBAL - Validation Accuracy: 0.5162\n",
      "Epoch(36) - GLOBAL - Validation Utility score: 2222.8076\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(37) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(37) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(37) - Fold 0 - Validation Accuracy : 0.5232\n",
      "Epoch(37) - Fold 0 - Validation Utility score : 280.7818\n",
      "Epoch(37) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(37) - Fold 1 - Validation Accuracy : 0.5237\n",
      "Epoch(37) - Fold 1 - Validation Utility score : 543.1531\n",
      "Epoch(37) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(37) - Fold 2 - Validation Accuracy : 0.5100\n",
      "Epoch(37) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(37) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(37) - Fold 3 - Validation Accuracy : 0.5085\n",
      "Epoch(37) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(37) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(37) - Fold 4 - Validation Accuracy : 0.5157\n",
      "Epoch(37) - Fold 4 - Validation Utility score : 993.1099\n",
      "Epoch(37) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(37) - GLOBAL - Validation Accuracy: 0.5162\n",
      "Epoch(37) - GLOBAL - Validation Utility score: 1817.0448\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(38) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(38) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(38) - Fold 0 - Validation Accuracy : 0.5213\n",
      "Epoch(38) - Fold 0 - Validation Utility score : 116.4470\n",
      "Epoch(38) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(38) - Fold 1 - Validation Accuracy : 0.5229\n",
      "Epoch(38) - Fold 1 - Validation Utility score : 511.0188\n",
      "Epoch(38) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(38) - Fold 2 - Validation Accuracy : 0.5103\n",
      "Epoch(38) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(38) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(38) - Fold 3 - Validation Accuracy : 0.5080\n",
      "Epoch(38) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(38) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(38) - Fold 4 - Validation Accuracy : 0.5146\n",
      "Epoch(38) - Fold 4 - Validation Utility score : 986.3845\n",
      "Epoch(38) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(38) - GLOBAL - Validation Accuracy: 0.5154\n",
      "Epoch(38) - GLOBAL - Validation Utility score: 1613.8503\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(39) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(39) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(39) - Fold 0 - Validation Accuracy : 0.5238\n",
      "Epoch(39) - Fold 0 - Validation Utility score : 321.4871\n",
      "Epoch(39) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(39) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(39) - Fold 1 - Validation Utility score : 643.9218\n",
      "Epoch(39) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(39) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(39) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(39) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(39) - Fold 3 - Validation Accuracy : 0.5089\n",
      "Epoch(39) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(39) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(39) - Fold 4 - Validation Accuracy : 0.5153\n",
      "Epoch(39) - Fold 4 - Validation Utility score : 1157.5635\n",
      "Epoch(39) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(39) - GLOBAL - Validation Accuracy: 0.5161\n",
      "Epoch(39) - GLOBAL - Validation Utility score: 2122.9724\n",
      "Saving model corresponding to last_utility_score == 2122.9723699410765\n",
      "\n",
      "\n",
      "Epoch(40) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(40) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(40) - Fold 0 - Validation Accuracy : 0.5233\n",
      "Epoch(40) - Fold 0 - Validation Utility score : 311.2391\n",
      "Epoch(40) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(40) - Fold 1 - Validation Accuracy : 0.5225\n",
      "Epoch(40) - Fold 1 - Validation Utility score : 562.1041\n",
      "Epoch(40) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(40) - Fold 2 - Validation Accuracy : 0.5097\n",
      "Epoch(40) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(40) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(40) - Fold 3 - Validation Accuracy : 0.5095\n",
      "Epoch(40) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(40) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(40) - Fold 4 - Validation Accuracy : 0.5149\n",
      "Epoch(40) - Fold 4 - Validation Utility score : 1105.9196\n",
      "Epoch(40) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(40) - GLOBAL - Validation Accuracy: 0.5160\n",
      "Epoch(40) - GLOBAL - Validation Utility score: 1979.2628\n",
      "Saving model corresponding to last_utility_score == 1979.262778024787\n",
      "\n",
      "\n",
      "Epoch(41) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(41) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(41) - Fold 0 - Validation Accuracy : 0.5187\n",
      "Epoch(41) - Fold 0 - Validation Utility score : 66.3865\n",
      "Epoch(41) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(41) - Fold 1 - Validation Accuracy : 0.5213\n",
      "Epoch(41) - Fold 1 - Validation Utility score : 438.0379\n",
      "Epoch(41) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(41) - Fold 2 - Validation Accuracy : 0.5117\n",
      "Epoch(41) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(41) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(41) - Fold 3 - Validation Accuracy : 0.5080\n",
      "Epoch(41) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(41) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(41) - Fold 4 - Validation Accuracy : 0.5144\n",
      "Epoch(41) - Fold 4 - Validation Utility score : 894.0533\n",
      "Epoch(41) - GLOBAL - Validation Loss: 0.6922\n",
      "Epoch(41) - GLOBAL - Validation Accuracy: 0.5148\n",
      "Epoch(41) - GLOBAL - Validation Utility score: 1398.4777\n",
      "Intermediate early stopping : vepoch_loss = 0.6922, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(42) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(42) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(42) - Fold 0 - Validation Accuracy : 0.5252\n",
      "Epoch(42) - Fold 0 - Validation Utility score : 420.9330\n",
      "Epoch(42) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(42) - Fold 1 - Validation Accuracy : 0.5237\n",
      "Epoch(42) - Fold 1 - Validation Utility score : 740.2309\n",
      "Epoch(42) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(42) - Fold 2 - Validation Accuracy : 0.5098\n",
      "Epoch(42) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(42) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(42) - Fold 3 - Validation Accuracy : 0.5091\n",
      "Epoch(42) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(42) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(42) - Fold 4 - Validation Accuracy : 0.5163\n",
      "Epoch(42) - Fold 4 - Validation Utility score : 1177.2828\n",
      "Epoch(42) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(42) - GLOBAL - Validation Accuracy: 0.5168\n",
      "Epoch(42) - GLOBAL - Validation Utility score: 2338.4466\n",
      "Saving model corresponding to last_utility_score == 2338.4466325011026\n",
      "\n",
      "\n",
      "Epoch(43) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(43) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(43) - Fold 0 - Validation Accuracy : 0.5239\n",
      "Epoch(43) - Fold 0 - Validation Utility score : 248.1894\n",
      "Epoch(43) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(43) - Fold 1 - Validation Accuracy : 0.5236\n",
      "Epoch(43) - Fold 1 - Validation Utility score : 633.0153\n",
      "Epoch(43) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(43) - Fold 2 - Validation Accuracy : 0.5100\n",
      "Epoch(43) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(43) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(43) - Fold 3 - Validation Accuracy : 0.5110\n",
      "Epoch(43) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(43) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(43) - Fold 4 - Validation Accuracy : 0.5161\n",
      "Epoch(43) - Fold 4 - Validation Utility score : 1112.1899\n",
      "Epoch(43) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(43) - GLOBAL - Validation Accuracy: 0.5169\n",
      "Epoch(43) - GLOBAL - Validation Utility score: 1993.3946\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(44) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(44) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(44) - Fold 0 - Validation Accuracy : 0.5230\n",
      "Epoch(44) - Fold 0 - Validation Utility score : 413.4033\n",
      "Epoch(44) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(44) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(44) - Fold 1 - Validation Utility score : 678.3649\n",
      "Epoch(44) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(44) - Fold 2 - Validation Accuracy : 0.5102\n",
      "Epoch(44) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(44) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(44) - Fold 3 - Validation Accuracy : 0.5104\n",
      "Epoch(44) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(44) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(44) - Fold 4 - Validation Accuracy : 0.5173\n",
      "Epoch(44) - Fold 4 - Validation Utility score : 1004.6654\n",
      "Epoch(44) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(44) - GLOBAL - Validation Accuracy: 0.5169\n",
      "Epoch(44) - GLOBAL - Validation Utility score: 2096.4336\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(45) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(45) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(45) - Fold 0 - Validation Accuracy : 0.5222\n",
      "Epoch(45) - Fold 0 - Validation Utility score : 323.2247\n",
      "Epoch(45) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(45) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(45) - Fold 1 - Validation Utility score : 779.6550\n",
      "Epoch(45) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(45) - Fold 2 - Validation Accuracy : 0.5107\n",
      "Epoch(45) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(45) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(45) - Fold 3 - Validation Accuracy : 0.5105\n",
      "Epoch(45) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(45) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(45) - Fold 4 - Validation Accuracy : 0.5188\n",
      "Epoch(45) - Fold 4 - Validation Utility score : 1154.8106\n",
      "Epoch(45) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(45) - GLOBAL - Validation Accuracy: 0.5172\n",
      "Epoch(45) - GLOBAL - Validation Utility score: 2257.6903\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(46) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(46) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(46) - Fold 0 - Validation Accuracy : 0.5244\n",
      "Epoch(46) - Fold 0 - Validation Utility score : 351.2877\n",
      "Epoch(46) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(46) - Fold 1 - Validation Accuracy : 0.5236\n",
      "Epoch(46) - Fold 1 - Validation Utility score : 659.9197\n",
      "Epoch(46) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(46) - Fold 2 - Validation Accuracy : 0.5096\n",
      "Epoch(46) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(46) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(46) - Fold 3 - Validation Accuracy : 0.5098\n",
      "Epoch(46) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(46) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(46) - Fold 4 - Validation Accuracy : 0.5165\n",
      "Epoch(46) - Fold 4 - Validation Utility score : 1008.0187\n",
      "Epoch(46) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(46) - GLOBAL - Validation Accuracy: 0.5168\n",
      "Epoch(46) - GLOBAL - Validation Utility score: 2019.2260\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6919\n",
      "\n",
      "\n",
      "Epoch(47) - Training Loss: 0.6915\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(47) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(47) - Fold 0 - Validation Accuracy : 0.5236\n",
      "Epoch(47) - Fold 0 - Validation Utility score : 408.0606\n",
      "Epoch(47) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(47) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(47) - Fold 1 - Validation Utility score : 822.4830\n",
      "Epoch(47) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(47) - Fold 2 - Validation Accuracy : 0.5095\n",
      "Epoch(47) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(47) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(47) - Fold 3 - Validation Accuracy : 0.5110\n",
      "Epoch(47) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(47) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(47) - Fold 4 - Validation Accuracy : 0.5199\n",
      "Epoch(47) - Fold 4 - Validation Utility score : 1190.0857\n",
      "Epoch(47) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(47) - GLOBAL - Validation Accuracy: 0.5175\n",
      "Epoch(47) - GLOBAL - Validation Utility score: 2420.6293\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6919\n",
      "Meet Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 558801<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_150655-huxbitdb/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_150655-huxbitdb/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>0.69153</td></tr><tr><td>Global valid/Loss</td><td>0.69194</td></tr><tr><td>Global valid/Accuracy</td><td>0.51751</td></tr><tr><td>Global valid/Utility</td><td>2420.62929</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>0.69152</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>0.52355</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>408.06057</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>0.69109</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>0.52352</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>822.48298</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>0.69285</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>0.50955</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>0.69283</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>0.51102</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>0.69143</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>0.51991</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>1190.08573</td></tr><tr><td>Best accuracy</td><td>0.51682</td></tr><tr><td>Best utility</td><td>2338.44663</td></tr><tr><td>_runtime</td><td>3848</td></tr><tr><td>_timestamp</td><td>1613488263</td></tr><tr><td>_step</td><td>47</td></tr><tr><td>Final utility score</td><td>{'utility_score': 23...</td></tr><tr><td>Batch size</td><td>43931</td></tr><tr><td>Patience</td><td>5</td></tr><tr><td>Number of epochs</td><td>1000</td></tr><tr><td>Best epoch</td><td>42</td></tr><tr><td>Number of parameters per layer</td><td>[8384, 64, 2048, 32,...</td></tr><tr><td>Model architecture</td><td>MLP(<BR>  (AEncoder)...</td></tr><tr><td>comment</td><td>All folds MLP with a...</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Loss</td><td>█▆▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Accuracy</td><td>▁▂▁▂▂▂▃▂▃▃▄▅▆▇▅▆▇▇▆▇▇▆▇▆▆▇▇▇▆█▇▇▇▇▇█████</td></tr><tr><td>Global valid/Utility</td><td>▁▁▁▁▁▁▁▁▁▁▂▃▄▆▃▄▆▆▅▆▅▄▆▄▅▆▆▅▄▇▇▆▆▇▇█▇▇██</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>█▆▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▂▁▂▂▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>▃▁▁▁▁▁▂▁▂▃▄▅▆▇▅▆▇▇▆▇▇▆▇▆▆▇▇▇▆██▇▇█▇██▇▇█</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>▃▁▁▁▁▁▁▁▁▁▁▁▁▄▁▂▅▅▃▆▄▂▄▂▂▅▅▄▂█▇▆▃▆▆█▅█▆█</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>█▇▅▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>▁▂▂▃▂▃▃▃▃▄▅▅██▆▇█████▇█▇▇███▇███████████</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>▁▁▁▁▁▁▁▁▁▁▁▂▄▅▃▄▅▅▄▅▅▄▅▃▄▅▆▄▃█▇▆▅▆▆▇▆▇██</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>█▅▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>▁▃▃▃▃▄▄▃▄▄▄▅▅▆▅▆▇▇▇▇▇▆▇▇▇▇▇▇▇████▇▇████▇</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>█▇▄▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>▂▁▁▁▁▂▃▂▃▄▄▅▅▅▅▅▅▅▅▅▆▅▆▅▅▆▆▆▄▇▇▆▆▇▇▇████</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>█▆▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>▁▂▃▃▃▃▃▃▃▄▄▄▅▆▅▅▆▆▅▆▆▆▆▅▆▆▆▆▅▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>▁▁▁▁▁▁▁▁▁▂▃▄▅▆▅▅▇▇▆▇▆▅▇▅▆▆▇▆▅▇█▇▇████▇██</td></tr><tr><td>Best accuracy</td><td>▁▂▂▂▂▂▂▃▃▃▄▄▅▆▇▆▇▇▇▇▇▇▇█████</td></tr><tr><td>Best utility</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▃▄▆▄▆▆▆▆▆▆▇█▇▇██</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 241 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">earnest-sweep-16</strong>: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/huxbitdb\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/huxbitdb</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training summary:\n",
      "{'utility_score': 2338.4466325011026, 'utility_scores': [420.93295721697535, 740.2309213419873, -0.0, -0.0, 1177.2827539421403], 'utility_score_std': 451.0996616049885, 'accuracy_scores': [0.5251803659763858, 0.5237486837486838, 0.5097939595334052, 0.5091240362428949, 0.5162628539230878]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5tdz2xg7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leakyrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 14151\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.47868291383350214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0019039651777024798\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_autoenc: encoder-only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.00014741356663454342\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">dry-sweep-17</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/5tdz2xg7\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/5tdz2xg7</a><br/>\n",
       "                Run data is saved locally in <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_161108-5tdz2xg7</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Run config :\n",
      "config: {'activation_function': 'leakyrelu', 'batch_size': 14151, 'dropout': 0.47868291383350214, 'learning_rate': 0.0019039651777024798, 'use_autoenc': 'encoder-only', 'weight_decay': 0.00014741356663454342, 'epochs': 1000}\n",
      "Epoch(0) - Training Loss: 0.7934\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(0) - Fold 0 - Validation Loss : 0.6949\n",
      "Epoch(0) - Fold 0 - Validation Accuracy : 0.5001\n",
      "Epoch(0) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 1 - Validation Loss : 0.6941\n",
      "Epoch(0) - Fold 1 - Validation Accuracy : 0.5063\n",
      "Epoch(0) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 2 - Validation Loss : 0.6944\n",
      "Epoch(0) - Fold 2 - Validation Accuracy : 0.5018\n",
      "Epoch(0) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 3 - Validation Loss : 0.6945\n",
      "Epoch(0) - Fold 3 - Validation Accuracy : 0.4998\n",
      "Epoch(0) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 4 - Validation Loss : 0.6947\n",
      "Epoch(0) - Fold 4 - Validation Accuracy : 0.4988\n",
      "Epoch(0) - Fold 4 - Validation Utility score : 17.5859\n",
      "Epoch(0) - GLOBAL - Validation Loss: 0.6945\n",
      "Epoch(0) - GLOBAL - Validation Accuracy: 0.5014\n",
      "Epoch(0) - GLOBAL - Validation Utility score: 17.5859\n",
      "Saving model corresponding to last_utility_score == 17.58587772262379\n",
      "\n",
      "\n",
      "Epoch(1) - Training Loss: 0.6954\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(1) - Fold 0 - Validation Loss : 0.6936\n",
      "Epoch(1) - Fold 0 - Validation Accuracy : 0.5003\n",
      "Epoch(1) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 1 - Validation Loss : 0.6931\n",
      "Epoch(1) - Fold 1 - Validation Accuracy : 0.5063\n",
      "Epoch(1) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 2 - Validation Loss : 0.6935\n",
      "Epoch(1) - Fold 2 - Validation Accuracy : 0.5018\n",
      "Epoch(1) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 3 - Validation Loss : 0.6937\n",
      "Epoch(1) - Fold 3 - Validation Accuracy : 0.4996\n",
      "Epoch(1) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 4 - Validation Loss : 0.6938\n",
      "Epoch(1) - Fold 4 - Validation Accuracy : 0.4990\n",
      "Epoch(1) - Fold 4 - Validation Utility score : 18.1490\n",
      "Epoch(1) - GLOBAL - Validation Loss: 0.6935\n",
      "Epoch(1) - GLOBAL - Validation Accuracy: 0.5014\n",
      "Epoch(1) - GLOBAL - Validation Utility score: 18.1490\n",
      "Saving model corresponding to last_utility_score == 18.149047138596327\n",
      "\n",
      "\n",
      "Epoch(2) - Training Loss: 0.6937\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(2) - Fold 0 - Validation Loss : 0.6932\n",
      "Epoch(2) - Fold 0 - Validation Accuracy : 0.5014\n",
      "Epoch(2) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 1 - Validation Loss : 0.6928\n",
      "Epoch(2) - Fold 1 - Validation Accuracy : 0.5070\n",
      "Epoch(2) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 2 - Validation Loss : 0.6933\n",
      "Epoch(2) - Fold 2 - Validation Accuracy : 0.5030\n",
      "Epoch(2) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 3 - Validation Loss : 0.6934\n",
      "Epoch(2) - Fold 3 - Validation Accuracy : 0.5015\n",
      "Epoch(2) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 4 - Validation Loss : 0.6934\n",
      "Epoch(2) - Fold 4 - Validation Accuracy : 0.5001\n",
      "Epoch(2) - Fold 4 - Validation Utility score : 32.0219\n",
      "Epoch(2) - GLOBAL - Validation Loss: 0.6932\n",
      "Epoch(2) - GLOBAL - Validation Accuracy: 0.5026\n",
      "Epoch(2) - GLOBAL - Validation Utility score: 32.0219\n",
      "Saving model corresponding to last_utility_score == 32.021935497188004\n",
      "\n",
      "\n",
      "Epoch(3) - Training Loss: 0.6934\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(3) - Fold 0 - Validation Loss : 0.6929\n",
      "Epoch(3) - Fold 0 - Validation Accuracy : 0.5070\n",
      "Epoch(3) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 1 - Validation Loss : 0.6926\n",
      "Epoch(3) - Fold 1 - Validation Accuracy : 0.5113\n",
      "Epoch(3) - Fold 1 - Validation Utility score : 25.6284\n",
      "Epoch(3) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(3) - Fold 2 - Validation Accuracy : 0.5033\n",
      "Epoch(3) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(3) - Fold 3 - Validation Accuracy : 0.5043\n",
      "Epoch(3) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 4 - Validation Loss : 0.6931\n",
      "Epoch(3) - Fold 4 - Validation Accuracy : 0.5041\n",
      "Epoch(3) - Fold 4 - Validation Utility score : 138.2746\n",
      "Epoch(3) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(3) - GLOBAL - Validation Accuracy: 0.5060\n",
      "Epoch(3) - GLOBAL - Validation Utility score: 163.9030\n",
      "Saving model corresponding to last_utility_score == 163.9029946446112\n",
      "\n",
      "\n",
      "Epoch(4) - Training Loss: 0.6932\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(4) - Fold 0 - Validation Loss : 0.6927\n",
      "Epoch(4) - Fold 0 - Validation Accuracy : 0.5122\n",
      "Epoch(4) - Fold 0 - Validation Utility score : 0.0442\n",
      "Epoch(4) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(4) - Fold 1 - Validation Accuracy : 0.5157\n",
      "Epoch(4) - Fold 1 - Validation Utility score : 44.1289\n",
      "Epoch(4) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(4) - Fold 2 - Validation Accuracy : 0.5046\n",
      "Epoch(4) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(4) - Fold 3 - Validation Accuracy : 0.5058\n",
      "Epoch(4) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 4 - Validation Loss : 0.6929\n",
      "Epoch(4) - Fold 4 - Validation Accuracy : 0.5057\n",
      "Epoch(4) - Fold 4 - Validation Utility score : 264.5070\n",
      "Epoch(4) - GLOBAL - Validation Loss: 0.6928\n",
      "Epoch(4) - GLOBAL - Validation Accuracy: 0.5088\n",
      "Epoch(4) - GLOBAL - Validation Utility score: 308.6801\n",
      "Saving model corresponding to last_utility_score == 308.6800870703703\n",
      "\n",
      "\n",
      "Epoch(5) - Training Loss: 0.6930\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(5) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(5) - Fold 0 - Validation Accuracy : 0.5206\n",
      "Epoch(5) - Fold 0 - Validation Utility score : 168.1356\n",
      "Epoch(5) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(5) - Fold 1 - Validation Accuracy : 0.5243\n",
      "Epoch(5) - Fold 1 - Validation Utility score : 452.6110\n",
      "Epoch(5) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(5) - Fold 2 - Validation Accuracy : 0.5073\n",
      "Epoch(5) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(5) - Fold 3 - Validation Accuracy : 0.5066\n",
      "Epoch(5) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(5) - Fold 4 - Validation Accuracy : 0.5100\n",
      "Epoch(5) - Fold 4 - Validation Utility score : 879.3348\n",
      "Epoch(5) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(5) - GLOBAL - Validation Accuracy: 0.5138\n",
      "Epoch(5) - GLOBAL - Validation Utility score: 1500.0814\n",
      "Saving model corresponding to last_utility_score == 1500.0814317701456\n",
      "\n",
      "\n",
      "Epoch(6) - Training Loss: 0.6929\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(6) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(6) - Fold 0 - Validation Accuracy : 0.5132\n",
      "Epoch(6) - Fold 0 - Validation Utility score : 0.0047\n",
      "Epoch(6) - Fold 1 - Validation Loss : 0.6924\n",
      "Epoch(6) - Fold 1 - Validation Accuracy : 0.5156\n",
      "Epoch(6) - Fold 1 - Validation Utility score : 58.6831\n",
      "Epoch(6) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(6) - Fold 2 - Validation Accuracy : 0.5053\n",
      "Epoch(6) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(6) - Fold 3 - Validation Accuracy : 0.5050\n",
      "Epoch(6) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 4 - Validation Loss : 0.6926\n",
      "Epoch(6) - Fold 4 - Validation Accuracy : 0.5058\n",
      "Epoch(6) - Fold 4 - Validation Utility score : 359.3838\n",
      "Epoch(6) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(6) - GLOBAL - Validation Accuracy: 0.5090\n",
      "Epoch(6) - GLOBAL - Validation Utility score: 418.0716\n",
      "Intermediate early stopping : vepoch_loss = 0.6927, the_last_loss=0.6926\n",
      "\n",
      "\n",
      "Epoch(7) - Training Loss: 0.6927\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(7) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(7) - Fold 0 - Validation Accuracy : 0.5213\n",
      "Epoch(7) - Fold 0 - Validation Utility score : 172.7062\n",
      "Epoch(7) - Fold 1 - Validation Loss : 0.6921\n",
      "Epoch(7) - Fold 1 - Validation Accuracy : 0.5235\n",
      "Epoch(7) - Fold 1 - Validation Utility score : 394.2774\n",
      "Epoch(7) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(7) - Fold 2 - Validation Accuracy : 0.5087\n",
      "Epoch(7) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(7) - Fold 3 - Validation Accuracy : 0.5063\n",
      "Epoch(7) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 4 - Validation Loss : 0.6924\n",
      "Epoch(7) - Fold 4 - Validation Accuracy : 0.5107\n",
      "Epoch(7) - Fold 4 - Validation Utility score : 876.6850\n",
      "Epoch(7) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(7) - GLOBAL - Validation Accuracy: 0.5141\n",
      "Epoch(7) - GLOBAL - Validation Utility score: 1443.6686\n",
      "Saving model corresponding to last_utility_score == 1443.668580441211\n",
      "\n",
      "\n",
      "Epoch(8) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(8) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(8) - Fold 0 - Validation Accuracy : 0.5202\n",
      "Epoch(8) - Fold 0 - Validation Utility score : 126.5417\n",
      "Epoch(8) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(8) - Fold 1 - Validation Accuracy : 0.5226\n",
      "Epoch(8) - Fold 1 - Validation Utility score : 385.4036\n",
      "Epoch(8) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(8) - Fold 2 - Validation Accuracy : 0.5094\n",
      "Epoch(8) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(8) - Fold 3 - Validation Accuracy : 0.5074\n",
      "Epoch(8) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(8) - Fold 4 - Validation Accuracy : 0.5099\n",
      "Epoch(8) - Fold 4 - Validation Utility score : 837.9447\n",
      "Epoch(8) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(8) - GLOBAL - Validation Accuracy: 0.5139\n",
      "Epoch(8) - GLOBAL - Validation Utility score: 1349.8899\n",
      "Saving model corresponding to last_utility_score == 1349.8898908071005\n",
      "\n",
      "\n",
      "Epoch(9) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(9) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(9) - Fold 0 - Validation Accuracy : 0.5204\n",
      "Epoch(9) - Fold 0 - Validation Utility score : 83.2276\n",
      "Epoch(9) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(9) - Fold 1 - Validation Accuracy : 0.5224\n",
      "Epoch(9) - Fold 1 - Validation Utility score : 329.5591\n",
      "Epoch(9) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(9) - Fold 2 - Validation Accuracy : 0.5078\n",
      "Epoch(9) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(9) - Fold 3 - Validation Accuracy : 0.5063\n",
      "Epoch(9) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(9) - Fold 4 - Validation Accuracy : 0.5105\n",
      "Epoch(9) - Fold 4 - Validation Utility score : 792.8825\n",
      "Epoch(9) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(9) - GLOBAL - Validation Accuracy: 0.5135\n",
      "Epoch(9) - GLOBAL - Validation Utility score: 1205.6691\n",
      "Saving model corresponding to last_utility_score == 1205.669132979231\n",
      "\n",
      "\n",
      "Epoch(10) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(10) - Fold 0 - Validation Loss : 0.6919\n",
      "Epoch(10) - Fold 0 - Validation Accuracy : 0.5204\n",
      "Epoch(10) - Fold 0 - Validation Utility score : 150.6548\n",
      "Epoch(10) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(10) - Fold 1 - Validation Accuracy : 0.5222\n",
      "Epoch(10) - Fold 1 - Validation Utility score : 343.8996\n",
      "Epoch(10) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(10) - Fold 2 - Validation Accuracy : 0.5084\n",
      "Epoch(10) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(10) - Fold 3 - Validation Accuracy : 0.5078\n",
      "Epoch(10) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(10) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(10) - Fold 4 - Validation Accuracy : 0.5107\n",
      "Epoch(10) - Fold 4 - Validation Utility score : 754.0037\n",
      "Epoch(10) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(10) - GLOBAL - Validation Accuracy: 0.5139\n",
      "Epoch(10) - GLOBAL - Validation Utility score: 1248.5581\n",
      "Saving model corresponding to last_utility_score == 1248.5581052092298\n",
      "\n",
      "\n",
      "Epoch(11) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(11) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(11) - Fold 0 - Validation Accuracy : 0.5248\n",
      "Epoch(11) - Fold 0 - Validation Utility score : 335.9127\n",
      "Epoch(11) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(11) - Fold 1 - Validation Accuracy : 0.5238\n",
      "Epoch(11) - Fold 1 - Validation Utility score : 587.6606\n",
      "Epoch(11) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(11) - Fold 2 - Validation Accuracy : 0.5102\n",
      "Epoch(11) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(11) - Fold 3 - Validation Accuracy : 0.5081\n",
      "Epoch(11) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(11) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(11) - Fold 4 - Validation Accuracy : 0.5129\n",
      "Epoch(11) - Fold 4 - Validation Utility score : 949.1288\n",
      "Epoch(11) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(11) - GLOBAL - Validation Accuracy: 0.5160\n",
      "Epoch(11) - GLOBAL - Validation Utility score: 1872.7021\n",
      "Saving model corresponding to last_utility_score == 1872.7021107582223\n",
      "\n",
      "\n",
      "Epoch(12) - Training Loss: 0.6921\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(12) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(12) - Fold 0 - Validation Accuracy : 0.5231\n",
      "Epoch(12) - Fold 0 - Validation Utility score : 182.4846\n",
      "Epoch(12) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(12) - Fold 1 - Validation Accuracy : 0.5222\n",
      "Epoch(12) - Fold 1 - Validation Utility score : 401.0889\n",
      "Epoch(12) - Fold 2 - Validation Loss : 0.6926\n",
      "Epoch(12) - Fold 2 - Validation Accuracy : 0.5099\n",
      "Epoch(12) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(12) - Fold 3 - Validation Accuracy : 0.5083\n",
      "Epoch(12) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(12) - Fold 4 - Validation Loss : 0.6919\n",
      "Epoch(12) - Fold 4 - Validation Accuracy : 0.5117\n",
      "Epoch(12) - Fold 4 - Validation Utility score : 694.2540\n",
      "Epoch(12) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(12) - GLOBAL - Validation Accuracy: 0.5150\n",
      "Epoch(12) - GLOBAL - Validation Utility score: 1277.8274\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(13) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(13) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(13) - Fold 0 - Validation Accuracy : 0.5201\n",
      "Epoch(13) - Fold 0 - Validation Utility score : 146.9215\n",
      "Epoch(13) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(13) - Fold 1 - Validation Accuracy : 0.5228\n",
      "Epoch(13) - Fold 1 - Validation Utility score : 362.7033\n",
      "Epoch(13) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(13) - Fold 2 - Validation Accuracy : 0.5111\n",
      "Epoch(13) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(13) - Fold 3 - Validation Accuracy : 0.5092\n",
      "Epoch(13) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(13) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(13) - Fold 4 - Validation Accuracy : 0.5132\n",
      "Epoch(13) - Fold 4 - Validation Utility score : 872.0660\n",
      "Epoch(13) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(13) - GLOBAL - Validation Accuracy: 0.5153\n",
      "Epoch(13) - GLOBAL - Validation Utility score: 1381.6908\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(14) - Training Loss: 0.6919\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(14) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(14) - Fold 0 - Validation Accuracy : 0.5193\n",
      "Epoch(14) - Fold 0 - Validation Utility score : 112.5256\n",
      "Epoch(14) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(14) - Fold 1 - Validation Accuracy : 0.5227\n",
      "Epoch(14) - Fold 1 - Validation Utility score : 445.4045\n",
      "Epoch(14) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(14) - Fold 2 - Validation Accuracy : 0.5104\n",
      "Epoch(14) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(14) - Fold 3 - Validation Accuracy : 0.5106\n",
      "Epoch(14) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(14) - Fold 4 - Validation Loss : 0.6920\n",
      "Epoch(14) - Fold 4 - Validation Accuracy : 0.5138\n",
      "Epoch(14) - Fold 4 - Validation Utility score : 763.7243\n",
      "Epoch(14) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(14) - GLOBAL - Validation Accuracy: 0.5154\n",
      "Epoch(14) - GLOBAL - Validation Utility score: 1321.6544\n",
      "Intermediate early stopping : vepoch_loss = 0.6923, the_last_loss=0.6921\n",
      "\n",
      "\n",
      "Epoch(15) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(15) - Fold 0 - Validation Loss : 0.6915\n",
      "Epoch(15) - Fold 0 - Validation Accuracy : 0.5240\n",
      "Epoch(15) - Fold 0 - Validation Utility score : 303.5514\n",
      "Epoch(15) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(15) - Fold 1 - Validation Accuracy : 0.5245\n",
      "Epoch(15) - Fold 1 - Validation Utility score : 833.6045\n",
      "Epoch(15) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(15) - Fold 2 - Validation Accuracy : 0.5106\n",
      "Epoch(15) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(15) - Fold 3 - Validation Accuracy : 0.5124\n",
      "Epoch(15) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(15) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(15) - Fold 4 - Validation Accuracy : 0.5175\n",
      "Epoch(15) - Fold 4 - Validation Utility score : 886.0173\n",
      "Epoch(15) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(15) - GLOBAL - Validation Accuracy: 0.5178\n",
      "Epoch(15) - GLOBAL - Validation Utility score: 2023.1733\n",
      "Saving model corresponding to last_utility_score == 2023.1732642361408\n",
      "\n",
      "\n",
      "Epoch(16) - Training Loss: 0.6918\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(16) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(16) - Fold 0 - Validation Accuracy : 0.5231\n",
      "Epoch(16) - Fold 0 - Validation Utility score : 289.7341\n",
      "Epoch(16) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(16) - Fold 1 - Validation Accuracy : 0.5237\n",
      "Epoch(16) - Fold 1 - Validation Utility score : 533.4689\n",
      "Epoch(16) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(16) - Fold 2 - Validation Accuracy : 0.5112\n",
      "Epoch(16) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(16) - Fold 3 - Validation Accuracy : 0.5115\n",
      "Epoch(16) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(16) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(16) - Fold 4 - Validation Accuracy : 0.5159\n",
      "Epoch(16) - Fold 4 - Validation Utility score : 1071.4717\n",
      "Epoch(16) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(16) - GLOBAL - Validation Accuracy: 0.5171\n",
      "Epoch(16) - GLOBAL - Validation Utility score: 1894.6748\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(17) - Training Loss: 0.6917\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(17) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(17) - Fold 0 - Validation Accuracy : 0.5242\n",
      "Epoch(17) - Fold 0 - Validation Utility score : 373.8045\n",
      "Epoch(17) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(17) - Fold 1 - Validation Accuracy : 0.5248\n",
      "Epoch(17) - Fold 1 - Validation Utility score : 716.2996\n",
      "Epoch(17) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(17) - Fold 2 - Validation Accuracy : 0.5123\n",
      "Epoch(17) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(17) - Fold 3 - Validation Accuracy : 0.5114\n",
      "Epoch(17) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(17) - Fold 4 - Validation Loss : 0.6917\n",
      "Epoch(17) - Fold 4 - Validation Accuracy : 0.5185\n",
      "Epoch(17) - Fold 4 - Validation Utility score : 1101.5569\n",
      "Epoch(17) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(17) - GLOBAL - Validation Accuracy: 0.5182\n",
      "Epoch(17) - GLOBAL - Validation Utility score: 2191.6610\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(18) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(18) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(18) - Fold 0 - Validation Accuracy : 0.5230\n",
      "Epoch(18) - Fold 0 - Validation Utility score : 268.1318\n",
      "Epoch(18) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(18) - Fold 1 - Validation Accuracy : 0.5241\n",
      "Epoch(18) - Fold 1 - Validation Utility score : 666.2031\n",
      "Epoch(18) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(18) - Fold 2 - Validation Accuracy : 0.5120\n",
      "Epoch(18) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(18) - Fold 3 - Validation Accuracy : 0.5126\n",
      "Epoch(18) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(18) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(18) - Fold 4 - Validation Accuracy : 0.5190\n",
      "Epoch(18) - Fold 4 - Validation Utility score : 1136.5517\n",
      "Epoch(18) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(18) - GLOBAL - Validation Accuracy: 0.5181\n",
      "Epoch(18) - GLOBAL - Validation Utility score: 2070.8866\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(19) - Training Loss: 0.6916\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(19) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(19) - Fold 0 - Validation Accuracy : 0.5238\n",
      "Epoch(19) - Fold 0 - Validation Utility score : 372.5757\n",
      "Epoch(19) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(19) - Fold 1 - Validation Accuracy : 0.5238\n",
      "Epoch(19) - Fold 1 - Validation Utility score : 878.1709\n",
      "Epoch(19) - Fold 2 - Validation Loss : 0.6929\n",
      "Epoch(19) - Fold 2 - Validation Accuracy : 0.5101\n",
      "Epoch(19) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(19) - Fold 3 - Validation Accuracy : 0.5130\n",
      "Epoch(19) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(19) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(19) - Fold 4 - Validation Accuracy : 0.5193\n",
      "Epoch(19) - Fold 4 - Validation Utility score : 1060.1166\n",
      "Epoch(19) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(19) - GLOBAL - Validation Accuracy: 0.5180\n",
      "Epoch(19) - GLOBAL - Validation Utility score: 2310.8632\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(20) - Training Loss: 0.6915\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(20) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(20) - Fold 0 - Validation Accuracy : 0.5242\n",
      "Epoch(20) - Fold 0 - Validation Utility score : 292.8805\n",
      "Epoch(20) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(20) - Fold 1 - Validation Accuracy : 0.5240\n",
      "Epoch(20) - Fold 1 - Validation Utility score : 731.8733\n",
      "Epoch(20) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(20) - Fold 2 - Validation Accuracy : 0.5103\n",
      "Epoch(20) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(20) - Fold 3 - Validation Accuracy : 0.5137\n",
      "Epoch(20) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(20) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(20) - Fold 4 - Validation Accuracy : 0.5202\n",
      "Epoch(20) - Fold 4 - Validation Utility score : 1060.5752\n",
      "Epoch(20) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(20) - GLOBAL - Validation Accuracy: 0.5185\n",
      "Epoch(20) - GLOBAL - Validation Utility score: 2085.3290\n",
      "Saving model corresponding to last_utility_score == 2085.328997682278\n",
      "\n",
      "\n",
      "Epoch(21) - Training Loss: 0.6914\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(21) - Fold 0 - Validation Loss : 0.6917\n",
      "Epoch(21) - Fold 0 - Validation Accuracy : 0.5222\n",
      "Epoch(21) - Fold 0 - Validation Utility score : 286.4890\n",
      "Epoch(21) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(21) - Fold 1 - Validation Accuracy : 0.5220\n",
      "Epoch(21) - Fold 1 - Validation Utility score : 797.4891\n",
      "Epoch(21) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(21) - Fold 2 - Validation Accuracy : 0.5107\n",
      "Epoch(21) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(21) - Fold 3 - Validation Accuracy : 0.5149\n",
      "Epoch(21) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(21) - Fold 4 - Validation Loss : 0.6915\n",
      "Epoch(21) - Fold 4 - Validation Accuracy : 0.5212\n",
      "Epoch(21) - Fold 4 - Validation Utility score : 1068.4130\n",
      "Epoch(21) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(21) - GLOBAL - Validation Accuracy: 0.5182\n",
      "Epoch(21) - GLOBAL - Validation Utility score: 2152.3911\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6920\n",
      "\n",
      "\n",
      "Epoch(22) - Training Loss: 0.6913\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(22) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(22) - Fold 0 - Validation Accuracy : 0.5257\n",
      "Epoch(22) - Fold 0 - Validation Utility score : 373.4563\n",
      "Epoch(22) - Fold 1 - Validation Loss : 0.6912\n",
      "Epoch(22) - Fold 1 - Validation Accuracy : 0.5244\n",
      "Epoch(22) - Fold 1 - Validation Utility score : 663.9309\n",
      "Epoch(22) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(22) - Fold 2 - Validation Accuracy : 0.5122\n",
      "Epoch(22) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(22) - Fold 3 - Validation Accuracy : 0.5127\n",
      "Epoch(22) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(22) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(22) - Fold 4 - Validation Accuracy : 0.5211\n",
      "Epoch(22) - Fold 4 - Validation Utility score : 1241.4908\n",
      "Epoch(22) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(22) - GLOBAL - Validation Accuracy: 0.5192\n",
      "Epoch(22) - GLOBAL - Validation Utility score: 2278.8781\n",
      "Saving model corresponding to last_utility_score == 2278.8780849848426\n",
      "\n",
      "\n",
      "Epoch(23) - Training Loss: 0.6913\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(23) - Fold 0 - Validation Loss : 0.6912\n",
      "Epoch(23) - Fold 0 - Validation Accuracy : 0.5259\n",
      "Epoch(23) - Fold 0 - Validation Utility score : 495.8622\n",
      "Epoch(23) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(23) - Fold 1 - Validation Accuracy : 0.5234\n",
      "Epoch(23) - Fold 1 - Validation Utility score : 976.1211\n",
      "Epoch(23) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(23) - Fold 2 - Validation Accuracy : 0.5095\n",
      "Epoch(23) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 3 - Validation Loss : 0.6931\n",
      "Epoch(23) - Fold 3 - Validation Accuracy : 0.5124\n",
      "Epoch(23) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(23) - Fold 4 - Validation Loss : 0.6911\n",
      "Epoch(23) - Fold 4 - Validation Accuracy : 0.5224\n",
      "Epoch(23) - Fold 4 - Validation Utility score : 1361.2009\n",
      "Epoch(23) - GLOBAL - Validation Loss: 0.6918\n",
      "Epoch(23) - GLOBAL - Validation Accuracy: 0.5187\n",
      "Epoch(23) - GLOBAL - Validation Utility score: 2833.1842\n",
      "Saving model corresponding to last_utility_score == 2833.18415265963\n",
      "\n",
      "\n",
      "Epoch(24) - Training Loss: 0.6912\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(24) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(24) - Fold 0 - Validation Accuracy : 0.5258\n",
      "Epoch(24) - Fold 0 - Validation Utility score : 479.0395\n",
      "Epoch(24) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(24) - Fold 1 - Validation Accuracy : 0.5226\n",
      "Epoch(24) - Fold 1 - Validation Utility score : 839.1830\n",
      "Epoch(24) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(24) - Fold 2 - Validation Accuracy : 0.5106\n",
      "Epoch(24) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(24) - Fold 3 - Validation Accuracy : 0.5135\n",
      "Epoch(24) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(24) - Fold 4 - Validation Loss : 0.6916\n",
      "Epoch(24) - Fold 4 - Validation Accuracy : 0.5202\n",
      "Epoch(24) - Fold 4 - Validation Utility score : 1220.5127\n",
      "Epoch(24) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(24) - GLOBAL - Validation Accuracy: 0.5185\n",
      "Epoch(24) - GLOBAL - Validation Utility score: 2538.7353\n",
      "Intermediate early stopping : vepoch_loss = 0.6921, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(25) - Training Loss: 0.6912\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(25) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(25) - Fold 0 - Validation Accuracy : 0.5213\n",
      "Epoch(25) - Fold 0 - Validation Utility score : 149.7456\n",
      "Epoch(25) - Fold 1 - Validation Loss : 0.6915\n",
      "Epoch(25) - Fold 1 - Validation Accuracy : 0.5226\n",
      "Epoch(25) - Fold 1 - Validation Utility score : 565.3714\n",
      "Epoch(25) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(25) - Fold 2 - Validation Accuracy : 0.5125\n",
      "Epoch(25) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(25) - Fold 3 - Validation Accuracy : 0.5147\n",
      "Epoch(25) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(25) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(25) - Fold 4 - Validation Accuracy : 0.5213\n",
      "Epoch(25) - Fold 4 - Validation Utility score : 1279.2647\n",
      "Epoch(25) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(25) - GLOBAL - Validation Accuracy: 0.5185\n",
      "Epoch(25) - GLOBAL - Validation Utility score: 1994.3817\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(26) - Training Loss: 0.6912\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(26) - Fold 0 - Validation Loss : 0.6914\n",
      "Epoch(26) - Fold 0 - Validation Accuracy : 0.5224\n",
      "Epoch(26) - Fold 0 - Validation Utility score : 387.2611\n",
      "Epoch(26) - Fold 1 - Validation Loss : 0.6911\n",
      "Epoch(26) - Fold 1 - Validation Accuracy : 0.5222\n",
      "Epoch(26) - Fold 1 - Validation Utility score : 821.8315\n",
      "Epoch(26) - Fold 2 - Validation Loss : 0.6926\n",
      "Epoch(26) - Fold 2 - Validation Accuracy : 0.5096\n",
      "Epoch(26) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(26) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(26) - Fold 3 - Validation Accuracy : 0.5116\n",
      "Epoch(26) - Fold 3 - Validation Utility score : 9.6178\n",
      "Epoch(26) - Fold 4 - Validation Loss : 0.6913\n",
      "Epoch(26) - Fold 4 - Validation Accuracy : 0.5227\n",
      "Epoch(26) - Fold 4 - Validation Utility score : 1224.8415\n",
      "Epoch(26) - GLOBAL - Validation Loss: 0.6919\n",
      "Epoch(26) - GLOBAL - Validation Accuracy: 0.5177\n",
      "Epoch(26) - GLOBAL - Validation Utility score: 2443.5519\n",
      "Intermediate early stopping : vepoch_loss = 0.6919, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(27) - Training Loss: 0.6911\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(27) - Fold 0 - Validation Loss : 0.6918\n",
      "Epoch(27) - Fold 0 - Validation Accuracy : 0.5209\n",
      "Epoch(27) - Fold 0 - Validation Utility score : 145.0999\n",
      "Epoch(27) - Fold 1 - Validation Loss : 0.6913\n",
      "Epoch(27) - Fold 1 - Validation Accuracy : 0.5233\n",
      "Epoch(27) - Fold 1 - Validation Utility score : 675.0841\n",
      "Epoch(27) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(27) - Fold 2 - Validation Accuracy : 0.5120\n",
      "Epoch(27) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 3 - Validation Loss : 0.6928\n",
      "Epoch(27) - Fold 3 - Validation Accuracy : 0.5123\n",
      "Epoch(27) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(27) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(27) - Fold 4 - Validation Accuracy : 0.5214\n",
      "Epoch(27) - Fold 4 - Validation Utility score : 1024.0860\n",
      "Epoch(27) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(27) - GLOBAL - Validation Accuracy: 0.5180\n",
      "Epoch(27) - GLOBAL - Validation Utility score: 1844.2700\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6918\n",
      "\n",
      "\n",
      "Epoch(28) - Training Loss: 0.6911\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(28) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(28) - Fold 0 - Validation Accuracy : 0.5224\n",
      "Epoch(28) - Fold 0 - Validation Utility score : 312.6122\n",
      "Epoch(28) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(28) - Fold 1 - Validation Accuracy : 0.5221\n",
      "Epoch(28) - Fold 1 - Validation Utility score : 768.8419\n",
      "Epoch(28) - Fold 2 - Validation Loss : 0.6927\n",
      "Epoch(28) - Fold 2 - Validation Accuracy : 0.5109\n",
      "Epoch(28) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 3 - Validation Loss : 0.6927\n",
      "Epoch(28) - Fold 3 - Validation Accuracy : 0.5146\n",
      "Epoch(28) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(28) - Fold 4 - Validation Loss : 0.6914\n",
      "Epoch(28) - Fold 4 - Validation Accuracy : 0.5239\n",
      "Epoch(28) - Fold 4 - Validation Utility score : 1210.9979\n",
      "Epoch(28) - GLOBAL - Validation Loss: 0.6920\n",
      "Epoch(28) - GLOBAL - Validation Accuracy: 0.5188\n",
      "Epoch(28) - GLOBAL - Validation Utility score: 2292.4521\n",
      "Intermediate early stopping : vepoch_loss = 0.6920, the_last_loss=0.6918\n",
      "Meet Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 565453<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_161108-5tdz2xg7/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_161108-5tdz2xg7/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>0.69107</td></tr><tr><td>Global valid/Loss</td><td>0.69198</td></tr><tr><td>Global valid/Accuracy</td><td>0.5188</td></tr><tr><td>Global valid/Utility</td><td>2292.45207</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>0.69164</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>0.52244</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>312.61225</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>0.69144</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>0.52215</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>768.84195</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>0.69271</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>0.51086</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>0.69273</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>0.51465</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>-0.0</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>0.69138</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>0.52393</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>1210.99788</td></tr><tr><td>Best accuracy</td><td>0.51873</td></tr><tr><td>Best utility</td><td>2833.18415</td></tr><tr><td>_runtime</td><td>3044</td></tr><tr><td>_timestamp</td><td>1613491313</td></tr><tr><td>_step</td><td>28</td></tr><tr><td>Final utility score</td><td>{'utility_score': 28...</td></tr><tr><td>Batch size</td><td>14151</td></tr><tr><td>Patience</td><td>5</td></tr><tr><td>Number of epochs</td><td>1000</td></tr><tr><td>Best epoch</td><td>23</td></tr><tr><td>Number of parameters per layer</td><td>[8384, 64, 2048, 32,...</td></tr><tr><td>Model architecture</td><td>MLP(<BR>  (AEncoder)...</td></tr><tr><td>comment</td><td>All folds MLP with a...</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Global train/loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Global valid/Loss</td><td>█▅▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▂▁▂▁</td></tr><tr><td>Global valid/Accuracy</td><td>▁▁▁▃▄▆▄▆▆▆▆▇▆▆▆▇▇█████████▇▇█</td></tr><tr><td>Global valid/Utility</td><td>▁▁▁▁▂▅▂▅▄▄▄▆▄▄▄▆▆▆▆▇▆▆▇█▇▆▇▆▇</td></tr><tr><td>Fold valid Loss/Loss fold 0</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▁▂▂▂▂▂</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 0</td><td>▁▁▁▃▄▇▅▇▆▇▆█▇▆▆▇▇█▇▇█▇███▇▇▇▇</td></tr><tr><td>Fold valid Utility/Utility fold 0</td><td>▁▁▁▁▁▃▁▃▃▂▃▆▄▃▃▅▅▆▅▆▅▅▆██▃▆▃▅</td></tr><tr><td>Fold valid Loss/Loss fold 1</td><td>█▆▅▅▄▄▄▃▃▃▃▂▂▂▃▂▂▂▂▂▂▂▁▁▂▂▁▂▂</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 1</td><td>▁▁▁▃▅█▅█▇▇▇█▇▇▇██████▇█▇▇▇▇▇▇</td></tr><tr><td>Fold valid Utility/Utility fold 1</td><td>▁▁▁▁▁▄▁▄▄▃▃▅▄▄▄▇▅▆▆▇▆▇▆█▇▅▇▆▇</td></tr><tr><td>Fold valid Loss/Loss fold 2</td><td>█▅▄▃▂▂▂▁▁▁▁▁▁▁▂▁▁▁▂▂▁▁▁▁▂▂▁▂▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 2</td><td>▁▁▂▂▃▅▃▅▆▅▅▆▆▇▇▇▇██▆▇▇█▆▇█▆█▇</td></tr><tr><td>Fold valid Utility/Utility fold 2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 3</td><td>█▅▃▃▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▂▁▁▂▂▁▁▂▁▁</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 3</td><td>▁▁▂▃▄▄▃▄▅▄▅▅▅▅▆▇▆▆▇▇▇█▇▇▇█▇▇█</td></tr><tr><td>Fold valid Utility/Utility fold 3</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁</td></tr><tr><td>Fold valid Loss/Loss fold 4</td><td>█▆▅▅▅▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁▂▂▁▂▂</td></tr><tr><td>Fold valid Accuracy/Accuracy fold 4</td><td>▁▁▁▂▃▄▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇█▇▇█▇█</td></tr><tr><td>Fold valid Utility/Utility fold 4</td><td>▁▁▁▂▂▅▃▅▅▅▅▆▅▅▅▆▆▇▇▆▆▆▇█▇█▇▆▇</td></tr><tr><td>Best accuracy</td><td>▁▁▁▃▄▆▆▆▆▆▇▇████</td></tr><tr><td>Best utility</td><td>▁▁▁▁▂▅▅▄▄▄▆▆▆▇██</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 146 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">dry-sweep-17</strong>: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/5tdz2xg7\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/5tdz2xg7</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training summary:\n",
      "{'utility_score': 2833.18415265963, 'utility_scores': [495.86221383203196, 976.1210729071522, -0.0, -0.0, 1361.2008659204455], 'utility_score_std': 537.8053538011781, 'accuracy_scores': [0.5259245085115732, 0.5233696033696034, 0.5095055990003502, 0.512423321514998, 0.5224397802507396]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: go806j74 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leakyrelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 14705\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3340782446216876\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0015960482949756078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_autoenc: encoder-only\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 9.031503775127845e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.19 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">eager-sweep-18</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/sweeps/hq9t5iju</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/fboyer/janestreet-mlp/runs/go806j74\" target=\"_blank\">https://wandb.ai/fboyer/janestreet-mlp/runs/go806j74</a><br/>\n",
       "                Run data is saved locally in <code>/home/francois/coding/OC/PJ9/wandb/run-20210216_170159-go806j74</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Run config :\n",
      "config: {'activation_function': 'leakyrelu', 'batch_size': 14705, 'dropout': 0.3340782446216876, 'learning_rate': 0.0015960482949756078, 'use_autoenc': 'encoder-only', 'weight_decay': 9.031503775127845e-05, 'epochs': 1000}\n",
      "Epoch(0) - Training Loss: 0.7654\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(0) - Fold 0 - Validation Loss : 0.6945\n",
      "Epoch(0) - Fold 0 - Validation Accuracy : 0.5001\n",
      "Epoch(0) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 1 - Validation Loss : 0.6942\n",
      "Epoch(0) - Fold 1 - Validation Accuracy : 0.5056\n",
      "Epoch(0) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 2 - Validation Loss : 0.6944\n",
      "Epoch(0) - Fold 2 - Validation Accuracy : 0.5015\n",
      "Epoch(0) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 3 - Validation Loss : 0.6947\n",
      "Epoch(0) - Fold 3 - Validation Accuracy : 0.5001\n",
      "Epoch(0) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(0) - Fold 4 - Validation Loss : 0.6946\n",
      "Epoch(0) - Fold 4 - Validation Accuracy : 0.4986\n",
      "Epoch(0) - Fold 4 - Validation Utility score : 10.7691\n",
      "Epoch(0) - GLOBAL - Validation Loss: 0.6945\n",
      "Epoch(0) - GLOBAL - Validation Accuracy: 0.5012\n",
      "Epoch(0) - GLOBAL - Validation Utility score: 10.7691\n",
      "Saving model corresponding to last_utility_score == 10.769055698967474\n",
      "\n",
      "\n",
      "Epoch(1) - Training Loss: 0.6963\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(1) - Fold 0 - Validation Loss : 0.6937\n",
      "Epoch(1) - Fold 0 - Validation Accuracy : 0.5002\n",
      "Epoch(1) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 1 - Validation Loss : 0.6931\n",
      "Epoch(1) - Fold 1 - Validation Accuracy : 0.5065\n",
      "Epoch(1) - Fold 1 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 2 - Validation Loss : 0.6936\n",
      "Epoch(1) - Fold 2 - Validation Accuracy : 0.5025\n",
      "Epoch(1) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 3 - Validation Loss : 0.6937\n",
      "Epoch(1) - Fold 3 - Validation Accuracy : 0.5000\n",
      "Epoch(1) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(1) - Fold 4 - Validation Loss : 0.6937\n",
      "Epoch(1) - Fold 4 - Validation Accuracy : 0.4996\n",
      "Epoch(1) - Fold 4 - Validation Utility score : 23.2401\n",
      "Epoch(1) - GLOBAL - Validation Loss: 0.6936\n",
      "Epoch(1) - GLOBAL - Validation Accuracy: 0.5018\n",
      "Epoch(1) - GLOBAL - Validation Utility score: 23.2401\n",
      "Saving model corresponding to last_utility_score == 23.240053960788348\n",
      "\n",
      "\n",
      "Epoch(2) - Training Loss: 0.6935\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(2) - Fold 0 - Validation Loss : 0.6929\n",
      "Epoch(2) - Fold 0 - Validation Accuracy : 0.5073\n",
      "Epoch(2) - Fold 0 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 1 - Validation Loss : 0.6925\n",
      "Epoch(2) - Fold 1 - Validation Accuracy : 0.5124\n",
      "Epoch(2) - Fold 1 - Validation Utility score : 27.3162\n",
      "Epoch(2) - Fold 2 - Validation Loss : 0.6931\n",
      "Epoch(2) - Fold 2 - Validation Accuracy : 0.5026\n",
      "Epoch(2) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 3 - Validation Loss : 0.6933\n",
      "Epoch(2) - Fold 3 - Validation Accuracy : 0.5043\n",
      "Epoch(2) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(2) - Fold 4 - Validation Loss : 0.6932\n",
      "Epoch(2) - Fold 4 - Validation Accuracy : 0.5030\n",
      "Epoch(2) - Fold 4 - Validation Utility score : 144.3533\n",
      "Epoch(2) - GLOBAL - Validation Loss: 0.6930\n",
      "Epoch(2) - GLOBAL - Validation Accuracy: 0.5059\n",
      "Epoch(2) - GLOBAL - Validation Utility score: 171.6695\n",
      "Saving model corresponding to last_utility_score == 171.66947959568517\n",
      "\n",
      "\n",
      "Epoch(3) - Training Loss: 0.6931\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(3) - Fold 0 - Validation Loss : 0.6925\n",
      "Epoch(3) - Fold 0 - Validation Accuracy : 0.5134\n",
      "Epoch(3) - Fold 0 - Validation Utility score : 1.4271\n",
      "Epoch(3) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(3) - Fold 1 - Validation Accuracy : 0.5170\n",
      "Epoch(3) - Fold 1 - Validation Utility score : 226.9645\n",
      "Epoch(3) - Fold 2 - Validation Loss : 0.6930\n",
      "Epoch(3) - Fold 2 - Validation Accuracy : 0.5050\n",
      "Epoch(3) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 3 - Validation Loss : 0.6932\n",
      "Epoch(3) - Fold 3 - Validation Accuracy : 0.5073\n",
      "Epoch(3) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(3) - Fold 4 - Validation Loss : 0.6928\n",
      "Epoch(3) - Fold 4 - Validation Accuracy : 0.5068\n",
      "Epoch(3) - Fold 4 - Validation Utility score : 477.2371\n",
      "Epoch(3) - GLOBAL - Validation Loss: 0.6927\n",
      "Epoch(3) - GLOBAL - Validation Accuracy: 0.5099\n",
      "Epoch(3) - GLOBAL - Validation Utility score: 705.6287\n",
      "Saving model corresponding to last_utility_score == 705.6286737871706\n",
      "\n",
      "\n",
      "Epoch(4) - Training Loss: 0.6928\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(4) - Fold 0 - Validation Loss : 0.6921\n",
      "Epoch(4) - Fold 0 - Validation Accuracy : 0.5226\n",
      "Epoch(4) - Fold 0 - Validation Utility score : 311.3090\n",
      "Epoch(4) - Fold 1 - Validation Loss : 0.6920\n",
      "Epoch(4) - Fold 1 - Validation Accuracy : 0.5243\n",
      "Epoch(4) - Fold 1 - Validation Utility score : 596.7684\n",
      "Epoch(4) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(4) - Fold 2 - Validation Accuracy : 0.5075\n",
      "Epoch(4) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(4) - Fold 3 - Validation Accuracy : 0.5064\n",
      "Epoch(4) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(4) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(4) - Fold 4 - Validation Accuracy : 0.5119\n",
      "Epoch(4) - Fold 4 - Validation Utility score : 865.6160\n",
      "Epoch(4) - GLOBAL - Validation Loss: 0.6925\n",
      "Epoch(4) - GLOBAL - Validation Accuracy: 0.5145\n",
      "Epoch(4) - GLOBAL - Validation Utility score: 1773.6934\n",
      "Saving model corresponding to last_utility_score == 1773.6933828172641\n",
      "\n",
      "\n",
      "Epoch(5) - Training Loss: 0.6927\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(5) - Fold 0 - Validation Loss : 0.6923\n",
      "Epoch(5) - Fold 0 - Validation Accuracy : 0.5164\n",
      "Epoch(5) - Fold 0 - Validation Utility score : 31.0557\n",
      "Epoch(5) - Fold 1 - Validation Loss : 0.6922\n",
      "Epoch(5) - Fold 1 - Validation Accuracy : 0.5204\n",
      "Epoch(5) - Fold 1 - Validation Utility score : 394.8812\n",
      "Epoch(5) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(5) - Fold 2 - Validation Accuracy : 0.5077\n",
      "Epoch(5) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(5) - Fold 3 - Validation Accuracy : 0.5069\n",
      "Epoch(5) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(5) - Fold 4 - Validation Loss : 0.6925\n",
      "Epoch(5) - Fold 4 - Validation Accuracy : 0.5092\n",
      "Epoch(5) - Fold 4 - Validation Utility score : 727.3538\n",
      "Epoch(5) - GLOBAL - Validation Loss: 0.6926\n",
      "Epoch(5) - GLOBAL - Validation Accuracy: 0.5121\n",
      "Epoch(5) - GLOBAL - Validation Utility score: 1153.2907\n",
      "Intermediate early stopping : vepoch_loss = 0.6926, the_last_loss=0.6925\n",
      "\n",
      "\n",
      "Epoch(6) - Training Loss: 0.6925\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(6) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(6) - Fold 0 - Validation Accuracy : 0.5196\n",
      "Epoch(6) - Fold 0 - Validation Utility score : 125.6171\n",
      "Epoch(6) - Fold 1 - Validation Loss : 0.6919\n",
      "Epoch(6) - Fold 1 - Validation Accuracy : 0.5222\n",
      "Epoch(6) - Fold 1 - Validation Utility score : 397.3319\n",
      "Epoch(6) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(6) - Fold 2 - Validation Accuracy : 0.5077\n",
      "Epoch(6) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(6) - Fold 3 - Validation Accuracy : 0.5074\n",
      "Epoch(6) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(6) - Fold 4 - Validation Loss : 0.6923\n",
      "Epoch(6) - Fold 4 - Validation Accuracy : 0.5110\n",
      "Epoch(6) - Fold 4 - Validation Utility score : 833.2871\n",
      "Epoch(6) - GLOBAL - Validation Loss: 0.6924\n",
      "Epoch(6) - GLOBAL - Validation Accuracy: 0.5136\n",
      "Epoch(6) - GLOBAL - Validation Utility score: 1356.2361\n",
      "Saving model corresponding to last_utility_score == 1356.2360601141945\n",
      "\n",
      "\n",
      "Epoch(7) - Training Loss: 0.6923\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(7) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(7) - Fold 0 - Validation Accuracy : 0.5193\n",
      "Epoch(7) - Fold 0 - Validation Utility score : 123.0854\n",
      "Epoch(7) - Fold 1 - Validation Loss : 0.6918\n",
      "Epoch(7) - Fold 1 - Validation Accuracy : 0.5223\n",
      "Epoch(7) - Fold 1 - Validation Utility score : 492.9333\n",
      "Epoch(7) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(7) - Fold 2 - Validation Accuracy : 0.5076\n",
      "Epoch(7) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(7) - Fold 3 - Validation Accuracy : 0.5069\n",
      "Epoch(7) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(7) - Fold 4 - Validation Loss : 0.6922\n",
      "Epoch(7) - Fold 4 - Validation Accuracy : 0.5101\n",
      "Epoch(7) - Fold 4 - Validation Utility score : 892.7483\n",
      "Epoch(7) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(7) - GLOBAL - Validation Accuracy: 0.5132\n",
      "Epoch(7) - GLOBAL - Validation Utility score: 1508.7670\n",
      "Saving model corresponding to last_utility_score == 1508.766998005161\n",
      "\n",
      "\n",
      "Epoch(8) - Training Loss: 0.6922\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(8) - Fold 0 - Validation Loss : 0.6920\n",
      "Epoch(8) - Fold 0 - Validation Accuracy : 0.5184\n",
      "Epoch(8) - Fold 0 - Validation Utility score : 77.8794\n",
      "Epoch(8) - Fold 1 - Validation Loss : 0.6917\n",
      "Epoch(8) - Fold 1 - Validation Accuracy : 0.5214\n",
      "Epoch(8) - Fold 1 - Validation Utility score : 396.2797\n",
      "Epoch(8) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(8) - Fold 2 - Validation Accuracy : 0.5083\n",
      "Epoch(8) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 3 - Validation Loss : 0.6930\n",
      "Epoch(8) - Fold 3 - Validation Accuracy : 0.5075\n",
      "Epoch(8) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(8) - Fold 4 - Validation Loss : 0.6921\n",
      "Epoch(8) - Fold 4 - Validation Accuracy : 0.5100\n",
      "Epoch(8) - Fold 4 - Validation Utility score : 786.5849\n",
      "Epoch(8) - GLOBAL - Validation Loss: 0.6923\n",
      "Epoch(8) - GLOBAL - Validation Accuracy: 0.5131\n",
      "Epoch(8) - GLOBAL - Validation Utility score: 1260.7440\n",
      "Saving model corresponding to last_utility_score == 1260.743995818371\n",
      "\n",
      "\n",
      "Epoch(9) - Training Loss: 0.6920\n",
      "Activation stats: No data returned for stats at layer 2\n",
      "Epoch(9) - Fold 0 - Validation Loss : 0.6916\n",
      "Epoch(9) - Fold 0 - Validation Accuracy : 0.5235\n",
      "Epoch(9) - Fold 0 - Validation Utility score : 333.3693\n",
      "Epoch(9) - Fold 1 - Validation Loss : 0.6914\n",
      "Epoch(9) - Fold 1 - Validation Accuracy : 0.5242\n",
      "Epoch(9) - Fold 1 - Validation Utility score : 749.3820\n",
      "Epoch(9) - Fold 2 - Validation Loss : 0.6928\n",
      "Epoch(9) - Fold 2 - Validation Accuracy : 0.5103\n",
      "Epoch(9) - Fold 2 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 3 - Validation Loss : 0.6929\n",
      "Epoch(9) - Fold 3 - Validation Accuracy : 0.5090\n",
      "Epoch(9) - Fold 3 - Validation Utility score : -0.0000\n",
      "Epoch(9) - Fold 4 - Validation Loss : 0.6918\n",
      "Epoch(9) - Fold 4 - Validation Accuracy : 0.5131\n",
      "Epoch(9) - Fold 4 - Validation Utility score : 946.3771\n",
      "Epoch(9) - GLOBAL - Validation Loss: 0.6921\n",
      "Epoch(9) - GLOBAL - Validation Accuracy: 0.5160\n",
      "Epoch(9) - GLOBAL - Validation Utility score: 2029.1285\n",
      "Saving model corresponding to last_utility_score == 2029.1284593656067\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if (DO_SWEEP == True):\n",
    "    wandb.agent(sweep_id, function=train, project=\"janestreet-mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (DO_SINGLE_TRAIN == True):\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2579 with shuffle and RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.onnx.export(model, batch, MODEL_FILE_ONNX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note utility score précédent :  \n",
    "\n",
    "{'utility_score': 2699.3290911247423, 'utility_scores': [433.21587581983806, 842.8579165327393, -0.0, -0.0, 1423.255298772165], 'utility_score_std': 541.5654345633293, 'accuracy_scores': [0.5243157432212159, 0.5228992628992629, 0.5123754728769456, 0.5104606336878834, 0.5277785603606142]}\n",
    "\n",
    "(avec std scale)\n",
    "\n",
    "\n",
    "Training summary:\n",
    "{'utility_score': 2697.374406045479, 'utility_scores': [448.22515142892547, 938.181355255796, -0.0, -0.0, 1310.9678993607574], 'utility_score_std': 518.5674763422022, 'accuracy_scores': [0.5212753894345934, 0.5206107406107406, 0.5085924573123425, 0.5062820079914457, 0.525750105648683]}\n",
    "\n",
    "\n",
    "Essayer : \n",
    "> avec features supplémentaires  \n",
    "> augmenter le dropout de la couche avec bcp de 0, ou supprimer la couche  \n",
    "> bouger le weight decay : essayer 1e-5, et 1e-3  \n",
    "> augmenter la taille du batch  \n",
    "> label smoothing   (voir loss_fn = SmoothBCEwLogits(smoothing=0.005)  dans janestreet_kaggle....)  \n",
    "> différents triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model_load = nn.Sequential(\n",
    "        #nn.Dropout(0.2),\n",
    "        nn.Linear(len(FEATURES_LIST_TOTRAIN), 130),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "\n",
    "        nn.Linear(130, 130),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),    \n",
    "\n",
    "        nn.Linear(130, 130),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),    \n",
    "\n",
    "        nn.Linear(130, 130),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),    \n",
    "\n",
    "        nn.Linear(130, 130),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),    \n",
    "\n",
    "        nn.Linear(130, 130),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),    \n",
    "    \n",
    "        nn.Linear(130, 130),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),    \n",
    "    \n",
    "        nn.Linear(130, 130),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),    \n",
    "\n",
    "        nn.Linear(130, 60),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),    \n",
    "    \n",
    "        nn.Linear(60, 30),\n",
    "        #nn.BatchNorm1d(130),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),    \n",
    "       \n",
    "        nn.Linear(30, 1),\n",
    "        nn.Sigmoid(),\n",
    "    ).double().to('cuda')\n",
    "    \n",
    "model_load.load_state_dict(torch.load(f'model_NN_allfolds_V1.pt',map_location=torch.device('cuda')))\n",
    "'''\n",
    "\n",
    "#model_load.eval()\n",
    "#print(accuracy_score(ts_test_y.cpu().numpy(), (model_load(ts_test).squeeze() > 0.5).cpu().numpy()))\n",
    "#\n",
    "#model_load.eval()\n",
    "#print(utility_function(df.loc[test_index], (model_load(ts_test).squeeze() > 0.5).cpu().numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, fill NA with :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.009838564545944745,\n",
       " 0.38557755173112973,\n",
       " 0.35768747744650975,\n",
       " 0.00891916614596665,\n",
       " 0.0041500560373424495,\n",
       " -0.0037146189993207766,\n",
       " -0.012589244366156346,\n",
       " 0.051776552018932685,\n",
       " 0.026828095990947754,\n",
       " 0.24881331937245502,\n",
       " 0.18234851148590248,\n",
       " 0.08912156181298928,\n",
       " 0.049485535154017296,\n",
       " 0.14310535183278583,\n",
       " 0.08902722352210106,\n",
       " 0.21167757450938102,\n",
       " 0.146300650876364,\n",
       " 0.12121931699105562,\n",
       " 0.11358210894993667,\n",
       " 0.2938148492026861,\n",
       " 0.26876788737703755,\n",
       " 0.18691131282167164,\n",
       " 0.1769785779830002,\n",
       " 0.25244128771902047,\n",
       " 0.23856075429165213,\n",
       " 0.29407078502434514,\n",
       " 0.273177703966479,\n",
       " 0.13548298050171867,\n",
       " 0.16087630644126466,\n",
       " 0.32189235718153003,\n",
       " 0.3425343272966006,\n",
       " 0.2205604165416505,\n",
       " 0.25013120792951216,\n",
       " 0.3082216783372597,\n",
       " 0.3353533199754549,\n",
       " 0.34145307300650396,\n",
       " 0.36582532760649067,\n",
       " 0.029320465264380657,\n",
       " 0.02289177995103487,\n",
       " 0.04002162079212139,\n",
       " 0.05074972651124518,\n",
       " 0.4450543980970518,\n",
       " 0.36018357114469624,\n",
       " 0.34602868865463743,\n",
       " 0.4115306048129169,\n",
       " 0.43803102237933605,\n",
       " 0.47611584684954844,\n",
       " 0.3478667314970123,\n",
       " 0.4996310121501766,\n",
       " 0.5640008775247856,\n",
       " 0.5122603244317466,\n",
       " 0.45738658177408503,\n",
       " 0.04574377016024373,\n",
       " 0.36269998611838594,\n",
       " 0.35886983636928554,\n",
       " 0.652597182609052,\n",
       " 0.8049459750150331,\n",
       " 0.6613497470714732,\n",
       " 0.679812464521779,\n",
       " 0.7625897106372482,\n",
       " 0.5563956951455176,\n",
       " 0.5581652498654769,\n",
       " 0.5455413826521486,\n",
       " 0.546778335577234,\n",
       " 0.43505876086903456,\n",
       " 0.6075653248439333,\n",
       " 0.6085039517279847,\n",
       " 0.5951947177318683,\n",
       " 0.5959424881601522,\n",
       " 0.36954104040881697,\n",
       " 0.24337091134397526,\n",
       " 0.33227354399541986,\n",
       " 0.005393298121375514,\n",
       " -0.03286771852370292,\n",
       " -0.00020445421701550574,\n",
       " -0.019091946690617916,\n",
       " -0.031898281803949866,\n",
       " -0.07680002772370834,\n",
       " -0.00605952373252944,\n",
       " -0.035434597323818526,\n",
       " -0.002099458966825259,\n",
       " -0.014418274525843731,\n",
       " -0.03461507559647192,\n",
       " -0.0800853052057879,\n",
       " 0.3982158398248166,\n",
       " 0.5578243392749649,\n",
       " 0.4024042638598482,\n",
       " 0.44445105036718896,\n",
       " 0.5140947514539359,\n",
       " 0.40051646364922716,\n",
       " 0.41025294617564356,\n",
       " 0.5205121351461534,\n",
       " 0.4050807138243217,\n",
       " 0.4088298932713245,\n",
       " 0.42889387778006083,\n",
       " 0.41763183586073954,\n",
       " 0.40226847198530646,\n",
       " 0.5590945852445534,\n",
       " 0.40710700821605167,\n",
       " 0.4368573700084827,\n",
       " 0.5001226990638947,\n",
       " 0.40856460238921344,\n",
       " 0.40506301819893675,\n",
       " 0.48140573756748783,\n",
       " 0.40165573205168165,\n",
       " 0.40706131905131204,\n",
       " 0.4530453026311098,\n",
       " 0.41501192155955596,\n",
       " 0.39999263512557864,\n",
       " 0.4165405195231404,\n",
       " 0.4007356675614491,\n",
       " 0.40687807118570485,\n",
       " 0.41228491406734663,\n",
       " 0.4026373333613518,\n",
       " 0.40711205681095564,\n",
       " 0.37341742416551793,\n",
       " 0.40443262685246384,\n",
       " 0.40103337181422305,\n",
       " 0.38581705373929415,\n",
       " 0.41559987309867774,\n",
       " 0.33512703226889273,\n",
       " 0.2687757036832287,\n",
       " 0.34355231662463237,\n",
       " 0.27999728178893696,\n",
       " 0.33515369461396705,\n",
       " 0.24487524464105123,\n",
       " 0.3391777949954427,\n",
       " 0.2323808666181667,\n",
       " 0.3425608266217579,\n",
       " 0.24561818215100586]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then, normalize with :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0088,  0.3957,  0.3306,  0.0092,  0.0034, -0.0050, -0.0146,  0.0553,\n",
       "         0.0251,  0.2647,  0.1671,  0.0949,  0.0445,  0.1525,  0.0800,  0.2217,\n",
       "         0.1283,  0.1218,  0.1096,  0.2977,  0.2646,  0.1881,  0.1725,  0.2547,\n",
       "         0.2327,  0.2979,  0.2685,  0.1399,  0.1629,  0.3306,  0.3439,  0.2268,\n",
       "         0.2519,  0.3164,  0.3360,  0.3528,  0.3677,  0.0265,  0.0186,  0.0432,\n",
       "         0.0530,  0.4542,  0.3776,  0.4162,  0.4393,  0.4865,  0.4921,  0.3684,\n",
       "         0.5014,  0.5438,  0.5307,  0.4567,  0.0565,  0.3890,  0.3769,  0.7755,\n",
       "         0.9247,  0.7859,  0.8085,  0.8990,  0.5534,  0.5555,  0.5592,  0.5614,\n",
       "         0.4423,  0.6188,  0.6172,  0.5977,  0.5981,  0.3774,  0.2389,  0.3080,\n",
       "         0.0041, -0.0322, -0.0016, -0.0199, -0.0316, -0.0932, -0.0081, -0.0358,\n",
       "        -0.0025, -0.0149, -0.0350, -0.1015,  0.3934,  0.5416,  0.3924,  0.4281,\n",
       "         0.4976,  0.3994,  0.4332,  0.5235,  0.4224,  0.4221,  0.4348,  0.4547,\n",
       "         0.3984,  0.5422,  0.3973,  0.4259,  0.4865,  0.4105,  0.4340,  0.4839,\n",
       "         0.4168,  0.4198,  0.4614,  0.4553,  0.3950,  0.3824,  0.3900,  0.3918,\n",
       "         0.3807,  0.4035,  0.4320,  0.3767,  0.4279,  0.4207,  0.3952,  0.4465,\n",
       "         0.3616,  0.2999,  0.3709,  0.3035,  0.3601,  0.2778,  0.3743,  0.2571,\n",
       "         0.3739,  0.2682], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  2.5724,  2.4543,  1.9501,  1.7327,  1.7503,  1.6707,  1.6297,\n",
       "         1.8147,  2.4146,  1.7088,  1.6546,  2.3538,  2.2777,  2.0171,  1.8925,\n",
       "         2.2236,  1.5821,  1.9931,  1.7196,  1.9315,  2.4339,  1.7864,  2.1404,\n",
       "         2.6117,  2.0852,  2.2918,  1.4115,  1.8827,  1.7403,  2.0817,  1.6850,\n",
       "         2.4817,  1.9481,  2.0704,  2.4316,  2.2853,  2.0566,  2.1225,  1.6162,\n",
       "         2.3138,  1.9912,  2.4127,  2.3259,  2.7887,  1.9650,  2.8462,  2.2005,\n",
       "         3.0387,  3.5713,  3.7193,  2.8348,  1.8877,  2.2007,  1.9352,  7.1295,\n",
       "        11.0556,  7.5957,  8.1579,  9.9465,  2.2164,  1.9947,  2.1712,  2.2567,\n",
       "         2.3735,  2.1915,  1.7553,  2.5883,  2.5263,  2.2991,  2.4406,  1.8076,\n",
       "         1.8125,  2.1476,  1.7792,  1.9738,  2.2283,  2.6795,  2.1807,  1.7949,\n",
       "         1.7688,  2.2805,  1.9767,  2.4821,  1.9748,  2.4948,  1.9679,  2.6387,\n",
       "         2.5943,  2.6160,  2.0864,  2.6942,  2.0670,  2.2104,  2.1212,  2.5054,\n",
       "         2.1243,  2.5619,  2.3017,  2.1175,  2.2689,  2.6136,  2.3357,  2.2557,\n",
       "         1.8389,  2.0931,  2.7896,  2.4935,  2.4409,  2.5761,  1.9721,  1.9469,\n",
       "         2.6040,  2.8786,  2.1073,  2.3353,  2.3193,  2.5076,  2.4064,  2.0617,\n",
       "         1.9008,  2.1498,  2.1102,  1.9852,  1.7631,  2.2454,  2.5548,  1.8003,\n",
       "         2.3295,  1.7714], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_train_std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
