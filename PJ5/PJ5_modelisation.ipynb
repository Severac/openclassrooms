{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Openclassrooms PJ5 : Online Retail dataset :  modelisation notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, importlib\n",
    "importlib.reload(sys.modules['functions'])\n",
    "\n",
    "from functions import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import urllib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import qgrid\n",
    "\n",
    "import glob\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "DATA_PATH = os.path.join(\"datasets\", \"onlineretail\")\n",
    "DATA_PATH = os.path.join(DATA_PATH, \"out\")\n",
    "\n",
    "DATA_PATH_FILE_INPUT = os.path.join(DATA_PATH, \"OnlineRetail_transformed.csv\")\n",
    "\n",
    "\n",
    "ALL_FEATURES = []\n",
    "\n",
    "MODEL_FEATURES = []\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [16,9] # Taille par défaut des figures de matplotlib\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#import common_functions\n",
    "\n",
    "####### Paramètres pour sauver et restaurer les modèles :\n",
    "import pickle\n",
    "####### Paramètres à changer par l'utilisateur selon son besoin :\n",
    "\n",
    "RECOMPUTE_GRIDSEARCH = True  # CAUTION : computation is several hours long\n",
    "SAVE_GRID_RESULTS = False # If True : grid results object will be saved to pickle files that have GRIDSEARCH_FILE_PREFIX\n",
    "LOAD_GRID_RESULTS = False # If True : grid results object will be loaded from pickle files that have GRIDSEARCH_FILE_PREFIX\n",
    "                          # Grid search results are loaded with full samples (SAMPLED_DATA must be False)\n",
    "\n",
    "'''\n",
    "RECOMPUTE_GRIDSEARCH = True  # CAUTION : computation is several hours long\n",
    "SAVE_GRID_RESULTS = True # If True : grid results object will be saved to pickle files that have GRIDSEARCH_FILE_PREFIX\n",
    "LOAD_GRID_RESULTS = False # If True : grid results object will be loaded from pickle files that have GRIDSEARCH_FILE_PREFIX\n",
    "'''\n",
    "#GRIDSEARCH_CSV_FILE = 'grid_search_results.csv'\n",
    "\n",
    "GRIDSEARCH_FILE_PREFIX = 'grid_search_results_'\n",
    "\n",
    "EXECUTE_INTERMEDIATE_MODELS = True # If True: every intermediate model (which results are manually analyzed in the notebook) will be executed\n",
    "\n",
    "\n",
    "# Necessary for predictors used in the notebook :\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "### For progress bar :\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# Statsmodel : \n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "SAVE_API_MODEL = True # If True : API model ill be saved\n",
    "API_MODEL_PICKLE_FILE = 'API_model_PJ5.pickle'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(DATA_PATH_FILE_INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_train, df_test = custom_train_test_split_sample(df, 'TotalPrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 361443 entries, 368341 to 198864\n",
      "Data columns (total 11 columns):\n",
      "InvoiceNo                361443 non-null object\n",
      "StockCode                361443 non-null object\n",
      "Description              361443 non-null object\n",
      "Quantity                 361443 non-null int64\n",
      "InvoiceDate              361443 non-null object\n",
      "UnitPrice                361443 non-null float64\n",
      "CustomerID               361443 non-null int64\n",
      "Country                  361443 non-null object\n",
      "TotalPrice               361443 non-null float64\n",
      "DescriptionNormalized    361443 non-null object\n",
      "InvoiceMonth             361443 non-null object\n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 33.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
