{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Openclassrooms PJ4 : transats dataset : modelisation notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import urllib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import qgrid\n",
    "\n",
    "import glob\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "DATA_PATH = os.path.join(\"datasets\", \"transats\")\n",
    "DATA_PATH = os.path.join(DATA_PATH, \"out\")\n",
    "\n",
    "DATA_PATH_FILE_INPUT = os.path.join(DATA_PATH, \"transats_metadata_transformed.csv\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [16,9] # Taille par d√©faut des figures de matplotlib\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#import common_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qgrid_show(df):\n",
    "    display(qgrid.show_grid(df, grid_options={'forceFitColumns': False, 'defaultColumnWidth': 170}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_column_information(df, column_name):\n",
    "    column_type = df.dtypes[column_name]\n",
    "    print(f'Column {column_name}, type {column_type}\\n')\n",
    "    print('--------------------------')\n",
    "\n",
    "    print(df[[column_name]].groupby(column_name).size().sort_values(ascending=False))\n",
    "    print(df[column_name].unique())    \n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_percent_complete(df):\n",
    "    not_na = 100 - (df.isnull().sum() * 100 / len(df))\n",
    "    not_na_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                     'percent_complete': not_na}).sort_values(by='percent_complete', ascending=False)\n",
    "    display(not_na_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hhmm timed features formatted\n",
    "feats_hhmm = ['CRS_DEP_TIME',  'CRS_ARR_TIME']\n",
    "\n",
    "df = pd.read_csv(DATA_PATH_FILE_INPUT, sep=',', header=0, encoding='utf-8', low_memory=False, parse_dates=feats_hhmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5547828, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>percent_complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ORIGIN</th>\n",
       "      <td>ORIGIN</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <td>CRS_DEP_TIME</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MONTH</th>\n",
       "      <td>MONTH</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <td>DAY_OF_MONTH</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <td>DAY_OF_WEEK</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNIQUE_CARRIER</th>\n",
       "      <td>UNIQUE_CARRIER</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEST</th>\n",
       "      <td>DEST</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <td>CRS_ARR_TIME</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DISTANCE</th>\n",
       "      <td>DISTANCE</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <td>CRS_ELAPSED_TIME</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <td>ARR_DELAY</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <td>DEP_DELAY</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <td>TAXI_OUT</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <td>TAIL_NUM</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       column_name  percent_complete\n",
       "ORIGIN                      ORIGIN             100.0\n",
       "CRS_DEP_TIME          CRS_DEP_TIME             100.0\n",
       "MONTH                        MONTH             100.0\n",
       "DAY_OF_MONTH          DAY_OF_MONTH             100.0\n",
       "DAY_OF_WEEK            DAY_OF_WEEK             100.0\n",
       "UNIQUE_CARRIER      UNIQUE_CARRIER             100.0\n",
       "DEST                          DEST             100.0\n",
       "CRS_ARR_TIME          CRS_ARR_TIME             100.0\n",
       "DISTANCE                  DISTANCE             100.0\n",
       "CRS_ELAPSED_TIME  CRS_ELAPSED_TIME             100.0\n",
       "ARR_DELAY                ARR_DELAY             100.0\n",
       "DEP_DELAY                DEP_DELAY             100.0\n",
       "TAXI_OUT                  TAXI_OUT             100.0\n",
       "TAIL_NUM                  TAIL_NUM             100.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_percent_complete(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column ORIGIN, type object\n",
      "\n",
      "--------------------------\n",
      "ORIGIN\n",
      "ATL    392037\n",
      "ORD    240967\n",
      "DEN    222012\n",
      "LAX    210219\n",
      "DFW    194370\n",
      "        ...  \n",
      "MMH        91\n",
      "GST        83\n",
      "DLG        83\n",
      "PGD        78\n",
      "AKN        63\n",
      "Length: 308, dtype: int64\n",
      "['DFW' 'DTW' 'SEA' 'JFK' 'SJC' 'ORD' 'PHX' 'STL' 'LAX' 'MCO' 'DEN' 'MIA'\n",
      " 'KOA' 'IAH' 'AUS' 'LAS' 'SLC' 'TUS' 'STT' 'BOS' 'FLL' 'SFO' 'OGG' 'TPA'\n",
      " 'SNA' 'OKC' 'HNL' 'PHL' 'LGA' 'RDU' 'DCA' 'RIC' 'ATL' 'LBB' 'CLT' 'ELP'\n",
      " 'SAN' 'BNA' 'JAC' 'SMF' 'EWR' 'IAD' 'LIH' 'SJU' 'ABQ' 'ORF' 'JAX' 'MSY'\n",
      " 'SAT' 'MCI' 'GUC' 'IND' 'PDX' 'BWI' 'MSP' 'MKE' 'TUL' 'ONT' 'RSW' 'RNO'\n",
      " 'DSM' 'MFE' 'PSP' 'OMA' 'EGE' 'PBI' 'SDF' 'PIT' 'FAT' 'DAY' 'STX' 'COS'\n",
      " 'CMH' 'MTJ' 'HDN' 'BDL' 'MEM' 'CLE' 'HOU' 'BOI' 'OAK' 'GEG' 'ANC' 'BUF'\n",
      " 'SYR' 'ALB' 'PVD' 'ROC' 'ILM' 'ICT' 'PWM' 'GSO' 'CHS' 'MDT' 'BHM' 'ADQ'\n",
      " 'BET' 'BRW' 'SCC' 'FAI' 'JNU' 'KTN' 'YAK' 'CDV' 'SIT' 'PSG' 'WRG' 'OME'\n",
      " 'OTZ' 'BUR' 'BLI' 'ADK' 'SWF' 'LGB' 'PSE' 'BQN' 'HPN' 'SAV' 'SRQ' 'BTV'\n",
      " 'ORH' 'DAB' 'CVG' 'BIS' 'AVL' 'GRR' 'FNT' 'MYR' 'JAN' 'BIL' 'FAR' 'PNS'\n",
      " 'AGS' 'GSP' 'LEX' 'DAL' 'ATW' 'GPT' 'MLB' 'BZN' 'CAK' 'CHO' 'MSN' 'EYW'\n",
      " 'TRI' 'LFT' 'ROA' 'ECP' 'VPS' 'XNA' 'EVV' 'AVP' 'MDW' 'HSV' 'FAY' 'LIT'\n",
      " 'TYS' 'TLH' 'MSO' 'CHA' 'TTN' 'UST' 'MOB' 'PHF' 'CAE' 'FSD' 'ITO' 'LBE'\n",
      " 'ABE' 'BMI' 'CRW' 'ACY' 'PPG' 'IAG' 'ACT' 'MLU' 'GRK' 'SHV' 'FSM' 'MAF'\n",
      " 'SAF' 'JLN' 'LRD' 'BRO' 'TYR' 'GJT' 'YUM' 'DLH' 'GRB' 'LAN' 'SBA' 'ASE'\n",
      " 'DRO' 'IDA' 'RAP' 'FCA' 'LNK' 'AMA' 'BFL' 'MLI' 'LSE' 'SBN' 'PSC' 'MOT'\n",
      " 'FLG' 'ISN' 'GFK' 'GTF' 'FWA' 'MRY' 'MBS' 'PIA' 'SUN' 'TWF' 'SGF' 'CPR'\n",
      " 'BTR' 'PBG' 'CRP' 'CID' 'SBP' 'RKS' 'CMX' 'MMH' 'PLN' 'EKO' 'GCC' 'AZO'\n",
      " 'MFR' 'SMX' 'EUG' 'RST' 'TVC' 'SPI' 'SGU' 'HLN' 'RDM' 'ACV' 'EAU' 'DVL'\n",
      " 'JMS' 'MKG' 'HYS' 'PAH' 'COD' 'ABR' 'ITH' 'APN' 'ESC' 'BJI' 'MQT' 'CIU'\n",
      " 'BGM' 'RHI' 'LWS' 'IMT' 'BRD' 'INL' 'PIH' 'GUM' 'HIB' 'BTM' 'CDC' 'OTH'\n",
      " 'RDD' 'MHT' 'GNV' 'MEI' 'PIB' 'BPT' 'LAW' 'AEX' 'TXK' 'ROW' 'ERI' 'CLL'\n",
      " 'HOB' 'LCH' 'HRL' 'CWA' 'OAJ' 'ELM' 'VLD' 'MGM' 'BGR' 'GTR' 'CSG' 'BQK'\n",
      " 'DHN' 'EWN' 'ABY' 'SCE' 'ISP' 'LAR' 'SPS' 'SJT' 'GGG' 'WYS' 'ACK' 'MVY'\n",
      " 'HYA' 'GST' 'AKN' 'DLG' 'GCK' 'ABI' 'GRI' 'PGD']\n",
      "\n",
      "\n",
      "Column CRS_DEP_TIME, type object\n",
      "\n",
      "--------------------------\n",
      "CRS_DEP_TIME\n",
      "0600    97434\n",
      "0700    76991\n",
      "0800    55002\n",
      "0900    39424\n",
      "0630    38003\n",
      "        ...  \n",
      "0430        1\n",
      "0438        1\n",
      "0242        1\n",
      "0313        1\n",
      "0431        1\n",
      "Length: 1334, dtype: int64\n",
      "['1100' '1513' '1523' ... '0357' '0313' '0121']\n",
      "\n",
      "\n",
      "Column MONTH, type int64\n",
      "\n",
      "--------------------------\n",
      "MONTH\n",
      "3     588508\n",
      "7     490066\n",
      "8     489142\n",
      "6     479990\n",
      "5     474862\n",
      "10    466950\n",
      "9     452060\n",
      "12    451324\n",
      "11    448428\n",
      "1     432691\n",
      "2     415608\n",
      "4     358199\n",
      "dtype: int64\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "\n",
      "\n",
      "Column DAY_OF_MONTH, type int64\n",
      "\n",
      "--------------------------\n",
      "DAY_OF_MONTH\n",
      "26    187059\n",
      "15    186909\n",
      "18    186829\n",
      "28    186391\n",
      "22    185971\n",
      "27    185269\n",
      "21    184786\n",
      "14    184673\n",
      "11    184579\n",
      "29    184324\n",
      "19    183866\n",
      "20    182712\n",
      "2     182115\n",
      "12    181894\n",
      "17    181152\n",
      "16    180942\n",
      "13    180887\n",
      "25    180712\n",
      "6     180497\n",
      "1     180009\n",
      "5     179859\n",
      "8     179817\n",
      "23    179579\n",
      "7     179288\n",
      "10    178582\n",
      "3     178207\n",
      "4     178086\n",
      "9     177951\n",
      "24    172169\n",
      "30    164855\n",
      "31    107859\n",
      "dtype: int64\n",
      "[ 6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29\n",
      " 30 31  1  2  3  4  5]\n",
      "\n",
      "\n",
      "Column DAY_OF_WEEK, type int64\n",
      "\n",
      "--------------------------\n",
      "DAY_OF_WEEK\n",
      "5    830315\n",
      "4    825634\n",
      "1    817835\n",
      "3    817405\n",
      "2    810568\n",
      "7    770714\n",
      "6    675357\n",
      "dtype: int64\n",
      "[3 4 5 6 7 1 2]\n",
      "\n",
      "\n",
      "Column UNIQUE_CARRIER, type object\n",
      "\n",
      "--------------------------\n",
      "UNIQUE_CARRIER\n",
      "WN    1274612\n",
      "DL     964023\n",
      "AA     871930\n",
      "OO     592938\n",
      "UA     537793\n",
      "EV     488872\n",
      "B6     279611\n",
      "AS     165641\n",
      "NK     135322\n",
      "F9      94376\n",
      "HA      76265\n",
      "VX      66445\n",
      "dtype: int64\n",
      "['AA' 'AS' 'B6' 'DL' 'F9' 'HA' 'NK' 'EV' 'OO' 'UA' 'VX' 'WN']\n",
      "\n",
      "\n",
      "Column DEST, type object\n",
      "\n",
      "--------------------------\n",
      "DEST\n",
      "ATL    391837\n",
      "ORD    240613\n",
      "DEN    221846\n",
      "LAX    210294\n",
      "DFW    193996\n",
      "        ...  \n",
      "ADK        95\n",
      "DLG        84\n",
      "GST        82\n",
      "PGD        77\n",
      "AKN        63\n",
      "Length: 308, dtype: int64\n",
      "['DTW' 'DFW' 'JFK' 'SEA' 'ORD' 'SJC' 'STL' 'DCA' 'TPA' 'MIA' 'DEN' 'LAX'\n",
      " 'KOA' 'IAH' 'AUS' 'LAS' 'MCO' 'SLC' 'STT' 'BOS' 'FLL' 'SFO' 'HNL' 'OGG'\n",
      " 'TUL' 'PHL' 'SNA' 'IAD' 'LGA' 'RDU' 'EWR' 'RIC' 'PDX' 'CLT' 'ELP' 'SAN'\n",
      " 'SAT' 'MCI' 'BNA' 'PHX' 'ONT' 'TUS' 'SMF' 'OKC' 'LIH' 'ORF' 'RSW' 'BWI'\n",
      " 'MSP' 'GUC' 'IND' 'ATL' 'SJU' 'PSP' 'MSY' 'COS' 'MKE' 'JAX' 'PIT' 'RNO'\n",
      " 'MFE' 'PBI' 'EGE' 'DAY' 'ABQ' 'LBB' 'SDF' 'STX' 'DSM' 'OMA' 'CLE' 'BDL'\n",
      " 'FAT' 'CMH' 'JAC' 'MTJ' 'HDN' 'MEM' 'HOU' 'BOI' 'OAK' 'GEG' 'ANC' 'BUF'\n",
      " 'ICT' 'PVD' 'ALB' 'SYR' 'ILM' 'PWM' 'ROC' 'CHS' 'MDT' 'GSO' 'BHM' 'BLI'\n",
      " 'BET' 'ADQ' 'BRW' 'SCC' 'FAI' 'KTN' 'YAK' 'CDV' 'JNU' 'SIT' 'WRG' 'PSG'\n",
      " 'OME' 'OTZ' 'BUR' 'ADK' 'LGB' 'SWF' 'HPN' 'PSE' 'BQN' 'SRQ' 'SAV' 'BTV'\n",
      " 'ORH' 'DAB' 'CVG' 'FAR' 'MSN' 'GRR' 'EVV' 'AVP' 'BIL' 'AGS' 'DAL' 'TRI'\n",
      " 'MDW' 'GPT' 'PHF' 'MLB' 'BZN' 'CHA' 'MSO' 'CHO' 'LEX' 'EYW' 'ECP' 'VPS'\n",
      " 'GSP' 'ATW' 'LFT' 'SGF' 'CAK' 'FSD' 'FAY' 'PNS' 'LIT' 'ROA' 'MHT' 'JAN'\n",
      " 'MYR' 'HSV' 'TYS' 'FNT' 'CID' 'TTN' 'BIS' 'UST' 'AVL' 'CAE' 'CRW' 'ITO'\n",
      " 'ACY' 'LBE' 'ABE' 'XNA' 'BMI' 'PPG' 'IAG' 'JLN' 'SHV' 'TYR' 'MLU' 'GRK'\n",
      " 'MAF' 'BTR' 'LAW' 'SPI' 'ACT' 'BRO' 'AEX' 'LCH' 'YUM' 'DLH' 'FWA' 'GRB'\n",
      " 'SBN' 'LAN' 'SBA' 'DRO' 'RAP' 'ASE' 'MOT' 'EUG' 'MMH' 'LNK' 'MFR' 'GJT'\n",
      " 'GTF' 'SMX' 'MLI' 'LSE' 'PSC' 'FCA' 'FLG' 'HLN' 'ACV' 'MBS' 'PIA' 'RST'\n",
      " 'PBG' 'BFL' 'SUN' 'IDA' 'MRY' 'GFK' 'AMA' 'CRP' 'SBP' 'ISN' 'SGU' 'TWF'\n",
      " 'PLN' 'EKO' 'CPR' 'LAR' 'TVC' 'AZO' 'RDM' 'CLL' 'CMX' 'COD' 'EAU' 'JMS'\n",
      " 'DVL' 'PAH' 'MKG' 'GCC' 'ABR' 'APN' 'ITH' 'MQT' 'CIU' 'BGM' 'RHI' 'IMT'\n",
      " 'LWS' 'INL' 'PIH' 'GUM' 'HIB' 'ESC' 'BJI' 'BRD' 'BTM' 'CDC' 'RKS' 'HYS'\n",
      " 'RDD' 'OTH' 'TLH' 'MOB' 'GNV' 'MEI' 'PIB' 'FSM' 'BPT' 'SAF' 'LRD' 'TXK'\n",
      " 'ROW' 'CWA' 'ERI' 'HRL' 'HOB' 'ELM' 'SCE' 'OAJ' 'VLD' 'MGM' 'GTR' 'BQK'\n",
      " 'DHN' 'CSG' 'BGR' 'ABY' 'EWN' 'ISP' 'SJT' 'SPS' 'GGG' 'WYS' 'MVY' 'ACK'\n",
      " 'HYA' 'GST' 'DLG' 'AKN' 'GCK' 'ABI' 'GRI' 'PGD']\n",
      "\n",
      "\n",
      "Column CRS_ARR_TIME, type object\n",
      "\n",
      "--------------------------\n",
      "CRS_ARR_TIME\n",
      "1700    18385\n",
      "1650    17336\n",
      "2100    17133\n",
      "1305    16386\n",
      "1655    16311\n",
      "        ...  \n",
      "0238        1\n",
      "0252        1\n",
      "0406        1\n",
      "0418        1\n",
      "0255        1\n",
      "Length: 1439, dtype: int64\n",
      "['1438' '1724' '1730' ... '0406' '0252' '0231']\n",
      "\n",
      "\n",
      "Column DISTANCE, type float64\n",
      "\n",
      "--------------------------\n",
      "DISTANCE\n",
      "337.0     52623\n",
      "447.0     28488\n",
      "404.0     27110\n",
      "594.0     26994\n",
      "867.0     26238\n",
      "          ...  \n",
      "115.0         1\n",
      "1672.0        1\n",
      "132.0         1\n",
      "2209.0        1\n",
      "30.0          1\n",
      "Length: 1347, dtype: int64\n",
      "[ 986. 2422. 1829. ...  514. 1573.   47.]\n",
      "\n",
      "\n",
      "Column CRS_ELAPSED_TIME, type float64\n",
      "\n",
      "--------------------------\n",
      "CRS_ELAPSED_TIME\n",
      "80.0     115132\n",
      "85.0     113336\n",
      "90.0      99627\n",
      "70.0      97365\n",
      "75.0      94439\n",
      "          ...  \n",
      "449.0         1\n",
      "583.0         1\n",
      "534.0         1\n",
      "542.0         1\n",
      "468.0         1\n",
      "Length: 574, dtype: int64\n",
      "[158. 191. 187. 317. 321. 385. 382. 258. 284. 280. 148. 149. 120. 114.\n",
      "  97.  99. 295. 159. 153. 183. 185. 236. 234. 271. 281. 311. 312. 358.\n",
      " 363. 165. 163. 196. 201. 202. 205. 142. 178. 180. 182. 170. 171. 175.\n",
      " 166. 204. 212. 211. 215. 216. 262. 264. 268. 294. 291. 297. 357. 177.\n",
      "  77.  75.  78.  76. 186. 181. 155. 156. 168. 129. 132. 241. 189. 130.\n",
      " 199. 194. 206. 200. 323. 327.  98. 402. 184. 167. 169. 203. 328. 318.\n",
      "  84.  81.  88.  93. 359. 313. 267. 266.  89. 244. 240.  68. 208. 176.\n",
      " 408. 410. 219. 209. 394. 330. 329. 378. 384. 516. 524.  66.  69. 427.\n",
      " 430. 509. 514. 443. 439. 446. 403. 395. 309. 314. 337. 335. 307. 303.\n",
      " 400. 405. 332. 399. 197. 230. 375. 380. 326. 393. 389. 390. 336. 239.\n",
      " 238. 316. 190. 188. 364. 373. 319. 324. 147. 237. 192. 279. 278. 277.\n",
      " 242. 233. 261. 356. 361. 325. 274. 397. 334. 179. 401. 381. 113. 109.\n",
      "  91.  92.  74.  83. 388. 222. 150. 231. 341. 345. 387. 207. 198. 162.\n",
      " 140. 136. 252. 391. 416. 226. 254. 193. 126. 354. 210. 365. 260.  70.\n",
      "  64.  73. 131. 128. 108. 100. 101. 107. 105. 221. 144. 110. 161. 133.\n",
      " 248. 250.  65. 121. 298. 287. 283. 263. 355. 308. 352. 228.  63.  62.\n",
      " 145. 195. 235. 232. 293. 290. 164. 143. 218. 257. 383. 273. 174. 173.\n",
      " 141. 160. 223. 225. 247. 377. 217.  94. 448.  82. 249. 275.  72. 265.\n",
      "  61. 433. 432. 396. 331. 507. 511. 151. 518. 527. 224. 366. 374. 370.\n",
      " 172. 137. 320. 362.  67. 135. 289. 288. 125. 152. 124.  90. 122.  87.\n",
      "  85. 116. 118. 214. 286. 127. 106. 134. 117. 146. 119.  95. 103. 104.\n",
      " 213.  71. 102. 220. 154.  96. 372. 368. 315. 253. 348. 123.  56.  86.\n",
      " 157. 139. 112. 259. 245. 255. 251. 256. 338. 340. 229.  79. 138. 344.\n",
      " 111. 276. 304. 301. 369.  80. 272. 246. 285. 351.  60. 115. 227.  59.\n",
      "  57. 342.  58. 243. 269. 322. 333. 270. 339. 386. 300. 343. 282.  55.\n",
      " 414. 299. 404. 306. 305. 347. 310. 349. 350. 421. 411. 412. 418.  52.\n",
      " 302.  49.  48.  54. 367. 292.  50.  51. 371. 409.  53.  44. 415. 353.\n",
      " 296. 346. 426. 376. 425. 360. 379.  45.  47.  25.  46.  32.  39.  21.\n",
      "  40.  42. 419.  30.  24.  36.  41.  43. 398.  37. 392.  34. 413. 611.\n",
      " 473. 585. 705. 406. 517. 616. 544. 575. 615. 424.  35.  38.  33. 482.\n",
      " 407. 578. 683. 646. 475. 493. 570. 456. 521. 466. 555. 562. 480. 417.\n",
      " 460. 685. 477. 435. 520. 450. 423. 471. 542. 420. 548. 584. 515. 610.\n",
      " 695. 462.  22.  31.  28. 464. 513. 510. 613. 523. 525. 463. 579. 679.\n",
      " 647. 494. 564. 461. 474. 700. 587. 676. 633. 558. 472. 438. 675. 437.\n",
      " 455. 453. 451. 434. 505. 530. 593. 452. 428. 595. 665. 440. 465. 508.\n",
      " 454. 519. 512.  23.  26. 532. 535. 580. 470. 467.  18. 468. 654. 565.\n",
      " 618. 545. 500. 650. 447. 476. 499. 436. 488. 457. 441. 484. 495.  29.\n",
      "  27. 422. 469. 531. 576. 574. 583. 655. 586. 504. 489. 496. 459. 485.\n",
      " 506.  20. 528. 526. 577. 660. 581. 614. 490. 546. 497. 429. 537. 442.\n",
      " 444. 534. 445. 591. 589. 644. 573. 672. 560. 627. 606. 604. 529. 670.\n",
      " 625. 559. 449. 704. 617. 552. 588. 698. 549. 503. 569. 686. 486. 571.]\n",
      "\n",
      "\n",
      "Column ARR_DELAY, type float64\n",
      "\n",
      "--------------------------\n",
      "ARR_DELAY\n",
      "-9.0       173678\n",
      "-10.0      173531\n",
      "-11.0      171905\n",
      "-8.0       171547\n",
      "-7.0       168101\n",
      "            ...  \n",
      " 1122.0         1\n",
      " 1123.0         1\n",
      " 1124.0         1\n",
      " 1132.0         1\n",
      "-152.0          1\n",
      "Length: 1385, dtype: int64\n",
      "[  -6.  -12.    7. ...  813.  997. 1145.]\n",
      "\n",
      "\n",
      "Column DEP_DELAY, type float64\n",
      "\n",
      "--------------------------\n",
      "DEP_DELAY\n",
      "-3.0       453418\n",
      "-5.0       447193\n",
      "-4.0       444253\n",
      "-2.0       429821\n",
      "-1.0       376195\n",
      "            ...  \n",
      " 1127.0         1\n",
      " 1130.0         1\n",
      " 1134.0         1\n",
      " 1137.0         1\n",
      "-204.0          1\n",
      "Length: 1331, dtype: int64\n",
      "[  -3.   -4.   -5. ...  964.  -60. 1088.]\n",
      "\n",
      "\n",
      "Column TAXI_OUT, type float64\n",
      "\n",
      "--------------------------\n",
      "TAXI_OUT\n",
      "12.0     454445\n",
      "11.0     448910\n",
      "13.0     433665\n",
      "10.0     412580\n",
      "14.0     397419\n",
      "          ...  \n",
      "169.0         1\n",
      "165.0         1\n",
      "164.0         1\n",
      "163.0         1\n",
      "186.0         1\n",
      "Length: 178, dtype: int64\n",
      "[ 15.  14.  21.  13.  20.  11.  12.  18.  24.  23.  17.   9.  16.  42.\n",
      "  19.  34.  10.  28.  33.  22.  27.  30.  25.  32.  40.  29.  45.  36.\n",
      "  46.  39.  26.  37.   8.   7.  31.  38.  41.  35.  58.  61.  44.  43.\n",
      "  75.  59.  48.  47.  86.  65.  53.  55.  49.  60.  66.  97.  57.  52.\n",
      " 105.  84.  51.  73.  56.  79.  62.  67.  50.  54. 121.   6.  70.  63.\n",
      "  83.  68.  81.  64.  72. 139.  69.  89.   5.  78.  74.  77.  87.  76.\n",
      "  98. 106. 128. 109. 111. 118.  82.  95.  93.  94.  88.  91. 124.  85.\n",
      "  71.  80.  99. 102.  90.  96. 104.   1. 131. 132. 107. 103. 101. 112.\n",
      " 137.   4. 110. 126. 158.   3.   2. 135.  92. 141. 130. 120. 114. 119.\n",
      " 129. 122. 108. 156. 125. 140. 115. 100. 138. 113. 133. 134. 117. 147.\n",
      " 123. 146. 143. 148. 127. 136. 116. 157. 151. 144. 150. 145. 155. 142.\n",
      " 161. 159. 149. 160. 154. 166. 153. 185. 152. 162. 168. 172. 183. 163.\n",
      " 167. 186. 170. 174. 165. 164. 176. 169. 179. 178.]\n",
      "\n",
      "\n",
      "Column TAIL_NUM, type object\n",
      "\n",
      "--------------------------\n",
      "TAIL_NUM\n",
      "N491HA    3930\n",
      "N486HA    3725\n",
      "N492HA    3703\n",
      "N493HA    3649\n",
      "N476HA    3629\n",
      "          ... \n",
      "N852NW       2\n",
      "N670US       1\n",
      "N854NW       1\n",
      "N665US       1\n",
      "N668US       1\n",
      "Length: 5033, dtype: int64\n",
      "['N4YBAA' 'N434AA' 'N541AA' ... 'N8513F' 'N7882B' 'N8517F']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column_name in df.columns:\n",
    "    print_column_information(df, column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantitative features : ['MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'DISTANCE', 'CRS_ELAPSED_TIME', 'ARR_DELAY', 'DEP_DELAY', 'TAXI_OUT'] \n",
      "\n",
      "Qualitative features : ['ORIGIN', 'CRS_DEP_TIME', 'UNIQUE_CARRIER', 'DEST', 'CRS_ARR_TIME', 'TAIL_NUM'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Below are feature from dataset that we decided to keep: \n",
    "all_features = ['ORIGIN','CRS_DEP_TIME','MONTH','DAY_OF_MONTH','DAY_OF_WEEK','UNIQUE_CARRIER','DEST','CRS_ARR_TIME','DISTANCE','CRS_ELAPSED_TIME','ARR_DELAY','DEP_DELAY', 'TAXI_OUT', 'TAIL_NUM']\n",
    "\n",
    "model1_features = ['ORIGIN','CRS_DEP_TIME','MONTH','DAY_OF_MONTH','DAY_OF_WEEK','UNIQUE_CARRIER','DEST','CRS_ARR_TIME','DISTANCE','CRS_ELAPSED_TIME']\n",
    "model1_label = 'ARR_DELAY'\n",
    "\n",
    "quantitative_features = []\n",
    "qualitative_features = []\n",
    "features_todrop = []\n",
    "\n",
    "for feature_name in all_features:\n",
    "    if (df[feature_name].dtype == 'object'):\n",
    "        qualitative_features.append(feature_name)\n",
    "        \n",
    "    else:\n",
    "        quantitative_features.append(feature_name)\n",
    "\n",
    "print(f'Quantitative features : {quantitative_features} \\n')\n",
    "print(f'Qualitative features : {qualitative_features} \\n')        \n",
    "        \n",
    "\n",
    "#Commented out : no drop of features\n",
    "#for df_column in df.columns:\n",
    "#    if df_column not in all_features:\n",
    "#        features_todrop.append(df_column)\n",
    "#        \n",
    "#print(f'Features to drop : {features_todrop} \\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert _TIME features (HHMM format) to minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df convert_HHMM_to_Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          1438\n",
       "1          1438\n",
       "2          1438\n",
       "3          1438\n",
       "4          1438\n",
       "           ... \n",
       "5547823    0830\n",
       "5547824    1355\n",
       "5547825    1125\n",
       "5547826    1235\n",
       "5547827    0820\n",
       "Name: CRS_ARR_TIME, Length: 5547828, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CRS_ARR_TIME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenation of first 2 digits (hours)  and last 2 digits (minutes)\n",
    "df_CRS_ARR_TIME = pd.concat([df['CRS_ARR_TIME'].str.slice(start=0,stop=2, step=1),df['CRS_ARR_TIME'].str.slice(start=2,stop=4, step=1)], axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion of hours and minutes into minutes :  HH*60 + MM = minutes\n",
    "df['CRS_ARR_TIME'] = (df_CRS_ARR_TIME.iloc[:, [0]] * 60 + df_CRS_ARR_TIME.iloc[:, [1]])['CRS_ARR_TIME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>UNIQUE_CARRIER</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DFW</td>\n",
       "      <td>1100</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>AA</td>\n",
       "      <td>DTW</td>\n",
       "      <td>878</td>\n",
       "      <td>986.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>N4YBAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DFW</td>\n",
       "      <td>1100</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>DTW</td>\n",
       "      <td>878</td>\n",
       "      <td>986.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>N434AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DFW</td>\n",
       "      <td>1100</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>AA</td>\n",
       "      <td>DTW</td>\n",
       "      <td>878</td>\n",
       "      <td>986.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>N541AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DFW</td>\n",
       "      <td>1100</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>AA</td>\n",
       "      <td>DTW</td>\n",
       "      <td>878</td>\n",
       "      <td>986.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>N489AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DFW</td>\n",
       "      <td>1100</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>AA</td>\n",
       "      <td>DTW</td>\n",
       "      <td>878</td>\n",
       "      <td>986.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>N439AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547823</th>\n",
       "      <td>TUS</td>\n",
       "      <td>0755</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>WN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>510</td>\n",
       "      <td>451.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>N7703A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547824</th>\n",
       "      <td>TUS</td>\n",
       "      <td>1320</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>WN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>835</td>\n",
       "      <td>451.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>N7815L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547825</th>\n",
       "      <td>TUS</td>\n",
       "      <td>0705</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>WN</td>\n",
       "      <td>MDW</td>\n",
       "      <td>685</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>N967WN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547826</th>\n",
       "      <td>TUS</td>\n",
       "      <td>1220</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>WN</td>\n",
       "      <td>SAN</td>\n",
       "      <td>755</td>\n",
       "      <td>368.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>N271LV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547827</th>\n",
       "      <td>TUS</td>\n",
       "      <td>0800</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>WN</td>\n",
       "      <td>SAN</td>\n",
       "      <td>500</td>\n",
       "      <td>368.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>N762SW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5547828 rows √ó 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ORIGIN CRS_DEP_TIME  MONTH  DAY_OF_MONTH  DAY_OF_WEEK UNIQUE_CARRIER  \\\n",
       "0          DFW         1100      1             6            3             AA   \n",
       "1          DFW         1100      1             7            4             AA   \n",
       "2          DFW         1100      1             8            5             AA   \n",
       "3          DFW         1100      1             9            6             AA   \n",
       "4          DFW         1100      1            10            7             AA   \n",
       "...        ...          ...    ...           ...          ...            ...   \n",
       "5547823    TUS         0755     12            31            6             WN   \n",
       "5547824    TUS         1320     12            31            6             WN   \n",
       "5547825    TUS         0705     12            31            6             WN   \n",
       "5547826    TUS         1220     12            31            6             WN   \n",
       "5547827    TUS         0800     12            31            6             WN   \n",
       "\n",
       "        DEST  CRS_ARR_TIME  DISTANCE  CRS_ELAPSED_TIME  ARR_DELAY  DEP_DELAY  \\\n",
       "0        DTW           878     986.0             158.0       -6.0       -3.0   \n",
       "1        DTW           878     986.0             158.0      -12.0       -4.0   \n",
       "2        DTW           878     986.0             158.0        7.0       -5.0   \n",
       "3        DTW           878     986.0             158.0       -5.0        2.0   \n",
       "4        DTW           878     986.0             158.0      113.0      100.0   \n",
       "...      ...           ...       ...               ...        ...        ...   \n",
       "5547823  LAX           510     451.0              95.0      -13.0       -8.0   \n",
       "5547824  LAX           835     451.0              95.0        9.0        5.0   \n",
       "5547825  MDW           685    1440.0             200.0      -30.0       -6.0   \n",
       "5547826  SAN           755     368.0              75.0       -4.0       -1.0   \n",
       "5547827  SAN           500     368.0              80.0       -9.0       -2.0   \n",
       "\n",
       "         TAXI_OUT TAIL_NUM  \n",
       "0            15.0   N4YBAA  \n",
       "1            14.0   N434AA  \n",
       "2            21.0   N541AA  \n",
       "3            13.0   N489AA  \n",
       "4            20.0   N439AA  \n",
       "...           ...      ...  \n",
       "5547823      11.0   N7703A  \n",
       "5547824      13.0   N7815L  \n",
       "5547825       9.0   N967WN  \n",
       "5547826      10.0   N271LV  \n",
       "5547827       9.0   N762SW  \n",
       "\n",
       "[5547828 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing\n",
    "#from sklearn.neighbors import KNeighborsTransformer\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis\n",
    "\n",
    "import statistics\n",
    "\n",
    "class DuplicatesRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.df_origin = None\n",
    "        return None\n",
    "    \n",
    "    def fit(self, df, labels=None):      \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        self.df_origin = df\n",
    "        df = df.copy(deep=True)\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        return(df)\n",
    "    \n",
    "class NumericalFeaturesImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, numerical_features=['movie_facebook_likes', 'num_voted_users', 'cast_total_facebook_likes', 'imdb_score' , 'actor_1_facebook_likes', 'actor_2_facebook_likes', 'facenumber_in_poster', 'duration', 'num_user_for_reviews', 'actor_3_facebook_likes', 'num_critic_for_reviews', 'director_facebook_likes', 'budget', 'gross','title_year']):\n",
    "        self.numerical_features = numerical_features\n",
    "    \n",
    "    def fit(self, df, labels=None):      \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        numerical_features_columns = df[self.numerical_features].columns\n",
    "        numerical_features_index = df[self.numerical_features].index\n",
    "\n",
    "        # Imputation par r√©gression lin√©aire :\n",
    "        imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "        transformed_data = imp.fit_transform(df[self.numerical_features])  \n",
    "\n",
    "        # Drop des features non imput√©es sur l'axe des colonnes\n",
    "        df.drop(labels=self.numerical_features, axis=1, inplace=True)\n",
    "        \n",
    "        # Recr√©ation d'un dataframe avec les features imput√©es\n",
    "        df_numerical_features_imputed = pd.DataFrame(data=transformed_data, columns=numerical_features_columns, index=numerical_features_index)\n",
    "        \n",
    "        df = pd.concat([df, df_numerical_features_imputed], axis=1)\n",
    "        \n",
    "        return(df)\n",
    "\n",
    "'''\n",
    "Cette fonction fait un 1 hot encoding des features qui sont des cat√©gories\n",
    "Elle fonctionne pour les 2 cas de figure suivant :\n",
    "- Les valeurs possibles de la colonne sont une cha√Æne de caract√®re (ex : cat1)\n",
    "- Les valeurs possibles de la colonne sont des cha√Ænes de caract√®re avec des s√©parateurs (ex:  cat1|cat2|cat3)\n",
    "'''\n",
    "    \n",
    "def add_categorical_features_1hot(df, categorical_features_totransform):\n",
    "    #df.drop(labels=categorical_features_totransform, axis=1, inplace=True)\n",
    "    \n",
    "    for feature_totransform in categorical_features_totransform:\n",
    "        print(f'Adding 1hot Feature : {feature_totransform}')\n",
    "        \n",
    "        df_transformed = df[feature_totransform].str.get_dummies().add_prefix(feature_totransform +'_')   \n",
    "        df.drop(labels=feature_totransform, axis=1, inplace=True)\n",
    "        \n",
    "        df = pd.concat([df, df_transformed], axis=1)\n",
    "        \n",
    "    return(df)\n",
    "\n",
    "\n",
    "'''\n",
    "Cette fonction commence par merger les valeurs de toutes les colonnes comprises dans \n",
    "categorical_features_tomerge_andtransform  dans une seule colonne temporaire\n",
    "Puis elle fait un 1 hot encode du r√©sultat en appelant la fonction add_categorical_features_1hot\n",
    "\n",
    "df :  dataframe source, sur lequel on va droper les features avant transformation, et ajouter les features apr√®s transformation\n",
    "categorical_features_tomerge_andtransform : la liste des cat√©gories √† merger et √† 1 hot encode,\n",
    "             par exemple: ['actor_1_name', 'actor_2_name', 'actor_3_name']\n",
    "merged_feature_name : le nom de la feature qui sera merg√©e\n",
    "    exemple si le nom est 'actors_names'\n",
    "    On pourra avoir les colonnes suivantes de cr√©√©es:  'actors_names_Le nom du 1er acteur', 'actors_names_Le nom du 2eme acteur'\n",
    "          \n",
    "'''\n",
    "def add_categorical_features_merge_and_1hot(df, categorical_features_tomerge_andtransform, merged_feature_name):\n",
    "    #df.drop(labels=categorical_features_tomerge_andtransform, axis=1, inplace=True)\n",
    "    \n",
    "    cnt = 0\n",
    "    for feature_totransform in categorical_features_tomerge_andtransform:                            \n",
    "        if (cnt == 0):\n",
    "            df[merged_feature_name] = df[feature_totransform]\n",
    "        \n",
    "        else:\n",
    "            df[merged_feature_name] = df[merged_feature_name] + '|' + df[feature_totransform]\n",
    "            \n",
    "        cnt += 1\n",
    "    \n",
    "    df.drop(labels=categorical_features_tomerge_andtransform, axis=1, inplace=True)\n",
    "    \n",
    "    return(add_categorical_features_1hot(df, [merged_feature_name]))\n",
    "    \n",
    "\n",
    "        \n",
    "class CategoricalFeatures1HotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, categorical_features_totransform =['country', 'language', 'director_name', 'genres', 'plot_keywords', 'color', 'content_rating']):\n",
    "        self.categorical_features_totransform = categorical_features_totransform\n",
    "    \n",
    "    def fit(self, df, labels=None):      \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):       \n",
    "        return(add_categorical_features_1hot(df, self.categorical_features_totransform))\n",
    "\n",
    "class CategoricalFeaturesMergerAnd1HotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, categorical_features_tomerge_andtransform = ['actor_1_name', 'actor_2_name', 'actor_3_name'], merged_feature_name = 'actors_names'):\n",
    "        self.categorical_features_tomerge_andtransform = categorical_features_tomerge_andtransform\n",
    "        self.merged_feature_name = merged_feature_name\n",
    "    \n",
    "    def fit(self, df, labels=None):      \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):       \n",
    "        return(add_categorical_features_merge_and_1hot(df, self.categorical_features_tomerge_andtransform, self.merged_feature_name))   \n",
    "\n",
    "class CategoricalFeaturesBowEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, categorical_features_tobow = ['movie_title']):\n",
    "        self.categorical_features_tobow = categorical_features_tobow\n",
    "    \n",
    "    def fit(self, df, labels=None):      \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):       \n",
    "        for feature_tobow in self.categorical_features_tobow:\n",
    "            print(f'Adding bow Feature. : {feature_tobow}')\n",
    "\n",
    "            df_transformed = df[feature_tobow].str.lower().str.replace(r'[^\\w\\s]', '').str.replace(u'\\xa0', u'').str.get_dummies(sep=' ').add_prefix(feature_tobow +'_')\n",
    "            df.drop(labels=feature_tobow, axis=1, inplace=True)\n",
    "            df = pd.concat([df, df_transformed], axis=1)\n",
    "        \n",
    "        return(df)\n",
    "\n",
    "class FeaturesDroper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_todrop = ['aspect_ratio', 'movie_imdb_link']):\n",
    "        self.features_todrop = features_todrop\n",
    "    \n",
    "    def fit(self, df, labels=None):      \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):       \n",
    "        #df.drop(labels=self.features_todrop, axis=1, inplace=True)  \n",
    "        if (self.features_todrop != None):\n",
    "            for feature_to_drop in self.features_todrop:\n",
    "                df = df.loc[:,~df.columns.str.startswith(feature_to_drop)]\n",
    "            print('Features drop done')\n",
    "            \n",
    "        return(df)\n",
    "    \n",
    "'''\n",
    "This function predicts imdb_score using KNN technique\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "class KNNTransform(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, knn_params =  {'n_neighbors':6, 'algorithm':'ball_tree', 'metric':'minkowski'}):\n",
    "        self.knn_params = knn_params\n",
    "        self.nbrs = None\n",
    "        self.labels = None\n",
    "        self.metric = None\n",
    "    \n",
    "    def fit(self, X, labels=None, df_encoded=None):  \n",
    "        # df_encoded sert pour la classe KNNTransform_predict_similarity\n",
    "        # df_encoded est le df 1hot encoded num√©rique apr√®s les √©tapes de transformation\n",
    "        print('KNN fit')\n",
    "        self.df_encoded = df_encoded\n",
    "        self.labels = labels\n",
    "        self.nbrs = NearestNeighbors(n_neighbors=self.knn_params['n_neighbors'], algorithm=self.knn_params['algorithm'], metric=self.knn_params['metric']).fit(X)\n",
    "        return self\n",
    "\n",
    "    \n",
    "    '''\n",
    "    # This function returns similarity score for each film instance in X  (summed for all X instances)\n",
    "    # The more the score is, the more recommended films (knn_matrix[film_instance, 1...5]) \n",
    "    # are close to input film (knn_matrix[film_instance, 0]) \n",
    "\n",
    "    /!\\ To calculate similarity,  this method requires to set global variable df_encoded \n",
    "    (df_encoded as being the output of preparation_pipeline)\n",
    "    \n",
    "    Previous version of the method used to accept df_encoded pass as a parameter to KNNTransform fit function\n",
    "    Parameter was passed like this :\n",
    "    recommendation_pipeline_PCA_KNN.fit(df_encoded, labels, KNN__df_encoded = df_encoded)\n",
    "    > But this did not work with GridSearchCV (that does not support third customer parameter to fit function)\n",
    "    '''\n",
    "    def score(self, X, y=None):\n",
    "        print('KNN score')\n",
    "\n",
    "        distances_matrix, knn_matrix = self.nbrs.kneighbors(X)\n",
    "\n",
    "        scorings = []\n",
    "        \n",
    "        scaler = MinMaxScaler() \n",
    "        array_scaled = scaler.fit_transform(df_encoded)\n",
    "        df_scaled  = pd.DataFrame(data=array_scaled , columns=df_encoded.columns, index=df_encoded.index)\n",
    "        \n",
    "    \n",
    "        # Drop features that have nothing to do with the film items themselves, and are not to be taken into account for similarity\n",
    "        df_scaled.drop(labels=['movie_facebook_likes', 'num_voted_users', 'cast_total_facebook_likes', 'imdb_score', 'actor_1_facebook_likes', 'actor_2_facebook_likes', 'num_user_for_reviews', 'actor_3_facebook_likes', 'num_critic_for_reviews', 'director_facebook_likes'], axis=1, inplace=True)\n",
    "        \n",
    "        \n",
    "        for i in range(0, X.shape[0]):\n",
    "            scoring_1 = get_similarity_df_scaled_input(df_scaled, knn_matrix[i, 0], knn_matrix[i, 1]).sum()\n",
    "            scoring_2 = get_similarity_df_scaled_input(df_scaled, knn_matrix[i, 0], knn_matrix[i, 2]).sum()\n",
    "            scoring_3 = get_similarity_df_scaled_input(df_scaled, knn_matrix[i, 0], knn_matrix[i, 3]).sum()\n",
    "            scoring_4 = get_similarity_df_scaled_input(df_scaled, knn_matrix[i, 0], knn_matrix[i, 4]).sum()\n",
    "            scoring_5 = get_similarity_df_scaled_input(df_scaled, knn_matrix[i, 0], knn_matrix[i, 5]).sum()\n",
    "                \n",
    "            scorings.append((scoring_1 + scoring_2 + scoring_3 + scoring_4 + scoring_5) / 5)\n",
    "        \n",
    "        return(statistics.mean(scorings))\n",
    "    \n",
    "    \n",
    "    def predict(self, X, y=None): # Quand on appelle predict, transform est appel√© avant automatiquement\n",
    "        print('KNN predict')\n",
    "\n",
    "        distances_matrix, knn_matrix = self.nbrs.kneighbors(X)\n",
    "\n",
    "        # Pour chaque film (chaque ligne comprise dans X), on calcule la pr√©diction du score ci-dessous\n",
    "        # On fait la moyenne des scores  (compris dans labels) de chaques films renvoy√©s par le KNN\n",
    "        scoring_predictions = (self.labels[knn_matrix[:,1]] + self.labels[knn_matrix[:,2]] + self.labels[knn_matrix[:,3]] + self.labels[knn_matrix[:,4]] + self.labels[knn_matrix[:,5]])/5\n",
    "        \n",
    "        return(scoring_predictions)\n",
    "    \n",
    "    def transform(self, X):   \n",
    "        print('KNN transform')\n",
    "        #distances_matrix, reco_matrix = nbrs.kneighbors(X)\n",
    "        return(self.nbrs.kneighbors(X))    \n",
    "\n",
    "    \n",
    "'''\n",
    "Cette fonction permet de fournir un score de similarit√© moyen entre chaque pr√©diction et le film d'origine\n",
    "\n",
    "On peut calculer cette similarit√© en faisant un apply sur 2 variables:  \n",
    "en appelant la fonction get_similarity_df(df_encoded, index1, index2).  \n",
    "Pour √ßa, on passe df_encoded √† la classe KNNTransform\n",
    "\n",
    "Le param√®tre devra √™tre pass√© comme ceci:\n",
    "recommendation_pipeline_PCA_KNN.fit(df_encoded, labels, KNN__df_encoded = df_encoded)\n",
    "'''\n",
    "    \n",
    "class KNNTransform_predict_similarity(KNNTransform):\n",
    "    def score(self, X, y=None):\n",
    "        distances_matrix, knn_matrix = self.nbrs.kneighbors(X)\n",
    "\n",
    "        scaler = MinMaxScaler() \n",
    "        array_scaled = scaler.fit_transform(self.df_encoded)        \n",
    "        \n",
    "        scoring_1 = ((array_scaled[:, 0] + array_scaled[:, 1]) / 2)\n",
    "        # A compl√©ter\n",
    "    \n",
    "    def predict(self, X, y=None): # Quand on appelle predict, transform est appel√© avant automatiquement\n",
    "        print('KNN predict')\n",
    "\n",
    "        distances_matrix, knn_matrix = self.nbrs.kneighbors(X)\n",
    "\n",
    "        scoring_predictions = []\n",
    "        \n",
    "        scaler = MinMaxScaler() \n",
    "        array_scaled = scaler.fit_transform(self.df_encoded)\n",
    "        df_scaled  = pd.DataFrame(data=array_scaled , columns=self.df_encoded.columns, index=self.df_encoded.index)\n",
    "        \n",
    "        print('X.shape[0] : ' + str(X.shape[0]))\n",
    "        for i in range(0, X.shape[0]):\n",
    "            scoring_1 = get_similarity_df_scaled_input(df_scaled, knn_matrix[i, 0], knn_matrix[i, 1]).sum()\n",
    "            scoring_2 = get_similarity_df_scaled_input(df_scaled, knn_matrix[i, 0], knn_matrix[i, 2]).sum()\n",
    "            scoring_3 = get_similarity_df_scaled_input(df_scaled, knn_matrix[i, 0], knn_matrix[i, 3]).sum()\n",
    "            scoring_4 = get_similarity_df_scaled_input(df_scaled, knn_matrix[i, 0], knn_matrix[i, 4]).sum()\n",
    "            scoring_5 = get_similarity_df_scaled_input(df_scaled, knn_matrix[i, 0], knn_matrix[i, 5]).sum()\n",
    "                \n",
    "            scoring_predictions.append((scoring_1 + scoring_2 + scoring_3 + scoring_4 + scoring_5) / 5)\n",
    "            \n",
    "        '''\n",
    "        df_knn_matrix = pd.DataFrame(data=knn_matrix)\n",
    "        \n",
    "        df_knn_matrix['similarity_1_score'] = df[[0, 1]].apply(segmentMatch, axis=1)\n",
    "        \n",
    "        # Pour chaque film (chaque ligne comprise dans X), on calcule la pr√©diction du score ci-dessous\n",
    "        # On fait la moyenne des scores  (compris dans labels) de chaques films renvoy√©s par le KNN\n",
    "        scoring_predictions = (self.labels[knn_matrix[:,1]] + self.labels[knn_matrix[:,2]] + self.labels[knn_matrix[:,3]] + self.labels[knn_matrix[:,4]] + self.labels[knn_matrix[:,5]])/5\n",
    "        '''\n",
    "        \n",
    "        return(scoring_predictions)\n",
    "    \n",
    "'''\n",
    "This function wraps NCA transformer. What it does more, is that it generates discretized categorical labels\n",
    "from numerical score labels that are passed as input.\n",
    "Labels are mandatory in order to use NCA transformer.\n",
    "'''    \n",
    "    \n",
    "class NCATransform(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nca_params =  {'random_state':42, 'n_components':200 }):\n",
    "        self.nca_params = nca_params\n",
    "        self.nca = None\n",
    "\n",
    "    def fit(self, X, labels=None):      \n",
    "        print('NCA fit')\n",
    "        self.labels = labels\n",
    "\n",
    "        # Discretize labels for the need of NCA algorithm :\n",
    "        df_labels =  pd.DataFrame(data=labels)\n",
    "        self.labels_discrete = pd.cut(df_labels[0], bins=range(1,10), right=True).astype(str).tolist()\n",
    "        \n",
    "        self.nca = NeighborhoodComponentsAnalysis(random_state=self.nca_params['random_state'], n_components=self.nca_params['n_components'])\n",
    "        self.nca.fit(X, self.labels_discrete)\n",
    "            \n",
    "        return self\n",
    " \n",
    "    def transform(self, X):   \n",
    "        print('NCA transform')\n",
    "        return(self.nca.transform(X))    \n",
    "    \n",
    "'''\n",
    "This class wraps either NCA transformer, or PCA transformer (to be used with grid search)\n",
    "'''\n",
    "\n",
    "class DimensionalityReduction_Transform(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, reduction_params =  {'reduction_type': 'PCA', 'n_components':200 }):\n",
    "        self.reduction_params = reduction_params\n",
    "        self.model = None\n",
    "        #self.pca = None\n",
    "\n",
    "    def fit(self, X, labels=None):      \n",
    "        if (self.reduction_params['reduction_type'] == 'NCA'):        \n",
    "            print('NCA fit')\n",
    "            self.labels = labels\n",
    "\n",
    "            # Discretize labels for the need of NCA algorithm :\n",
    "            df_labels =  pd.DataFrame(data=labels)\n",
    "            self.labels_discrete = pd.cut(df_labels[0], bins=range(1,10), right=True).astype(str).tolist()\n",
    "\n",
    "            self.model = NeighborhoodComponentsAnalysis(random_state=42, n_components=self.reduction_params['n_components'])\n",
    "            self.model.fit(X, self.labels_discrete)\n",
    "\n",
    "            return self\n",
    " \n",
    "        if (self.reduction_params['reduction_type'] == 'PCA'):\n",
    "            self.model = decomposition.PCA(n_components=self.reduction_params['n_components'])\n",
    "            self.model.fit(X)\n",
    "            \n",
    "            return self\n",
    "            \n",
    "\n",
    "    def transform(self, X):   \n",
    "        if (self.reduction_params['reduction_type'] == 'NCA'):\n",
    "            print('NCA transform')\n",
    "        \n",
    "        if (self.reduction_params['reduction_type'] == 'PCA'):\n",
    "            print('PCA transform')\n",
    "        \n",
    "        return(self.model.transform(X))\n",
    "\n",
    "class PipelineFinal(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, params=None):\n",
    "        print('init')\n",
    "        self.params = params\n",
    "    \n",
    "    def fit(self, df, labels=None):   \n",
    "        print('fit')\n",
    "        return self\n",
    "    \n",
    "    def predict(self, df, y=None):\n",
    "        print('predict')\n",
    "        return([i for i in range(df.shape[0])])\n",
    "    \n",
    "    def fit_predict(self, df, labels=None):\n",
    "        self.fit(df)\n",
    "        return self.predict(df)\n",
    "    \n",
    "    def transform(self, df):\n",
    "        print('transform')\n",
    "        return(df)\n",
    "        #return(df.to_numpy())\n",
    "\n",
    "\n",
    "preparation_pipeline = Pipeline([\n",
    "    ('duplicates_remover', DuplicatesRemover()),\n",
    "    ('numerical_features_imputer', NumericalFeaturesImputer()),\n",
    "    ('categoricalfeatures_1hotencoder', CategoricalFeatures1HotEncoder()),\n",
    "    ('categoricalfeatures_merger_1hotencoder', CategoricalFeaturesMergerAnd1HotEncoder()),\n",
    "    ('categoricalfeatures_bow_1hotencoder', CategoricalFeaturesBowEncoder()),\n",
    "    ('features_droper', FeaturesDroper(features_todrop=['aspect_ratio', 'movie_imdb_link'])),\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "recommendation_pipeline_KNN = Pipeline([\n",
    "    ('features_droper', FeaturesDroper(features_todrop=['imdb_score'])),\n",
    "    ('standardscaler', preprocessing.StandardScaler()),\n",
    "    ('reduction', DimensionalityReduction_Transform(reduction_params = {'reduction_type' : 'PCA', 'n_components' : 200 })),\n",
    "    ('KNN', KNNTransform(knn_params =  {'n_neighbors':6, 'algorithm':'ball_tree', 'metric':'minkowski'})),\n",
    "])\n",
    "\n",
    "recommendation_pipeline_PCA_KNN = Pipeline([\n",
    "    ('features_droper', FeaturesDroper(features_todrop=['imdb_score'])),\n",
    "    ('standardscaler', preprocessing.StandardScaler()),\n",
    "    ('pca', decomposition.PCA(n_components=200)),\n",
    "    ('KNN', KNNTransform()),\n",
    "    #('pipeline_final', PipelineFinal()),\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "recommendation_pipeline_NCA_KNN = Pipeline([\n",
    "    ('features_droper', FeaturesDroper(features_todrop=['imdb_score'])),\n",
    "    ('standardscaler', preprocessing.StandardScaler()),\n",
    "    ('NCA', NCATransform(nca_params =  {'random_state':42, 'n_components':200 })),\n",
    "    ('KNN', KNNTransform(knn_params =  {'n_neighbors':6, 'algorithm':'ball_tree', 'metric':'minkowski'})),\n",
    "    #('pipeline_final', PipelineFinal()),\n",
    "])\n",
    "\n",
    "\n",
    "recommendation_pipeline_NMF = Pipeline([\n",
    "    ('features_droper', FeaturesDroper(features_todrop=['imdb_score'])),\n",
    "    ('standardscaler', preprocessing.StandardScaler()),\n",
    "    ('NMF', NMF(n_components=200, init='random', random_state=0)),\n",
    "    ('KNN', KNNTransform()),\n",
    "    #('pipeline_final', PipelineFinal()),\n",
    "\n",
    "])\n",
    "\n",
    "reducer_pipeline = Pipeline([\n",
    "    ('features_droper', FeaturesDroper(features_todrop=['imdb_score'])),\n",
    "    ('standardscaler', preprocessing.StandardScaler()),\n",
    "    ('NCA', NCATransform(nca_params =  {'random_state':42, 'n_components':200 })),\n",
    "])\n",
    "\n",
    "reducer_pipeline10 = Pipeline([\n",
    "    ('features_droper', FeaturesDroper(features_todrop=['imdb_score'])),\n",
    "    ('standardscaler', preprocessing.StandardScaler()),\n",
    "    ('NCA', NCATransform(nca_params =  {'random_state':42, 'n_components':10 })),\n",
    "])\n",
    "\n",
    "'''\n",
    "kmeans_transformer_pipeline = Pipeline([\n",
    "    ('kmeans', KMeans(n_clusters=10)),\n",
    "    #('pipeline_final', PipelineFinal()),\n",
    "\n",
    "])\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
