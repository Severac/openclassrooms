{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Openclassrooms PJ4 : transats dataset : modelisation notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import urllib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import qgrid\n",
    "\n",
    "import glob\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "SAMPLED_DATA = False  # If True : data is sampled (1000 instances only) for faster testing purposes\n",
    "\n",
    "DATA_PATH = os.path.join(\"datasets\", \"transats\")\n",
    "DATA_PATH = os.path.join(DATA_PATH, \"out\")\n",
    "\n",
    "DATA_PATH_FILE_INPUT = os.path.join(DATA_PATH, \"transats_metadata_transformed.csv\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [16,9] # Taille par défaut des figures de matplotlib\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#import common_functions\n",
    "\n",
    "####### Paramètres pour sauver et restaurer les modèles :\n",
    "import pickle\n",
    "####### Paramètres à changer par l'utilisateur selon son besoin :\n",
    "RECOMPUTE_GRIDSEARCH = False  # CAUTION : computation is several hours long\n",
    "SAVE_GRID_RESULTS = False # If True : grid results object will be saved to pickle files that have GRIDSEARCH_FILE_PREFIX\n",
    "LOAD_GRID_RESULTS = True # If True : grid results object will be loaded from pickle files that have GRIDSEARCH_FILE_PREFIX\n",
    "\n",
    "#GRIDSEARCH_CSV_FILE = 'grid_search_results.csv'\n",
    "\n",
    "GRIDSEARCH_FILE_PREFIX = 'grid_search_results_'\n",
    "\n",
    "EXECUTE_INTERMEDIATE_MODELS = True # If True: every intermediate model (which results are manually analyzed in the notebook) will be executed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qgrid_show(df):\n",
    "    display(qgrid.show_grid(df, grid_options={'forceFitColumns': False, 'defaultColumnWidth': 170}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_column_information(df, column_name):\n",
    "    column_type = df.dtypes[column_name]\n",
    "    print(f'Column {column_name}, type {column_type}\\n')\n",
    "    print('--------------------------')\n",
    "\n",
    "    print(df[[column_name]].groupby(column_name).size().sort_values(ascending=False))\n",
    "    print(df[column_name].unique())    \n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_percent_complete(df):\n",
    "    not_na = 100 - (df.isnull().sum() * 100 / len(df))\n",
    "    not_na_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                     'percent_complete': not_na}).sort_values(by='percent_complete', ascending=False)\n",
    "    display(not_na_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_features(df, all_features):\n",
    "    quantitative_features = []\n",
    "    qualitative_features = []\n",
    "    features_todrop = []\n",
    "\n",
    "    for feature_name in all_features:\n",
    "        if (df[feature_name].dtype == 'object'):\n",
    "            qualitative_features.append(feature_name)\n",
    "\n",
    "        else:\n",
    "            quantitative_features.append(feature_name)\n",
    "\n",
    "    print(f'Quantitative features : {quantitative_features} \\n')\n",
    "    print(f'Qualitative features : {qualitative_features} \\n')  \n",
    "    \n",
    "    return quantitative_features, qualitative_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_or_load_search_params(grid_search, save_file_suffix):\n",
    "    if (SAVE_GRID_RESULTS == True):\n",
    "        #df_grid_search_results = pd.concat([pd.DataFrame(grid_search.cv_results_[\"params\"]),pd.DataFrame(grid_search.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)\n",
    "        #df_grid_search_results.to_csv(GRIDSEARCH_CSV_FILE)\n",
    "\n",
    "        df_grid_search_results = pd.concat([pd.DataFrame(grid_search.cv_results_[\"params\"]),pd.DataFrame(grid_search.cv_results_[\"mean_test_score\"], columns=[\"mean_test_score\"])],axis=1)\n",
    "        df_grid_search_results = pd.concat([df_grid_search_results,pd.DataFrame(grid_search.cv_results_[\"std_test_score\"], columns=[\"std_test_score\"])],axis=1)\n",
    "        df_grid_search_results = pd.concat([df_grid_search_results,pd.DataFrame(grid_search.cv_results_[\"mean_fit_time\"], columns=[\"mean_fit_time\"])],axis=1)\n",
    "        df_grid_search_results = pd.concat([df_grid_search_results,pd.DataFrame(grid_search.cv_results_[\"mean_score_time\"], columns=[\"mean_score_time\"])],axis=1)\n",
    "        df_grid_search_results.to_csv(GRIDSEARCH_FILE_PREFIX + save_file_suffix + '.csv')\n",
    "\n",
    "        with open(GRIDSEARCH_FILE_PREFIX + save_file_suffix + '.pickle', 'wb') as f:\n",
    "            pickle.dump(grid_search, f, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "        return(grid_search, df_grid_search_results)\n",
    "\n",
    "    if (LOAD_GRID_RESULTS == True):\n",
    "        if ((SAVE_GRID_RESULTS == True) or (RECOMPUTE_GRIDSEARCH == True)):\n",
    "            print('Error : if want to load grid results, you should not have saved them or recomputed them before, or you will loose all your training data')\n",
    "\n",
    "        else:\n",
    "            with open(GRIDSEARCH_FILE_PREFIX + save_file_suffix + '.pickle', 'rb') as f:\n",
    "                grid_search = pickle.load(f)\n",
    "\n",
    "            df_grid_search_results = pd.concat([pd.DataFrame(grid_search.cv_results_[\"params\"]),pd.DataFrame(grid_search.cv_results_[\"mean_test_score\"], columns=[\"mean_test_score\"])],axis=1)\n",
    "            df_grid_search_results = pd.concat([df_grid_search_results,pd.DataFrame(grid_search.cv_results_[\"std_test_score\"], columns=[\"std_test_score\"])],axis=1)\n",
    "            df_grid_search_results = pd.concat([df_grid_search_results,pd.DataFrame(grid_search.cv_results_[\"mean_fit_time\"], columns=[\"mean_fit_time\"])],axis=1)\n",
    "            df_grid_search_results = pd.concat([df_grid_search_results,pd.DataFrame(grid_search.cv_results_[\"mean_score_time\"], columns=[\"mean_score_time\"])],axis=1)\n",
    "            \n",
    "            return(grid_search, df_grid_search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, Y_test):\n",
    "    Y_predict = model.predict(X_test)\n",
    "    mse = mean_squared_error(Y_test, Y_predict)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'RMSE : {rmse}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hhmm timed features formatted\n",
    "feats_hhmm = ['CRS_DEP_TIME',  'CRS_ARR_TIME']\n",
    "\n",
    "df = pd.read_csv(DATA_PATH_FILE_INPUT, sep=',', header=0, encoding='utf-8', low_memory=False, parse_dates=feats_hhmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5547828, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>percent_complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ORIGIN</td>\n",
       "      <td>ORIGIN</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CRS_DEP_TIME</td>\n",
       "      <td>CRS_DEP_TIME</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MONTH</td>\n",
       "      <td>MONTH</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_OF_MONTH</td>\n",
       "      <td>DAY_OF_MONTH</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_OF_WEEK</td>\n",
       "      <td>DAY_OF_WEEK</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>UNIQUE_CARRIER</td>\n",
       "      <td>UNIQUE_CARRIER</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DEST</td>\n",
       "      <td>DEST</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CRS_ARR_TIME</td>\n",
       "      <td>CRS_ARR_TIME</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DISTANCE</td>\n",
       "      <td>DISTANCE</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CRS_ELAPSED_TIME</td>\n",
       "      <td>CRS_ELAPSED_TIME</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ARR_DELAY</td>\n",
       "      <td>ARR_DELAY</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DEP_DELAY</td>\n",
       "      <td>DEP_DELAY</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TAXI_OUT</td>\n",
       "      <td>TAXI_OUT</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TAIL_NUM</td>\n",
       "      <td>TAIL_NUM</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       column_name  percent_complete\n",
       "ORIGIN                      ORIGIN             100.0\n",
       "CRS_DEP_TIME          CRS_DEP_TIME             100.0\n",
       "MONTH                        MONTH             100.0\n",
       "DAY_OF_MONTH          DAY_OF_MONTH             100.0\n",
       "DAY_OF_WEEK            DAY_OF_WEEK             100.0\n",
       "UNIQUE_CARRIER      UNIQUE_CARRIER             100.0\n",
       "DEST                          DEST             100.0\n",
       "CRS_ARR_TIME          CRS_ARR_TIME             100.0\n",
       "DISTANCE                  DISTANCE             100.0\n",
       "CRS_ELAPSED_TIME  CRS_ELAPSED_TIME             100.0\n",
       "ARR_DELAY                ARR_DELAY             100.0\n",
       "DEP_DELAY                DEP_DELAY             100.0\n",
       "TAXI_OUT                  TAXI_OUT             100.0\n",
       "TAIL_NUM                  TAIL_NUM             100.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_percent_complete(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor column_name in df.columns:\\n    print_column_information(df, column_name)\\n    \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for column_name in df.columns:\n",
    "    print_column_information(df, column_name)\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantitative features : ['MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'DISTANCE', 'CRS_ELAPSED_TIME', 'ARR_DELAY', 'DEP_DELAY', 'TAXI_OUT'] \n",
      "\n",
      "Qualitative features : ['ORIGIN', 'CRS_DEP_TIME', 'UNIQUE_CARRIER', 'DEST', 'CRS_ARR_TIME', 'TAIL_NUM'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Below are feature from dataset that we decided to keep: \n",
    "all_features = ['ORIGIN','CRS_DEP_TIME','MONTH','DAY_OF_MONTH','DAY_OF_WEEK','UNIQUE_CARRIER','DEST','CRS_ARR_TIME','DISTANCE','CRS_ELAPSED_TIME','ARR_DELAY','DEP_DELAY', 'TAXI_OUT', 'TAIL_NUM']\n",
    "\n",
    "model1_features = ['ORIGIN','CRS_DEP_TIME','MONTH','DAY_OF_MONTH','DAY_OF_WEEK','UNIQUE_CARRIER','DEST','CRS_ARR_TIME','DISTANCE','CRS_ELAPSED_TIME']\n",
    "model1_label = 'ARR_DELAY'\n",
    "\n",
    "quantitative_features = []\n",
    "qualitative_features = []\n",
    "features_todrop = []\n",
    "\n",
    "for feature_name in all_features:\n",
    "    if (df[feature_name].dtype == 'object'):\n",
    "        qualitative_features.append(feature_name)\n",
    "        \n",
    "    else:\n",
    "        quantitative_features.append(feature_name)\n",
    "\n",
    "print(f'Quantitative features : {quantitative_features} \\n')\n",
    "print(f'Qualitative features : {qualitative_features} \\n')        \n",
    "        \n",
    "\n",
    "#Commented out : no drop of features\n",
    "#for df_column in df.columns:\n",
    "#    if df_column not in all_features:\n",
    "#        features_todrop.append(df_column)\n",
    "#        \n",
    "#print(f'Features to drop : {features_todrop} \\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train set, test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.1, random_state=42)\n",
    "df_train = df_train.copy()\n",
    "df_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (SAMPLED_DATA == True):\n",
    "    df_train = df_train.sample(1200000).copy(deep=True)\n",
    "    df = df.loc[df_train.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>UNIQUE_CARRIER</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3352894</td>\n",
       "      <td>HPN</td>\n",
       "      <td>1537</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>B6</td>\n",
       "      <td>PBI</td>\n",
       "      <td>1829</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>N339JB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1268114</td>\n",
       "      <td>ORD</td>\n",
       "      <td>1220</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>UA</td>\n",
       "      <td>IAH</td>\n",
       "      <td>1509</td>\n",
       "      <td>925.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>N79402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2193866</td>\n",
       "      <td>SAN</td>\n",
       "      <td>1335</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>UA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1703</td>\n",
       "      <td>853.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>N17244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3874513</td>\n",
       "      <td>HDN</td>\n",
       "      <td>1620</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>OO</td>\n",
       "      <td>LAX</td>\n",
       "      <td>1738</td>\n",
       "      <td>763.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>N785SK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2213800</td>\n",
       "      <td>ORD</td>\n",
       "      <td>0730</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>UA</td>\n",
       "      <td>BOS</td>\n",
       "      <td>1044</td>\n",
       "      <td>867.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>N801UA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570006</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1355</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>WN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>1520</td>\n",
       "      <td>862.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>N455WN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2234489</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1725</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>VX</td>\n",
       "      <td>DAL</td>\n",
       "      <td>2250</td>\n",
       "      <td>1476.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>N625VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4926484</td>\n",
       "      <td>IAH</td>\n",
       "      <td>1015</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>UA</td>\n",
       "      <td>SJU</td>\n",
       "      <td>1630</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>N67812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4304572</td>\n",
       "      <td>IAH</td>\n",
       "      <td>1950</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>UA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>2115</td>\n",
       "      <td>224.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>N834UA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1692743</td>\n",
       "      <td>CHA</td>\n",
       "      <td>1621</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>OO</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1716</td>\n",
       "      <td>106.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>N427SW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4993045 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ORIGIN CRS_DEP_TIME  MONTH  DAY_OF_MONTH  DAY_OF_WEEK UNIQUE_CARRIER  \\\n",
       "3352894    HPN         1537      3            29            2             B6   \n",
       "1268114    ORD         1220      6            22            3             UA   \n",
       "2193866    SAN         1335     12            26            1             UA   \n",
       "3874513    HDN         1620      1            22            5             OO   \n",
       "2213800    ORD         0730     12            12            1             UA   \n",
       "...        ...          ...    ...           ...          ...            ...   \n",
       "1570006    DEN         1355      5             7            6             WN   \n",
       "2234489    SFO         1725     12            13            2             VX   \n",
       "4926484    IAH         1015     11            11            5             UA   \n",
       "4304572    IAH         1950     10             4            2             UA   \n",
       "1692743    CHA         1621      5            15            7             OO   \n",
       "\n",
       "        DEST CRS_ARR_TIME  DISTANCE  CRS_ELAPSED_TIME  ARR_DELAY  DEP_DELAY  \\\n",
       "3352894  PBI         1829    1056.0             172.0       10.0        1.0   \n",
       "1268114  IAH         1509     925.0             169.0      175.0      184.0   \n",
       "2193866  DEN         1703     853.0             148.0      -12.0        5.0   \n",
       "3874513  LAX         1738     763.0             138.0      -16.0      -10.0   \n",
       "2213800  BOS         1044     867.0             134.0       53.0       52.0   \n",
       "...      ...          ...       ...               ...        ...        ...   \n",
       "1570006  LAX         1520     862.0             145.0       13.0        5.0   \n",
       "2234489  DAL         2250    1476.0             205.0      -12.0       -5.0   \n",
       "4926484  SJU         1630    2007.0             255.0       -5.0        1.0   \n",
       "4304572  DFW         2115     224.0              85.0      -15.0       -2.0   \n",
       "1692743  ATL         1716     106.0              55.0       64.0       61.0   \n",
       "\n",
       "         TAXI_OUT TAIL_NUM  \n",
       "3352894       9.0   N339JB  \n",
       "1268114      23.0   N79402  \n",
       "2193866      20.0   N17244  \n",
       "3874513       9.0   N785SK  \n",
       "2213800      31.0   N801UA  \n",
       "...           ...      ...  \n",
       "1570006      16.0   N455WN  \n",
       "2234489      11.0   N625VA  \n",
       "4926484      20.0   N67812  \n",
       "4304572      18.0   N834UA  \n",
       "1692743      28.0   N427SW  \n",
       "\n",
       "[4993045 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.loc[df_train.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nColumnTransformer([\\n        ('standardscaler_specific', StandardScaler(), ['MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'DISTANCE', 'CRS_ELAPSED_TIME', 'ARR_DELAY', 'DEP_DELAY', 'TAXI_OUT'])\\n    ], remainder='passthrough')\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import statistics\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "'''\n",
    "Cette fonction fait un 1 hot encoding des features qui sont des catégories\n",
    "Old function not used anymore\n",
    "'''\n",
    "    \n",
    "def add_categorical_features_1hot(df, categorical_features_totransform):\n",
    "    #df.drop(labels=categorical_features_totransform, axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    #df_encoded = pd.get_dummies(df, columns=categorical_features_totransform, sparse=True)\n",
    "    \n",
    "    for feature_totransform in categorical_features_totransform:\n",
    "        print(f'Adding 1hot Feature : {feature_totransform}')\n",
    "        \n",
    "        print('First')\n",
    "        df_transformed = df[feature_totransform].str.get_dummies().add_prefix(feature_totransform +'_')   \n",
    "        \n",
    "        #df_new = pd.get_dummies(df, columns=['ORIGIN'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #df.drop(labels=feature_totransform, axis=1, inplace=True)\n",
    "        print('Second')\n",
    "        del df[feature_totransform]\n",
    "        \n",
    "        print('Third')\n",
    "        df = pd.concat([df, df_transformed], axis=1)\n",
    "        \n",
    "    return(df)\n",
    "\n",
    "\n",
    "class HHMM_to_Minutes(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_toconvert = ['CRS_DEP_TIME', 'CRS_ARR_TIME']):\n",
    "        self.features_toconvert = features_toconvert\n",
    "        return None\n",
    "    \n",
    "    def fit(self, df):      \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):       \n",
    "        for feature_toconvert in self.features_toconvert:\n",
    "            print(f'Converting feature {feature_toconvert}\\n')\n",
    "            #print('1\\n')\n",
    "            df_concat = pd.concat([df[feature_toconvert].str.slice(start=0,stop=2, step=1),df[feature_toconvert].str.slice(start=2,stop=4, step=1)], axis=1).astype(int).copy(deep=True)\n",
    "                    \n",
    "            #print('2\\n')\n",
    "            df[feature_toconvert] = (df_concat.iloc[:, [0]] * 60 + df_concat.iloc[:, [1]])[feature_toconvert]\n",
    "            \n",
    "            #print('3\\n')\n",
    "        \n",
    "        return(df)\n",
    "\n",
    "    \n",
    "'''\n",
    "class CategoricalFeatures1HotEncoder_old(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, categorical_features_totransform=['ORIGIN', 'UNIQUE_CARRIER', 'DEST']):\n",
    "        self.categorical_features_totransform = categorical_features_totransform\n",
    "    \n",
    "    def fit(self, df, labels=None):      \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        # /!\\ Array will not have the same shape if we fit an ensemble of samples that have less values than total dataset\n",
    "        df_encoded = pd.get_dummies(df, columns=self.categorical_features_totransform, sparse=True)  # Sparse allows to gain memory. But then, standardscale must be with_mean=False\n",
    "        #df_encoded = pd.get_dummies(df, columns=self.categorical_features_totransform, sparse=False)\n",
    "        print('type of df : ' + str(type(df_encoded)))\n",
    "        return(df_encoded)\n",
    "'''\n",
    "\n",
    "class CategoricalFeatures1HotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, categorical_features_totransform=['ORIGIN', 'UNIQUE_CARRIER', 'DEST']):\n",
    "        self.categorical_features_totransform = categorical_features_totransform\n",
    "        self.fitted = False\n",
    "        self.all_feature_values = {}\n",
    "        #self.df_encoded = None\n",
    "    \n",
    "    def fit(self, df, labels=None):      \n",
    "        print('Fit data')\n",
    "        for feature_name in self.categorical_features_totransform:\n",
    "            self.all_feature_values[feature_name] = feature_name + '_' + df[feature_name].unique()\n",
    "        \n",
    "        self.fitted = True\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        if (self.fitted == False):\n",
    "            self.fit(df)\n",
    "        \n",
    "        print('Transform data')\n",
    "        print('1hot encode categorical features...')\n",
    "        df_encoded = pd.get_dummies(df, columns=self.categorical_features_totransform, sparse=True)  # Sparse allows to gain memory. But then, standardscale must be with_mean=False\n",
    "        #df_encoded = pd.get_dummies(df, columns=self.categorical_features_totransform, sparse=False)\n",
    "        \n",
    "        # Get category values that were in fitted data, but that are not in data to transform \n",
    "        for feature_name, feature_values in self.all_feature_values.items():\n",
    "            diff_columns = list(set(feature_values) - set(df_encoded.columns.tolist()))\n",
    "            print(f'Column values that were in fitted data but not in current data: {diff_columns}')\n",
    "        \n",
    "            if (len(diff_columns) > 0):\n",
    "                print('Adding those column with 0 values to the DataFrme...')\n",
    "                # Create columns with 0 for the above categories, in order to preserve same matrix shape between train et test set\n",
    "                zeros_dict = dict.fromkeys(diff_columns, 0)\n",
    "                df_encoded.assign(**zeros_dict)\n",
    "        \n",
    "        print('type of df : ' + str(type(df_encoded)))\n",
    "        return(df_encoded)\n",
    "    \n",
    "    \n",
    "class FeaturesSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_toselect = None):  # If None : every column is kept, nothing is done\n",
    "        self.features_toselect = features_toselect\n",
    "    \n",
    "    def fit(self, df, labels=None):      \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):       \n",
    "        if (self.features_toselect != None):\n",
    "            filter_cols = [col for col in df if (col.startswith(tuple(self.features_toselect)))]\n",
    "            return(df[filter_cols])    \n",
    "\n",
    "        else:\n",
    "            return(df)\n",
    "\n",
    "'''\n",
    "In order have less features globally: we Keep only features_tofilter that represent percent_tokeep% of total values\n",
    "Features which values represent less than percent_tokeep% will be set \"OTHERS\" value instead of their real value\n",
    "'''\n",
    "\n",
    "class Filter_High_Percentile(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_tofilter = ['ORIGIN', 'DEST'], percent_tokeep = 80):\n",
    "        self.features_tofilter = features_tofilter\n",
    "        self.percent_tokeep = percent_tokeep\n",
    "        self.high_percentile = None\n",
    "        self.low_percentile = None\n",
    "    \n",
    "    def fit(self, df, labels=None): \n",
    "        print('Fit high percentile filter...')\n",
    "        for feature_tofilter in self.features_tofilter:\n",
    "            # Get feature_tofilter values that represent 80% of data\n",
    "            self.high_percentile = ((((df[[feature_tofilter]].groupby(feature_tofilter).size() / len(df)).sort_values(ascending=False)) * 100).cumsum() < self.percent_tokeep).where(lambda x : x == True).dropna().index.values.tolist()\n",
    "            self.low_percentile = ((((df[[feature_tofilter]].groupby(feature_tofilter).size() / len(df)).sort_values(ascending=False)) * 100).cumsum() >= self.percent_tokeep).where(lambda x : x == True).dropna().index.values.tolist()\n",
    "\n",
    "            total = len(df[feature_tofilter].unique())\n",
    "            high_percentile_sum = len(self.high_percentile)\n",
    "            low_percentile_sum = len(self.low_percentile)\n",
    "            high_low_sum = high_percentile_sum + low_percentile_sum\n",
    "\n",
    "            print(f'Total number of {feature_tofilter} values : {total}')\n",
    "            print(f'Number of {feature_tofilter} high percentile (> {self.percent_tokeep}%) values : {high_percentile_sum}')\n",
    "            print(f'Number of {feature_tofilter} low percentile values : {low_percentile_sum}')\n",
    "            print(f'Sum of high percentile + low percentile values : {high_low_sum}')\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):       \n",
    "        if (self.features_tofilter != None):\n",
    "            print('Apply high percentile filter...')\n",
    "            \n",
    "            for feature_tofilter in self.features_tofilter:\n",
    "                df.loc[df[feature_tofilter].isin(self.low_percentile), feature_tofilter] = 'OTHERS'   \n",
    "            \n",
    "            return(df)    \n",
    "\n",
    "        else:\n",
    "            return(df)\n",
    "        \n",
    "\n",
    "    \n",
    "class DenseToSparseConverter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):  # If None : every column is kept, nothing is done\n",
    "        return None\n",
    "    \n",
    "    def fit(self, matrix, labels=None):      \n",
    "        return self\n",
    "    \n",
    "    def transform(self, matrix):   \n",
    "        return(sparse.csr_matrix(matrix))\n",
    "\n",
    "        \n",
    "        \n",
    "'''\n",
    "conversion_pipeline = Pipeline([\n",
    "    ('data_converter', HHMM_to_Minutes()),\n",
    "    #('categoricalfeatures_1hotencoder', CategoricalFeatures1HotEncoder()),\n",
    "    #('standardscaler', preprocessing.StandardScaler()),\n",
    "])\n",
    "'''\n",
    "\n",
    "preparation_pipeline = Pipeline([\n",
    "    ('filter_highpercentile', Filter_High_Percentile()),\n",
    "    ('data_converter', HHMM_to_Minutes()),\n",
    "    ('categoricalfeatures_1hotencoder', CategoricalFeatures1HotEncoder()),\n",
    "    #('standardscaler', preprocessing.StandardScaler()),\n",
    "])\n",
    "\n",
    "\n",
    "# If matrix is sparse, with_mean=False must be passed to StandardScaler\n",
    "prediction_pipeline = Pipeline([\n",
    "    ('features_selector', FeaturesSelector(features_toselect=['ORIGIN','CRS_DEP_TIME','MONTH','DAY_OF_MONTH','DAY_OF_WEEK','UNIQUE_CARRIER','DEST','CRS_ARR_TIME','DISTANCE','CRS_ELAPSED_TIME'])),\n",
    "    ('standardscaler', ColumnTransformer([\n",
    "        ('standardscaler_specific', StandardScaler(), ['CRS_DEP_TIME','MONTH','DAY_OF_MONTH', 'DAY_OF_WEEK', 'CRS_ARR_TIME', 'DISTANCE', 'CRS_ELAPSED_TIME'])\n",
    "    ], remainder='passthrough', sparse_threshold=1)),\n",
    "    \n",
    "    ('dense_to_sparse_converter', DenseToSparseConverter()),\n",
    "    #('predictor', To_Complete(predictor_params =  {'n_neighbors':6, 'algorithm':'ball_tree', 'metric':'minkowski'})),\n",
    "])\n",
    "#copy=False passed to StandardScaler() allows to gain memory\n",
    "\n",
    "'''\n",
    "# Old code that used scikit learn OneHotEncoder (which does not keep DataFrame type) instead of Pandas\n",
    "preparation_pipeline2 = Pipeline([\n",
    "    ('data_converter', HHMM_to_Minutes()),\n",
    "    ('multiple_encoder', ColumnTransformer([\n",
    "        ('categoricalfeatures_1hotencoder', OneHotEncoder(), ['ORIGIN', 'UNIQUE_CARRIER', 'DEST'])\n",
    "    ], remainder='passthrough')),\n",
    "    #('standardscaler', preprocessing.StandardScaler()),\n",
    "])\n",
    "'''\n",
    "\n",
    "'''\n",
    "ColumnTransformer([\n",
    "        ('standardscaler_specific', StandardScaler(), ['MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'DISTANCE', 'CRS_ELAPSED_TIME', 'ARR_DELAY', 'DEP_DELAY', 'TAXI_OUT'])\n",
    "    ], remainder='passthrough')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit high percentile filter...\n",
      "Total number of ORIGIN values : 308\n",
      "Number of ORIGIN high percentile (> 80%) values : 45\n",
      "Number of ORIGIN low percentile values : 263\n",
      "Sum of high percentile + low percentile values : 308\n",
      "Total number of DEST values : 308\n",
      "Number of DEST high percentile (> 80%) values : 45\n",
      "Number of DEST low percentile values : 263\n",
      "Sum of high percentile + low percentile values : 308\n",
      "Apply high percentile filter...\n",
      "Converting feature CRS_DEP_TIME\n",
      "\n",
      "Converting feature CRS_ARR_TIME\n",
      "\n",
      "Fit data\n",
      "Transform data\n",
      "1hot encode categorical features...\n",
      "Column values that were in fitted data but not in current data: []\n",
      "Column values that were in fitted data but not in current data: []\n",
      "Column values that were in fitted data but not in current data: []\n",
      "type of df : <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df_train_transformed = preparation_pipeline.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4993045, 115)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4993045 entries, 3352894 to 1692743\n",
      "Columns: 115 entries, CRS_DEP_TIME to DEST_TPA\n",
      "dtypes: Sparse[uint8, 0](104), float64(5), int64(5), object(1)\n",
      "memory usage: 528.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train_transformed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npd.set_option('display.max_columns', 1000)\\ndf_train_transformed\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "df_train_transformed\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_transformed = prediction_pipeline.fit_transform(df_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4993045, 111)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(df_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "sparse.issparse(df_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame.sparse.from_spmatrix(df_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train_transformed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantitative features : ['MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'DISTANCE', 'CRS_ELAPSED_TIME', 'ARR_DELAY', 'DEP_DELAY', 'TAXI_OUT'] \n",
      "\n",
      "Qualitative features : ['ORIGIN', 'CRS_DEP_TIME', 'UNIQUE_CARRIER', 'DEST', 'CRS_ARR_TIME', 'TAIL_NUM'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "quantitative_features, qualitative_features = identify_features(df, all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply high percentile filter...\n",
      "Converting feature CRS_DEP_TIME\n",
      "\n",
      "Converting feature CRS_ARR_TIME\n",
      "\n",
      "Transform data\n",
      "1hot encode categorical features...\n",
      "Column values that were in fitted data but not in current data: []\n",
      "Column values that were in fitted data but not in current data: []\n",
      "Column values that were in fitted data but not in current data: []\n",
      "type of df : <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(554783, 111)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_transformed = preparation_pipeline.transform(df_test)\n",
    "df_test_transformed = prediction_pipeline.transform(df_test_transformed)\n",
    "df_test_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4993045, 111)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4993045,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[model1_label].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "if (EXECUTE_INTERMEDIATE_MODELS == True):\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(df_train_transformed, df_train[model1_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "if (EXECUTE_INTERMEDIATE_MODELS == True):\n",
    "    df_test_predictions = lin_reg.predict(df_test_transformed)\n",
    "    lin_mse = mean_squared_error(df_test[model1_label], df_test_predictions)\n",
    "    lin_rmse = np.sqrt(lin_mse)\n",
    "    lin_rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> 42.17  (42.16679389006135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (EXECUTE_INTERMEDIATE_MODELS == True):\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Comparison actual values / predict values')\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.xlabel(\"Actual\")\n",
    "    plt.scatter(df_test[model1_label], df_test_predictions, color='coral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "#scores = cross_validate(lin_reg, df_train_transformed, df_train[model1_label], scoring='neg_root_mean_squared_error', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNET regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "shuffled_split_train = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "eNet = ElasticNet()\n",
    "\n",
    "grid_search = GridSearchCV(eNet, param_grid = {\"max_iter\": [1, 5, 10],\n",
    "                      \"alpha\": [10, 100],\n",
    "                      \"l1_ratio\": np.arange(0.0, 1.0, 0.4)},cv=shuffled_split_train, scoring='neg_mean_squared_error', error_score=np.nan, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.model_selection import GridSearchCV\\n\\neNet = ElasticNet()\\n\\ngrid_search = GridSearchCV(eNet, param_grid = {\"max_iter\": [1, 5, 10],\\n                      \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\\n                      \"l1_ratio\": np.arange(0.0, 1.0, 0.1)},cv=shuffled_split_train, scoring=\\'neg_mean_squared_error\\', error_score=np.nan, verbose=2)\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "eNet = ElasticNet()\n",
    "\n",
    "grid_search = GridSearchCV(eNet, param_grid = {\"max_iter\": [1, 5, 10],\n",
    "                      \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                      \"l1_ratio\": np.arange(0.0, 1.0, 0.1)},cv=shuffled_split_train, scoring='neg_mean_squared_error', error_score=np.nan, verbose=2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (RECOMPUTE_GRIDSEARCH == True):\n",
    "    grid_search.fit(df_train_transformed, df_train[model1_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search, df_grid_search_results = save_or_load_search_params(grid_search, 'eNet_20200319')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1741.474494</td>\n",
       "      <td>11.553554</td>\n",
       "      <td>8.451748</td>\n",
       "      <td>0.021589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>-1741.606988</td>\n",
       "      <td>11.553293</td>\n",
       "      <td>19.897743</td>\n",
       "      <td>0.017433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-1741.606988</td>\n",
       "      <td>11.553293</td>\n",
       "      <td>11.345686</td>\n",
       "      <td>0.018125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1746.266246</td>\n",
       "      <td>11.555358</td>\n",
       "      <td>3.253050</td>\n",
       "      <td>0.018168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-1746.268263</td>\n",
       "      <td>11.555355</td>\n",
       "      <td>10.535562</td>\n",
       "      <td>0.017086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>-1746.268263</td>\n",
       "      <td>11.555355</td>\n",
       "      <td>19.410727</td>\n",
       "      <td>0.016518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>-1746.670284</td>\n",
       "      <td>11.555964</td>\n",
       "      <td>3.243109</td>\n",
       "      <td>0.018928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>-1746.670284</td>\n",
       "      <td>11.555964</td>\n",
       "      <td>3.316887</td>\n",
       "      <td>0.018247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1746.670284</td>\n",
       "      <td>11.555964</td>\n",
       "      <td>2.742426</td>\n",
       "      <td>0.017680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1746.913947</td>\n",
       "      <td>11.555634</td>\n",
       "      <td>2.613709</td>\n",
       "      <td>0.016329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>-1746.913947</td>\n",
       "      <td>11.555634</td>\n",
       "      <td>2.716009</td>\n",
       "      <td>0.018829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>-1746.913947</td>\n",
       "      <td>11.555634</td>\n",
       "      <td>2.635636</td>\n",
       "      <td>0.016907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1746.913947</td>\n",
       "      <td>11.555634</td>\n",
       "      <td>2.718752</td>\n",
       "      <td>0.017407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>-1746.913947</td>\n",
       "      <td>11.555634</td>\n",
       "      <td>2.728197</td>\n",
       "      <td>0.017755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>-1746.913947</td>\n",
       "      <td>11.555634</td>\n",
       "      <td>2.657087</td>\n",
       "      <td>0.016606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1746.913947</td>\n",
       "      <td>11.555634</td>\n",
       "      <td>2.710231</td>\n",
       "      <td>0.016306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>-1746.913947</td>\n",
       "      <td>11.555634</td>\n",
       "      <td>2.742407</td>\n",
       "      <td>0.016709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>-1746.913947</td>\n",
       "      <td>11.555634</td>\n",
       "      <td>2.641766</td>\n",
       "      <td>0.016149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha  l1_ratio  max_iter  mean_test_score  std_test_score  mean_fit_time  \\\n",
       "0      10       0.0         1     -1741.474494       11.553554       8.451748   \n",
       "2      10       0.0        10     -1741.606988       11.553293      19.897743   \n",
       "1      10       0.0         5     -1741.606988       11.553293      11.345686   \n",
       "9     100       0.0         1     -1746.266246       11.555358       3.253050   \n",
       "10    100       0.0         5     -1746.268263       11.555355      10.535562   \n",
       "11    100       0.0        10     -1746.268263       11.555355      19.410727   \n",
       "4      10       0.4         5     -1746.670284       11.555964       3.243109   \n",
       "5      10       0.4        10     -1746.670284       11.555964       3.316887   \n",
       "3      10       0.4         1     -1746.670284       11.555964       2.742426   \n",
       "6      10       0.8         1     -1746.913947       11.555634       2.613709   \n",
       "7      10       0.8         5     -1746.913947       11.555634       2.716009   \n",
       "8      10       0.8        10     -1746.913947       11.555634       2.635636   \n",
       "12    100       0.4         1     -1746.913947       11.555634       2.718752   \n",
       "13    100       0.4         5     -1746.913947       11.555634       2.728197   \n",
       "14    100       0.4        10     -1746.913947       11.555634       2.657087   \n",
       "15    100       0.8         1     -1746.913947       11.555634       2.710231   \n",
       "16    100       0.8         5     -1746.913947       11.555634       2.742407   \n",
       "17    100       0.8        10     -1746.913947       11.555634       2.641766   \n",
       "\n",
       "    mean_score_time  \n",
       "0          0.021589  \n",
       "2          0.017433  \n",
       "1          0.018125  \n",
       "9          0.018168  \n",
       "10         0.017086  \n",
       "11         0.016518  \n",
       "4          0.018928  \n",
       "5          0.018247  \n",
       "3          0.017680  \n",
       "6          0.016329  \n",
       "7          0.018829  \n",
       "8          0.016907  \n",
       "12         0.017407  \n",
       "13         0.017755  \n",
       "14         0.016606  \n",
       "15         0.016306  \n",
       "16         0.016709  \n",
       "17         0.016149  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grid_search_results.sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.73092378560532"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(1741.47)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> 41.73092378560532"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=10, copy_X=True, fit_intercept=True, l1_ratio=0.0, max_iter=1,\n",
       "           normalize=False, positive=False, precompute=False, random_state=None,\n",
       "           selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (EXECUTE_INTERMEDIATE_MODELS == True):\n",
    "    if (RECOMPUTE_GRIDSEARCH == True):\n",
    "        df_test_predictions = grid_search.best_estimator_.predict(df_test_transformed)\n",
    "        mse = mean_squared_error(df_test[model1_label], df_test_predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'brier_score_loss',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "sorted(metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random value between min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1191.3536427817378"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_random = np.random.randint(df['ARR_DELAY'].min(), df['ARR_DELAY'].max(), df_test['ARR_DELAY'].shape)\n",
    "naive_mse = mean_squared_error(df_test[model1_label], y_pred_random)\n",
    "naive_rmse = np.sqrt(naive_mse)\n",
    "naive_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Always mean naive approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 42.63\n"
     ]
    }
   ],
   "source": [
    "from sklearn import dummy\n",
    "\n",
    "dum = dummy.DummyRegressor(strategy='mean')\n",
    "\n",
    "# Entraînement\n",
    "dum.fit(df_train_transformed, df_train[model1_label])\n",
    "\n",
    "# Prédiction sur le jeu de test\n",
    "y_pred_dum = dum.predict(df_test_transformed)\n",
    "\n",
    "# Evaluate\n",
    "print(\"RMSE : {:.2f}\".format(np.sqrt(mean_squared_error(df_test[model1_label], y_pred_dum)) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f6f5c5cd390>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df_test[model1_label], y_pred_dum, color='coral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3746453    62.0\n",
       "1300593   -22.0\n",
       "4707023   -11.0\n",
       "1752505   -38.0\n",
       "2152691    -1.0\n",
       "           ... \n",
       "2882585    -8.0\n",
       "298857     -7.0\n",
       "4799315     5.0\n",
       "5392696     7.0\n",
       "236730     -4.0\n",
       "Name: ARR_DELAY, Length: 554783, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[model1_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.45500812, 3.45500812, 3.45500812, ..., 3.45500812, 3.45500812,\n",
       "       3.45500812])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_dum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.15843930273253"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ARR_DELAY'].abs().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> With all samples and 70% most represented features, without StandardScale :  on test set : lin_rmse = 42.17  \n",
    "=> With all samples and 80% most represented features, without StandardScale :  on test set : lin_rmse = 42.16  \n",
    "=> With all samples and 80% most represented features, with StandardScale :  on test set : lin_rmse = 42.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "if (EXECUTE_INTERMEDIATE_MODELS == True):\n",
    "    random_reg = RandomForestRegressor(n_estimators=10, max_depth=2, random_state=42)\n",
    "    random_reg.fit(df_train_transformed, df_train[model1_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (EXECUTE_INTERMEDIATE_MODELS == True):\n",
    "    df_test_predictions = random_reg.predict(df_test_transformed)\n",
    "    mse = mean_squared_error(df_test[model1_label], df_test_predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> 42.373691516139964"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.svm import SVR\\n\\nsvm_reg = SVR(kernel=\"rbf\", verbose=True)\\nsvm_reg.fit(df_train_transformed, df_train[model1_label])\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg = SVR(kernel=\"rbf\", verbose=True)\n",
    "svm_reg.fit(df_train_transformed, df_train[model1_label])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "svm_reg = LinearSVR(random_state=42, tol=1e-5, verbose=True)\n",
    "\n",
    "if (EXECUTE_INTERMEDIATE_MODELS == True):\n",
    "    svm_reg.fit(df_train_transformed, df_train[model1_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (EXECUTE_INTERMEDIATE_MODELS == True):\n",
    "    evaluate_model(svm_reg, df_test_transformed, df_test[model1_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> RMSE : 43.45607643335432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_SVR = GridSearchCV(svm_reg, param_grid = {\"epsilon\": [0, 0.5],\n",
    "                              \"C\": [1, 5, 10, 100, 1000],\n",
    "                              \"loss\": ['epsilon_insensitive', 'squared_epsilon_insensitive'],},cv=shuffled_split_train, scoring='neg_mean_squared_error', error_score=np.nan, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (EXECUTE_INTERMEDIATE_MODELS == True):\n",
    "    if (RECOMPUTE_GRIDSEARCH == True):\n",
    "        grid_search_SVR.fit(df_train_transformed, df_train[model1_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Warning at execution : /home/francois/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
    "  \"the number of iterations.\", ConvergenceWarning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_SVR, df_grid_search_results = save_or_load_search_params(grid_search_SVR, 'LinearSVR_20200319')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>-1709.197402</td>\n",
       "      <td>11.709555</td>\n",
       "      <td>1122.307692</td>\n",
       "      <td>0.036019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>-1709.244359</td>\n",
       "      <td>11.702259</td>\n",
       "      <td>1070.694849</td>\n",
       "      <td>0.021828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>-1709.572593</td>\n",
       "      <td>11.470917</td>\n",
       "      <td>1055.509449</td>\n",
       "      <td>0.022631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>-1709.621480</td>\n",
       "      <td>11.463629</td>\n",
       "      <td>1050.236998</td>\n",
       "      <td>0.023208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>-1715.010698</td>\n",
       "      <td>12.839219</td>\n",
       "      <td>1056.915728</td>\n",
       "      <td>0.022069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>-1715.049010</td>\n",
       "      <td>12.840819</td>\n",
       "      <td>1047.752463</td>\n",
       "      <td>0.023156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "      <td>-1814.960137</td>\n",
       "      <td>12.048914</td>\n",
       "      <td>247.978703</td>\n",
       "      <td>0.022987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "      <td>-1815.410220</td>\n",
       "      <td>11.888318</td>\n",
       "      <td>157.402844</td>\n",
       "      <td>0.022296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "      <td>-1815.462776</td>\n",
       "      <td>11.828610</td>\n",
       "      <td>42.894303</td>\n",
       "      <td>0.022394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "      <td>-1815.600737</td>\n",
       "      <td>11.898766</td>\n",
       "      <td>43.644705</td>\n",
       "      <td>0.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "      <td>-1815.607988</td>\n",
       "      <td>12.038682</td>\n",
       "      <td>153.694325</td>\n",
       "      <td>0.021426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "      <td>-1815.636601</td>\n",
       "      <td>12.021697</td>\n",
       "      <td>261.497981</td>\n",
       "      <td>0.021107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "      <td>-1818.004440</td>\n",
       "      <td>11.994120</td>\n",
       "      <td>835.328805</td>\n",
       "      <td>0.021213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "      <td>-1820.272458</td>\n",
       "      <td>13.721677</td>\n",
       "      <td>824.308765</td>\n",
       "      <td>0.022514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "      <td>-1856.537673</td>\n",
       "      <td>64.989712</td>\n",
       "      <td>1042.778224</td>\n",
       "      <td>0.025488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "      <td>-1900.136722</td>\n",
       "      <td>31.031540</td>\n",
       "      <td>1054.354182</td>\n",
       "      <td>0.033746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>-2137.841281</td>\n",
       "      <td>199.219969</td>\n",
       "      <td>1082.613571</td>\n",
       "      <td>0.021808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>-2147.444703</td>\n",
       "      <td>203.239140</td>\n",
       "      <td>1062.552231</td>\n",
       "      <td>0.021881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>-2714.239875</td>\n",
       "      <td>333.853246</td>\n",
       "      <td>1062.645818</td>\n",
       "      <td>0.024787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>-2739.302029</td>\n",
       "      <td>341.016237</td>\n",
       "      <td>1099.370119</td>\n",
       "      <td>0.025768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C  epsilon                         loss  mean_test_score  \\\n",
       "1      1      0.0  squared_epsilon_insensitive     -1709.197402   \n",
       "3      1      0.5  squared_epsilon_insensitive     -1709.244359   \n",
       "5      5      0.0  squared_epsilon_insensitive     -1709.572593   \n",
       "7      5      0.5  squared_epsilon_insensitive     -1709.621480   \n",
       "9     10      0.0  squared_epsilon_insensitive     -1715.010698   \n",
       "11    10      0.5  squared_epsilon_insensitive     -1715.049010   \n",
       "8     10      0.0          epsilon_insensitive     -1814.960137   \n",
       "6      5      0.5          epsilon_insensitive     -1815.410220   \n",
       "2      1      0.5          epsilon_insensitive     -1815.462776   \n",
       "0      1      0.0          epsilon_insensitive     -1815.600737   \n",
       "4      5      0.0          epsilon_insensitive     -1815.607988   \n",
       "10    10      0.5          epsilon_insensitive     -1815.636601   \n",
       "14   100      0.5          epsilon_insensitive     -1818.004440   \n",
       "12   100      0.0          epsilon_insensitive     -1820.272458   \n",
       "18  1000      0.5          epsilon_insensitive     -1856.537673   \n",
       "16  1000      0.0          epsilon_insensitive     -1900.136722   \n",
       "15   100      0.5  squared_epsilon_insensitive     -2137.841281   \n",
       "13   100      0.0  squared_epsilon_insensitive     -2147.444703   \n",
       "19  1000      0.5  squared_epsilon_insensitive     -2714.239875   \n",
       "17  1000      0.0  squared_epsilon_insensitive     -2739.302029   \n",
       "\n",
       "    std_test_score  mean_fit_time  mean_score_time  \n",
       "1        11.709555    1122.307692         0.036019  \n",
       "3        11.702259    1070.694849         0.021828  \n",
       "5        11.470917    1055.509449         0.022631  \n",
       "7        11.463629    1050.236998         0.023208  \n",
       "9        12.839219    1056.915728         0.022069  \n",
       "11       12.840819    1047.752463         0.023156  \n",
       "8        12.048914     247.978703         0.022987  \n",
       "6        11.888318     157.402844         0.022296  \n",
       "2        11.828610      42.894303         0.022394  \n",
       "0        11.898766      43.644705         0.022400  \n",
       "4        12.038682     153.694325         0.021426  \n",
       "10       12.021697     261.497981         0.021107  \n",
       "14       11.994120     835.328805         0.021213  \n",
       "12       13.721677     824.308765         0.022514  \n",
       "18       64.989712    1042.778224         0.025488  \n",
       "16       31.031540    1054.354182         0.033746  \n",
       "15      199.219969    1082.613571         0.021808  \n",
       "13      203.239140    1062.552231         0.021881  \n",
       "19      333.853246    1062.645818         0.024787  \n",
       "17      341.016237    1099.370119         0.025768  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grid_search_results.sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.34244068750659"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(1709.197402)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(C=1, dual=True, epsilon=0, fit_intercept=True, intercept_scaling=1.0,\n",
       "          loss='squared_epsilon_insensitive', max_iter=1000, random_state=0,\n",
       "          tol=1e-05, verbose=True)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_SVR.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 42.166794620090805\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(grid_search_SVR.best_estimator_, df_test_transformed, df_test[model1_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Best estimator :  inearSVR(C=1, dual=True, epsilon=0, fit_intercept=True, intercept_scaling=1.0,\n",
    "          loss='squared_epsilon_insensitive', max_iter=1000, random_state=0,\n",
    "          tol=1e-05, verbose=True)  \n",
    "\n",
    "=> RMSE : 42.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial features + linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4993045x111 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 49930450 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = ColumnTransformer([\n",
    "                                ('poly', PolynomialFeatures(degree=2), [0, 1, 2, 3, 4, 5, 6])     \n",
    "                                ], remainder='passthrough', sparse_threshold=1)\n",
    "\n",
    "#poly.fit(df_train_transformed, df_train[model1_label])\n",
    "#poly.fit(df_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (EXECUTE_INTERMEDIATE_MODELS == True):\n",
    "    df_train_transformed = poly.fit_transform(df_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (EXECUTE_INTERMEDIATE_MODELS == True):\n",
    "    df_test_transformed = poly.transform(df_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4993045, 140)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if (EXECUTE_INTERMEDIATE_MODELS == True):\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(df_train_transformed, df_train[model1_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 42.11719088178065\n"
     ]
    }
   ],
   "source": [
    "if (EXECUTE_INTERMEDIATE_MODELS == True):\n",
    "    evaluate_model(lin_reg, df_test_transformed, df_test[model1_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> 42.11719088178065"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial features + random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "if (EXECUTE_INTERMEDIATE_MODELS == True):\n",
    "    random_reg = RandomForestRegressor(n_estimators=10, max_depth=2, random_state=42)\n",
    "    random_reg.fit(df_train_transformed, df_train[model1_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 42.29092202765607\n"
     ]
    }
   ],
   "source": [
    "if (EXECUTE_INTERMEDIATE_MODELS == True):\n",
    "    df_test_predictions = random_reg.predict(df_test_transformed)\n",
    "    evaluate_model(random_reg, df_test_transformed, df_test[model1_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Too slow\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "if (EXECUTE_INTERMEDIATE_MODELS == True):\n",
    "    random_reg = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42)\n",
    "    random_reg.fit(df_train_transformed, df_train[model1_label])\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "if (EXECUTE_INTERMEDIATE_MODELS == True):\n",
    "    df_test_predictions = random_reg.predict(df_test_transformed)\n",
    "    evaluate_model(random_reg, df_test_transformed, df_test[model1_label])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (139805260,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-a28763c4f230>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                 ], remainder='passthrough', sparse_threshold=1)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpoly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel1_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;31m# we use fit_transform to make sure to set sparse_output_ (for which we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;31m# need the transformed data) to have consistent output type in predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     message=self._log_message(name, idx, len(transformers)))\n\u001b[1;32m    419\u001b[0m                 for idx, (name, trans, column, weight) in enumerate(\n\u001b[0;32m--> 420\u001b[0;31m                         self._iter(fitted=fitted, replace_strings=True), 1))\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"Expected 2D array, got 1D array instead\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1519\u001b[0m                                                     \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m                                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteraction_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m                                                     deg)\n\u001b[0m\u001b[1;32m   1522\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mXp_next\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/preprocessing/_csr_polynomial_expansion.pyx\u001b[0m in \u001b[0;36msklearn.preprocessing._csr_polynomial_expansion._csr_polynomial_expansion\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate array with shape (139805260,) and data type float64"
     ]
    }
   ],
   "source": [
    "poly = ColumnTransformer([\n",
    "                                ('poly', PolynomialFeatures(degree=2), [0, 1, 2, 3, 4, 5, 6])     \n",
    "                                ], remainder='passthrough', sparse_threshold=1)\n",
    "\n",
    "poly.fit(df_train_transformed, df_train[model1_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "polynomial_reg = Pipeline([('poly_columntransformer', ColumnTransformer([\n",
    "                                ('poly', PolynomialFeatures(degree=3), ['CRS_DEP_TIME','MONTH','DAY_OF_MONTH', 'DAY_OF_WEEK', 'CRS_ARR_TIME', 'DISTANCE', 'CRS_ELAPSED_TIME'])     \n",
    "                                ], remainder='passthrough', sparse_threshold=1)),\n",
    "                          ('linear', LinearRegression(fit_intercept=False))])\n",
    "\n",
    "polynomial_reg.fit(df_train_transformed, df_train[model1_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "polynomial_reg = Pipeline([('poly', PolynomialFeatures(degree=3)),\n",
    "                          ('linear', LinearRegression(fit_intercept=False))])\n",
    "\n",
    "polynomial_reg.fit(df_train_transformed, df_train[model1_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(polynomial_reg, df_test_transformed, df_test[model1_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annex : unused code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn import linear_model\\n\\nregressor = linear_model.SGDRegressor(max_iter=1000, tol=1e-3, penalty=None, eta0=0.1)\\nregressor.fit(df_transformed, df_train[model1_label])\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn import linear_model\n",
    "\n",
    "regressor = linear_model.SGDRegressor(max_iter=1000, tol=1e-3, penalty=None, eta0=0.1)\n",
    "regressor.fit(df_transformed, df_train[model1_label])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.svm import SVR\\n\\nsvm_reg = SVR(kernel=\"linear\")\\nsvm_reg.fit(df_train_transformed, df_train[model1_label])\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg = SVR(kernel=\"linear\")\n",
    "svm_reg.fit(df_train_transformed, df_train[model1_label])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_test_predictions = svm_reg.predict(df_test_transformed)\\nsvm_mse = mean_squared_error(df_test[model1_label], df_test_predictions)\\nsvm_rmse = np.sqrt(svm_mse)\\nsvm_rmse\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_test_predictions = svm_reg.predict(df_test_transformed)\n",
    "svm_mse = mean_squared_error(df_test[model1_label], df_test_predictions)\n",
    "svm_rmse = np.sqrt(svm_mse)\n",
    "svm_rmse\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.model_selection import StratifiedShuffleSplit\\n\\nstratified_split_train = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "stratified_split_train = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
